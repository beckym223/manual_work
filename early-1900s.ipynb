{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4141397846.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    words =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = \n",
    "\n",
    "counter=Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(counter.items())\n",
    "d = {}\n",
    "for word in df.loc[df[1]>1,0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m d2 \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 20\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mword\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m         d2[word] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words2 = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    page = int(pagetxt[:-4])\n",
    "    year = int(year)\n",
    "    if year<1904 and year>1900 or (year==1900 and page>13):\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words2.extend([w.lower() for w in words])\n",
    "counter2=Counter(all_words2)\n",
    "df2 = pd.DataFrame(counter2.items())\n",
    "d2 = {}\n",
    "for word in df2[0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d2[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(\"[A-Za-z]*ll[A-Za-z]*|[A-Za-z]*cl[A-Za-z]*\",text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>clergylnen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>otlle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>lllln</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>preparillg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>sllrely</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>college</td>\n",
       "      <td>37</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>38</td>\n",
       "      <td>0.011370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>alld</td>\n",
       "      <td>47</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>129</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2\n",
       "1206  clergylnen    1  0.000299\n",
       "1598       otlle    1  0.000299\n",
       "1599       lllln    1  0.000299\n",
       "1600  preparillg    1  0.000299\n",
       "1601     sllrely    1  0.000299\n",
       "...          ...  ...       ...\n",
       "1074     college   37  0.011071\n",
       "7           well   38  0.011370\n",
       "151         alld   47  0.014063\n",
       "6           will   57  0.017056\n",
       "0            all  129  0.038600\n",
       "\n",
       "[2413 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = pd.DataFrame(all_counter.items())\n",
    "ac[2] = ac[1].apply(lambda x: x/sum(ac[1]))\n",
    "\n",
    "sc = pd.DataFrame(some_counter.items())\n",
    "\n",
    "sc[2] = sc[1].apply(lambda x: x/sum(sc[1]))\n",
    "# sc.sort_values(1)\n",
    "sc.sort_values(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [('n', 'll'),\n",
    "         ('u', 'll'),\n",
    "         ('h', 'll'),\n",
    "         ('n', 'il'),\n",
    "         ('u','il'),\n",
    "         ('h', 'il'),\n",
    "         ('m', 'nl'),\n",
    "         ('m', 'ln'),\n",
    "         ('d', 'cl'),\n",
    "         ('w', 'vv'),\n",
    "         ('m','lll'),\n",
    "         ('n','rl'),\n",
    "         ('u','tl'),\n",
    "         ('n','tl'),\n",
    "         ]\n",
    "         \n",
    "\n",
    "pattern = \"|\".join([f\"[A-Za-z]*{char[1]}[A-Za-z]*\" for char in set(chars) ])\n",
    "\n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(pattern,text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n",
    "\n",
    "#df = new_melt.merge(ac,left_on='new_word',right_on = 'corpus_word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>old_count</th>\n",
       "      <th>full_transformation</th>\n",
       "      <th>end_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>differellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sellse</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dyllamic</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dissellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>collsistently</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75233</th>\n",
       "      <td>acllievelllellts</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>achievements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76742</th>\n",
       "      <td>colilnlissioll</td>\n",
       "      <td>1</td>\n",
       "      <td>_il-&gt;n_ln-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100186</th>\n",
       "      <td>ullclerstalldillg</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n_cl-&gt;d</td>\n",
       "      <td>understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77036</th>\n",
       "      <td>lltllllall</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168328</th>\n",
       "      <td>ftltlclalnelltal</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_cl-&gt;d_ln-&gt;m_ll-&gt;n_tl-&gt;n</td>\n",
       "      <td>fundamental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  og_word old_count             full_transformation  \\\n",
       "3              differellt         1                          _ll->n   \n",
       "4                  sellse         1                          _ll->n   \n",
       "9                dyllamic         1                          _ll->n   \n",
       "15               dissellt         1                          _ll->n   \n",
       "16          collsistently         1                          _ll->n   \n",
       "...                   ...       ...                             ...   \n",
       "75233    acllievelllellts         1        _ll->h_ll->n_ll->n_nl->m   \n",
       "76742      colilnlissioll         1        _il->n_ln->m_ll->n_nl->m   \n",
       "100186  ullclerstalldillg         1        _ll->n_ll->n_ll->n_cl->d   \n",
       "77036          lltllllall         1  _tl->u_ll->h_ll->n_ll->n_nl->m   \n",
       "168328   ftltlclalnelltal         1  _tl->u_cl->d_ln->m_ll->n_tl->n   \n",
       "\n",
       "             end_word  \n",
       "3           different  \n",
       "4               sense  \n",
       "9             dynamic  \n",
       "15            dissent  \n",
       "16       consistently  \n",
       "...               ...  \n",
       "75233    achievements  \n",
       "76742      commission  \n",
       "100186  understanding  \n",
       "77036           human  \n",
       "168328    fundamental  \n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>transformations</th>\n",
       "      <th>duplicate_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>lllally</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>nlany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>goverlllnellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>governlnent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ecollolllics</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>econonlics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>developlllellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>developnlent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>departlllellts</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>departnlents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78140</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>hmmderless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78180</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_rl-&gt;n_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78386</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_rl-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78797</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_rl-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88577</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_ll-&gt;n_rl-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               og_word                 transformations  duplicate_of\n",
       "460            lllally                    _ll->n_ll->n         nlany\n",
       "466      goverlllnellt                    _ll->n_ll->n   governlnent\n",
       "570       ecollolllics                    _ll->n_ll->n    econonlics\n",
       "575     developlllellt                    _ll->n_ll->n  developnlent\n",
       "729     departlllellts                    _ll->n_ll->n  departnlents\n",
       "...                ...                             ...           ...\n",
       "78140  llllllllderless  _ll->h_ll->n_nl->m_ll->n_nl->m    hmmderless\n",
       "78180  llllllllderless  _rl->n_ll->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78386  llllllllderless  _ll->n_rl->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78797  llllllllderless  _ll->n_nl->m_rl->n_ll->n_nl->m    mmlldeness\n",
       "88577  llllllllderless  _ll->n_nl->m_ll->n_rl->n_nl->m    mmlldeness\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_reached_elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n",
      "hi-(0)->man|hi-(0)->man\n",
      "hi-(0)->man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Transformation('hi','man','0'), Transformation('hi','man','0')]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Type\n",
    "from collections.abc import MutableSequence\n",
    "import numpy as np\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FinishedState():\n",
    "#     all_intermediate: dict[str,str] = {}\n",
    "#     def __init__(self, start,end, transformations,intermediates):\n",
    "#         self.og:str = start\n",
    "#         self.end:str = end\n",
    "#         self.transformations: TransList = transformations\n",
    "\n",
    "#     def update_intermediate(self):\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable,Set,Dict\n",
    "class Transformation(object):\n",
    "    NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def is_null(self)->bool:\n",
    "        return self.old==self.new\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "    \n",
    "    def check_transform(self,s:str)->str|None:\n",
    "        i = self.start_idx\n",
    "        if not self.old in s[i:]:\n",
    "            return None\n",
    "        return self.transform(s)\n",
    "\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return Transformation(self.old,self.new,self.start_idx)\n",
    "    \n",
    "    def __repr__(self)->str:\n",
    "        return f\"Transformation('{self.old}','{self.new}','{self.start_idx}')\"\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return f\"{self.old}-({self.start_idx})->{self.new}\"\n",
    "\n",
    "class TransList(list[Transformation]):\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return \"|\".join([str(s) for s in self])\n",
    "NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "\n",
    "class Transformation(object):\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "class Transformation(object):\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "\n",
    "class StrNode(object):\n",
    "    known_words:Set[str] = set()\n",
    "    known_transformations: dict[str,str] = {} #will be the og words that got transformed\n",
    "    @classmethod\n",
    "    def update_known_words(cls,words: Iterable[str]):\n",
    "        cls.known_words.update(words)\n",
    "\n",
    "    @classmethod\n",
    "    def from_parent(cls,parent,transformation:Transformation,check_if_finished=True): #type:ignore\n",
    "        parent_s = parent.current\n",
    "        new_str = transformation.transform(parent_s)\n",
    "        finished=False\n",
    "        if check_if_finished:\n",
    "            finished = new_str in StrNode.known_words\n",
    "        return StrNode(parent.og,new_str,parent,transformation,finished)\n",
    "\n",
    "\n",
    "    def __init__(self,start_str:str,current:str|None=None, parent= None,parent_trans:Transformation|None = None,finished=False):\n",
    "        self.og = start_str\n",
    "        self.children:list[StrNode]=[]\n",
    "        self.parent:Optional[StrNode] = parent\n",
    "        self.parent_trans:Transformation=parent_trans or Transformation(\"\",\"\")\n",
    "        self.current:str = current if current is not None else start_str\n",
    "        self.leaf:bool = finished\n",
    "        self.next:Optional[StrNode] = None\n",
    "\n",
    "    def is_root(self)->bool:\n",
    "        return self.parent is None\n",
    "\n",
    "\n",
    "    def make_children(self,t:Transformation)->list[StrNode]|StrNode #type:ignore\n",
    "        current = self.current\n",
    "        child_list:list[StrNode] = []\n",
    "\n",
    "        for i in range(len(current)):\n",
    "            new_t = t.change_start_idx(i)\n",
    "            n = StrNode.from_parent(self,new_t)\n",
    "            if n.current==current: #means no change\n",
    "                continue\n",
    "\n",
    "            if n.is_leaf():\n",
    "                print(f\"Found ending state from {self.og} to {n.current}\")\n",
    "                return n\n",
    "            if n.current in StrNode.known_transformations:\n",
    "                end_str = StrNode.known_transformations[n.current]\n",
    "                print(f\"Made known transformation from {self.og} to {n.current} to {end_str}\")\n",
    "                return StrNode(self.og,n.current,n,Transformation(n.current,end_str))\n",
    "            \n",
    "\n",
    "            child_list.append(n)\n",
    "        self.children.extend(child_list)\n",
    "\n",
    "        print(f\"Adding {len(child_list)} to children and returning new ones\")\n",
    "        return child_list\n",
    "    \n",
    "    def reset_orig_string(self):\n",
    "        self.og = self.current\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def is_leaf(self)->bool:\n",
    "        return self.leaf\n",
    "\n",
    "def get_previous_strings(finished_node:StrNode)->list[str]:\n",
    "    if not finished_node.is_leaf():\n",
    "        raise ValueError(\"we need to make sure the node is a final one\")\n",
    "    node = finished_node\n",
    "    strings = [node.current]\n",
    "    while node.parent is not None:\n",
    "        strings.append(node.current)\n",
    "        node = node.parent\n",
    "    return strings\n",
    "\n",
    "def iterate_through_changes(known_words:list[str],\n",
    "                            unknown_words:list[str],\n",
    "                            char_changes:list[tuple[str,str]],max_iterations=5):\n",
    "    \n",
    "\n",
    "    unfinished_nodes: dict[str,set[StrNode]] = {uk:set([StrNode(uk,uk,None,None,False)]) for uk in unknown_words}\n",
    "    known_mapping:dict[str,str] = {}\n",
    "    StrNode.known_words = set(known_words)\n",
    "    StrNode.known_transformations = known_mapping\n",
    "    iteration=0\n",
    "    any_change= True\n",
    "    while iteration<max_iterations and len(unknown_words)>0 and any_change:\n",
    "        iteration+=1\n",
    "        any_change = False\n",
    "        for new,old in char_changes:\n",
    "            t = Transformation(old,new)\n",
    "            for og_word,node_set in unfinished_nodes.items():\n",
    "                if og_word in known_mapping:\n",
    "                    unfinished_nodes.pop(og_word)\n",
    "                    continue\n",
    "                for node in node_set:\n",
    "                    node_str = node.current\n",
    "                    found_result = known_mapping.get(node_str)\n",
    "                    if found_result is not None:\n",
    "                        known_mapping[og_word] = found_result\n",
    "                        unfinished_nodes.pop(og_word)\n",
    "                        break\n",
    "                    children = node.make_children(t)\n",
    "                    if len(children)>0:\n",
    "                        any_change = True\n",
    "                    if isinstance(children,StrNode): #means they got finished state\n",
    "                        final:StrNode = children\n",
    "                        final_str:str = children.current\n",
    "                        known_mapping[og_word] = final_str\n",
    "                        known_mapping.update({intermediate:final_str for intermediate in get_previous_strings(final)})\n",
    "                        break\n",
    "                    else:\n",
    "                        unfinished_nodes[og_word].update(node.children)\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "            col = f\"{a}->{b}\"\n",
    "            not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "        intermediate_steps.append(not_found)\n",
    "\n",
    "        new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "        if len(new_melt)==0:\n",
    "            print(\"None left\")\n",
    "            break\n",
    "        new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "        new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "        new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "        new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "        already_made.update(new_melt['current_word'])\n",
    "        newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "        found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "        \n",
    "        reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "        step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "        new_melt['current_word'] = new_melt['new_word']\n",
    "        not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Set, Optional\n",
    "from collections import deque,defaultdict\n",
    "\n",
    "\n",
    "class Transformation:\n",
    "    def __init__(self, old: str, new: str):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "\n",
    "    def apply(self, s: str, start_idx: int) -> Optional[str]:\n",
    "        \"\"\"Applies the transformation at the given index.\"\"\"\n",
    "        if s[start_idx:].startswith(self.old):\n",
    "            return s[:start_idx] + self.new + s[start_idx + len(self.old):]\n",
    "        return None\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, known_words: Set[str]):\n",
    "        self.known_words = known_words\n",
    "        self.visited: Dict[str, str] = {}  # Tracks visited states and their closest known word.\n",
    "        self.paths: Dict[str, List[str]] = {}  # Stores paths from any word to its known word.\n",
    "\n",
    "\n",
    "    def is_known(self, word: str) -> bool:\n",
    "        \"\"\"Checks if the word is known.\"\"\"\n",
    "        return word in self.known_words\n",
    "\n",
    "    def any_previous_path_to_known(self,node:'Node')->bool:\n",
    "        path = node.get_path()\n",
    "        any_path = self.paths.keys()\n",
    "        try:\n",
    "            for p in path[1:]:\n",
    "                if p in any_path:\n",
    "                    return True\n",
    "            return False\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "    def mark_visited(self, word: str, path: List[str],real_word:bool) -> bool:\n",
    "        \"\"\"\n",
    "        Marks a word as visited.\n",
    "        If the word is already visited, returns False.\n",
    "        Otherwise, updates the path to the known word and returns True.\n",
    "        \"\"\"\n",
    "        if word in self.visited and not real_word:\n",
    "            return False\n",
    "        \n",
    "        self.visited[word] = path[-1]  # Store the last word in the path as the connection.\n",
    "        if real_word:\n",
    "            self.paths[word] = path\n",
    "        return True\n",
    "\n",
    "    def get_path_to_known(self, word: str) -> Optional[List[str]]:\n",
    "        \"\"\"Retrieves the path from the word to the known word, if available.\"\"\"\n",
    "        return self.paths.get(word)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, word: str, parent: Optional[\"Node\"], root_word:str, transformation: Optional[Transformation]):\n",
    "        self.word = word\n",
    "        self.parent = parent\n",
    "        self.root_word=root_word\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def get_path(self) -> List[str]:\n",
    "        \"\"\"Retrieves the transformation path from the root to this node.\"\"\"\n",
    "        path = []\n",
    "        node = self\n",
    "        while node:\n",
    "            path.append(node.word)\n",
    "            node = node.parent\n",
    "        return path[::-1]  # Reverse to get root-to-leaf order\n",
    "\n",
    "\n",
    "def iterate_through_changes(\n",
    "    known_words: set[str],\n",
    "    unknown_words: List[str],\n",
    "    char_changes: List[Tuple[str, str]],\n",
    "    max_iterations: int = 5\n",
    ") -> Dict[str, List[str]]:\n",
    "    known_set = set(known_words)\n",
    "    graph = Graph(known_set)\n",
    "    results: Dict[str, List[str]] = {}\n",
    "    #connected_to_known:defaultdict[str,bool] =defaultdict(bool)\n",
    "\n",
    "    # Initialize the queue with all unknown words\n",
    "    queue = deque([Node(word, None, word,None) for word in unknown_words])\n",
    "    for word in unknown_words:\n",
    "        graph.mark_visited(word, [word],False)\n",
    "\n",
    "    for word in known_words:\n",
    "        graph.mark_visited(word,[word],True)\n",
    "\n",
    "    iteration = 0\n",
    "    while queue and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        next_iter_queue = deque()\n",
    "        print(f\"Iteration{iteration}: Queue of {len(queue)}\")\n",
    "        for old, new in char_changes:\n",
    "            transformation = Transformation(old, new)\n",
    "            next_char_queue = deque()\n",
    "            \n",
    "            while queue:\n",
    "                node = queue.popleft()\n",
    "                current_word = node.word\n",
    "                root = node.root_word\n",
    "                if graph.get_path_to_known(current_word) is not None or graph.get_path_to_known(root) is not None:\n",
    "                    continue\n",
    "\n",
    "                # Try applying the transformation at every valid index\n",
    "                for i in range(len(current_word) - len(old) + 1):\n",
    "                    new_word = transformation.apply(current_word, i)\n",
    "                   \n",
    "                    if not new_word:\n",
    "                        continue\n",
    "                    #print(\"Found new word:\", new_word)\n",
    "\n",
    "                    # If the new word is already connected to a known word\n",
    "                    if new_word in graph.visited:\n",
    "                        path_to_known = graph.get_path_to_known(new_word)\n",
    "                        if path_to_known:\n",
    "                            #print(f\"wow found a path from {current_word} to {new_word}\")\n",
    "                            node_path = node.get_path()\n",
    "                            full_path = node_path + path_to_known\n",
    "                            results[node_path[0]] = node.get_path() + path_to_known\n",
    "                            for i,step in enumerate(full_path):\n",
    "                                graph.paths[step] = full_path[i:]\n",
    "                            continue\n",
    "                    else:\n",
    "                        graph.mark_visited(new_word, node.get_path() + [new_word],False)\n",
    "                    next_iter_queue.append(node)\n",
    "                    next_iter_queue.append(Node(new_word, node, root, transformation))\n",
    "                next_char_queue.append(node)\n",
    "\n",
    "                    # Otherwise, mark it visited and enqueue for further exploration\n",
    "            queue = next_char_queue\n",
    "                #if graph.mark_visited(new_word, node.get_path() + [new_word]):\n",
    "        queue.clear()\n",
    "        print(f\"Queued for next iteration: {len(next_iter_queue)}\")\n",
    "        while next_iter_queue:\n",
    "\n",
    "            node = next_iter_queue.popleft()\n",
    "            if graph.any_previous_path_to_known(node):\n",
    "                continue\n",
    "            queue.append(node)\n",
    "        print(f\"After culling: \",len(queue))\n",
    "\n",
    "\n",
    "    # For any unknown word that has no transformation path, set an empty path\n",
    "    for word in unknown_words:\n",
    "        if word not in results:\n",
    "            results[word] = []\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Graph.mark_visited() missing 1 required positional argument: 'real_word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[292], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m queue \u001b[38;5;241m=\u001b[39m deque([Node(word, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m unknown_words])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m unknown_words:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark_visited\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m<\u001b[39m max_iterations:\n",
      "\u001b[0;31mTypeError\u001b[0m: Graph.mark_visited() missing 1 required positional argument: 'real_word'"
     ]
    }
   ],
   "source": [
    "# Initialize the queue with all unknown words\n",
    "known_set = set(known_words)\n",
    "graph = Graph(known_set)\n",
    "results: Dict[str, List[str]] = {}\n",
    "queue = deque([Node(word, None, None) for word in unknown_words])\n",
    "for word in unknown_words:\n",
    "    graph.mark_visited(word, [word])\n",
    "\n",
    "iteration = 0\n",
    "while queue and iteration < max_iterations:\n",
    "    iteration += 1\n",
    "    next_queue = deque()\n",
    "\n",
    "    for old, new in char_changes:\n",
    "        transformation = Transformation(old, new)\n",
    "\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            current_word = node.word\n",
    "\n",
    "            # Try applying the transformation at every valid index\n",
    "            for i in range(len(current_word) - len(old) + 1):\n",
    "                new_word = transformation.apply(current_word, i)\n",
    "                if not new_word:\n",
    "                    continue\n",
    "\n",
    "                # If the new word is already connected to a known word\n",
    "                if new_word in graph.visited:\n",
    "                    path_to_known = graph.get_path_to_known(new_word)\n",
    "                    if path_to_known:\n",
    "                        print(\"wow founda path from {current_word} to {new_word}\")\n",
    "                        results[node.get_path()[0]] = node.get_path() + path_to_known[1:]\n",
    "                        continue\n",
    "                \n",
    "\n",
    "                # Otherwise, mark it visited and enqueue for further exploration\n",
    "                if graph.mark_visited(new_word, node.get_path() + [new_word]):\n",
    "                    next_queue.append(Node(new_word, node, transformation))\n",
    "\n",
    "    queue = next_queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\n",
    "    (\"ll\", \"n\"),\n",
    "    (\"ll\", \"u\"),\n",
    "    (\"ll\", \"h\"),\n",
    "    (\"il\", \"n\"),\n",
    "    (\"il\", \"u\"),\n",
    "    (\"il\", \"h\"),\n",
    "    (\"nl\", \"m\"),\n",
    "    (\"ln\", \"m\"),\n",
    "    (\"cl\", \"d\"),\n",
    "    (\"vv\", \"w\"),\n",
    "    (\"lll\", \"m\"),\n",
    "    (\"rl\", \"n\"),\n",
    "    (\"tl\", \"u\"),\n",
    "    (\"tl\", \"n\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1: Queue of 2326\n",
      "Queued for next iteration: 19942\n",
      "After culling:  19901\n",
      "Iteration2: Queue of 19901\n",
      "Queued for next iteration: 157294\n",
      "After culling:  153807\n",
      "Iteration3: Queue of 153807\n",
      "Queued for next iteration: 1658920\n",
      "After culling:  1631771\n",
      "Iteration4: Queue of 1631771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x108288d70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queued for next iteration: 24404446\n",
      "After culling:  24368461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "corrections = json.load(open('corrections.json'))\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development_hospital_sometimes_healing_should_universities_undertake_departments_evolution\"\n",
    "known_words:set[str] = set(exists.split(\"_\")+list(ac['corpus_word'].astype(str)) +list(corrections.values()))\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = list(sc.loc[sc['og_word'].isin(known_words)==False,'og_word'])\n",
    "results= iterate_through_changes(known_words,not_found,chars,max_iterations=4)\n",
    "len([v for v in results.values() if len(v)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i,j in results.items() if len(j)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['different']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tlaat': ['tlaat'],\n",
       " 'llletllod': ['llletllod'],\n",
       " 'opporttlnity': ['opporttlnity'],\n",
       " 'differellt': ['differellt'],\n",
       " 'sellse': ['sellse'],\n",
       " 'illaterial': ['illaterial'],\n",
       " 'diminisll': ['diminisll'],\n",
       " 'otlly': ['otlly'],\n",
       " 'dynalllic': ['dynalllic'],\n",
       " 'dyllamic': ['dyllamic'],\n",
       " 'ollore': ['ollore'],\n",
       " 'otle': ['otle'],\n",
       " 'implicitly': ['implicitly'],\n",
       " 'hiln': ['hiln'],\n",
       " 'thorougllly': ['thorougllly'],\n",
       " 'dissellt': ['dissellt'],\n",
       " 'collsistently': ['collsistently'],\n",
       " 'borll': ['borll'],\n",
       " 'collsequelaces': ['collsequelaces'],\n",
       " 'llight': ['llight'],\n",
       " 'collnected': ['collnected'],\n",
       " 'prepossessiolls': ['prepossessiolls'],\n",
       " 'examille': ['examille'],\n",
       " 'critically': ['critically'],\n",
       " 'evetl': ['evetl'],\n",
       " 'intellectually': ['intellectually'],\n",
       " 'conditioll': ['conditioll'],\n",
       " 'observatioll': ['observatioll'],\n",
       " 'stability': ['stability'],\n",
       " 'jlldgments': ['jlldgments'],\n",
       " 'tl': ['tl'],\n",
       " 'criticislll': ['criticislll'],\n",
       " 'ollost': ['ollost'],\n",
       " 'incidentally': ['incidentally'],\n",
       " 'hourly': ['hourly'],\n",
       " 'intervelltion': ['intervelltion'],\n",
       " 'relnain': ['relnain'],\n",
       " 'weigll': ['weigll'],\n",
       " 'selectiorl': ['selectiorl'],\n",
       " 'gtlard': ['gtlard'],\n",
       " 'sall': ['sall'],\n",
       " 'methocls': ['methocls'],\n",
       " 'bllt': ['bllt'],\n",
       " 'ftllfillment': ['ftllfillment'],\n",
       " 'comlllllnity': ['comlllllnity'],\n",
       " 'ulldertake': ['ulldertake'],\n",
       " 'icleals': ['icleals'],\n",
       " 'mall': ['mall'],\n",
       " 'clouds': ['clouds'],\n",
       " 'chatllpion': ['chatllpion'],\n",
       " 'cotntnullity': ['cotntnullity'],\n",
       " 'clailus': ['clailus'],\n",
       " 'telnporary': ['telnporary'],\n",
       " 'illissioll': ['illissioll'],\n",
       " 'etllics': ['etllics'],\n",
       " 'lnatter': ['lnatter'],\n",
       " 'judgmellt': ['judgmellt'],\n",
       " 'llational': ['llational'],\n",
       " 'antecedellts': ['antecedellts'],\n",
       " 'growll': ['growll'],\n",
       " 'btlsiness': ['btlsiness'],\n",
       " 'alnong': ['alnong'],\n",
       " 'llilnself': ['llilnself'],\n",
       " 'envirollmellt': ['envirollmellt'],\n",
       " 'partially': ['partially'],\n",
       " 'nearsiglltedness': ['nearsiglltedness'],\n",
       " 'froln': ['froln'],\n",
       " 'astiglllatisill': ['astiglllatisill'],\n",
       " 'ellable': ['ellable'],\n",
       " 'hellry': ['hellry'],\n",
       " 'disinterestedlless': ['disinterestedlless'],\n",
       " 'diametrically': ['diametrically'],\n",
       " 'conditiotls': ['conditiotls'],\n",
       " 'canclid': ['canclid'],\n",
       " 'illtentioll': ['illtentioll'],\n",
       " 'prevellts': ['prevellts'],\n",
       " 'applyitlg': ['applyitlg'],\n",
       " 'judgilaellt': ['judgilaellt'],\n",
       " 'atlybody': ['atlybody'],\n",
       " 'sllggests': ['sllggests'],\n",
       " 'uncler': ['uncler'],\n",
       " 'circutllstallces': ['circutllstallces'],\n",
       " 'ollaki': ['ollaki'],\n",
       " 'llg': ['llg'],\n",
       " 'judglllellts': ['judglllellts'],\n",
       " 'fratlkly': ['fratlkly'],\n",
       " 'clailll': ['clailll'],\n",
       " 'ooll': ['ooll'],\n",
       " 'nlen': ['nlen'],\n",
       " 'ollixture': ['ollixture'],\n",
       " 'atld': ['atld'],\n",
       " 'cleceptioll': ['cleceptioll'],\n",
       " 'coollbille': ['coollbille'],\n",
       " 'botll': ['botll'],\n",
       " 'illdependent': ['illdependent'],\n",
       " 'tlzat': ['tlzat'],\n",
       " 'attelllpt': ['attelllpt'],\n",
       " 'ila': ['ila'],\n",
       " 'eminellt': ['eminellt'],\n",
       " 'lnental': ['lnental'],\n",
       " 'johll': ['johll'],\n",
       " 'assulllption': ['assulllption'],\n",
       " 'colllmuolity': ['colllmuolity'],\n",
       " 'pretellds': ['pretellds'],\n",
       " 'jllst': ['jllst'],\n",
       " 'reforlller': ['reforlller'],\n",
       " 'lnan': ['lnan'],\n",
       " 'claims': ['claims'],\n",
       " 'everytlling': ['everytlling'],\n",
       " 'allci': ['allci'],\n",
       " 'sarill': ['sarill'],\n",
       " 'visiollary': ['visiollary'],\n",
       " 'itlterests': ['itlterests'],\n",
       " 'lllealls': ['lllealls'],\n",
       " 'collcrete': ['collcrete'],\n",
       " 'tntlst': ['tntlst'],\n",
       " 'sentimellt': ['sentimellt'],\n",
       " 'elcconlplish': ['elcconlplish'],\n",
       " 'wllolly': ['wllolly'],\n",
       " 'illdividual': ['illdividual'],\n",
       " 'workillg': ['workillg'],\n",
       " 'recognitioll': ['recognitioll'],\n",
       " 'permissioll': ['permissioll'],\n",
       " 'variotls': ['variotls'],\n",
       " 'menlbers': ['menlbers'],\n",
       " 'accordilg': ['accordilg'],\n",
       " 'deprivillg': ['deprivillg'],\n",
       " 'sometilnes': ['sometilnes'],\n",
       " 'cllallces': ['cllallces'],\n",
       " 'silogle': ['silogle'],\n",
       " 'grollp': ['grollp'],\n",
       " 'balallce': ['balallce'],\n",
       " 'cotltributes': ['cotltributes'],\n",
       " 'annillilation': ['annillilation'],\n",
       " 'predolninallce': ['predolninallce'],\n",
       " 'iclelltified': ['iclelltified'],\n",
       " 'cllance': ['cllance'],\n",
       " 'collflicting': ['collflicting'],\n",
       " 'cotlditioil': ['cotlditioil'],\n",
       " 'nulnber': ['nulnber'],\n",
       " 'fulldalnental': ['fulldalnental'],\n",
       " 'outlilled': ['outlilled'],\n",
       " 'ollr': ['ollr'],\n",
       " 'dtlces': ['dtlces'],\n",
       " 'showll': ['showll'],\n",
       " 'colltribllte': ['colltribllte'],\n",
       " 'neecls': ['neecls'],\n",
       " 'lnall': ['lnall'],\n",
       " 'conclusiolls': ['conclusiolls'],\n",
       " 'lullell': ['lullell'],\n",
       " 'econelllist': ['econelllist'],\n",
       " 'illottlent': ['illottlent'],\n",
       " 'adjllstlnent': ['adjllstlnent'],\n",
       " 'conaproollise': ['conaproollise'],\n",
       " 'positiolls': ['positiolls'],\n",
       " 'chanopioll': ['chanopioll'],\n",
       " 'llilll': ['llilll'],\n",
       " 'sionilar': ['sionilar'],\n",
       " 'wlaicll': ['wlaicll'],\n",
       " 'comlllol': ['comlllol'],\n",
       " 'llniotls': ['llniotls'],\n",
       " 'civili': ['civili'],\n",
       " 'comlnunities': ['comlnunities'],\n",
       " 'frotll': ['frotll'],\n",
       " 'trallsaction': ['trallsaction'],\n",
       " 'tlansaction': ['tlansaction'],\n",
       " 'reglllator': ['reglllator'],\n",
       " 'itlerease': ['itlerease'],\n",
       " 'reasoll': ['reasoll'],\n",
       " 'owller': ['owller'],\n",
       " 'alld': ['alld'],\n",
       " 'sllowed': ['sllowed'],\n",
       " 'colntnullity': ['colntnullity'],\n",
       " 'ilumecliately': ['ilumecliately'],\n",
       " 'accolllpanied': ['accolllpanied'],\n",
       " 'poillt': ['poillt'],\n",
       " 'perlnanent': ['perlnanent'],\n",
       " 'illfluellce': ['illfluellce'],\n",
       " 'correctilag': ['correctilag'],\n",
       " 'forlllation': ['forlllation'],\n",
       " 'lls': ['lls'],\n",
       " 'adoptioll': ['adoptioll'],\n",
       " 'illorality': ['illorality'],\n",
       " 'aclvocacy': ['aclvocacy'],\n",
       " 'ilzterests': ['ilzterests'],\n",
       " 'ratller': ['ratller'],\n",
       " 'llecessit': ['llecessit'],\n",
       " 'governlllent': ['governlllent'],\n",
       " 'clifferellt': ['clifferellt'],\n",
       " 'recogllition': ['recogllition'],\n",
       " 'clas': ['clas'],\n",
       " 'seeril': ['seeril'],\n",
       " 'argulnent': ['argulnent'],\n",
       " 'betweetl': ['betweetl'],\n",
       " 'aillls': ['aillls'],\n",
       " 'eoznlllullity': ['eoznlllullity'],\n",
       " 'profouncler': ['profouncler'],\n",
       " 'stucly': ['stucly'],\n",
       " 'collstitlltiollal': ['collstitlltiollal'],\n",
       " 'llistoryr': ['llistoryr'],\n",
       " 'ldarlialllents': ['ldarlialllents'],\n",
       " 'eollgresses': ['eollgresses'],\n",
       " 'collstlmtllation': ['collstlmtllation'],\n",
       " 'bargaills': ['bargaills'],\n",
       " 'tloe': ['tloe'],\n",
       " 'ereatioll': ['ereatioll'],\n",
       " 'ptlblie': ['ptlblie'],\n",
       " 'parlialnellt': ['parlialnellt'],\n",
       " 'fronl': ['fronl'],\n",
       " 'nvestlaillstel': ['nvestlaillstel'],\n",
       " 'illterchange': ['illterchange'],\n",
       " 'lnenlbel': ['lnenlbel'],\n",
       " 'eilliglltened': ['eilliglltened'],\n",
       " 'loeallll': ['loeallll'],\n",
       " 'wlliell': ['wlliell'],\n",
       " 'llollle': ['llollle'],\n",
       " 'tile': ['tile'],\n",
       " 'aetioll': ['aetioll'],\n",
       " 'esselltial': ['esselltial'],\n",
       " 'flllletioll': ['flllletioll'],\n",
       " 'parliaments': ['parliaments'],\n",
       " 'vvas': ['vvas'],\n",
       " 'otltside': ['otltside'],\n",
       " 'tlleil': ['tlleil'],\n",
       " 'exigelleies': ['exigelleies'],\n",
       " 'ellabled': ['ellabled'],\n",
       " 'tlleoll': ['tlleoll'],\n",
       " 'eoznllloll': ['eoznllloll'],\n",
       " 'extellsiolls': ['extellsiolls'],\n",
       " 'eolllmoll': ['eolllmoll'],\n",
       " 'fallell': ['fallell'],\n",
       " 'trtle': ['trtle'],\n",
       " 'parliaulent': ['parliaulent'],\n",
       " 'llad': ['llad'],\n",
       " 'additioll': ['additioll'],\n",
       " 'tllemseln': ['tllemseln'],\n",
       " 'comlnolzs': ['comlnolzs'],\n",
       " 'origillate': ['origillate'],\n",
       " 'killgs': ['killgs'],\n",
       " 'avoidillg': ['avoidillg'],\n",
       " 'eompellilag': ['eompellilag'],\n",
       " 'autlloritative': ['autlloritative'],\n",
       " 'presetltation': ['presetltation'],\n",
       " 'opillio': ['opillio'],\n",
       " 'wlaell': ['wlaell'],\n",
       " 'parliamellt': ['parliamellt'],\n",
       " 'illtellded': ['illtellded'],\n",
       " 'salne': ['salne'],\n",
       " 'fullction': ['fullction'],\n",
       " 'clifferent': ['clifferent'],\n",
       " 'tllal': ['tllal'],\n",
       " 'collalllon': ['collalllon'],\n",
       " 'tlaall': ['tlaall'],\n",
       " 'vvllat': ['vvllat'],\n",
       " 'forlned': ['forlned'],\n",
       " 'extensioll': ['extensioll'],\n",
       " 'll': ['ll'],\n",
       " 'diserellt': ['diserellt'],\n",
       " 'comtnullity': ['comtnullity'],\n",
       " 'lnealas': ['lnealas'],\n",
       " 'illforlnation': ['illforlnation'],\n",
       " 'wllicll': ['wllicll'],\n",
       " 'collgressional': ['collgressional'],\n",
       " 'epreselltaties': ['epreselltaties'],\n",
       " 'formatioll': ['formatioll'],\n",
       " 'sentilnellt': ['sentilnellt'],\n",
       " 'parlialnents': ['parlialnents'],\n",
       " 'lllaking': ['lllaking'],\n",
       " 'opilliolls': ['opilliolls'],\n",
       " 'accompallied': ['accompallied'],\n",
       " 'sallltary': ['sallltary'],\n",
       " 'thillk': ['thillk'],\n",
       " 'recoanitioll': ['recoanitioll'],\n",
       " 'collvictioll': ['collvictioll'],\n",
       " 'epreselltative': ['epreselltative'],\n",
       " 'utterallces': ['utterallces'],\n",
       " 'collstituellts': ['collstituellts'],\n",
       " 'tllall': ['tllall'],\n",
       " 'gelzerally': ['gelzerally'],\n",
       " 'educatiollal': ['educatiollal'],\n",
       " 'incidellt': ['incidellt'],\n",
       " 'positiotl': ['positiotl'],\n",
       " 'clistrict': ['clistrict'],\n",
       " 'mallifests': ['mallifests'],\n",
       " 'appropriatioll': ['appropriatioll'],\n",
       " 'stalld': ['stalld'],\n",
       " 'illcreasingly': ['illcreasingly'],\n",
       " 'bellalf': ['bellalf'],\n",
       " 'beconle': ['beconle'],\n",
       " 'llloderll': ['llloderll'],\n",
       " 'patcllwork': ['patcllwork'],\n",
       " 'demallds': ['demallds'],\n",
       " 'llotoriotls': ['llotoriotls'],\n",
       " 'estilnate': ['estilnate'],\n",
       " 'parliamelltary': ['parliamelltary'],\n",
       " 'glorificatioll': ['glorificatioll'],\n",
       " 'idealizatioll': ['idealizatioll'],\n",
       " 'cotnlllon': ['cotnlllon'],\n",
       " 'eneratiolls': ['eneratiolls'],\n",
       " 'illlmediately': ['illlmediately'],\n",
       " 'passillg': ['passillg'],\n",
       " 'lessellilag': ['lessellilag'],\n",
       " 'systemgivillg': ['systemgivillg'],\n",
       " 'lnayor': ['lnayor'],\n",
       " 'persolls': ['persolls'],\n",
       " 'tllayor': ['tllayor'],\n",
       " 'ordillary': ['ordillary'],\n",
       " 'lnunicipality': ['lnunicipality'],\n",
       " 'pllllldered': ['pllllldered'],\n",
       " 'sanle': ['sanle'],\n",
       " 'tendelley': ['tendelley'],\n",
       " 'sllos': ['sllos'],\n",
       " 'eonneetioll': ['eonneetioll'],\n",
       " 'beilag': ['beilag'],\n",
       " 'eonstitlltiolls': ['eonstitlltiolls'],\n",
       " 'instrulllellts': ['instrulllellts'],\n",
       " 'providillg': ['providillg'],\n",
       " 'referellee': ['referellee'],\n",
       " 'argumellt': ['argumellt'],\n",
       " 'whetl': ['whetl'],\n",
       " 'ehallge': ['ehallge'],\n",
       " 'signifieallt': ['signifieallt'],\n",
       " 'trelld': ['trelld'],\n",
       " 'abanclotsllllent': ['abanclotsllllent'],\n",
       " 'clebate': ['clebate'],\n",
       " 'eolntnon': ['eolntnon'],\n",
       " 'sllbstitu': ['sllbstitu'],\n",
       " 'partisall': ['partisall'],\n",
       " 'eollverted': ['eollverted'],\n",
       " 'wllieh': ['wllieh'],\n",
       " 'prevellted': ['prevellted'],\n",
       " 'goverlllz': ['goverlllz'],\n",
       " 'lellt': ['lellt'],\n",
       " 'eommullity': ['eommullity'],\n",
       " 'improvelnellts': ['improvelnellts'],\n",
       " 'maellillery': ['maellillery'],\n",
       " 'orgalliza': ['orgalliza'],\n",
       " 'dllrillg': ['dllrillg'],\n",
       " 'suell': ['suell'],\n",
       " 'eompetitioll': ['eompetitioll'],\n",
       " 'lpally': ['lpally'],\n",
       " 'lilles': ['lilles'],\n",
       " 'eall': ['eall'],\n",
       " 'eeollotny': ['eeollotny'],\n",
       " 'parallel': ['parallel'],\n",
       " 'railroads': ['railroads'],\n",
       " 'eonlpetillg': ['eonlpetillg'],\n",
       " 'workswitllotlt': ['workswitllotlt'],\n",
       " 'expellse': ['expellse'],\n",
       " 'climinished': ['climinished'],\n",
       " 'eollvenienee': ['eollvenienee'],\n",
       " 'eanllot': ['eanllot'],\n",
       " 'lllanr': ['lllanr'],\n",
       " 'eoll': ['eoll'],\n",
       " 'dallger': ['dallger'],\n",
       " 'elllarge': ['elllarge'],\n",
       " 'vhiell': ['vhiell'],\n",
       " 'detrimellt': ['detrimellt'],\n",
       " 'otllel': ['otllel'],\n",
       " 'beilog': ['beilog'],\n",
       " 'overtakell': ['overtakell'],\n",
       " 'xvill': ['xvill'],\n",
       " 'elltrusted': ['elltrusted'],\n",
       " 'tllein': ['tllein'],\n",
       " 'illclireet': ['illclireet'],\n",
       " 'proteetiotl': ['proteetiotl'],\n",
       " 'eolllmereial': ['eolllmereial'],\n",
       " 'eolnpetition': ['eolnpetition'],\n",
       " 'lnore': ['lnore'],\n",
       " 'inclividualized': ['inclividualized'],\n",
       " 'eorl': ['eorl'],\n",
       " 'selfisllness': ['selfisllness'],\n",
       " 'eonlulereial': ['eonlulereial'],\n",
       " 'lllelch': ['lllelch'],\n",
       " 'ulllimited': ['ulllimited'],\n",
       " 'proulotillg': ['proulotillg'],\n",
       " 'eonedellee': ['eonedellee'],\n",
       " 'illclividual': ['illclividual'],\n",
       " 'illitiative': ['illitiative'],\n",
       " 'ilnmediate': ['ilnmediate'],\n",
       " 'regulatillg': ['regulatillg'],\n",
       " 'silnilar': ['silnilar'],\n",
       " 'otlr': ['otlr'],\n",
       " 'lrlunieipalities': ['lrlunieipalities'],\n",
       " 'givillg': ['givillg'],\n",
       " 'ulldreamed': ['ulldreamed'],\n",
       " 'ldllt': ['ldllt'],\n",
       " 'eolllbi': ['eolllbi'],\n",
       " 'tlse': ['tlse'],\n",
       " 'llatiollal': ['llatiollal'],\n",
       " 'neeessarily': ['neeessarily'],\n",
       " 'recogllitioll': ['recogllitioll'],\n",
       " 'strengtll': ['strengtll'],\n",
       " 'pursllits': ['pursllits'],\n",
       " 'lllember': ['lllember'],\n",
       " 'federatioll': ['federatioll'],\n",
       " 'systenl': ['systenl'],\n",
       " 'theilown': ['theilown'],\n",
       " 'llesr': ['llesr'],\n",
       " 'inlpossible': ['inlpossible'],\n",
       " 'represellt': ['represellt'],\n",
       " 'fulldamental': ['fulldamental'],\n",
       " 'boullded': ['boullded'],\n",
       " 'beyolld': ['beyolld'],\n",
       " 'cleluded': ['cleluded'],\n",
       " 'constitutionally': ['constitutionally'],\n",
       " 'lnean': ['lnean'],\n",
       " 'hallds': ['hallds'],\n",
       " 'colldltions': ['colldltions'],\n",
       " 'flllfil': ['flllfil'],\n",
       " 'xnorally': ['xnorally'],\n",
       " 'politically': ['politically'],\n",
       " 'rollle': ['rollle'],\n",
       " 'ruilled': ['ruilled'],\n",
       " 'faitil': ['faitil'],\n",
       " 'alzlericall': ['alzlericall'],\n",
       " 'leecls': ['leecls'],\n",
       " 'indllstry': ['indllstry'],\n",
       " 'goverlllllent': ['goverlllllent'],\n",
       " 'collectivisin': ['collectivisin'],\n",
       " 'collectivism': ['collectivism'],\n",
       " 'allalces': ['allalces'],\n",
       " 'cllaracters': ['cllaracters'],\n",
       " 'detnallds': ['detnallds'],\n",
       " 'lnen': ['lnen'],\n",
       " 'colllpromise': ['colllpromise'],\n",
       " 'ullclerstalldillg': ['ullclerstalldillg'],\n",
       " 'bargaill': ['bargaill'],\n",
       " 'colllonercial': ['colllonercial'],\n",
       " 'illethods': ['illethods'],\n",
       " 'coillproulise': ['coillproulise'],\n",
       " 'convictioll': ['convictioll'],\n",
       " 'successflll': ['successflll'],\n",
       " 'lllan': ['lllan'],\n",
       " 'illusion': ['illusion'],\n",
       " 'ecollomists': ['ecollomists'],\n",
       " 'collditiolls': ['collditiolls'],\n",
       " 'treatmellt': ['treatmellt'],\n",
       " 'plovillg': ['plovillg'],\n",
       " 'ullw': ['ullw'],\n",
       " 'derstallding': ['derstallding'],\n",
       " 'lleecls': ['lleecls'],\n",
       " 'evokillg': ['evokillg'],\n",
       " 'svllatever': ['svllatever'],\n",
       " 'kllowledge': ['kllowledge'],\n",
       " 'breadtll': ['breadtll'],\n",
       " 'ptlrpose': ['ptlrpose'],\n",
       " 'llotlling': ['llotlling'],\n",
       " 'toucllillg': ['toucllillg'],\n",
       " 'sll': ['sll'],\n",
       " 'folloving': ['folloving'],\n",
       " 'qllol': ['qllol'],\n",
       " 'atioll': ['atioll'],\n",
       " 'fllrllishes': ['fllrllishes'],\n",
       " 'conlpetition': ['conlpetition'],\n",
       " 'cllanlpiolls': ['cllanlpiolls'],\n",
       " 'dolllillated': ['dolllillated'],\n",
       " 'harmollized': ['harmollized'],\n",
       " 'elelnellts': ['elelnellts'],\n",
       " 'cllristiallity': ['cllristiallity'],\n",
       " 'itrlpossible': ['itrlpossible'],\n",
       " 'lllatl': ['lllatl'],\n",
       " 'conclitions': ['conclitions'],\n",
       " 'cullilillg': ['cullilillg'],\n",
       " 'materialisln': ['materialisln'],\n",
       " 'absorbillg': ['absorbillg'],\n",
       " 'feeclillg': ['feeclillg'],\n",
       " 'cnildren': ['cnildren'],\n",
       " 'warpillg': ['warpillg'],\n",
       " 'lnoral': ['lnoral'],\n",
       " 'wilich': ['wilich'],\n",
       " 'clown': ['clown'],\n",
       " 'bidclillg': ['bidclillg'],\n",
       " 'politicialls': ['politicialls'],\n",
       " 'mollopolists': ['mollopolists'],\n",
       " 'tlleologialls': ['tlleologialls'],\n",
       " 'bellillcl': ['bellillcl'],\n",
       " 'btlt': ['btlt'],\n",
       " 'togetllel': ['togetllel'],\n",
       " 'llumaol': ['llumaol'],\n",
       " 'clivil': ['clivil'],\n",
       " 'ulllatlity': ['ulllatlity'],\n",
       " 'delllonracy': ['delllonracy'],\n",
       " 'gallizillg': ['gallizillg'],\n",
       " 'maclliller': ['maclliller'],\n",
       " 'llt': ['llt'],\n",
       " 'aillst': ['aillst'],\n",
       " 'tlwis': ['tlwis'],\n",
       " 'utterallce': ['utterallce'],\n",
       " 'clearcllt': ['clearcllt'],\n",
       " 'sioll': ['sioll'],\n",
       " 'opillioil': ['opillioil'],\n",
       " 'jtlst': ['jtlst'],\n",
       " 'llseci': ['llseci'],\n",
       " 'lncavrorable': ['lncavrorable'],\n",
       " 'lllanifestatioll': ['lllanifestatioll'],\n",
       " 'econolnic': ['econolnic'],\n",
       " 'alltic': ['alltic'],\n",
       " 'tliat': ['tliat'],\n",
       " 'everybocly': ['everybocly'],\n",
       " 'cllll': ['cllll'],\n",
       " 'illg': ['illg'],\n",
       " 'celltllries': ['celltllries'],\n",
       " 'pllysical': ['pllysical'],\n",
       " 'allead': ['allead'],\n",
       " 'hulllalwity': ['hulllalwity'],\n",
       " 'stalldard': ['stalldard'],\n",
       " 'lllode': ['lllode'],\n",
       " 'livillg': ['livillg'],\n",
       " 'comllloll': ['comllloll'],\n",
       " 'colllfortable': ['colllfortable'],\n",
       " 'wlloul': ['wlloul'],\n",
       " 'sillt': ['sillt'],\n",
       " 'ollce': ['ollce'],\n",
       " 'olltburst': ['olltburst'],\n",
       " 'writtell': ['writtell'],\n",
       " 'cllristiall': ['cllristiall'],\n",
       " 'heavenlr': ['heavenlr'],\n",
       " 'pently': ['pently'],\n",
       " 'lillers': ['lillers'],\n",
       " 'pllilosopllers': ['pllilosopllers'],\n",
       " 'eartll': ['eartll'],\n",
       " 'colnpetition': ['colnpetition'],\n",
       " 'rapllael': ['rapllael'],\n",
       " 'worsllip': ['worsllip'],\n",
       " 'lninimuln': ['lninimuln'],\n",
       " 'kllosr': ['kllosr'],\n",
       " 'meallwhile': ['meallwhile'],\n",
       " 'tllou': ['tllou'],\n",
       " 'parellt': ['parellt'],\n",
       " 'ecollol': ['ecollol'],\n",
       " 'slle': ['slle'],\n",
       " 'colusecratioll': ['colusecratioll'],\n",
       " 'cailnibalistll': ['cailnibalistll'],\n",
       " 'llalld': ['llalld'],\n",
       " 'listetl': ['listetl'],\n",
       " 'lllese': ['lllese'],\n",
       " 'worcls': ['worcls'],\n",
       " 'sturcly': ['sturcly'],\n",
       " 'alnericall': ['alnericall'],\n",
       " 'delatonciatioll': ['delatonciatioll'],\n",
       " 'cail': ['cail'],\n",
       " 'iglltly': ['iglltly'],\n",
       " 'ilnpl': ['ilnpl'],\n",
       " 'gll': ['gll'],\n",
       " 'olloies': ['olloies'],\n",
       " 'callec': ['callec'],\n",
       " 'titiotl': ['titiotl'],\n",
       " 'cellters': ['cellters'],\n",
       " 'svllere': ['svllere'],\n",
       " 'lnell': ['lnell'],\n",
       " 'lllel': ['lllel'],\n",
       " 'srall': ['srall'],\n",
       " 'coollpesitioll': ['coollpesitioll'],\n",
       " 'possessiotl': ['possessiotl'],\n",
       " 'nvllid': ['nvllid'],\n",
       " 'illlites': ['illlites'],\n",
       " 'nvitll': ['nvitll'],\n",
       " 'tlze': ['tlze'],\n",
       " 'colnpetitiolo': ['colnpetitiolo'],\n",
       " 'tllaol': ['tllaol'],\n",
       " 'tlleft': ['tlleft'],\n",
       " 'recollciliatioll': ['recollciliatioll'],\n",
       " 'crowcliilg': ['crowcliilg'],\n",
       " 'lnel': ['lnel'],\n",
       " 'platitilig': ['platitilig'],\n",
       " 'llpoll': ['llpoll'],\n",
       " 'sicle': ['sicle'],\n",
       " 'tlae': ['tlae'],\n",
       " 'colupetitiotl': ['colupetitiotl'],\n",
       " 'slnft': ['slnft'],\n",
       " 'iicliisiokl': ['iicliisiokl'],\n",
       " 'lilnself': ['lilnself'],\n",
       " 'brotl': ['brotl'],\n",
       " 'otl': ['otl'],\n",
       " 'lnutual': ['lnutual'],\n",
       " 'altrtlidlll': ['altrtlidlll'],\n",
       " 'golclel': ['golclel'],\n",
       " 'lllle': ['lllle'],\n",
       " 'neiglll': ['neiglll'],\n",
       " 'ollrselves': ['ollrselves'],\n",
       " 'rellderi': ['rellderi'],\n",
       " 'eolllpetition': ['eolllpetition'],\n",
       " 'sllell': ['sllell'],\n",
       " 'eolltl': ['eolltl'],\n",
       " 'aclietory': ['aclietory'],\n",
       " 'eeolleiliatioll': ['eeolleiliatioll'],\n",
       " 'ulldoubted': ['ulldoubted'],\n",
       " 'utlqtlestiolled': ['utlqtlestiolled'],\n",
       " 'unallitr': ['unallitr'],\n",
       " 'cllal': ['cllal'],\n",
       " 'bascoln': ['bascoln'],\n",
       " 'milllleapolis': ['milllleapolis'],\n",
       " 'atlsinson': ['atlsinson'],\n",
       " 'septelilber': ['septelilber'],\n",
       " 'stolle': ['stolle'],\n",
       " 'cliainet': ['cliainet'],\n",
       " 'rlcally': ['rlcally'],\n",
       " 'wrllat': ['wrllat'],\n",
       " 'corclially': ['corclially'],\n",
       " 'arclently': ['arclently'],\n",
       " 'adlilires': ['adlilires'],\n",
       " 'sollrce': ['sollrce'],\n",
       " 'altinclanee': ['altinclanee'],\n",
       " 'cleserwrilig': ['cleserwrilig'],\n",
       " 'cilildrell': ['cilildrell'],\n",
       " 'lloic': ['lloic'],\n",
       " 'tlat': ['tlat'],\n",
       " 'tilese': ['tilese'],\n",
       " 'cil': ['cil'],\n",
       " 'lillgs': ['lillgs'],\n",
       " 'allcl': ['allcl'],\n",
       " 'cecled': ['cecled'],\n",
       " 'desllitioll': ['desllitioll'],\n",
       " 'ozzitld': ['ozzitld'],\n",
       " 'rlleol': ['rlleol'],\n",
       " 'clls': ['clls'],\n",
       " 'cl': ['cl'],\n",
       " 'cotllpetitioll': ['cotllpetitioll'],\n",
       " 'colrlpetition': ['colrlpetition'],\n",
       " 'iln': ['iln'],\n",
       " 'strlltrt': ['strlltrt'],\n",
       " 'cotlisietilla': ['cotlisietilla'],\n",
       " 'clictiolzaries': ['clictiolzaries'],\n",
       " 'solzllelllliilc': ['solzllelllliilc'],\n",
       " 'lell': ['lell'],\n",
       " 'tllezn': ['tllezn'],\n",
       " 'elldeavorint': ['elldeavorint'],\n",
       " 'otiler': ['otiler'],\n",
       " 'encleavoritlo': ['encleavoritlo'],\n",
       " 'tilne': ['tilne'],\n",
       " 'colll': ['colll'],\n",
       " 'eotltest': ['eotltest'],\n",
       " 'villd': ['villd'],\n",
       " 'cellttlry': ['cellttlry'],\n",
       " 'dictiollarr': ['dictiollarr'],\n",
       " 'cle': ['cle'],\n",
       " 'llsts': ['llsts'],\n",
       " 'llstvvllat': ['llstvvllat'],\n",
       " 'ullderstallcls': ['ullderstallcls'],\n",
       " 'lclrce': ['lclrce'],\n",
       " 'sellsse': ['sellsse'],\n",
       " 'llell': ['llell'],\n",
       " 'consiclers': ['consiclers'],\n",
       " 'eolls': ['eolls'],\n",
       " 'atl': ['atl'],\n",
       " 'elllploylnellt': ['elllploylnellt'],\n",
       " 'ilis': ['ilis'],\n",
       " 'utlcler': ['utlcler'],\n",
       " 'ebilae': ['ebilae'],\n",
       " 'etlougll': ['etlougll'],\n",
       " 'precisiotl': ['precisiotl'],\n",
       " 'il': ['il'],\n",
       " 'cjefilli': ['cjefilli'],\n",
       " 'tiolls': ['tiolls'],\n",
       " 'conapetltiola': ['conapetltiola'],\n",
       " 'conlflicting': ['conlflicting'],\n",
       " 'dowtl': ['dowtl'],\n",
       " 'salld': ['salld'],\n",
       " 'arllled': ['arllled'],\n",
       " 'comttlerce': ['comttlerce'],\n",
       " 'tilat': ['tilat'],\n",
       " 'llarles': ['llarles'],\n",
       " 'trallsl': ['trallsl'],\n",
       " 'jacobsell': ['jacobsell'],\n",
       " 'talkillg': ['talkillg'],\n",
       " 'crilllillal': ['crilllillal'],\n",
       " 'strllt': ['strllt'],\n",
       " 'conflictillg': ['conflictillg'],\n",
       " 'dolaolllillated': ['dolaolllillated'],\n",
       " 'llpelitioll': ['llpelitioll'],\n",
       " 'colnpetitioul': ['colnpetitioul'],\n",
       " 'trll': ['trll'],\n",
       " 'oollllcls': ['oollllcls'],\n",
       " 'llk': ['llk'],\n",
       " 'lntl': ['lntl'],\n",
       " 'stl': ['stl'],\n",
       " 'lilizited': ['lilizited'],\n",
       " 'collstittiollal': ['collstittiollal'],\n",
       " 'statllte': ['statllte'],\n",
       " 'rllggle': ['rllggle'],\n",
       " 'lzollaclaries': ['lzollaclaries'],\n",
       " 'lnove': ['lnove'],\n",
       " 'factlltie': ['factlltie'],\n",
       " 'pllrstlit': ['pllrstlit'],\n",
       " 'elillood': ['elillood'],\n",
       " 'alllell': ['alllell'],\n",
       " 'letlt': ['letlt'],\n",
       " 'qllalificatioll': ['qllalificatioll'],\n",
       " 'zzlillc': ['zzlillc'],\n",
       " 'silllple': ['silllple'],\n",
       " 'obviralls': ['obviralls'],\n",
       " 'difficlllties': ['difficlllties'],\n",
       " 'valli': ['valli'],\n",
       " 'lilce': ['lilce'],\n",
       " 'aziallr': ['aziallr'],\n",
       " 'svllell': ['svllell'],\n",
       " 'lnelltioned': ['lnelltioned'],\n",
       " 'tearillg': ['tearillg'],\n",
       " 'lclil': ['lclil'],\n",
       " 'illsufficiellt': ['illsufficiellt'],\n",
       " 'xllpply': ['xllpply'],\n",
       " 'stlcll': ['stlcll'],\n",
       " 'illcolplete': ['illcolplete'],\n",
       " 'inlperfeeit': ['inlperfeeit'],\n",
       " 'pictllre': ['pictllre'],\n",
       " 'strllgg': ['strllgg'],\n",
       " 'ttltesz': ['ttltesz'],\n",
       " 'clescrilde': ['clescrilde'],\n",
       " 'cotoopotofloll': ['cotoopotofloll'],\n",
       " 'llollg': ['llollg'],\n",
       " 'exrell': ['exrell'],\n",
       " 'wloell': ['wloell'],\n",
       " 'lli': ['lli'],\n",
       " 'llc': ['llc'],\n",
       " 'lilnitations': ['lilnitations'],\n",
       " 'clo': ['clo'],\n",
       " 'iclea': ['iclea'],\n",
       " 'coillpttitioil': ['coillpttitioil'],\n",
       " 'elelnelljc': ['elelnelljc'],\n",
       " 'orcler': ['orcler'],\n",
       " 'relacler': ['relacler'],\n",
       " 'neally': ['neally'],\n",
       " 'tllilld': ['tllilld'],\n",
       " 'tlie': ['tlie'],\n",
       " 'prilzciple': ['prilzciple'],\n",
       " 'oltltior': ['oltltior'],\n",
       " 'licll': ['licll'],\n",
       " 'wllerevel': ['wllerevel'],\n",
       " 'lfotllil': ['lfotllil'],\n",
       " 'cotllci': ['cotllci'],\n",
       " 'ollt': ['ollt'],\n",
       " 'fllndal': ['fllndal'],\n",
       " 'lnutalilfll': ['lnutalilfll'],\n",
       " 'colrlletitiolz': ['colrlletitiolz'],\n",
       " 'alllat': ['alllat'],\n",
       " 'tllexl': ['tllexl'],\n",
       " 'iilciple': ['iilciple'],\n",
       " 'eqllally': ['eqllally'],\n",
       " 'fainiliar': ['fainiliar'],\n",
       " 'natlll': ['natlll'],\n",
       " 'reslllti': ['reslllti'],\n",
       " 'stlrvi': ['stlrvi'],\n",
       " 'ellvirollinellt': ['ellvirollinellt'],\n",
       " 'partictllar': ['partictllar'],\n",
       " 'qtlite': ['qtlite'],\n",
       " 'fclllziliar': ['fclllziliar'],\n",
       " 'olletllocls': ['olletllocls'],\n",
       " 'pearallce': ['pearallce'],\n",
       " 'epocll': ['epocll'],\n",
       " 'makillg': ['makillg'],\n",
       " 'origill': ['origill'],\n",
       " 'brollgllt': ['brollgllt'],\n",
       " 'otlt': ['otlt'],\n",
       " 'llard': ['llard'],\n",
       " 'crllel': ['crllel'],\n",
       " 'strl': ['strl'],\n",
       " 'rollsseall': ['rollsseall'],\n",
       " 'mild': ['mild'],\n",
       " 'clescriptiosls': ['clescriptiosls'],\n",
       " 'collcepticall': ['collcepticall'],\n",
       " 'itl': ['itl'],\n",
       " 'tootll': ['tootll'],\n",
       " 'ritll': ['ritll'],\n",
       " 'ravill': ['ravill'],\n",
       " 'htl': ['htl'],\n",
       " 'allill': ['allill'],\n",
       " 'glacliatol': ['glacliatol'],\n",
       " 'sllonv': ['sllonv'],\n",
       " 'eattlres': ['eattlres'],\n",
       " 'wllerebr': ['wllerebr'],\n",
       " 'strotlbest': ['strotlbest'],\n",
       " 'clltzllinbest': ['clltzllinbest'],\n",
       " 'clay': ['clay'],\n",
       " 'lleed': ['lleed'],\n",
       " 'turll': ['turll'],\n",
       " 'tllllillld': ['tllllillld'],\n",
       " 'qllal': ['qllal'],\n",
       " 'tlot': ['tlot'],\n",
       " 'mwallace': ['mwallace'],\n",
       " 'lollg': ['lollg'],\n",
       " 'attelltiool': ['attelltiool'],\n",
       " 'paillless': ['paillless'],\n",
       " 'allloilg': ['allloilg'],\n",
       " 'allilncals': ['allilncals'],\n",
       " 'atllotoilt': ['atllotoilt'],\n",
       " 'llgble': ['llgble'],\n",
       " 'cls': ['cls'],\n",
       " 'lnaximutn': ['lnaximutn'],\n",
       " 'elljoylnent': ['elljoylnent'],\n",
       " 'luillillltlln': ['luillillltlln'],\n",
       " 'stlhetfillg': ['stlhetfillg'],\n",
       " 'xvatcll': ['xvatcll'],\n",
       " 'aailalal': ['aailalal'],\n",
       " 'exceptiollal': ['exceptiollal'],\n",
       " 'lnolnents': ['lnolnents'],\n",
       " 'cclll': ['cclll'],\n",
       " 'concltlcle': ['concltlcle'],\n",
       " 'otllerwise': ['otllerwise'],\n",
       " 'sllbsequent': ['sllbsequent'],\n",
       " 'fllrtller': ['fllrtller'],\n",
       " 'lllerelr': ['lllerelr'],\n",
       " 'tllc': ['tllc'],\n",
       " 'offsldril': ['offsldril'],\n",
       " 'colnpaniolzs': ['colnpaniolzs'],\n",
       " 'lnl': ['lnl'],\n",
       " 'artlollg': ['artlollg'],\n",
       " 'bxistellce': ['bxistellce'],\n",
       " 'xvinislll': ['xvinislll'],\n",
       " 'weapolls': ['weapolls'],\n",
       " 'llulnan': ['llulnan'],\n",
       " 'llasten': ['llasten'],\n",
       " 'orgallie': ['orgallie'],\n",
       " 'emergellce': ['emergellce'],\n",
       " 'prilllitize': ['prilllitize'],\n",
       " 'aililnals': ['aililnals'],\n",
       " 'apparelltly': ['apparelltly'],\n",
       " 'eolle': ['eolle'],\n",
       " 'tnigntily': ['tnigntily'],\n",
       " 'ullceasillt': ['ullceasillt'],\n",
       " 'evollltioll': ['evollltioll'],\n",
       " 'acllievement': ['acllievement'],\n",
       " 'ellds': ['ellds'],\n",
       " 'grall': ['grall'],\n",
       " 'lelllx': ['lelllx'],\n",
       " 'faintly': ['faintly'],\n",
       " 'apprellelld': ['apprellelld'],\n",
       " 'lllall': ['lllall'],\n",
       " 'rlerar': ['rlerar'],\n",
       " 'ldeginnilags': ['ldeginnilags'],\n",
       " 'ftltlclalnelltal': ['ftltlclalnelltal'],\n",
       " 'alliluate': ['alliluate'],\n",
       " 'lligller': ['lligller'],\n",
       " 'illd': ['illd'],\n",
       " 'lldes': ['lldes'],\n",
       " 'slatlghter': ['slatlghter'],\n",
       " 'slaugllter': ['slaugllter'],\n",
       " 'bradllally': ['bradllally'],\n",
       " 'clisllonorable': ['clisllonorable'],\n",
       " 'gaitl': ['gaitl'],\n",
       " 'colllel': ['colllel'],\n",
       " 'woll': ['woll'],\n",
       " 'battle': ['battle'],\n",
       " 'belollt': ['belollt'],\n",
       " 'ecollolllic': ['ecollolllic'],\n",
       " 'illdllstry': ['illdllstry'],\n",
       " 'tilnes': ['tilnes'],\n",
       " 'colrlpetitive': ['colrlpetitive'],\n",
       " 'foulld': ['foulld'],\n",
       " 'svithitl': ['svithitl'],\n",
       " 'fralne': ['fralne'],\n",
       " 'tellt': ['tellt'],\n",
       " 'colltinlled': ['colltinlled'],\n",
       " 'plalle': ['plalle'],\n",
       " 'incolnpatible': ['incolnpatible'],\n",
       " 'pil': ['pil'],\n",
       " 'recellt': ['recellt'],\n",
       " 'llollorable': ['llollorable'],\n",
       " 'colnpetitive': ['colnpetitive'],\n",
       " 'wllereby': ['wllereby'],\n",
       " 'secllred': ['secllred'],\n",
       " 'tllajc': ['tllajc'],\n",
       " 'lla': ['lla'],\n",
       " 'falltll': ['falltll'],\n",
       " 'outsicle': ['outsicle'],\n",
       " 'sillce': ['sillce'],\n",
       " 'begillnillg': ['begillnillg'],\n",
       " 'centtlry': ['centtlry'],\n",
       " 'iolcreasillb': ['iolcreasillb'],\n",
       " 'illtellsity': ['illtellsity'],\n",
       " 'cllik': ['cllik'],\n",
       " 'ell': ['ell'],\n",
       " 'ltlasred': ['ltlasred'],\n",
       " 'lllally': ['lllally'],\n",
       " 'ullwllolesollle': ['ullwllolesollle'],\n",
       " 'conclitio': ['conclitio'],\n",
       " 'aild': ['aild'],\n",
       " 'llllllllderless': ['llllllllderless'],\n",
       " 'installces': ['installces'],\n",
       " 'tll': ['tll'],\n",
       " 'falniliar': ['falniliar'],\n",
       " 'sidetlt': ['sidetlt'],\n",
       " 'plll': ['plll'],\n",
       " 'leclared': ['leclared'],\n",
       " 'goverlllnellt': ['goverlllnellt'],\n",
       " 'cohlpetitioll': ['cohlpetitioll'],\n",
       " 'lliaolself': ['lliaolself'],\n",
       " 'sllrprised': ['sllrprised'],\n",
       " 'filad': ['filad'],\n",
       " 'profolll': ['profolll'],\n",
       " 'illapressioll': ['illapressioll'],\n",
       " 'pregllant': ['pregllant'],\n",
       " 'llleaning': ['llleaning'],\n",
       " 'lllysteries': ['lllysteries'],\n",
       " 'allel': ['allel'],\n",
       " 'revealillg': ['revealillg'],\n",
       " 'reconciliations': ['reconciliations'],\n",
       " 'llulnallity': ['llulnallity'],\n",
       " 'eacly': ['eacly'],\n",
       " 'alnollg': ['alnollg'],\n",
       " 'atlilllals': ['atlilllals'],\n",
       " 'elllargelnellt': ['elllargelnellt'],\n",
       " 'telnptation': ['telnptation'],\n",
       " 'tlpon': ['tlpon'],\n",
       " 'earl': ['earl'],\n",
       " 'adattls': ['adattls'],\n",
       " 'pursllilag': ['pursllilag'],\n",
       " 'colulllon': ['colulllon'],\n",
       " 'grollps': ['grollps'],\n",
       " 'kil': ['kil'],\n",
       " 'gollen': ['gollen'],\n",
       " 'comltloll': ['comltloll'],\n",
       " 'agailn': ['agailn'],\n",
       " 'llotice': ['llotice'],\n",
       " 'pernlallent': ['pernlallent'],\n",
       " 'orgailization': ['orgailization'],\n",
       " 'tllell': ['tllell'],\n",
       " 'cliscover': ['cliscover'],\n",
       " 'embracillg': ['embracillg'],\n",
       " 'zalitlli': ['zalitlli'],\n",
       " 'illsllite': ['illsllite'],\n",
       " 'rollps': ['rollps'],\n",
       " 'llaving': ['llaving'],\n",
       " 'szlall': ['szlall'],\n",
       " 'illiolaty': ['illiolaty'],\n",
       " 'lzatioll': ['lzatioll'],\n",
       " 'coln': ['coln'],\n",
       " 'etitioll': ['etitioll'],\n",
       " 'cloes': ['cloes'],\n",
       " 'alolle': ['alolle'],\n",
       " 'walitll': ['walitll'],\n",
       " 'sympatlly': ['sympatlly'],\n",
       " 'benevoletlce': ['benevoletlce'],\n",
       " 'pllldllc': ['pllldllc'],\n",
       " 'clirected': ['clirected'],\n",
       " 'llulllallitariaoli': ['llulllallitariaoli'],\n",
       " 'gtllells': ['gtllells'],\n",
       " 'rutl': ['rutl'],\n",
       " 'lless': ['lless'],\n",
       " 'uleolll': ['uleolll'],\n",
       " 'grotlp': ['grotlp'],\n",
       " 'becollles': ['becollles'],\n",
       " 'splle': ['splle'],\n",
       " 'luilder': ['luilder'],\n",
       " 'illay': ['illay'],\n",
       " 'ecolne': ['ecolne'],\n",
       " 'walittless': ['walittless'],\n",
       " 'llloclern': ['llloclern'],\n",
       " 'pllilantllropy': ['pllilantllropy'],\n",
       " 'attellcls': ['attellcls'],\n",
       " 'ecotlomio': ['ecotlomio'],\n",
       " 'lterlaational': ['lterlaational'],\n",
       " 'potellt': ['potellt'],\n",
       " 'igllest': ['igllest'],\n",
       " 'inclisticltlal': ['inclisticltlal'],\n",
       " 'altruistll': ['altruistll'],\n",
       " 'eratioll': ['eratioll'],\n",
       " 'llealing': ['llealing'],\n",
       " 'beilevolellce': ['beilevolellce'],\n",
       " 'sometillles': ['sometillles'],\n",
       " 'llurllanitarian': ['llurllanitarian'],\n",
       " 'sllould': ['sllould'],\n",
       " 'weaklless': ['weaklless'],\n",
       " 'cleo': ['cleo'],\n",
       " 'avvorld': ['avvorld'],\n",
       " 'cotls': ['cotls'],\n",
       " 'goetlle': ['goetlle'],\n",
       " 'llospital': ['llospital'],\n",
       " 'sllcll': ['sllcll'],\n",
       " 'apprellelesioll': ['apprellelesioll'],\n",
       " 'tllrotlgll': ['tllrotlgll'],\n",
       " 'sollae': ['sollae'],\n",
       " 'illclividuals': ['illclividuals'],\n",
       " 'individllals': ['individllals'],\n",
       " 'behilld': ['behilld'],\n",
       " 'milcllless': ['milcllless'],\n",
       " 'lessells': ['lessells'],\n",
       " 'tlnfit': ['tlnfit'],\n",
       " 'reprodllction': ['reprodllction'],\n",
       " 'cloe': ['cloe'],\n",
       " 'ilacreasing': ['ilacreasing'],\n",
       " 'extellt': ['extellt'],\n",
       " 'pllts': ['pllts'],\n",
       " 'cliscourages': ['cliscourages'],\n",
       " 'inarl': ['inarl'],\n",
       " 'vllile': ['vllile'],\n",
       " 'attitucle': ['attitucle'],\n",
       " 'towarcls': ['towarcls'],\n",
       " 'crimillal': ['crimillal'],\n",
       " 'increasilog': ['increasilog'],\n",
       " 'inclillation': ['inclillation'],\n",
       " 'cletain': ['cletain'],\n",
       " 'idellce': ['idellce'],\n",
       " 'malacly': ['malacly'],\n",
       " 'sanitatioll': ['sanitatioll'],\n",
       " 'lneasllres': ['lneasllres'],\n",
       " 'luoderll': ['luoderll'],\n",
       " 'cinrilization': ['cinrilization'],\n",
       " 'nllo': ['nllo'],\n",
       " 'conlparisons': ['conlparisons'],\n",
       " ...}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the queue with all unknown words\n",
    "known_set = set(known_words)\n",
    "graph = Graph(known_set)\n",
    "results: Dict[str, List[str]] = {}\n",
    "unknown_words = not_found\n",
    "queue = deque([Node(word, None, None) for word in unknown_words])\n",
    "for word in unknown_words:\n",
    "    graph.mark_visited(word, [word])\n",
    "\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lllealls': ['lllealls', 'llleans', 'lneans'],\n",
       " 'lnall': ['lnall'],\n",
       " 'llilll': ['llilll', 'llinl', 'nilll', 'ninl'],\n",
       " 'governlllent': ['governlllent'],\n",
       " 'clifferellt': ['clifferellt'],\n",
       " 'recogllition': ['recogllition', 'recognition'],\n",
       " 'illforlnation': ['illforlnation'],\n",
       " 'collvictioll': ['collvictioll', 'collviction', 'conviction'],\n",
       " 'llloderll': ['llloderll', 'lnoderll'],\n",
       " 'eonstitlltiolls': ['eonstitlltiolls', 'eonstitntiolls', 'eonstitntions'],\n",
       " 'llatiollal': ['llatiollal', 'natiollal', 'national'],\n",
       " 'recogllitioll': ['recogllitioll'],\n",
       " 'goverlllllent': ['goverlllllent',\n",
       "  'goverlllnent',\n",
       "  'goverlnllent',\n",
       "  'goverlnnent'],\n",
       " 'lllan': ['lllan'],\n",
       " 'lleecls': ['lleecls'],\n",
       " 'llotlling': ['llotlling', 'llotning', 'notning'],\n",
       " 'comllloll': ['comllloll', 'comlllon', 'comlnon'],\n",
       " 'llalld': ['llalld', 'nalld', 'nand'],\n",
       " 'alnericall': ['alnericall'],\n",
       " 'lnell': ['lnell'],\n",
       " 'lllel': ['lllel'],\n",
       " 'eolllpetition': ['eolllpetition'],\n",
       " 'colll': ['colll'],\n",
       " 'cellttlry': ['cellttlry'],\n",
       " 'llell': ['llell'],\n",
       " 'conflictillg': ['conflictillg', 'conflicting'],\n",
       " 'silllple': ['silllple'],\n",
       " 'llollg': ['llollg', 'nollg', 'nong'],\n",
       " 'lllall': ['lllall', 'nlall', 'nlan'],\n",
       " 'illdllstry': ['illdllstry', 'illdnstry', 'indnstry'],\n",
       " 'lllally': ['lllally', 'lllany'],\n",
       " 'goverlllnellt': ['goverlllnellt',\n",
       "  'goverlnnellt',\n",
       "  'goverlnllent',\n",
       "  'goverlnnent'],\n",
       " 'alnollg': ['alnollg'],\n",
       " 'tllell': ['tllell', 'tllen', 'tnen'],\n",
       " 'sometillles': ['sometillles'],\n",
       " 'llleall': ['llleall', 'lneall'],\n",
       " 'collle': ['collle'],\n",
       " 'developlllellt': ['developlllellt', 'developlllent', 'developlnent'],\n",
       " 'lllind': ['lllind'],\n",
       " 'combinatiolls': ['combinatiolls', 'combinations'],\n",
       " 'lllllst': ['lllllst', 'lllnst', 'lnnst'],\n",
       " 'conclitiolls': ['conclitiolls'],\n",
       " 'colllpetitio': ['colllpetitio'],\n",
       " 'silllply': ['silllply'],\n",
       " 'lllilld': ['lllilld', 'lnilld'],\n",
       " 'nlally': ['nlally'],\n",
       " 'traillillg': ['traillillg', 'trainillg', 'training'],\n",
       " 'btlsilless': ['btlsilless'],\n",
       " 'folllld': ['folllld', 'fonlld', 'fonnd'],\n",
       " 'fullctioll': ['fullctioll', 'functioll', 'function'],\n",
       " 'lollclon': ['lollclon'],\n",
       " 'moclerll': ['moclerll'],\n",
       " 'lllliversities': ['lllliversities', 'nlliversities', 'nniversities'],\n",
       " 'eomlllereial': ['eomlllereial'],\n",
       " 'edlleatioll': ['edlleatioll', 'edneatioll', 'edneation'],\n",
       " 'lnally': ['lnally'],\n",
       " 'illstitutioll': ['illstitutioll', 'institutioll', 'institution'],\n",
       " 'lllakes': ['lllakes'],\n",
       " 'anlollg': ['anlollg'],\n",
       " 'callillg': ['callillg', 'canillg', 'caning'],\n",
       " 'illlportallt': ['illlportallt', 'ilnportallt', 'ilnportant'],\n",
       " 'eclucatioll': ['eclucatioll'],\n",
       " 'solllething': ['solllething'],\n",
       " 'collllected': ['collllected', 'conllected', 'connected'],\n",
       " 'llulnber': ['llulnber'],\n",
       " 'llle': ['llle'],\n",
       " 'eallnot': ['eallnot', 'eannot'],\n",
       " 'brallelles': ['brallelles', 'brallenes', 'branenes'],\n",
       " 'intilllately': ['intilllately', 'intinlately'],\n",
       " 'illcludes': ['illcludes'],\n",
       " 'orgallizatioll': ['orgallizatioll', 'organizatioll', 'organization'],\n",
       " 'proviclillg': ['proviclillg'],\n",
       " 'elelllents': ['elelllents', 'elelnents'],\n",
       " 'hilll': ['hilll'],\n",
       " 'cloillg': ['cloillg'],\n",
       " 'melllbers': ['melllbers'],\n",
       " 'ullcler': ['ullcler'],\n",
       " 'illstructioll': ['illstructioll'],\n",
       " 'econollly': ['econollly', 'econolny'],\n",
       " 'beginllillg': ['beginllillg', 'beginlling', 'beginnillg', 'beginning'],\n",
       " 'strellgthenillg': ['strellgthenillg', 'strellgthening', 'strengthening'],\n",
       " 'penllsylvallia': ['penllsylvallia', 'penllsylvania', 'pennsylvania'],\n",
       " 'pellnsylvallia': ['pellnsylvallia', 'pellnsylvania', 'pennsylvania'],\n",
       " 'fillance': ['fillance', 'finance'],\n",
       " 'tillle': ['tillle'],\n",
       " 'illterestilag': ['illterestilag'],\n",
       " 'illcreasillgly': ['illcreasillgly', 'increasillgly', 'increasingly'],\n",
       " 'lllerel': ['lllerel'],\n",
       " 'elljoying': ['elljoying', 'enjoying'],\n",
       " 'illcreasillg': ['illcreasillg', 'illcreasing', 'increasing'],\n",
       " 'outcollle': ['outcollle'],\n",
       " 'colllplex': ['colllplex'],\n",
       " 'ullderlyillg': ['ullderlyillg', 'ullderlying', 'underlying'],\n",
       " 'fallliliar': ['fallliliar'],\n",
       " 'collsequelltly': ['collsequelltly', 'collsequently', 'consequently'],\n",
       " 'colltl': ['colltl'],\n",
       " 'llly': ['llly'],\n",
       " 'cllildren': ['cllildren'],\n",
       " 'illstances': ['illstances', 'instances'],\n",
       " 'lllatter': ['lllatter'],\n",
       " 'colllplexity': ['colllplexity'],\n",
       " 'lllodern': ['lllodern'],\n",
       " 'llominally': ['llominally', 'llominany', 'nominany'],\n",
       " 'lllean': ['lllean'],\n",
       " 'illeqllality': ['illeqllality', 'illeqnality', 'ineqnality'],\n",
       " 'forllled': ['forllled'],\n",
       " 'wisconsill': ['wisconsill', 'wisconsin'],\n",
       " 'firlll': ['firlll'],\n",
       " 'concerllillg': ['concerllillg', 'concerlling', 'concernillg', 'concerning'],\n",
       " 'freeclolll': ['freeclolll'],\n",
       " 'illstruction': ['illstruction', 'instruction'],\n",
       " 'lilllited': ['lilllited'],\n",
       " 'collclition': ['collclition'],\n",
       " 'cllildrell': ['cllildrell', 'cnildrell'],\n",
       " 'seellls': ['seellls'],\n",
       " 'llen': ['llen', 'nen'],\n",
       " 'indepelldent': ['indepelldent', 'independent'],\n",
       " 'llothing': ['llothing', 'nothing'],\n",
       " 'notllillg': ['notllillg', 'notnillg', 'notning'],\n",
       " 'llletllod': ['llletllod', 'llletnod', 'lnetllod', 'lnetnod'],\n",
       " 'intellectually': ['intellectually',\n",
       "  'intellectuany',\n",
       "  'intenectually',\n",
       "  'intenectuany'],\n",
       " 'ftllfillment': ['ftllfillment', 'ftllfinment', 'ftnfillment', 'ftnfinment'],\n",
       " 'comlllllnity': ['comlllllnity', 'comlllnnity', 'comlnllnity', 'comlnnnity'],\n",
       " 'illissioll': ['illissioll', 'illission', 'inissioll', 'inission'],\n",
       " 'envirollmellt': ['envirollmellt',\n",
       "  'envirollment',\n",
       "  'environmellt',\n",
       "  'environment'],\n",
       " 'astiglllatisill': ['astiglllatisill',\n",
       "  'astiglllatisin',\n",
       "  'astiglnatisill',\n",
       "  'astiglnatisin'],\n",
       " 'illtentioll': ['illtentioll', 'illtention', 'intentioll', 'intention'],\n",
       " 'circutllstallces': ['circutllstallces',\n",
       "  'circutllstances',\n",
       "  'circutnstallces',\n",
       "  'circutnstances'],\n",
       " 'judglllellts': ['judglllellts', 'judglllents', 'judglnellts', 'judglnents'],\n",
       " 'coollbille': ['coollbille', 'coollbine', 'coonbille', 'coonbine'],\n",
       " 'wllolly': ['wllolly', 'wllony', 'wnolly', 'wnony'],\n",
       " 'cllallces': ['cllallces', 'cllances', 'cnallces', 'cnances'],\n",
       " 'colltribllte': ['colltribllte', 'colltribnte', 'contribllte', 'contribnte'],\n",
       " 'lullell': ['lullell', 'lullen', 'lunell', 'lunen'],\n",
       " 'illfluellce': ['illfluellce', 'illfluence', 'influellce', 'influence'],\n",
       " 'eoznlllullity': ['eoznlllullity',\n",
       "  'eoznlllunity',\n",
       "  'eoznlnullity',\n",
       "  'eoznlnunity'],\n",
       " 'collstitlltiollal': ['collstitlltiollal',\n",
       "  'collstitntiollal',\n",
       "  'collstitntional',\n",
       "  'constitlltiollal',\n",
       "  'constitntiollal',\n",
       "  'constitntional'],\n",
       " 'collstlmtllation': ['collstlmtllation',\n",
       "  'collstlmtnation',\n",
       "  'constlmtllation',\n",
       "  'constlmtnation'],\n",
       " 'eilliglltened': ['eilliglltened',\n",
       "  'eilligntened',\n",
       "  'einiglltened',\n",
       "  'einigntened'],\n",
       " 'loeallll': ['loeallll', 'loealln', 'loeanll', 'loeann'],\n",
       " 'wlliell': ['wlliell', 'wllien', 'wniell', 'wnien'],\n",
       " 'llollle': ['llollle', 'llolne', 'nollle', 'nolne'],\n",
       " 'flllletioll': ['flllletioll',\n",
       "  'fllnetioll',\n",
       "  'fllnetion',\n",
       "  'fnlletioll',\n",
       "  'fnnetioll',\n",
       "  'fnnetion'],\n",
       " 'tlleoll': ['tlleoll', 'tlleon', 'tneoll', 'tneon'],\n",
       " 'eoznllloll': ['eoznllloll', 'eoznlllon', 'eoznlnoll', 'eoznlnon'],\n",
       " 'extellsiolls': ['extellsiolls', 'extellsions', 'extensiolls', 'extensions'],\n",
       " 'eolllmoll': ['eolllmoll', 'eolllmon', 'eolnmoll', 'eolnmon'],\n",
       " 'fallell': ['fallell', 'fallen', 'fanell', 'fanen'],\n",
       " 'illtellded': ['illtellded', 'illtended', 'intellded', 'intended'],\n",
       " 'collalllon': ['collalllon', 'collalnon', 'conalllon', 'conalnon'],\n",
       " 'wllicll': ['wllicll', 'wllicn', 'wnicll', 'wnicn'],\n",
       " 'opilliolls': ['opilliolls', 'opillions', 'opiniolls', 'opinions'],\n",
       " 'collstituellts': ['collstituellts',\n",
       "  'collstituents',\n",
       "  'constituellts',\n",
       "  'constituents'],\n",
       " 'tllall': ['tllall', 'tllan', 'tnall', 'tnan'],\n",
       " 'pllllldered': ['pllllldered', 'plllndered', 'plnlldered', 'plnndered'],\n",
       " 'instrulllellts': ['instrulllellts',\n",
       "  'instrulllents',\n",
       "  'instrulnellts',\n",
       "  'instrulnents'],\n",
       " 'abanclotsllllent': ['abanclotsllllent',\n",
       "  'abanclotsllnent',\n",
       "  'abanclotsnllent',\n",
       "  'abanclotsnnent'],\n",
       " 'maellillery': ['maellillery', 'maellinery', 'maenillery', 'maeninery'],\n",
       " 'dllrillg': ['dllrillg', 'dllring', 'dnrillg', 'dnring'],\n",
       " 'ullclerstalldillg': ['ullclerstalldillg',\n",
       "  'ullclerstandillg',\n",
       "  'ullclerstanding',\n",
       "  'unclerstalldillg',\n",
       "  'unclerstandillg',\n",
       "  'unclerstanding'],\n",
       " 'collditiolls': ['collditiolls', 'collditions', 'conditiolls', 'conditions'],\n",
       " 'toucllillg': ['toucllillg', 'touclling', 'toucnillg', 'toucning'],\n",
       " 'fllrllishes': ['fllrllishes', 'fllrnishes', 'fnrllishes', 'fnrnishes'],\n",
       " 'cllanlpiolls': ['cllanlpiolls', 'cllanlpions', 'cnanlpiolls', 'cnanlpions'],\n",
       " 'dolllillated': ['dolllillated', 'dolllinated', 'dolnillated', 'dolninated'],\n",
       " 'cllristiallity': ['cllristiallity',\n",
       "  'cllristianity',\n",
       "  'cnristiallity',\n",
       "  'cnristianity'],\n",
       " 'cullilillg': ['cullilillg', 'culliling', 'cunilillg', 'cuniling'],\n",
       " 'tlleologialls': ['tlleologialls',\n",
       "  'tlleologians',\n",
       "  'tneologialls',\n",
       "  'tneologians'],\n",
       " 'bellillcl': ['bellillcl', 'bellincl', 'benillcl', 'benincl'],\n",
       " 'gallizillg': ['gallizillg', 'gallizing', 'ganizillg', 'ganizing'],\n",
       " 'maclliller': ['maclliller', 'maclliner', 'macniller', 'macniner'],\n",
       " 'lllanifestatioll': ['lllanifestatioll',\n",
       "  'lllanifestation',\n",
       "  'lnanifestatioll',\n",
       "  'lnanifestation'],\n",
       " 'cllll': ['cllll', 'clln', 'cnll', 'cnn'],\n",
       " 'celltllries': ['celltllries', 'celltnries', 'centllries', 'centnries'],\n",
       " 'cllristiall': ['cllristiall', 'cllristian', 'cnristiall', 'cnristian'],\n",
       " 'pllilosopllers': ['pllilosopllers',\n",
       "  'pllilosopners',\n",
       "  'pnilosopllers',\n",
       "  'pnilosopners'],\n",
       " 'coollpesitioll': ['coollpesitioll',\n",
       "  'coollpesition',\n",
       "  'coonpesitioll',\n",
       "  'coonpesition'],\n",
       " 'recollciliatioll': ['recollciliatioll',\n",
       "  'recollciliation',\n",
       "  'reconciliatioll',\n",
       "  'reconciliation'],\n",
       " 'llpoll': ['llpoll', 'llpon', 'npoll', 'npon'],\n",
       " 'lllle': ['lllle', 'llne', 'nlle', 'nne'],\n",
       " 'sllell': ['sllell', 'sllen', 'snell', 'snen'],\n",
       " 'eeolleiliatioll': ['eeolleiliatioll',\n",
       "  'eeolleiliation',\n",
       "  'eeoneiliatioll',\n",
       "  'eeoneiliation'],\n",
       " 'milllleapolis': ['milllleapolis',\n",
       "  'millneapolis',\n",
       "  'minlleapolis',\n",
       "  'minneapolis'],\n",
       " 'desllitioll': ['desllitioll', 'desllition', 'desnitioll', 'desnition'],\n",
       " 'cotllpetitioll': ['cotllpetitioll',\n",
       "  'cotllpetition',\n",
       "  'cotnpetitioll',\n",
       "  'cotnpetition'],\n",
       " 'solzllelllliilc': ['solzllelllliilc',\n",
       "  'solzllenlliilc',\n",
       "  'solzllenniilc',\n",
       "  'solznelllliilc',\n",
       "  'solznenlliilc',\n",
       "  'solznenniilc'],\n",
       " 'llstvvllat': ['llstvvllat', 'llstvvnat', 'nstvvllat', 'nstvvnat'],\n",
       " 'ullderstallcls': ['ullderstallcls',\n",
       "  'ullderstancls',\n",
       "  'understallcls',\n",
       "  'understancls'],\n",
       " 'elllploylnellt': ['elllploylnellt',\n",
       "  'elllploylnent',\n",
       "  'elnploylnellt',\n",
       "  'elnploylnent'],\n",
       " 'crilllillal': ['crilllillal', 'crilllinal', 'crilnillal', 'crilninal'],\n",
       " 'dolaolllillated': ['dolaolllillated',\n",
       "  'dolaolllinated',\n",
       "  'dolaolnillated',\n",
       "  'dolaolninated'],\n",
       " 'llpelitioll': ['llpelitioll', 'llpelition', 'npelitioll', 'npelition'],\n",
       " 'oollllcls': ['oollllcls', 'oollncls', 'oonllcls', 'oonncls'],\n",
       " 'collstittiollal': ['collstittiollal',\n",
       "  'collstittional',\n",
       "  'constittiollal',\n",
       "  'constittional'],\n",
       " 'alllell': ['alllell', 'alllen', 'alnell', 'alnen'],\n",
       " 'qllalificatioll': ['qllalificatioll',\n",
       "  'qllalification',\n",
       "  'qnalificatioll',\n",
       "  'qnalification'],\n",
       " 'svllell': ['svllell', 'svllen', 'svnell', 'svnen'],\n",
       " 'illsufficiellt': ['illsufficiellt',\n",
       "  'illsufficient',\n",
       "  'insufficiellt',\n",
       "  'insufficient'],\n",
       " 'tllilld': ['tllilld', 'tllind', 'tnilld', 'tnind'],\n",
       " 'eqllally': ['eqllally', 'eqllany', 'eqnally', 'eqnany'],\n",
       " 'ellvirollinellt': ['ellvirollinellt',\n",
       "  'ellvironinellt',\n",
       "  'ellvironinent',\n",
       "  'envirollinellt',\n",
       "  'environinellt',\n",
       "  'environinent'],\n",
       " 'olletllocls': ['olletllocls', 'olletnocls', 'onetllocls', 'onetnocls'],\n",
       " 'brollgllt': ['brollgllt', 'brollgnt', 'brongllt', 'brongnt'],\n",
       " 'rollsseall': ['rollsseall', 'rollssean', 'ronsseall', 'ronssean'],\n",
       " 'collcepticall': ['collcepticall',\n",
       "  'collceptican',\n",
       "  'concepticall',\n",
       "  'conceptican'],\n",
       " 'allill': ['allill', 'allin', 'anill', 'anin'],\n",
       " 'clltzllinbest': ['clltzllinbest',\n",
       "  'clltzninbest',\n",
       "  'cntzllinbest',\n",
       "  'cntzninbest'],\n",
       " 'tllllillld': ['tllllillld',\n",
       "  'tllnillld',\n",
       "  'tllnilnd',\n",
       "  'tnllillld',\n",
       "  'tnnillld',\n",
       "  'tnnilnd'],\n",
       " 'luillillltlln': ['luillillltlln',\n",
       "  'luillilntlln',\n",
       "  'luillilntnn',\n",
       "  'luinillltlln',\n",
       "  'luinilntlln',\n",
       "  'luinilntnn'],\n",
       " 'fllrtller': ['fllrtller', 'fllrtner', 'fnrtller', 'fnrtner'],\n",
       " 'ullceasillt': ['ullceasillt', 'ullceasint', 'unceasillt', 'unceasint'],\n",
       " 'evollltioll': ['evollltioll', 'evollltion', 'evolntioll', 'evolntion'],\n",
       " 'apprellelld': ['apprellelld', 'apprellend', 'apprenelld', 'apprenend'],\n",
       " 'lligller': ['lligller', 'lligner', 'nigller', 'nigner'],\n",
       " 'bradllally': ['bradllally', 'bradllany', 'bradnally', 'bradnany'],\n",
       " 'ecollolllic': ['ecollolllic', 'ecollolnic'],\n",
       " 'colltinlled': ['colltinlled', 'colltinned', 'continlled', 'continned'],\n",
       " 'llollorable': ['llollorable', 'llonorable', 'nollorable', 'nonorable'],\n",
       " 'falltll': ['falltll', 'falltn', 'fantll', 'fantn'],\n",
       " 'begillnillg': ['begillnillg', 'begillning', 'beginnillg', 'beginning'],\n",
       " 'illtellsity': ['illtellsity', 'illtensity', 'intellsity', 'intensity'],\n",
       " 'ullwllolesollle': ['ullwllolesollle',\n",
       "  'ullwnolesollle',\n",
       "  'ullwnolesolne',\n",
       "  'unwllolesollle',\n",
       "  'unwnolesollle',\n",
       "  'unwnolesolne'],\n",
       " 'llllllllderless': ['llllllllderless',\n",
       "  'llnllllderless',\n",
       "  'llnnllderless',\n",
       "  'llnnnderless',\n",
       "  'nllllllderless',\n",
       "  'nnllllderless',\n",
       "  'nnnllderless',\n",
       "  'nnnnderless'],\n",
       " 'illapressioll': ['illapressioll',\n",
       "  'illapression',\n",
       "  'inapressioll',\n",
       "  'inapression'],\n",
       " 'llulnallity': ['llulnallity', 'llulnanity', 'nulnallity', 'nulnanity'],\n",
       " 'elllargelnellt': ['elllargelnellt',\n",
       "  'elllargelnent',\n",
       "  'elnargelnellt',\n",
       "  'elnargelnent'],\n",
       " 'illsllite': ['illsllite', 'illsnite', 'insllite', 'insnite'],\n",
       " 'pllldllc': ['pllldllc', 'pllldnc', 'plndllc', 'plndnc'],\n",
       " 'llulllallitariaoli': ['llulllallitariaoli',\n",
       "  'llulnallitariaoli',\n",
       "  'llulnanitariaoli',\n",
       "  'nulllallitariaoli',\n",
       "  'nulnallitariaoli',\n",
       "  'nulnanitariaoli'],\n",
       " 'gtllells': ['gtllells', 'gtllens', 'gtnells', 'gtnens'],\n",
       " 'pllilantllropy': ['pllilantllropy',\n",
       "  'pllilantnropy',\n",
       "  'pnilantllropy',\n",
       "  'pnilantnropy'],\n",
       " 'llurllanitarian': ['llurllanitarian',\n",
       "  'llurnanitarian',\n",
       "  'nurllanitarian',\n",
       "  'nurnanitarian'],\n",
       " 'sllcll': ['sllcll', 'sllcn', 'sncll', 'sncn'],\n",
       " 'apprellelesioll': ['apprellelesioll',\n",
       "  'apprellelesion',\n",
       "  'apprenelesioll',\n",
       "  'apprenelesion'],\n",
       " 'tllrotlgll': ['tllrotlgll', 'tllrotlgn', 'tnrotlgll', 'tnrotlgn'],\n",
       " 'tllrollt': ['tllrollt', 'tllront', 'tnrollt', 'tnront'],\n",
       " 'llomilliolls': ['llomilliolls',\n",
       "  'llominiolls',\n",
       "  'llominions',\n",
       "  'nomilliolls',\n",
       "  'nominiolls',\n",
       "  'nominions'],\n",
       " 'uncollsciollsly': ['uncollsciollsly',\n",
       "  'uncollscionsly',\n",
       "  'unconsciollsly',\n",
       "  'unconscionsly'],\n",
       " 'collstitllte': ['collstitllte', 'collstitnte', 'constitllte', 'constitnte'],\n",
       " 'elllillent': ['elllillent', 'elllinent', 'elnillent', 'elninent'],\n",
       " 'illustratioll': ['illustratioll',\n",
       "  'illustration',\n",
       "  'inustratioll',\n",
       "  'inustration'],\n",
       " 'fllrllislles': ['fllrllislles',\n",
       "  'fllrnislles',\n",
       "  'fllrnisnes',\n",
       "  'fnrllislles',\n",
       "  'fnrnislles',\n",
       "  'fnrnisnes'],\n",
       " 'llallel': ['llallel', 'llanel', 'nallel', 'nanel'],\n",
       " 'collsonallce': ['collsonallce', 'collsonance', 'consonallce', 'consonance'],\n",
       " 'portllllity': ['portllllity', 'portllnity', 'portnllity', 'portnnity'],\n",
       " 'ecollolllics': ['ecollolllics', 'ecollolnics'],\n",
       " 'esselltially': ['esselltially', 'esselltiany', 'essentially', 'essentiany'],\n",
       " 'attaillillg': ['attaillillg', 'attailling', 'attainillg', 'attaining'],\n",
       " 'gallizatioll': ['gallizatioll', 'gallization', 'ganizatioll', 'ganization'],\n",
       " 'ldllysicialls': ['ldllysicialls',\n",
       "  'ldllysicians',\n",
       "  'ldnysicialls',\n",
       "  'ldnysicians'],\n",
       " 'tllorollghly': ['tllorollghly', 'tlloronghly', 'tnorollghly', 'tnoronghly'],\n",
       " 'colltinually': ['colltinually', 'colltinuany', 'continually', 'continuany'],\n",
       " 'lletllod': ['lletllod', 'lletnod', 'netllod', 'netnod'],\n",
       " 'nallagetllel': ['nallagetllel', 'nallagetnel', 'nanagetllel', 'nanagetnel'],\n",
       " 'nailltellallce': ['nailltellallce',\n",
       "  'nailltenallce',\n",
       "  'nailltenance',\n",
       "  'naintellallce',\n",
       "  'naintenallce',\n",
       "  'naintenance'],\n",
       " 'illdividllallv': ['illdividllallv',\n",
       "  'illdividnallv',\n",
       "  'illdividnanv',\n",
       "  'individllallv',\n",
       "  'individnallv',\n",
       "  'individnanv'],\n",
       " 'fllrllislled': ['fllrllislled',\n",
       "  'fllrnislled',\n",
       "  'fllrnisned',\n",
       "  'fnrllislled',\n",
       "  'fnrnislled',\n",
       "  'fnrnisned'],\n",
       " 'illllstratioll': ['illllstratioll',\n",
       "  'illnstratioll',\n",
       "  'illnstration',\n",
       "  'inllstratioll',\n",
       "  'innstratioll',\n",
       "  'innstration'],\n",
       " 'llollopols': ['llollopols', 'llonopols', 'nollopols', 'nonopols'],\n",
       " 'llclerstalld': ['llclerstalld', 'llclerstand', 'nclerstalld', 'nclerstand'],\n",
       " 'ecollotllic': ['ecollotllic', 'ecollotnic', 'econotllic', 'econotnic'],\n",
       " 'lllailltellance': ['lllailltellance',\n",
       "  'lllaintellance',\n",
       "  'lllaintenance',\n",
       "  'lnailltellance',\n",
       "  'lnaintellance',\n",
       "  'lnaintenance'],\n",
       " 'govelnillelltal': ['govelnillelltal',\n",
       "  'govelnillental',\n",
       "  'govelninelltal',\n",
       "  'govelninental'],\n",
       " 'lllovelnelltvs': ['lllovelnelltvs',\n",
       "  'lllovelnentvs',\n",
       "  'lnovelnelltvs',\n",
       "  'lnovelnentvs'],\n",
       " 'ullderstalld': ['ullderstalld', 'ullderstand', 'understalld', 'understand'],\n",
       " 'sllllt': ['sllllt', 'sllnt', 'snllt', 'snnt'],\n",
       " 'otllicll': ['otllicll', 'otllicn', 'otnicll', 'otnicn'],\n",
       " 'follllclations': ['follllclations',\n",
       "  'follnclations',\n",
       "  'fonllclations',\n",
       "  'fonnclations'],\n",
       " 'nallicll': ['nallicll', 'nallicn', 'nanicll', 'nanicn'],\n",
       " 'jllicll': ['jllicll', 'jllicn', 'jnicll', 'jnicn'],\n",
       " 'acllievelllellts': ['acllievelllellts',\n",
       "  'acllievelnellts',\n",
       "  'acllievelnents',\n",
       "  'acnievelllellts',\n",
       "  'acnievelnellts',\n",
       "  'acnievelnents'],\n",
       " 'ecollollaic': ['ecollollaic', 'ecollonaic', 'econollaic', 'econonaic'],\n",
       " 'acljustlllellts': ['acljustlllellts',\n",
       "  'acljustlllents',\n",
       "  'acljustlnellts',\n",
       "  'acljustlnents'],\n",
       " 'lllovemellts': ['lllovemellts', 'lllovements', 'lnovemellts', 'lnovements'],\n",
       " 'colltrolled': ['colltrolled', 'colltroned', 'controlled', 'controned'],\n",
       " 'millimtltll': ['millimtltll', 'millimtltn', 'minimtltll', 'minimtltn'],\n",
       " 'illasmllcll': ['illasmllcll',\n",
       "  'illasmncll',\n",
       "  'illasmncn',\n",
       "  'inasmllcll',\n",
       "  'inasmncll',\n",
       "  'inasmncn'],\n",
       " 'sllblllit': ['sllblllit', 'sllblnit', 'snblllit', 'snblnit'],\n",
       " 'colllldetitioll': ['colllldetitioll',\n",
       "  'collndetitioll',\n",
       "  'collndetition',\n",
       "  'conlldetitioll',\n",
       "  'conndetitioll',\n",
       "  'conndetition'],\n",
       " 'ecoololllically': ['ecoololllically',\n",
       "  'ecoololllicany',\n",
       "  'ecoololnically',\n",
       "  'ecoololnicany'],\n",
       " 'ridellillb': ['ridellillb', 'ridellinb', 'ridenillb', 'rideninb'],\n",
       " 'sllffieiellt': ['sllffieiellt', 'sllffieient', 'snffieiellt', 'snffieient'],\n",
       " 'witllill': ['witllill', 'witllin', 'witnill', 'witnin'],\n",
       " 'ollteollle': ['ollteollle', 'ollteolne', 'onteollle', 'onteolne'],\n",
       " 'departlllellts': ['departlllellts', 'departlllents'],\n",
       " 'inoxrelllellt': ['inoxrelllellt',\n",
       "  'inoxrelllent',\n",
       "  'inoxrelnellt',\n",
       "  'inoxrelnent'],\n",
       " 'colllluercial': ['colllluercial',\n",
       "  'collnuercial',\n",
       "  'conlluercial',\n",
       "  'connuercial'],\n",
       " 'colllmissiollers': ['colllmissiollers',\n",
       "  'colllmissioners',\n",
       "  'colnmissiollers',\n",
       "  'colnmissioners'],\n",
       " 'eolllltries': ['eolllltries', 'eollntries', 'eonlltries', 'eonntries'],\n",
       " 'llilldrallee': ['llilldrallee',\n",
       "  'llindrallee',\n",
       "  'llindranee',\n",
       "  'nilldrallee',\n",
       "  'nindrallee',\n",
       "  'nindranee'],\n",
       " 'illtellect': ['illtellect', 'illtenect', 'intellect', 'intenect'],\n",
       " 'tllenllore': ['tllenllore', 'tllennore', 'tnenllore', 'tnennore'],\n",
       " 'bellclles': ['bellclles', 'bellcnes', 'benclles', 'bencnes'],\n",
       " 'gllzzlellt': ['gllzzlellt', 'gllzzlent', 'gnzzlellt', 'gnzzlent'],\n",
       " 'bllsilless': ['bllsilless', 'bllsiness', 'bnsilless', 'bnsiness'],\n",
       " 'lllllediate': ['lllllediate', 'lllnediate', 'lnllediate', 'lnnediate'],\n",
       " 'vasllillg': ['vasllillg', 'vaslling', 'vasnillg', 'vasning'],\n",
       " 'cleallillg': ['cleallillg', 'clealling', 'cleanillg', 'cleaning'],\n",
       " 'finalleially': ['finalleially', 'finalleiany', 'finaneially', 'finaneiany'],\n",
       " 'tllillg': ['tllillg', 'tlling', 'tnillg', 'tning'],\n",
       " 'eclllcatioll': ['eclllcatioll', 'eclllcation', 'eclncatioll', 'eclncation'],\n",
       " 'ballkillg': ['ballkillg', 'ballking', 'bankillg', 'banking'],\n",
       " 'svillillg': ['svillillg', 'svilling', 'svinillg', 'svining'],\n",
       " 'lligllel': ['lligllel', 'llignel', 'nigllel', 'nignel'],\n",
       " 'sllollld': ['sllollld', 'sllolnd', 'snollld', 'snolnd'],\n",
       " 'becolllillg': ['becolllillg', 'becollling', 'becolnillg', 'becolning'],\n",
       " 'collllllel': ['collllllel',\n",
       "  'collnllel',\n",
       "  'collnnel',\n",
       "  'conllllel',\n",
       "  'connllel',\n",
       "  'connnel'],\n",
       " 'illllst': ['illllst', 'illnst', 'inllst', 'innst'],\n",
       " 'eolllllluolity': ['eolllllluolity',\n",
       "  'eollnlluolity',\n",
       "  'eollnnuolity',\n",
       "  'eonlllluolity',\n",
       "  'eonnlluolity',\n",
       "  'eonnnuolity'],\n",
       " 'ecllleatioll': ['ecllleatioll', 'ecllleation', 'eclneatioll', 'eclneation'],\n",
       " 'intelleetllal': ['intelleetllal',\n",
       "  'intelleetnal',\n",
       "  'inteneetllal',\n",
       "  'inteneetnal'],\n",
       " 'rlllillg': ['rlllillg', 'rllling', 'rlnillg', 'rlning'],\n",
       " 'yolltll': ['yolltll', 'yolltn', 'yontll', 'yontn'],\n",
       " 'eollllnullity': ['eollllnullity',\n",
       "  'eollnnullity',\n",
       "  'eollnnunity',\n",
       "  'eonllnullity',\n",
       "  'eonnnullity',\n",
       "  'eonnnunity'],\n",
       " 'colllltl': ['colllltl', 'collntl', 'conlltl', 'conntl'],\n",
       " 'elergylllall': ['elergylllall', 'elergylllan', 'elergylnall', 'elergylnan'],\n",
       " 'tecllllieal': ['tecllllieal', 'tecllnieal', 'tecnllieal', 'tecnnieal'],\n",
       " 'llnclerlyillg': ['llnclerlyillg',\n",
       "  'llnclerlying',\n",
       "  'nnclerlyillg',\n",
       "  'nnclerlying'],\n",
       " 'inollograplls': ['inollograplls',\n",
       "  'inollograpns',\n",
       "  'inonograplls',\n",
       "  'inonograpns'],\n",
       " 'sllolllci': ['sllolllci', 'sllolnci', 'snolllci', 'snolnci'],\n",
       " 'eurrielllllm': ['eurrielllllm', 'eurrielllnm', 'eurrielnllm', 'eurrielnnm'],\n",
       " 'fllnclallleiltal': ['fllnclallleiltal',\n",
       "  'fllnclalneiltal',\n",
       "  'fnnclallleiltal',\n",
       "  'fnnclalneiltal'],\n",
       " 'illtroductioll': ['illtroductioll',\n",
       "  'illtroduction',\n",
       "  'introductioll',\n",
       "  'introduction'],\n",
       " 'fllrtllel': ['fllrtllel', 'fllrtnel', 'fnrtllel', 'fnrtnel'],\n",
       " 'illtellectual': ['illtellectual',\n",
       "  'illtenectual',\n",
       "  'intellectual',\n",
       "  'intenectual'],\n",
       " 'illtellectllal': ['illtellectllal',\n",
       "  'illtenectllal',\n",
       "  'illtenectnal',\n",
       "  'intellectllal',\n",
       "  'intenectllal',\n",
       "  'intenectnal'],\n",
       " 'illstallce': ['illstallce', 'illstance', 'installce', 'instance'],\n",
       " 'accollntillg': ['accollntillg', 'accollnting', 'acconntillg', 'acconnting'],\n",
       " 'collllotatioll': ['collllotatioll',\n",
       "  'collnotatioll',\n",
       "  'collnotation',\n",
       "  'conllotatioll',\n",
       "  'connotatioll',\n",
       "  'connotation'],\n",
       " 'lllecllanistn': ['lllecllanistn',\n",
       "  'lllecnanistn',\n",
       "  'lnecllanistn',\n",
       "  'lnecnanistn'],\n",
       " 'collllllercial': ['collllllercial',\n",
       "  'collnllercial',\n",
       "  'collnnercial',\n",
       "  'conllllercial',\n",
       "  'connllercial',\n",
       "  'connnercial'],\n",
       " 'fllllctioll': ['fllllctioll',\n",
       "  'fllnctioll',\n",
       "  'fllnction',\n",
       "  'fnllctioll',\n",
       "  'fnnctioll',\n",
       "  'fnnction'],\n",
       " 'rollllg': ['rollllg', 'rollng', 'ronllg', 'ronng'],\n",
       " 'allllounce': ['allllounce', 'allnounce', 'anllounce', 'announce'],\n",
       " 'allllollllces': ['allllollllces',\n",
       "  'allnollllces',\n",
       "  'allnonllces',\n",
       "  'allnonnces',\n",
       "  'anllollllces',\n",
       "  'annollllces',\n",
       "  'annonllces',\n",
       "  'annonnces'],\n",
       " 'statelllellt': ['statelllellt', 'statelllent', 'statelnellt', 'statelnent'],\n",
       " 'llotioll': ['llotioll', 'llotion', 'notioll', 'notion'],\n",
       " 'dartlllollth': ['dartlllollth', 'dartlllonth', 'dartlnollth', 'dartlnonth'],\n",
       " 'ellally': ['ellally', 'ellany', 'enally', 'enany'],\n",
       " 'traillillgortlledeveloplllent': ['traillillgortlledeveloplllent',\n",
       "  'traillingortlledeveloplllent',\n",
       "  'traillingortnedeveloplllent',\n",
       "  'traillingortnedeveloplnent',\n",
       "  'trainillgortlledeveloplllent',\n",
       "  'trainingortlledeveloplllent',\n",
       "  'trainingortnedeveloplllent',\n",
       "  'trainingortnedeveloplnent'],\n",
       " 'tllollsands': ['tllollsands', 'tllonsands', 'tnollsands', 'tnonsands'],\n",
       " 'illflllellee': ['illflllellee',\n",
       "  'illflnellee',\n",
       "  'illflnenee',\n",
       "  'inflllellee',\n",
       "  'inflnellee',\n",
       "  'inflnenee'],\n",
       " 'hllllclrecrs': ['hllllclrecrs', 'hllnclrecrs', 'hnllclrecrs', 'hnnclrecrs'],\n",
       " 'lllln': ['lllln', 'llnn', 'nlln', 'nnn'],\n",
       " 'illflllellce': ['illflllellce', 'illflnellce', 'illflnence', 'inflnence'],\n",
       " 'halldillg': ['halldillg', 'hallding', 'handillg', 'handing'],\n",
       " 'tllorllsoll': ['tllorllsoll',\n",
       "  'tllornsoll',\n",
       "  'tllornson',\n",
       "  'tnorllsoll',\n",
       "  'tnornsoll',\n",
       "  'tnornson'],\n",
       " 'govertllalellt': ['govertllalellt',\n",
       "  'govertllalent',\n",
       "  'govertnalellt',\n",
       "  'govertnalent'],\n",
       " 'lellgthelled': ['lellgthelled', 'lellgthened', 'lengthelled', 'lengthened'],\n",
       " 'follonvillg': ['follonvillg', 'follonving', 'fononvillg', 'fononving'],\n",
       " 'melltiolled': ['melltiolled', 'melltioned', 'mentiolled', 'mentioned'],\n",
       " 'engilleerillgy': ['engilleerillgy',\n",
       "  'engilleeringy',\n",
       "  'engineerillgy',\n",
       "  'engineeringy'],\n",
       " 'llotwithstallding': ['llotwithstallding',\n",
       "  'llotwithstanding',\n",
       "  'notwithstallding',\n",
       "  'notwithstanding'],\n",
       " 'sometllillz': ['sometllillz', 'sometllinz', 'sometnillz', 'sometninz'],\n",
       " 'illaliellable': ['illaliellable',\n",
       "  'illalienable',\n",
       "  'inaliellable',\n",
       "  'inalienable'],\n",
       " 'trlltlls': ['trlltlls', 'trlltns', 'trntlls', 'trntns'],\n",
       " 'itlstitlltioll': ['itlstitlltioll',\n",
       "  'itlstitlltion',\n",
       "  'itlstitntioll',\n",
       "  'itlstitntion'],\n",
       " 'acllllirably': ['acllllirably', 'acllnirably', 'acnllirably', 'acnnirably'],\n",
       " 'illtelligenl': ['illtelligenl', 'illtenigenl', 'intelligenl', 'intenigenl'],\n",
       " 'follnclatioll': ['follnclatioll',\n",
       "  'follnclation',\n",
       "  'fonnclatioll',\n",
       "  'fonnclation'],\n",
       " 'illdepenclellce': ['illdepenclellce',\n",
       "  'illdepenclence',\n",
       "  'indepenclellce',\n",
       "  'indepenclence'],\n",
       " 'lltllllall': ['lltllllall',\n",
       "  'lltnllall',\n",
       "  'lltnnall',\n",
       "  'lltnnan',\n",
       "  'ntllllall',\n",
       "  'ntnllall',\n",
       "  'ntnnall',\n",
       "  'ntnnan'],\n",
       " 'arllicll': ['arllicll', 'arllicn', 'arnicll', 'arnicn'],\n",
       " 'olloll': ['olloll', 'ollon', 'onoll', 'onon'],\n",
       " 'fllllest': ['fllllest', 'fllnest', 'fnllest', 'fnnest'],\n",
       " 'inclepelldellce': ['inclepelldellce',\n",
       "  'inclepelldence',\n",
       "  'inclependellce',\n",
       "  'inclependence'],\n",
       " 'funclalllelltal': ['funclalllelltal',\n",
       "  'funclalllental',\n",
       "  'funclalnelltal',\n",
       "  'funclalnental'],\n",
       " 'llolclillg': ['llolclillg', 'llolcling', 'nolclillg', 'nolcling'],\n",
       " 'collseqllently': ['collseqllently',\n",
       "  'collseqnently',\n",
       "  'conseqllently',\n",
       "  'conseqnently'],\n",
       " 'bellefieellee': ['bellefieellee',\n",
       "  'bellefieenee',\n",
       "  'benefieellee',\n",
       "  'benefieenee'],\n",
       " 'halllperillg': ['halllperillg', 'halllpering', 'halnperillg', 'halnpering'],\n",
       " 'allarclly': ['allarclly', 'allarcny', 'anarclly', 'anarcny'],\n",
       " 'svllicll': ['svllicll', 'svllicn', 'svnicll', 'svnicn'],\n",
       " 'owllersllip': ['owllersllip', 'owllersnip', 'ownersllip', 'ownersnip'],\n",
       " 'allotlle': ['allotlle', 'allotne', 'anotlle', 'anotne'],\n",
       " 'illdiviclllal': ['illdiviclllal',\n",
       "  'illdiviclnal',\n",
       "  'indiviclllal',\n",
       "  'indiviclnal'],\n",
       " 'comptllsioll': ['comptllsioll', 'comptllsion', 'comptnsioll', 'comptnsion'],\n",
       " 'solnetllillt': ['solnetllillt', 'solnetllint', 'solnetnillt', 'solnetnint'],\n",
       " 'fellowtlle': ['fellowtlle', 'fellowtne', 'fenowtlle', 'fenowtne'],\n",
       " 'ullicll': ['ullicll', 'ullicn', 'unicll', 'unicn'],\n",
       " 'tllelllfselxres': ['tllelllfselxres',\n",
       "  'tllelnfselxres',\n",
       "  'tnelllfselxres',\n",
       "  'tnelnfselxres'],\n",
       " 'ttzollgllt': ['ttzollgllt', 'ttzollgnt', 'ttzongllt', 'ttzongnt'],\n",
       " 'llteellth': ['llteellth', 'llteenth', 'nteellth', 'nteenth'],\n",
       " 'illllabiteci': ['illllabiteci', 'illnabiteci', 'inllabiteci', 'innabiteci'],\n",
       " 'ellorlllouslt': ['ellorlllouslt',\n",
       "  'ellorlnouslt',\n",
       "  'enorlllouslt',\n",
       "  'enorlnouslt'],\n",
       " 'trllislll': ['trllislll', 'trllisln', 'trnislll', 'trnisln'],\n",
       " 'rellbeillg': ['rellbeillg', 'rellbeing', 'renbeillg', 'renbeing'],\n",
       " 'illall': ['illall', 'illan', 'inall', 'inan'],\n",
       " 'furtllerlllore': ['furtllerlllore',\n",
       "  'furtllerlnore',\n",
       "  'furtnerlllore',\n",
       "  'furtnerlnore'],\n",
       " 'llollrs': ['llollrs', 'llonrs', 'nollrs', 'nonrs'],\n",
       " 'xvllicll': ['xvllicll', 'xvllicn', 'xvnicll', 'xvnicn'],\n",
       " 'clotllillg': ['clotllillg', 'clotlling', 'clotnillg', 'clotning'],\n",
       " 'tllilll': ['tllilll', 'tlliln', 'tnilll', 'tniln'],\n",
       " 'llnqllestionaldly': ['llnqllestionaldly',\n",
       "  'llnqnestionaldly',\n",
       "  'nnqllestionaldly',\n",
       "  'nnqnestionaldly'],\n",
       " 'kllowll': ['kllowll', 'kllown', 'knowll', 'known'],\n",
       " 'llicll': ['llicll', 'llicn', 'nicll', 'nicn'],\n",
       " 'brollllt': ['brollllt', 'brollnt', 'bronllt', 'bronnt'],\n",
       " 'freedollll': ['freedollll', 'freedolln', 'freedonll', 'freedonn'],\n",
       " 'llllonwealth': ['llllonwealth', 'llnonwealth', 'nllonwealth', 'nnonwealth'],\n",
       " 'colltellted': ['colltellted', 'colltented', 'contellted', 'contented'],\n",
       " 'phellomenoll': ['phellomenoll', 'phellomenon', 'phenomenoll', 'phenomenon'],\n",
       " 'discllssioll': ['discllssioll', 'discllssion', 'discnssioll', 'discnssion'],\n",
       " 'sllccessfully': ['sllccessfully',\n",
       "  'sllccessfuny',\n",
       "  'snccessfully',\n",
       "  'snccessfuny'],\n",
       " 'brillgillg': ['brillgillg', 'brillging', 'bringillg', 'bringing'],\n",
       " 'tllellaselves': ['tllellaselves',\n",
       "  'tllenaselves',\n",
       "  'tnellaselves',\n",
       "  'tnenaselves'],\n",
       " 'zllell': ['zllell', 'zllen', 'znell', 'znen'],\n",
       " 'llotllillal': ['llotllillal',\n",
       "  'llotnillal',\n",
       "  'llotninal',\n",
       "  'notllillal',\n",
       "  'notnillal',\n",
       "  'notninal'],\n",
       " 'llolll': ['llolll', 'lloln', 'nolll', 'noln'],\n",
       " 'llrcll': ['llrcll', 'llrcn', 'nrcll', 'nrcn'],\n",
       " 'pllilosoplly': ['pllilosoplly', 'pllilosopny', 'pnilosoplly', 'pnilosopny'],\n",
       " 'ullclerstalld': ['ullclerstalld',\n",
       "  'ullclerstand',\n",
       "  'unclerstalld',\n",
       "  'unclerstand'],\n",
       " 'collcernillg': ['collcernillg', 'collcerning', 'concernillg', 'concerning'],\n",
       " 'followillg': ['followillg', 'following', 'fonowillg', 'fonowing'],\n",
       " 'rllicll': ['rllicll', 'rllicn', 'rnicll', 'rnicn'],\n",
       " 'llealtll': ['llealtll', 'llealtn', 'nealtll', 'nealtn'],\n",
       " 'reglllatioll': ['reglllatioll', 'reglllation', 'reglnatioll', 'reglnation'],\n",
       " 'ellliglltenment': ['ellliglltenment',\n",
       "  'ellligntenment',\n",
       "  'elniglltenment',\n",
       "  'elnigntenment'],\n",
       " 'lnaintellallee': ['lnaintellallee',\n",
       "  'lnaintellanee',\n",
       "  'lnaintenallee',\n",
       "  'lnaintenanee'],\n",
       " 'weigllillg': ['weigllillg', 'weiglling', 'weignillg', 'weigning'],\n",
       " 'sollgllt': ['sollgllt', 'sollgnt', 'songllt', 'songnt'],\n",
       " 'agreelllellt': ['agreelllellt', 'agreelllent', 'agreelnellt', 'agreelnent'],\n",
       " 'lllilliollaire': ['lllilliollaire',\n",
       "  'llliniollaire',\n",
       "  'lllinionaire',\n",
       "  'lnilliollaire',\n",
       "  'lniniollaire',\n",
       "  'lninionaire'],\n",
       " 'agreetllellt': ['agreetllellt', 'agreetllent', 'agreetnellt', 'agreetnent'],\n",
       " 'llllllger': ['llllllger',\n",
       "  'llnllger',\n",
       "  'llnnger',\n",
       "  'nllllger',\n",
       "  'nnllger',\n",
       "  'nnnger'],\n",
       " 'ullquestiollably': ['ullquestiollably',\n",
       "  'ullquestionably',\n",
       "  'unquestiollably',\n",
       "  'unquestionably'],\n",
       " 'tllotlgllt': ['tllotlgllt', 'tllotlgnt', 'tnotlgllt', 'tnotlgnt'],\n",
       " 'tecllnically': ['tecllnically', 'tecllnicany', 'tecnnically', 'tecnnicany'],\n",
       " 'colltractill': ['colltractill', 'colltractin', 'contractill', 'contractin'],\n",
       " 'alllly': ['alllly', 'allny', 'anlly', 'anny'],\n",
       " 'ullioll': ['ullioll', 'ullion', 'unioll', 'union'],\n",
       " 'illstitlltiolls': ['illstitlltiolls',\n",
       "  'illstitntiolls',\n",
       "  'illstitntions',\n",
       "  'institntions'],\n",
       " 'ellliolltelleci': ['ellliolltelleci',\n",
       "  'ellliontelleci',\n",
       "  'elllionteneci',\n",
       "  'elniolltelleci',\n",
       "  'elniontelleci',\n",
       "  'elnionteneci'],\n",
       " 'llatiolls': ['llatiolls', 'llations', 'natiolls', 'nations'],\n",
       " 'wrlletller': ['wrlletller', 'wrlletner', 'wrnetller', 'wrnetner'],\n",
       " 'illdllstricll': ['illdllstricll',\n",
       "  'illdnstricll',\n",
       "  'illdnstricn',\n",
       "  'indllstricll',\n",
       "  'indnstricll',\n",
       "  'indnstricn'],\n",
       " 'sometllillg': ['sometllillg', 'sometlling', 'sometnillg', 'sometning'],\n",
       " 'ullquestiolled': ['ullquestiolled',\n",
       "  'ullquestioned',\n",
       "  'unquestiolled',\n",
       "  'unquestioned'],\n",
       " 'illllerent': ['illllerent', 'illnerent', 'inllerent', 'innerent'],\n",
       " 'skillfully': ['skillfully', 'skillfuny', 'skinfully', 'skinfuny'],\n",
       " 'llerdillg': ['llerdillg', 'llerding', 'nerdillg', 'nerding'],\n",
       " 'lloderll': ['lloderll', 'llodern', 'noderll', 'nodern'],\n",
       " 'overwhelllling': ['overwhelllling',\n",
       "  'overwhellning',\n",
       "  'overwhenlling',\n",
       "  'overwhenning'],\n",
       " 'dotllinatioll': ['dotllinatioll',\n",
       "  'dotllination',\n",
       "  'dotninatioll',\n",
       "  'dotnination'],\n",
       " 'ellliglltened': ['ellliglltened',\n",
       "  'ellligntened',\n",
       "  'elniglltened',\n",
       "  'elnigntened'],\n",
       " 'tlaat': [],\n",
       " 'opporttlnity': [],\n",
       " 'differellt': [],\n",
       " 'sellse': [],\n",
       " 'illaterial': [],\n",
       " 'diminisll': [],\n",
       " 'otlly': [],\n",
       " 'dynalllic': [],\n",
       " 'dyllamic': [],\n",
       " 'ollore': [],\n",
       " 'otle': [],\n",
       " 'implicitly': [],\n",
       " 'hiln': [],\n",
       " 'thorougllly': [],\n",
       " 'dissellt': [],\n",
       " 'collsistently': [],\n",
       " 'borll': [],\n",
       " 'collsequelaces': [],\n",
       " 'llight': [],\n",
       " 'collnected': [],\n",
       " 'prepossessiolls': [],\n",
       " 'examille': [],\n",
       " 'critically': [],\n",
       " 'evetl': [],\n",
       " 'conditioll': [],\n",
       " 'observatioll': [],\n",
       " 'stability': [],\n",
       " 'jlldgments': [],\n",
       " 'tl': [],\n",
       " 'criticislll': [],\n",
       " 'ollost': [],\n",
       " 'incidentally': [],\n",
       " 'hourly': [],\n",
       " 'intervelltion': [],\n",
       " 'relnain': [],\n",
       " 'weigll': [],\n",
       " 'selectiorl': [],\n",
       " 'gtlard': [],\n",
       " 'sall': [],\n",
       " 'methocls': [],\n",
       " 'bllt': [],\n",
       " 'ulldertake': [],\n",
       " 'icleals': [],\n",
       " 'mall': [],\n",
       " 'clouds': [],\n",
       " 'chatllpion': [],\n",
       " 'cotntnullity': [],\n",
       " 'clailus': [],\n",
       " 'telnporary': [],\n",
       " 'etllics': [],\n",
       " 'lnatter': [],\n",
       " 'judgmellt': [],\n",
       " 'llational': [],\n",
       " 'antecedellts': [],\n",
       " 'growll': [],\n",
       " 'btlsiness': [],\n",
       " 'alnong': [],\n",
       " 'llilnself': [],\n",
       " 'partially': [],\n",
       " 'nearsiglltedness': [],\n",
       " 'froln': [],\n",
       " 'ellable': [],\n",
       " 'hellry': [],\n",
       " 'disinterestedlless': [],\n",
       " 'diametrically': [],\n",
       " 'conditiotls': [],\n",
       " 'canclid': [],\n",
       " 'prevellts': [],\n",
       " 'applyitlg': [],\n",
       " 'judgilaellt': [],\n",
       " 'atlybody': [],\n",
       " 'sllggests': [],\n",
       " 'uncler': [],\n",
       " 'ollaki': [],\n",
       " 'llg': [],\n",
       " 'fratlkly': [],\n",
       " 'clailll': [],\n",
       " 'ooll': [],\n",
       " 'nlen': [],\n",
       " 'ollixture': [],\n",
       " 'atld': [],\n",
       " 'cleceptioll': [],\n",
       " 'botll': [],\n",
       " 'illdependent': [],\n",
       " 'tlzat': [],\n",
       " 'attelllpt': [],\n",
       " 'ila': [],\n",
       " 'eminellt': [],\n",
       " 'lnental': [],\n",
       " 'johll': [],\n",
       " 'assulllption': [],\n",
       " 'colllmuolity': [],\n",
       " 'pretellds': [],\n",
       " 'jllst': [],\n",
       " 'reforlller': [],\n",
       " 'lnan': [],\n",
       " 'claims': [],\n",
       " 'everytlling': [],\n",
       " 'allci': [],\n",
       " 'sarill': [],\n",
       " 'visiollary': [],\n",
       " 'itlterests': [],\n",
       " 'collcrete': [],\n",
       " 'tntlst': [],\n",
       " 'sentimellt': [],\n",
       " 'elcconlplish': [],\n",
       " 'illdividual': [],\n",
       " 'workillg': [],\n",
       " 'recognitioll': [],\n",
       " 'permissioll': [],\n",
       " 'variotls': [],\n",
       " 'menlbers': [],\n",
       " 'accordilg': [],\n",
       " 'deprivillg': [],\n",
       " 'sometilnes': [],\n",
       " 'silogle': [],\n",
       " 'grollp': [],\n",
       " 'balallce': [],\n",
       " 'cotltributes': [],\n",
       " 'annillilation': [],\n",
       " 'predolninallce': [],\n",
       " 'iclelltified': [],\n",
       " 'cllance': [],\n",
       " 'collflicting': [],\n",
       " 'cotlditioil': [],\n",
       " 'nulnber': [],\n",
       " 'fulldalnental': [],\n",
       " 'outlilled': [],\n",
       " 'ollr': [],\n",
       " 'dtlces': [],\n",
       " 'showll': [],\n",
       " 'neecls': [],\n",
       " 'conclusiolls': [],\n",
       " 'econelllist': [],\n",
       " 'illottlent': [],\n",
       " 'adjllstlnent': [],\n",
       " 'conaproollise': [],\n",
       " 'positiolls': [],\n",
       " 'chanopioll': [],\n",
       " 'sionilar': [],\n",
       " 'wlaicll': [],\n",
       " 'comlllol': [],\n",
       " 'llniotls': [],\n",
       " 'civili': [],\n",
       " 'comlnunities': [],\n",
       " 'frotll': [],\n",
       " 'trallsaction': [],\n",
       " 'tlansaction': [],\n",
       " 'reglllator': [],\n",
       " 'itlerease': [],\n",
       " 'reasoll': [],\n",
       " 'owller': [],\n",
       " 'alld': [],\n",
       " 'sllowed': [],\n",
       " 'colntnullity': [],\n",
       " 'ilumecliately': [],\n",
       " 'accolllpanied': [],\n",
       " 'poillt': [],\n",
       " 'perlnanent': [],\n",
       " 'correctilag': [],\n",
       " 'forlllation': [],\n",
       " 'lls': [],\n",
       " 'adoptioll': [],\n",
       " 'illorality': [],\n",
       " 'aclvocacy': [],\n",
       " 'ilzterests': [],\n",
       " 'ratller': [],\n",
       " 'llecessit': [],\n",
       " 'clas': [],\n",
       " 'seeril': [],\n",
       " 'argulnent': [],\n",
       " 'betweetl': [],\n",
       " 'aillls': [],\n",
       " 'profouncler': [],\n",
       " 'stucly': [],\n",
       " 'llistoryr': [],\n",
       " 'ldarlialllents': [],\n",
       " 'eollgresses': [],\n",
       " 'bargaills': [],\n",
       " 'tloe': [],\n",
       " 'ereatioll': [],\n",
       " 'ptlblie': [],\n",
       " 'parlialnellt': [],\n",
       " 'fronl': [],\n",
       " 'nvestlaillstel': [],\n",
       " 'illterchange': [],\n",
       " 'lnenlbel': [],\n",
       " 'tile': [],\n",
       " 'aetioll': [],\n",
       " 'esselltial': [],\n",
       " 'parliaments': [],\n",
       " 'vvas': [],\n",
       " 'otltside': [],\n",
       " 'tlleil': [],\n",
       " 'exigelleies': [],\n",
       " 'ellabled': [],\n",
       " 'trtle': [],\n",
       " 'parliaulent': [],\n",
       " 'llad': [],\n",
       " 'additioll': [],\n",
       " 'tllemseln': [],\n",
       " 'comlnolzs': [],\n",
       " 'origillate': [],\n",
       " 'killgs': [],\n",
       " 'avoidillg': [],\n",
       " 'eompellilag': [],\n",
       " 'autlloritative': [],\n",
       " 'presetltation': [],\n",
       " 'opillio': [],\n",
       " 'wlaell': [],\n",
       " 'parliamellt': [],\n",
       " 'salne': [],\n",
       " 'fullction': [],\n",
       " 'clifferent': [],\n",
       " 'tllal': [],\n",
       " 'tlaall': [],\n",
       " 'vvllat': [],\n",
       " 'forlned': [],\n",
       " 'extensioll': [],\n",
       " 'll': [],\n",
       " 'diserellt': [],\n",
       " 'comtnullity': [],\n",
       " 'lnealas': [],\n",
       " 'collgressional': [],\n",
       " 'epreselltaties': [],\n",
       " 'formatioll': [],\n",
       " 'sentilnellt': [],\n",
       " 'parlialnents': [],\n",
       " 'lllaking': [],\n",
       " 'accompallied': [],\n",
       " 'sallltary': [],\n",
       " 'thillk': [],\n",
       " 'recoanitioll': [],\n",
       " 'epreselltative': [],\n",
       " 'utterallces': [],\n",
       " 'gelzerally': [],\n",
       " 'educatiollal': [],\n",
       " 'incidellt': [],\n",
       " 'positiotl': [],\n",
       " 'clistrict': [],\n",
       " 'mallifests': [],\n",
       " 'appropriatioll': [],\n",
       " 'stalld': [],\n",
       " 'illcreasingly': [],\n",
       " 'bellalf': [],\n",
       " 'beconle': [],\n",
       " 'patcllwork': [],\n",
       " 'demallds': [],\n",
       " 'llotoriotls': [],\n",
       " 'estilnate': [],\n",
       " 'parliamelltary': [],\n",
       " 'glorificatioll': [],\n",
       " 'idealizatioll': [],\n",
       " 'cotnlllon': [],\n",
       " 'eneratiolls': [],\n",
       " 'illlmediately': [],\n",
       " 'passillg': [],\n",
       " 'lessellilag': [],\n",
       " 'systemgivillg': [],\n",
       " 'lnayor': [],\n",
       " 'persolls': [],\n",
       " 'tllayor': [],\n",
       " 'ordillary': [],\n",
       " 'lnunicipality': [],\n",
       " 'sanle': [],\n",
       " 'tendelley': [],\n",
       " 'sllos': [],\n",
       " 'eonneetioll': [],\n",
       " 'beilag': [],\n",
       " 'providillg': [],\n",
       " 'referellee': [],\n",
       " 'argumellt': [],\n",
       " 'whetl': [],\n",
       " 'ehallge': [],\n",
       " 'signifieallt': [],\n",
       " 'trelld': [],\n",
       " 'clebate': [],\n",
       " 'eolntnon': [],\n",
       " 'sllbstitu': [],\n",
       " 'partisall': [],\n",
       " 'eollverted': [],\n",
       " 'wllieh': [],\n",
       " 'prevellted': [],\n",
       " 'goverlllz': [],\n",
       " 'lellt': [],\n",
       " 'eommullity': [],\n",
       " 'improvelnellts': [],\n",
       " 'orgalliza': [],\n",
       " 'suell': [],\n",
       " 'eompetitioll': [],\n",
       " 'lpally': [],\n",
       " 'lilles': [],\n",
       " 'eall': [],\n",
       " 'eeollotny': [],\n",
       " 'parallel': [],\n",
       " 'railroads': [],\n",
       " 'eonlpetillg': [],\n",
       " 'workswitllotlt': [],\n",
       " 'expellse': [],\n",
       " 'climinished': [],\n",
       " 'eollvenienee': [],\n",
       " 'eanllot': [],\n",
       " 'lllanr': [],\n",
       " 'eoll': [],\n",
       " 'dallger': [],\n",
       " 'elllarge': [],\n",
       " 'vhiell': [],\n",
       " 'detrimellt': [],\n",
       " 'otllel': [],\n",
       " 'beilog': [],\n",
       " 'overtakell': [],\n",
       " 'xvill': [],\n",
       " 'elltrusted': [],\n",
       " 'tllein': [],\n",
       " 'illclireet': [],\n",
       " 'proteetiotl': [],\n",
       " 'eolllmereial': [],\n",
       " 'eolnpetition': [],\n",
       " 'lnore': [],\n",
       " 'inclividualized': [],\n",
       " 'eorl': [],\n",
       " 'selfisllness': [],\n",
       " 'eonlulereial': [],\n",
       " 'lllelch': [],\n",
       " 'ulllimited': [],\n",
       " 'proulotillg': [],\n",
       " 'eonedellee': [],\n",
       " 'illclividual': [],\n",
       " 'illitiative': [],\n",
       " 'ilnmediate': [],\n",
       " 'regulatillg': [],\n",
       " 'silnilar': [],\n",
       " 'otlr': [],\n",
       " 'lrlunieipalities': [],\n",
       " 'givillg': [],\n",
       " 'ulldreamed': [],\n",
       " 'ldllt': [],\n",
       " 'eolllbi': [],\n",
       " 'tlse': [],\n",
       " 'neeessarily': [],\n",
       " 'strengtll': [],\n",
       " 'pursllits': [],\n",
       " 'lllember': [],\n",
       " 'federatioll': [],\n",
       " 'systenl': [],\n",
       " 'theilown': [],\n",
       " 'llesr': [],\n",
       " 'inlpossible': [],\n",
       " 'represellt': [],\n",
       " 'fulldamental': [],\n",
       " 'boullded': [],\n",
       " 'beyolld': [],\n",
       " 'cleluded': [],\n",
       " 'constitutionally': [],\n",
       " 'lnean': [],\n",
       " 'hallds': [],\n",
       " 'colldltions': [],\n",
       " 'flllfil': [],\n",
       " 'xnorally': [],\n",
       " 'politically': [],\n",
       " 'rollle': [],\n",
       " 'ruilled': [],\n",
       " 'faitil': [],\n",
       " 'alzlericall': [],\n",
       " 'leecls': [],\n",
       " 'indllstry': [],\n",
       " 'collectivisin': [],\n",
       " 'collectivism': [],\n",
       " 'allalces': [],\n",
       " 'cllaracters': [],\n",
       " 'detnallds': [],\n",
       " 'lnen': [],\n",
       " 'colllpromise': [],\n",
       " 'bargaill': [],\n",
       " 'colllonercial': [],\n",
       " 'illethods': [],\n",
       " 'coillproulise': [],\n",
       " 'convictioll': [],\n",
       " 'successflll': [],\n",
       " 'illusion': [],\n",
       " 'ecollomists': [],\n",
       " 'treatmellt': [],\n",
       " 'plovillg': [],\n",
       " 'ullw': [],\n",
       " 'derstallding': [],\n",
       " 'evokillg': [],\n",
       " 'svllatever': [],\n",
       " 'kllowledge': [],\n",
       " 'breadtll': [],\n",
       " 'ptlrpose': [],\n",
       " 'sll': [],\n",
       " 'folloving': [],\n",
       " 'qllol': [],\n",
       " 'atioll': [],\n",
       " 'conlpetition': [],\n",
       " 'harmollized': [],\n",
       " 'elelnellts': [],\n",
       " 'itrlpossible': [],\n",
       " 'lllatl': [],\n",
       " 'conclitions': [],\n",
       " 'materialisln': [],\n",
       " 'absorbillg': [],\n",
       " 'feeclillg': [],\n",
       " 'cnildren': [],\n",
       " 'warpillg': [],\n",
       " 'lnoral': [],\n",
       " 'wilich': [],\n",
       " 'clown': [],\n",
       " 'bidclillg': [],\n",
       " 'politicialls': [],\n",
       " 'mollopolists': [],\n",
       " 'btlt': [],\n",
       " 'togetllel': [],\n",
       " 'llumaol': [],\n",
       " 'clivil': [],\n",
       " 'ulllatlity': [],\n",
       " 'delllonracy': [],\n",
       " 'llt': [],\n",
       " 'aillst': [],\n",
       " 'tlwis': [],\n",
       " 'utterallce': [],\n",
       " 'clearcllt': [],\n",
       " 'sioll': [],\n",
       " 'opillioil': [],\n",
       " 'jtlst': [],\n",
       " 'llseci': [],\n",
       " 'lncavrorable': [],\n",
       " 'econolnic': [],\n",
       " 'alltic': [],\n",
       " 'tliat': [],\n",
       " 'everybocly': [],\n",
       " 'illg': [],\n",
       " 'pllysical': [],\n",
       " 'allead': [],\n",
       " 'hulllalwity': [],\n",
       " 'stalldard': [],\n",
       " 'lllode': [],\n",
       " 'livillg': [],\n",
       " 'colllfortable': [],\n",
       " 'wlloul': [],\n",
       " 'sillt': [],\n",
       " 'ollce': [],\n",
       " 'olltburst': [],\n",
       " 'writtell': [],\n",
       " 'heavenlr': [],\n",
       " 'pently': [],\n",
       " 'lillers': [],\n",
       " 'eartll': [],\n",
       " 'colnpetition': [],\n",
       " 'rapllael': [],\n",
       " 'worsllip': [],\n",
       " 'lninimuln': [],\n",
       " 'kllosr': [],\n",
       " 'meallwhile': [],\n",
       " 'tllou': [],\n",
       " 'parellt': [],\n",
       " 'ecollol': [],\n",
       " 'slle': [],\n",
       " 'colusecratioll': [],\n",
       " 'cailnibalistll': [],\n",
       " 'listetl': [],\n",
       " 'lllese': [],\n",
       " 'worcls': [],\n",
       " 'sturcly': [],\n",
       " 'delatonciatioll': [],\n",
       " 'cail': [],\n",
       " 'iglltly': [],\n",
       " 'ilnpl': [],\n",
       " 'gll': [],\n",
       " 'olloies': [],\n",
       " 'callec': [],\n",
       " 'titiotl': [],\n",
       " 'cellters': [],\n",
       " 'svllere': [],\n",
       " 'srall': [],\n",
       " 'possessiotl': [],\n",
       " 'nvllid': [],\n",
       " 'illlites': [],\n",
       " 'nvitll': [],\n",
       " 'tlze': [],\n",
       " 'colnpetitiolo': [],\n",
       " 'tllaol': [],\n",
       " 'tlleft': [],\n",
       " 'crowcliilg': [],\n",
       " 'lnel': [],\n",
       " 'platitilig': [],\n",
       " 'sicle': [],\n",
       " 'tlae': [],\n",
       " 'colupetitiotl': [],\n",
       " 'slnft': [],\n",
       " 'iicliisiokl': [],\n",
       " 'lilnself': [],\n",
       " 'brotl': [],\n",
       " 'otl': [],\n",
       " 'lnutual': [],\n",
       " 'altrtlidlll': [],\n",
       " 'golclel': [],\n",
       " 'neiglll': [],\n",
       " 'ollrselves': [],\n",
       " 'rellderi': [],\n",
       " 'eolltl': [],\n",
       " 'aclietory': [],\n",
       " 'ulldoubted': [],\n",
       " 'utlqtlestiolled': [],\n",
       " 'unallitr': [],\n",
       " 'cllal': [],\n",
       " 'bascoln': [],\n",
       " 'atlsinson': [],\n",
       " 'septelilber': [],\n",
       " 'stolle': [],\n",
       " 'cliainet': [],\n",
       " 'rlcally': [],\n",
       " 'wrllat': [],\n",
       " 'corclially': [],\n",
       " 'arclently': [],\n",
       " 'adlilires': [],\n",
       " 'sollrce': [],\n",
       " 'altinclanee': [],\n",
       " 'cleserwrilig': [],\n",
       " 'cilildrell': [],\n",
       " 'lloic': [],\n",
       " 'tlat': [],\n",
       " 'tilese': [],\n",
       " 'cil': [],\n",
       " 'lillgs': [],\n",
       " 'allcl': [],\n",
       " 'cecled': [],\n",
       " 'ozzitld': [],\n",
       " 'rlleol': [],\n",
       " 'clls': [],\n",
       " 'cl': [],\n",
       " 'colrlpetition': [],\n",
       " 'iln': [],\n",
       " 'strlltrt': [],\n",
       " 'cotlisietilla': [],\n",
       " 'clictiolzaries': [],\n",
       " 'lell': [],\n",
       " 'tllezn': [],\n",
       " 'elldeavorint': [],\n",
       " 'otiler': [],\n",
       " 'encleavoritlo': [],\n",
       " 'tilne': [],\n",
       " 'eotltest': [],\n",
       " 'villd': [],\n",
       " 'dictiollarr': [],\n",
       " 'cle': [],\n",
       " 'llsts': [],\n",
       " 'lclrce': [],\n",
       " 'sellsse': [],\n",
       " 'consiclers': [],\n",
       " 'eolls': [],\n",
       " 'atl': [],\n",
       " 'ilis': [],\n",
       " 'utlcler': [],\n",
       " 'ebilae': [],\n",
       " 'etlougll': [],\n",
       " ...}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the queue with all unknown words\n",
    "known_set = set(known_words)\n",
    "graph = Graph(known_set)\n",
    "results: Dict[str, List[str]] = {}\n",
    "unknown_words = not_found\n",
    "queue = deque([Node(word, None, None) for word in unknown_words])\n",
    "for word in unknown_words:\n",
    "    graph.mark_visited(word, [word])\n",
    "\n",
    "iteration = 0\n",
    "while queue and iteration < 5:\n",
    "    iteration += 1\n",
    "    next_queue = deque()\n",
    "\n",
    "    for old, new in chars:\n",
    "        transformation = Transformation(old, new)\n",
    "\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            current_word = node.word\n",
    "\n",
    "            # Try applying the transformation at every valid index\n",
    "            for i in range(len(current_word) - len(old) + 1):\n",
    "                new_word = transformation.apply(current_word, i)\n",
    "                if not new_word:\n",
    "                    continue\n",
    "\n",
    "                # If the new word is already connected to a known word\n",
    "                if new_word in graph.visited:\n",
    "                    path_to_known = graph.get_path_to_known(new_word)\n",
    "                    if path_to_known:\n",
    "                        results[node.get_path()[0]] = node.get_path() + path_to_known[1:]\n",
    "                        continue\n",
    "                \n",
    "\n",
    "                # Otherwise, mark it visited and enqueue for further exploration\n",
    "                if graph.mark_visited(new_word, node.get_path() + [new_word]):\n",
    "                    next_queue.append(Node(new_word, node, transformation))\n",
    "\n",
    "    queue = next_queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ll', 'n'),\n",
       " ('ll', 'u'),\n",
       " ('ll', 'h'),\n",
       " ('il', 'n'),\n",
       " ('il', 'u'),\n",
       " ('il', 'h'),\n",
       " ('nl', 'm'),\n",
       " ('ln', 'm'),\n",
       " ('cl', 'd'),\n",
       " ('vv', 'w'),\n",
       " ('lll', 'm'),\n",
       " ('rl', 'n'),\n",
       " ('tl', 'u'),\n",
       " ('tl', 'n')]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lllelllmories': ['lllelllmories',\n",
       "  'lllelnmories',\n",
       "  'lnelllmories',\n",
       "  'lnelnmories'],\n",
       " 'froll': [],\n",
       " 'tlle': [],\n",
       " 'llemories': []}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw = ['memmories','from','the','other','side']\n",
    "uw = ['lllelllmories','froll','tlle','llemories']\n",
    "iterate_through_changes(kw,uw,chars,max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tlaat',\n",
       " 'dyllamic',\n",
       " 'ollore',\n",
       " 'implicitly',\n",
       " 'collsequelaces',\n",
       " 'critically',\n",
       " 'intellectually',\n",
       " 'stability',\n",
       " 'ollost',\n",
       " 'incidentally',\n",
       " 'hourly',\n",
       " 'gtlard',\n",
       " 'sall',\n",
       " 'ftllfillment',\n",
       " 'clouds',\n",
       " 'chatllpion',\n",
       " 'cotntnullity',\n",
       " 'clailus',\n",
       " 'illissioll',\n",
       " 'antecedellts',\n",
       " 'partially',\n",
       " 'nearsiglltedness',\n",
       " 'astiglllatisill',\n",
       " 'disinterestedlless',\n",
       " 'diametrically',\n",
       " 'prevellts',\n",
       " 'judgilaellt',\n",
       " 'atlybody',\n",
       " 'ollaki',\n",
       " 'llg',\n",
       " 'judglllellts',\n",
       " 'fratlkly',\n",
       " 'ooll',\n",
       " 'ollixture',\n",
       " 'cleceptioll',\n",
       " 'coollbille',\n",
       " 'tlzat',\n",
       " 'ila',\n",
       " 'eminellt',\n",
       " 'colllmuolity',\n",
       " 'pretellds',\n",
       " 'lnan',\n",
       " 'claims',\n",
       " 'allci',\n",
       " 'sarill',\n",
       " 'tntlst',\n",
       " 'elcconlplish',\n",
       " 'accordilg',\n",
       " 'deprivillg',\n",
       " 'silogle',\n",
       " 'annillilation',\n",
       " 'cotlditioil',\n",
       " 'dtlces',\n",
       " 'lnall',\n",
       " 'lullell',\n",
       " 'econelllist',\n",
       " 'conaproollise',\n",
       " 'chanopioll',\n",
       " 'llilll',\n",
       " 'sionilar',\n",
       " 'wlaicll',\n",
       " 'comlllol',\n",
       " 'civili',\n",
       " 'frotll',\n",
       " 'tlansaction',\n",
       " 'reglllator',\n",
       " 'itlerease',\n",
       " 'alld',\n",
       " 'colntnullity',\n",
       " 'ilumecliately',\n",
       " 'correctilag',\n",
       " 'forlllation',\n",
       " 'aclvocacy',\n",
       " 'ilzterests',\n",
       " 'llecessit',\n",
       " 'clifferellt',\n",
       " 'recogllition',\n",
       " 'clas',\n",
       " 'seeril',\n",
       " 'eoznlllullity',\n",
       " 'profouncler',\n",
       " 'llistoryr',\n",
       " 'ldarlialllents',\n",
       " 'eollgresses',\n",
       " 'collstlmtllation',\n",
       " 'bargaills',\n",
       " 'tloe',\n",
       " 'ereatioll',\n",
       " 'ptlblie',\n",
       " 'parlialnellt',\n",
       " 'fronl',\n",
       " 'nvestlaillstel',\n",
       " 'illterchange',\n",
       " 'lnenlbel',\n",
       " 'loeallll',\n",
       " 'wlliell',\n",
       " 'aetioll',\n",
       " 'flllletioll',\n",
       " 'parliaments',\n",
       " 'exigelleies',\n",
       " 'tlleoll',\n",
       " 'eoznllloll',\n",
       " 'extellsiolls',\n",
       " 'eolllmoll',\n",
       " 'fallell',\n",
       " 'parliaulent',\n",
       " 'tllemseln',\n",
       " 'comlnolzs',\n",
       " 'origillate',\n",
       " 'killgs',\n",
       " 'avoidillg',\n",
       " 'eompellilag',\n",
       " 'autlloritative',\n",
       " 'presetltation',\n",
       " 'opillio',\n",
       " 'wlaell',\n",
       " 'parliamellt',\n",
       " 'clifferent',\n",
       " 'tllal',\n",
       " 'collalllon',\n",
       " 'tlaall',\n",
       " 'forlned',\n",
       " 'll',\n",
       " 'diserellt',\n",
       " 'comtnullity',\n",
       " 'lnealas',\n",
       " 'collgressional',\n",
       " 'epreselltaties',\n",
       " 'formatioll',\n",
       " 'sentilnellt',\n",
       " 'parlialnents',\n",
       " 'accompallied',\n",
       " 'sallltary',\n",
       " 'recoanitioll',\n",
       " 'epreselltative',\n",
       " 'gelzerally',\n",
       " 'educatiollal',\n",
       " 'clistrict',\n",
       " 'mallifests',\n",
       " 'appropriatioll',\n",
       " 'bellalf',\n",
       " 'patcllwork',\n",
       " 'parliamelltary',\n",
       " 'idealizatioll',\n",
       " 'cotnlllon',\n",
       " 'eneratiolls',\n",
       " 'illlmediately',\n",
       " 'lessellilag',\n",
       " 'systemgivillg',\n",
       " 'lnayor',\n",
       " 'tllayor',\n",
       " 'lnunicipality',\n",
       " 'pllllldered',\n",
       " 'sanle',\n",
       " 'tendelley',\n",
       " 'sllos',\n",
       " 'eonneetioll',\n",
       " 'beilag',\n",
       " 'eonstitlltiolls',\n",
       " 'instrulllellts',\n",
       " 'referellee',\n",
       " 'argumellt',\n",
       " 'ehallge',\n",
       " 'signifieallt',\n",
       " 'abanclotsllllent',\n",
       " 'eolntnon',\n",
       " 'sllbstitu',\n",
       " 'partisall',\n",
       " 'eollverted',\n",
       " 'wllieh',\n",
       " 'goverlllz',\n",
       " 'eommullity',\n",
       " 'maellillery',\n",
       " 'orgalliza',\n",
       " 'suell',\n",
       " 'eompetitioll',\n",
       " 'lpally',\n",
       " 'eall',\n",
       " 'eeollotny',\n",
       " 'parallel',\n",
       " 'railroads',\n",
       " 'eonlpetillg',\n",
       " 'workswitllotlt',\n",
       " 'eollvenienee',\n",
       " 'eanllot',\n",
       " 'lllanr',\n",
       " 'eoll',\n",
       " 'vhiell',\n",
       " 'detrimellt',\n",
       " 'otllel',\n",
       " 'beilog',\n",
       " 'overtakell',\n",
       " 'xvill',\n",
       " 'elltrusted',\n",
       " 'tllein',\n",
       " 'illclireet',\n",
       " 'proteetiotl',\n",
       " 'eolllmereial',\n",
       " 'eolnpetition',\n",
       " 'inclividualized',\n",
       " 'eorl',\n",
       " 'eonlulereial',\n",
       " 'lllelch',\n",
       " 'ulllimited',\n",
       " 'proulotillg',\n",
       " 'eonedellee',\n",
       " 'illclividual',\n",
       " 'regulatillg',\n",
       " 'otlr',\n",
       " 'lrlunieipalities',\n",
       " 'ulldreamed',\n",
       " 'ldllt',\n",
       " 'eolllbi',\n",
       " 'llatiollal',\n",
       " 'neeessarily',\n",
       " 'recogllitioll',\n",
       " 'pursllits',\n",
       " 'federatioll',\n",
       " 'theilown',\n",
       " 'llesr',\n",
       " 'fulldamental',\n",
       " 'boullded',\n",
       " 'cleluded',\n",
       " 'constitutionally',\n",
       " 'colldltions',\n",
       " 'flllfil',\n",
       " 'xnorally',\n",
       " 'politically',\n",
       " 'rollle',\n",
       " 'ruilled',\n",
       " 'alzlericall',\n",
       " 'leecls',\n",
       " 'goverlllllent',\n",
       " 'collectivisin',\n",
       " 'collectivism',\n",
       " 'allalces',\n",
       " 'cllaracters',\n",
       " 'detnallds',\n",
       " 'lnen',\n",
       " 'colllonercial',\n",
       " 'illethods',\n",
       " 'coillproulise',\n",
       " 'convictioll',\n",
       " 'lllan',\n",
       " 'illusion',\n",
       " 'collditiolls',\n",
       " 'plovillg',\n",
       " 'ullw',\n",
       " 'derstallding',\n",
       " 'lleecls',\n",
       " 'evokillg',\n",
       " 'svllatever',\n",
       " 'breadtll',\n",
       " 'toucllillg',\n",
       " 'folloving',\n",
       " 'qllol',\n",
       " 'atioll',\n",
       " 'fllrllishes',\n",
       " 'cllanlpiolls',\n",
       " 'dolllillated',\n",
       " 'harmollized',\n",
       " 'cllristiallity',\n",
       " 'itrlpossible',\n",
       " 'lllatl',\n",
       " 'conclitions',\n",
       " 'cullilillg',\n",
       " 'cnildren',\n",
       " 'warpillg',\n",
       " 'wilich',\n",
       " 'bidclillg',\n",
       " 'mollopolists',\n",
       " 'tlleologialls',\n",
       " 'btlt',\n",
       " 'togetllel',\n",
       " 'llumaol',\n",
       " 'clivil',\n",
       " 'ulllatlity',\n",
       " 'delllonracy',\n",
       " 'gallizillg',\n",
       " 'maclliller',\n",
       " 'llt',\n",
       " 'aillst',\n",
       " 'tlwis',\n",
       " 'utterallce',\n",
       " 'clearcllt',\n",
       " 'sioll',\n",
       " 'jtlst',\n",
       " 'llseci',\n",
       " 'lncavrorable',\n",
       " 'alltic',\n",
       " 'tliat',\n",
       " 'everybocly',\n",
       " 'cllll',\n",
       " 'illg',\n",
       " 'allead',\n",
       " 'hulllalwity',\n",
       " 'colllfortable',\n",
       " 'wlloul',\n",
       " 'sillt',\n",
       " 'olltburst',\n",
       " 'cllristiall',\n",
       " 'heavenlr',\n",
       " 'lillers',\n",
       " 'colnpetition',\n",
       " 'rapllael',\n",
       " 'kllosr',\n",
       " 'tllou',\n",
       " 'ecollol',\n",
       " 'colusecratioll',\n",
       " 'cailnibalistll',\n",
       " 'lllese',\n",
       " 'sturcly',\n",
       " 'delatonciatioll',\n",
       " 'iglltly',\n",
       " 'ilnpl',\n",
       " 'gll',\n",
       " 'olloies',\n",
       " 'callec',\n",
       " 'titiotl',\n",
       " 'svllere',\n",
       " 'lnell',\n",
       " 'lllel',\n",
       " 'srall',\n",
       " 'coollpesitioll',\n",
       " 'nvllid',\n",
       " 'illlites',\n",
       " 'nvitll',\n",
       " 'tlze',\n",
       " 'colnpetitiolo',\n",
       " 'tllaol',\n",
       " 'tlleft',\n",
       " 'crowcliilg',\n",
       " 'lnel',\n",
       " 'platitilig',\n",
       " 'tlae',\n",
       " 'colupetitiotl',\n",
       " 'slnft',\n",
       " 'iicliisiokl',\n",
       " 'lilnself',\n",
       " 'brotl',\n",
       " 'altrtlidlll',\n",
       " 'golclel',\n",
       " 'neiglll',\n",
       " 'rellderi',\n",
       " 'eolllpetition',\n",
       " 'sllell',\n",
       " 'eolltl',\n",
       " 'aclietory',\n",
       " 'eeolleiliatioll',\n",
       " 'utlqtlestiolled',\n",
       " 'unallitr',\n",
       " 'cllal',\n",
       " 'bascoln',\n",
       " 'milllleapolis',\n",
       " 'atlsinson',\n",
       " 'septelilber',\n",
       " 'cliainet',\n",
       " 'rlcally',\n",
       " 'wrllat',\n",
       " 'corclially',\n",
       " 'arclently',\n",
       " 'adlilires',\n",
       " 'altinclanee',\n",
       " 'cleserwrilig',\n",
       " 'lloic',\n",
       " 'tlat',\n",
       " 'cil',\n",
       " 'lillgs',\n",
       " 'allcl',\n",
       " 'cecled',\n",
       " 'desllitioll',\n",
       " 'ozzitld',\n",
       " 'rlleol',\n",
       " 'clls',\n",
       " 'cotllpetitioll',\n",
       " 'colrlpetition',\n",
       " 'strlltrt',\n",
       " 'cotlisietilla',\n",
       " 'clictiolzaries',\n",
       " 'solzllelllliilc',\n",
       " 'lell',\n",
       " 'tllezn',\n",
       " 'elldeavorint',\n",
       " 'encleavoritlo',\n",
       " 'colll',\n",
       " 'eotltest',\n",
       " 'villd',\n",
       " 'dictiollarr',\n",
       " 'cle',\n",
       " 'llsts',\n",
       " 'llstvvllat',\n",
       " 'ullderstallcls',\n",
       " 'lclrce',\n",
       " 'sellsse',\n",
       " 'eolls',\n",
       " 'utlcler',\n",
       " 'ebilae',\n",
       " 'precisiotl',\n",
       " 'il',\n",
       " 'cjefilli',\n",
       " 'tiolls',\n",
       " 'conapetltiola',\n",
       " 'conlflicting',\n",
       " 'dowtl',\n",
       " 'salld',\n",
       " 'arllled',\n",
       " 'comttlerce',\n",
       " 'llarles',\n",
       " 'trallsl',\n",
       " 'jacobsell',\n",
       " 'talkillg',\n",
       " 'crilllillal',\n",
       " 'strllt',\n",
       " 'conflictillg',\n",
       " 'dolaolllillated',\n",
       " 'llpelitioll',\n",
       " 'colnpetitioul',\n",
       " 'trll',\n",
       " 'oollllcls',\n",
       " 'llk',\n",
       " 'lntl',\n",
       " 'stl',\n",
       " 'lilizited',\n",
       " 'collstittiollal',\n",
       " 'rllggle',\n",
       " 'lzollaclaries',\n",
       " 'factlltie',\n",
       " 'elillood',\n",
       " 'alllell',\n",
       " 'letlt',\n",
       " 'zzlillc',\n",
       " 'obviralls',\n",
       " 'valli',\n",
       " 'lilce',\n",
       " 'aziallr',\n",
       " 'svllell',\n",
       " 'tearillg',\n",
       " 'lclil',\n",
       " 'xllpply',\n",
       " 'illcolplete',\n",
       " 'inlperfeeit',\n",
       " 'pictllre',\n",
       " 'strllgg',\n",
       " 'ttltesz',\n",
       " 'clescrilde',\n",
       " 'cotoopotofloll',\n",
       " 'llollg',\n",
       " 'exrell',\n",
       " 'wloell',\n",
       " 'lli',\n",
       " 'llc',\n",
       " 'coillpttitioil',\n",
       " 'elelnelljc',\n",
       " 'relacler',\n",
       " 'neally',\n",
       " 'tlie',\n",
       " 'prilzciple',\n",
       " 'oltltior',\n",
       " 'licll',\n",
       " 'wllerevel',\n",
       " 'lfotllil',\n",
       " 'cotllci',\n",
       " 'fllndal',\n",
       " 'lnutalilfll',\n",
       " 'colrlletitiolz',\n",
       " 'alllat',\n",
       " 'tllexl',\n",
       " 'iilciple',\n",
       " 'fainiliar',\n",
       " 'natlll',\n",
       " 'reslllti',\n",
       " 'stlrvi',\n",
       " 'ellvirollinellt',\n",
       " 'fclllziliar',\n",
       " 'olletllocls',\n",
       " 'pearallce',\n",
       " 'makillg',\n",
       " 'otlt',\n",
       " 'crllel',\n",
       " 'strl',\n",
       " 'rollsseall',\n",
       " 'mild',\n",
       " 'clescriptiosls',\n",
       " 'collcepticall',\n",
       " 'tootll',\n",
       " 'ritll',\n",
       " 'ravill',\n",
       " 'htl',\n",
       " 'allill',\n",
       " 'glacliatol',\n",
       " 'sllonv',\n",
       " 'eattlres',\n",
       " 'wllerebr',\n",
       " 'strotlbest',\n",
       " 'clltzllinbest',\n",
       " 'tllllillld',\n",
       " 'qllal',\n",
       " 'mwallace',\n",
       " 'attelltiool',\n",
       " 'paillless',\n",
       " 'allloilg',\n",
       " 'allilncals',\n",
       " 'atllotoilt',\n",
       " 'llgble',\n",
       " 'cls',\n",
       " 'lnaximutn',\n",
       " 'luillillltlln',\n",
       " 'stlhetfillg',\n",
       " 'xvatcll',\n",
       " 'aailalal',\n",
       " 'cclll',\n",
       " 'concltlcle',\n",
       " 'sllbsequent',\n",
       " 'lllerelr',\n",
       " 'tllc',\n",
       " 'offsldril',\n",
       " 'colnpaniolzs',\n",
       " 'lnl',\n",
       " 'artlollg',\n",
       " 'bxistellce',\n",
       " 'xvinislll',\n",
       " 'weapolls',\n",
       " 'llasten',\n",
       " 'orgallie',\n",
       " 'emergellce',\n",
       " 'prilllitize',\n",
       " 'aililnals',\n",
       " 'eolle',\n",
       " 'tnigntily',\n",
       " 'ullceasillt',\n",
       " 'ellds',\n",
       " 'grall',\n",
       " 'lelllx',\n",
       " 'faintly',\n",
       " 'lllall',\n",
       " 'rlerar',\n",
       " 'ldeginnilags',\n",
       " 'ftltlclalnelltal',\n",
       " 'alliluate',\n",
       " 'illd',\n",
       " 'lldes',\n",
       " 'slaugllter',\n",
       " 'bradllally',\n",
       " 'clisllonorable',\n",
       " 'colllel',\n",
       " 'woll',\n",
       " 'battle',\n",
       " 'belollt',\n",
       " 'ecollolllic',\n",
       " 'illdllstry',\n",
       " 'svithitl',\n",
       " 'tellt',\n",
       " 'plalle',\n",
       " 'incolnpatible',\n",
       " 'pil',\n",
       " 'colnpetitive',\n",
       " 'tllajc',\n",
       " 'lla',\n",
       " 'falltll',\n",
       " 'outsicle',\n",
       " 'centtlry',\n",
       " 'iolcreasillb',\n",
       " 'illtellsity',\n",
       " 'cllik',\n",
       " 'ltlasred',\n",
       " 'ullwllolesollle',\n",
       " 'conclitio',\n",
       " 'aild',\n",
       " 'llllllllderless',\n",
       " 'installces',\n",
       " 'tll',\n",
       " 'sidetlt',\n",
       " 'plll',\n",
       " 'leclared',\n",
       " 'goverlllnellt',\n",
       " 'cohlpetitioll',\n",
       " 'lliaolself',\n",
       " 'sllrprised',\n",
       " 'filad',\n",
       " 'profolll',\n",
       " 'illapressioll',\n",
       " 'pregllant',\n",
       " 'lllysteries',\n",
       " 'allel',\n",
       " 'revealillg',\n",
       " 'reconciliations',\n",
       " 'eacly',\n",
       " 'alnollg',\n",
       " 'atlilllals',\n",
       " 'tlpon',\n",
       " 'earl',\n",
       " 'adattls',\n",
       " 'pursllilag',\n",
       " 'colulllon',\n",
       " 'kil',\n",
       " 'gollen',\n",
       " 'comltloll',\n",
       " 'agailn',\n",
       " 'pernlallent',\n",
       " 'tllell',\n",
       " 'cliscover',\n",
       " 'zalitlli',\n",
       " 'illsllite',\n",
       " 'rollps',\n",
       " 'szlall',\n",
       " 'illiolaty',\n",
       " 'lzatioll',\n",
       " 'coln',\n",
       " 'etitioll',\n",
       " 'walitll',\n",
       " 'benevoletlce',\n",
       " 'pllldllc',\n",
       " 'llulllallitariaoli',\n",
       " 'gtllells',\n",
       " 'lless',\n",
       " 'uleolll',\n",
       " 'grotlp',\n",
       " 'splle',\n",
       " 'luilder',\n",
       " 'ecolne',\n",
       " 'walittless',\n",
       " 'llloclern',\n",
       " 'pllilantllropy',\n",
       " 'ecotlomio',\n",
       " 'lterlaational',\n",
       " 'igllest',\n",
       " 'inclisticltlal',\n",
       " 'eratioll',\n",
       " 'beilevolellce',\n",
       " 'sometillles',\n",
       " 'llurllanitarian',\n",
       " 'cleo',\n",
       " 'avvorld',\n",
       " 'goetlle',\n",
       " 'sllcll',\n",
       " 'apprellelesioll',\n",
       " 'sollae',\n",
       " 'individllals',\n",
       " 'behilld',\n",
       " 'milcllless',\n",
       " 'lessells',\n",
       " 'reprodllction',\n",
       " 'cloe',\n",
       " 'ilacreasing',\n",
       " 'cliscourages',\n",
       " 'inarl',\n",
       " 'vllile',\n",
       " 'crimillal',\n",
       " 'increasilog',\n",
       " 'cletain',\n",
       " 'idellce',\n",
       " 'malacly',\n",
       " 'sanitatioll',\n",
       " 'luoderll',\n",
       " 'cinrilization',\n",
       " 'nllo',\n",
       " 'conlparisons',\n",
       " 'xtvritll',\n",
       " 'strellgth',\n",
       " 'srolnell',\n",
       " 'toclay',\n",
       " 'inllabit',\n",
       " 'blltland',\n",
       " 'uloclern',\n",
       " 'tllrollt',\n",
       " 'llleall',\n",
       " 'particlllar',\n",
       " 'tinle',\n",
       " 'lntimely',\n",
       " 'llomilliolls',\n",
       " 'aioderll',\n",
       " 'establislles',\n",
       " 'consciollsly',\n",
       " 'uncollsciollsly',\n",
       " 'nlany',\n",
       " 'elllillent',\n",
       " 'fitlaess',\n",
       " 'possildle',\n",
       " 'fitlless',\n",
       " 'svhile',\n",
       " 'ullfavorable',\n",
       " 'socially',\n",
       " 'metllods',\n",
       " 'deterluille',\n",
       " 'sllrvive',\n",
       " 'fllrllislles',\n",
       " 'livelillood',\n",
       " 'percelltat',\n",
       " 'tllerebv',\n",
       " 'fsdllud',\n",
       " 'spoils',\n",
       " 'illtense',\n",
       " 'isslles',\n",
       " 'stlrival',\n",
       " 'lcnowll',\n",
       " 'extellels',\n",
       " 'coltlpetil',\n",
       " 'ioll',\n",
       " 'hll',\n",
       " 'metllocls',\n",
       " 'corresponclilzg',\n",
       " 'llallel',\n",
       " 'bitterlless',\n",
       " 'collsonallce',\n",
       " 'portllllity',\n",
       " 'stlrvirral',\n",
       " 'utacler',\n",
       " 'sstelll',\n",
       " 'killel',\n",
       " 'trlle',\n",
       " 'llel',\n",
       " 'collfornlity',\n",
       " 'rlls',\n",
       " 'alullace',\n",
       " 'selectioll',\n",
       " 'llatt',\n",
       " 'tllel',\n",
       " 'pllrest',\n",
       " 'llosrever',\n",
       " 'lnaxinlum',\n",
       " 'cattle',\n",
       " 'lllind',\n",
       " 'milld',\n",
       " 'hatld',\n",
       " 'investigatilzg',\n",
       " 'outlines',\n",
       " 'gallizatioll',\n",
       " 'colulili',\n",
       " 'tnucll',\n",
       " 'stitiltioll',\n",
       " 'dil',\n",
       " 'ectl',\n",
       " 'overcroxtwdilag',\n",
       " 'illfected',\n",
       " 'valls',\n",
       " 'ceilin',\n",
       " 'aoltl',\n",
       " 'oranizatioll',\n",
       " 'ldllysicialls',\n",
       " 'clanger',\n",
       " 'trile',\n",
       " 'cllaslces',\n",
       " 'coticlitions',\n",
       " 'llnder',\n",
       " 'tllorollghly',\n",
       " 'conclition',\n",
       " 'deville',\n",
       " 'walllile',\n",
       " 'znibllt',\n",
       " 'clevise',\n",
       " 'rollts',\n",
       " 'xarotlld',\n",
       " 'ild',\n",
       " 'lrlore',\n",
       " 'conclitiolas',\n",
       " 'ily',\n",
       " 'ellts',\n",
       " 'stlt',\n",
       " 'estioll',\n",
       " 'lllity',\n",
       " 'lall',\n",
       " 'alliluals',\n",
       " 'elevatiolls',\n",
       " 'lnealls',\n",
       " 'bellind',\n",
       " 'combillations',\n",
       " 'colubillations',\n",
       " 'combinatiolls',\n",
       " 'neall',\n",
       " 'coznpetitiorl',\n",
       " 'wllete',\n",
       " 'cotupetitiotl',\n",
       " 'lletllod',\n",
       " 'owllel',\n",
       " 'nallagetllel',\n",
       " 'illclustl',\n",
       " 'terlus',\n",
       " 'elnployment',\n",
       " 'clisti',\n",
       " 'cli',\n",
       " 'fteretlce',\n",
       " 'socialilstic',\n",
       " 'nlnental',\n",
       " 'wllid',\n",
       " 'llppl',\n",
       " 'tssioll',\n",
       " 'dellla',\n",
       " 'lllaental',\n",
       " 'nailltellallce',\n",
       " 'conclitiolls',\n",
       " 'zlally',\n",
       " 'illdividllallv',\n",
       " 'lllelst',\n",
       " 'fllrllislled',\n",
       " 'irrialtioll',\n",
       " 'illllstratioll',\n",
       " 'clellts',\n",
       " 'irligation',\n",
       " 'irritatioll',\n",
       " 'colllpetitio',\n",
       " 'llollopols',\n",
       " 'peronaoletlt',\n",
       " 'llclerstalld',\n",
       " 'silllply',\n",
       " 'alnotlt',\n",
       " 'rebioll',\n",
       " 'costly',\n",
       " 'sllpplieel',\n",
       " 'divideolcls',\n",
       " 'lvestlnetlt',\n",
       " 'lnllst',\n",
       " 'irl',\n",
       " 'latiollal',\n",
       " 'ecollotllic',\n",
       " 'lililliam',\n",
       " 'atlatzzic',\n",
       " 'govelnillelltal',\n",
       " 'llolv',\n",
       " 'allude',\n",
       " 'ilaovelnellt',\n",
       " 'approaclleswi',\n",
       " 'tllotlt',\n",
       " 'reaclli',\n",
       " 'opldorttlnities',\n",
       " 'colilpetitioll',\n",
       " 'lllovelnelltvs',\n",
       " 'lllilld',\n",
       " 'llistol',\n",
       " 'nlove',\n",
       " 'nlents',\n",
       " 'centl',\n",
       " 'clereloldnlent',\n",
       " 'follnd',\n",
       " 'institlltiolas',\n",
       " 'colnpetitio',\n",
       " 'otllicll',\n",
       " 'nallicll',\n",
       " 'jllicll',\n",
       " 'savillgs',\n",
       " 'balllss',\n",
       " 'lnind',\n",
       " 'ecollollaic',\n",
       " 'jtlriclical',\n",
       " 'instittl',\n",
       " 'iilterests',\n",
       " 'oxilllation',\n",
       " 'perlxrlitted',\n",
       " 'illstitutioi',\n",
       " 'lnul',\n",
       " 'opporctlnity',\n",
       " 'illstitutional',\n",
       " 'lltiest',\n",
       " 'clelicate',\n",
       " 'colltrolled',\n",
       " 'furllishes',\n",
       " 'maxillluln',\n",
       " 'millimtltll',\n",
       " 'vllinks',\n",
       " 'qllietly',\n",
       " 'religioll',\n",
       " 'ellt',\n",
       " 'erforlll',\n",
       " 'plalles',\n",
       " 'llilagle',\n",
       " 'letld',\n",
       " 'slnpathy',\n",
       " 'clisplacine',\n",
       " 'colllldetitioll',\n",
       " 'coluzetitiotl',\n",
       " 'llss',\n",
       " 'lnerciflll',\n",
       " 'ldeetl',\n",
       " 'rell',\n",
       " 'tuall',\n",
       " 'evoltltion',\n",
       " 'luall',\n",
       " 'ecoslolllic',\n",
       " 'proclacillt',\n",
       " 'comptitioll',\n",
       " 'tninoletl',\n",
       " 'lllative',\n",
       " 'prillciles',\n",
       " 'psycholocically',\n",
       " 'etller',\n",
       " 'ecoololllically',\n",
       " 'ellgage',\n",
       " 'nlally',\n",
       " 'splleres',\n",
       " 'tlleself',\n",
       " 'ridellillb',\n",
       " 'llutnanity',\n",
       " 'attailltxlent',\n",
       " 'ribhtly',\n",
       " 'sllffieiellt',\n",
       " 'llei',\n",
       " 'tnealls',\n",
       " 'vlpbuilding',\n",
       " 'nlull',\n",
       " 'edtlca',\n",
       " 'college',\n",
       " 'wilderness',\n",
       " 'ullheeded',\n",
       " 'btlsilless',\n",
       " 'svorld',\n",
       " 'folllld',\n",
       " 'dozell',\n",
       " 'fullctioll',\n",
       " 'furnislling',\n",
       " 'annoullceinent',\n",
       " 'untiljilly',\n",
       " 'zzlollographs',\n",
       " 'appellded',\n",
       " 'colulnbiaulliversity',\n",
       " 'operatiotl',\n",
       " 'dartluouth',\n",
       " 'alnos',\n",
       " 'nallce',\n",
       " 'verlllont',\n",
       " 'econolnics',\n",
       " 'aiiciligan',\n",
       " 'colnmercial',\n",
       " 'illinois',\n",
       " 'lllal',\n",
       " 'edtlcation',\n",
       " 'formlllation',\n",
       " 'ollteollle',\n",
       " 'colnlllutlity',\n",
       " 'teellriieal',\n",
       " 'departlllellts',\n",
       " 'tetldelley',\n",
       " 'tlltls',\n",
       " 'eivilized',\n",
       " 'eoulltries',\n",
       " 'belgillm',\n",
       " 'teaelling',\n",
       " 'ulliversitr',\n",
       " 'lollclon',\n",
       " 'moclerll',\n",
       " 'satisfaetioll',\n",
       " 'faelllty',\n",
       " 'lnellt',\n",
       " 'aeeordill',\n",
       " 'strikil',\n",
       " 'belgillnl',\n",
       " 'giell',\n",
       " 'inoxrelllellt',\n",
       " 'statlls',\n",
       " 'provicling',\n",
       " 'sellools',\n",
       " 'colllluercial',\n",
       " 'seiellees',\n",
       " 'colnollereial',\n",
       " 'elatilng',\n",
       " 'comlllel',\n",
       " 'educalioll',\n",
       " 'appellcled',\n",
       " 'uiliversity',\n",
       " 'conlulissiollers',\n",
       " 'fehrtlartr',\n",
       " 'econonlics',\n",
       " 'igillal',\n",
       " 'lonclon',\n",
       " 'londoll',\n",
       " 'lldelshochschule',\n",
       " 'consttlaires',\n",
       " 'lvuvaill',\n",
       " 'dispositiolls',\n",
       " 'eolllltries',\n",
       " 'ulliversites',\n",
       " 'shollld',\n",
       " 'unclertake',\n",
       " 'etioll',\n",
       " 'beeallse',\n",
       " 'eertaill',\n",
       " 'bracle',\n",
       " 'eolninereial',\n",
       " 'cielllaild',\n",
       " 'illnovavion',\n",
       " 'eireumstallees',\n",
       " 'lland',\n",
       " 'eomlllereial',\n",
       " 'gracle',\n",
       " 'llniversities',\n",
       " 'quiekll',\n",
       " 'oleecls',\n",
       " 'olla',\n",
       " 'edlleatioll',\n",
       " 'lnally',\n",
       " 'eomll',\n",
       " 'tlli',\n",
       " 'llilldrallee',\n",
       " 'intelleetual',\n",
       " 'illstitutioll',\n",
       " 'nullity',\n",
       " 'sometinles',\n",
       " 'clead',\n",
       " 'meclioerity',\n",
       " 'clefeets',\n",
       " 'steatly',\n",
       " 'eontinlled',\n",
       " ...]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r,i in results.items() if len(i)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class FinalStrNode(StrNode):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  og_str,\n",
    "#                  current_str,\n",
    "#                  parent_node:FinalStrNode,\n",
    "#                  child_node:FinalStrNode,\n",
    "#                  path_to_end:Optional[TransList] = None,\n",
    "#                  end_str:str):\n",
    "#         self.children = [child_node] if child_node is not None else []\n",
    "#         self.parent:Optional[StrNode] = parent_node\n",
    "#         self.parent_trans:Transformation|None =parent_t\n",
    "#         self.current:str = current\n",
    "#         self.end_str = end_str\n",
    "#         self.leaf = self.children==[]\n",
    "#         self.path_to_end = path_to_end\n",
    "#         self.next = child_node\n",
    "\n",
    "#     def get_path_to_end(self)->TransList:\n",
    "#         if self.path_to_end is not None:\n",
    "#             return self.path_to_end\n",
    "#         node = self\n",
    "#         ts = TransList()\n",
    "#         while node.current!=self.end_str:\n",
    "#             child = node.next\n",
    "#             ts.append(child.parent_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: prev_steps, dtype: object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_melt['prev_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>old_count</th>\n",
       "      <th>prev_steps</th>\n",
       "      <th>current_word</th>\n",
       "      <th>transformation</th>\n",
       "      <th>new_word</th>\n",
       "      <th>in_other</th>\n",
       "      <th>any_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llletllod</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>nletnod</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>nletnod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>illaterial</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>inaterial</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>inaterial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollore</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>onore</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>onore</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dissellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>collsistently</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507145</th>\n",
       "      <td>hotlle</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>honle</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>honle</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507146</th>\n",
       "      <td>predominantly</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>predominanny</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>predominanny</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507147</th>\n",
       "      <td>cotllplacency</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>conlplacency</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>conlplacency</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507148</th>\n",
       "      <td>rtller</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>rnler</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>rnler</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507149</th>\n",
       "      <td>dotllinatioll</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>donlinatioll</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>donlinatioll</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189037 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              og_word  old_count          prev_steps  current_word  \\\n",
       "0           llletllod          1  _ll->n_ll->n_ll->n       nletnod   \n",
       "1          illaterial          1  _ll->n_ll->n_ll->n     inaterial   \n",
       "2              ollore          1  _ll->n_ll->n_ll->n         onore   \n",
       "3            dissellt          1  _ll->n_ll->n_ll->n       dissent   \n",
       "4       collsistently          1  _ll->n_ll->n_ll->n  consistently   \n",
       "...               ...        ...                 ...           ...   \n",
       "507145         hotlle          1  _tl->n_tl->n_tl->n         honle   \n",
       "507146  predominantly          1  _tl->n_tl->n_tl->n  predominanny   \n",
       "507147  cotllplacency          1  _tl->n_tl->n_tl->n  conlplacency   \n",
       "507148         rtller          1  _tl->n_tl->n_tl->n         rnler   \n",
       "507149  dotllinatioll          1  _tl->n_tl->n_tl->n  donlinatioll   \n",
       "\n",
       "       transformation      new_word  in_other  any_found  \n",
       "0               ll->n       nletnod     False      False  \n",
       "1               ll->n     inaterial     False      False  \n",
       "2               ll->n         onore     False      False  \n",
       "3               ll->n       dissent     False      False  \n",
       "4               ll->n  consistently     False      False  \n",
       "...               ...           ...       ...        ...  \n",
       "507145          tl->n         honle     False      False  \n",
       "507146          tl->n  predominanny     False      False  \n",
       "507147          tl->n  conlplacency     False      False  \n",
       "507148          tl->n         rnler     False      False  \n",
       "507149          tl->n  donlinatioll     False      False  \n",
       "\n",
       "[189037 rows x 8 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_melt\n",
    "'material_dissent_consistently_domination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cum_ct'] = df.groupby('corpus_word')['corp_count'].transform('sum')\n",
    "new = new_melt[new_melt['in_other']==False]\n",
    "for i,(b,a) in enumerate(chars):\n",
    "    col = f\"{a}->{b}\"\n",
    "    new[col] = new['new_word'].apply(lambda x: x.replace(a,b) if a in x else None)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ll-&gt;n</th>\n",
       "      <th>ll-&gt;u</th>\n",
       "      <th>ll-&gt;h</th>\n",
       "      <th>il-&gt;n</th>\n",
       "      <th>il-&gt;u</th>\n",
       "      <th>il-&gt;h</th>\n",
       "      <th>nl-&gt;m</th>\n",
       "      <th>ln-&gt;m</th>\n",
       "      <th>cl-&gt;d</th>\n",
       "      <th>vv-&gt;w</th>\n",
       "      <th>lll-&gt;m</th>\n",
       "      <th>rl-&gt;n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nletnod</td>\n",
       "      <td>uletuod</td>\n",
       "      <td>hlethod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>metllod</td>\n",
       "      <td>llletllod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttmity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>different</td>\n",
       "      <td>differeut</td>\n",
       "      <td>differeht</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sense</td>\n",
       "      <td>seuse</td>\n",
       "      <td>sehse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>funest</td>\n",
       "      <td>fuuest</td>\n",
       "      <td>fuhest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>wan</td>\n",
       "      <td>wau</td>\n",
       "      <td>wah</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>dearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>intenaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>feanessly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbunding</td>\n",
       "      <td>upbuuding</td>\n",
       "      <td>upbuhding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2780 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ll->n         ll->u         ll->h         il->n         il->u  \\\n",
       "2          nletnod       uletuod       hlethod     llletllod     llletllod   \n",
       "3     opporttlnity  opporttlnity  opporttlnity  opporttlnity  opporttlnity   \n",
       "4        different     differeut     differeht    differellt    differellt   \n",
       "5            sense         seuse         sehse        sellse        sellse   \n",
       "7           funest        fuuest        fuhest       fullest       fullest   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2918           wan           wau           wah          wall          wall   \n",
       "2919     clearness     clearness     clearness     clearness     clearness   \n",
       "2920    interlaced    interlaced    interlaced    interlaced    interlaced   \n",
       "2921    fearlessly    fearlessly    fearlessly    fearlessly    fearlessly   \n",
       "2922    upbuilding    upbuilding    upbuilding     upbunding     upbuuding   \n",
       "\n",
       "             il->h         nl->m        ln->m         cl->d         vv->w  \\\n",
       "2        llletllod     llletllod    llletllod     llletllod     llletllod   \n",
       "3     opporttlnity  opporttlnity  opporttmity  opporttlnity  opporttlnity   \n",
       "4       differellt    differellt   differellt    differellt    differellt   \n",
       "5           sellse        sellse       sellse        sellse        sellse   \n",
       "7          fullest       fullest      fullest       fullest       fullest   \n",
       "...            ...           ...          ...           ...           ...   \n",
       "2918          wall          wall         wall          wall          wall   \n",
       "2919     clearness     clearness    clearness      dearness     clearness   \n",
       "2920    interlaced    interlaced   interlaced    interlaced    interlaced   \n",
       "2921    fearlessly    fearlessly   fearlessly    fearlessly    fearlessly   \n",
       "2922     upbuhding    upbuilding   upbuilding    upbuilding    upbuilding   \n",
       "\n",
       "            lll->m         rl->n  \n",
       "2          metllod     llletllod  \n",
       "3     opporttlnity  opporttlnity  \n",
       "4       differellt    differellt  \n",
       "5           sellse        sellse  \n",
       "7          fullest       fullest  \n",
       "...            ...           ...  \n",
       "2918          wall          wall  \n",
       "2919     clearness     clearness  \n",
       "2920    interlaced     intenaced  \n",
       "2921    fearlessly     feanessly  \n",
       "2922    upbuilding    upbuilding  \n",
       "\n",
       "[2780 rows x 12 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 'll', 'u': 'll', 'm': 'nl', 'h': 'll', 'd': 'cl', 'l': 'i', 'w': 'vv'}\n"
     ]
    }
   ],
   "source": [
    "chars = [\"nll\",'ull','mlll','hll',\"dcl\",\"mrn\",'li','mln','mnl',\"wvv\"]\n",
    "cd = {}\n",
    "for c in chars:\n",
    "    cd[c[0]] = c[1:]\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = d\n",
    "def correct_word(word):\n",
    "    lower_word = word.lower()\n",
    "    if lower_word in corr:\n",
    "        corrected = corr[lower_word]\n",
    "        # Preserve capitalization\n",
    "        if word.istitle():\n",
    "            return corrected.capitalize()\n",
    "        elif word.isupper():\n",
    "            return corrected.upper()\n",
    "        else:\n",
    "            return corrected\n",
    "    return word\n",
    "\n",
    "# Correct text function\n",
    "def correct_text(text):\n",
    "    # Use regex to handle punctuation and retain word boundaries\n",
    "    return  re.sub(r'\\b\\w+\\b', lambda match: correct_word(match.group()), text)\n",
    "    \n",
    "\n",
    "\n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "new_folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/changed'\n",
    "os.makedirs(new_folder,exist_ok=True)\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        new = re.sub(r\"\\b(\\w+)(cl)\\b\",lambda match:match.group(1)+\"d\",text)\n",
    "        with open(path,'w') as f:\n",
    "            f.write(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellod ancly meowd'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"hellocl ancly meowcl\"\n",
    "re.sub(r\"\\b(\\w+)(cl)\\b\",lambda match:match.group(1)+\"d\",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betweell': 'between',\n",
       " 'ecollomics': 'economics',\n",
       " 'influellce': 'influence',\n",
       " 'opillion': 'opinion',\n",
       " 'mealls': 'means',\n",
       " 'presellt': 'present',\n",
       " 'ill': 'in',\n",
       " 'amollg': 'among',\n",
       " 'tlle': 'the',\n",
       " 'comlllercial': 'commercial',\n",
       " 'conditiolls': 'conditions',\n",
       " 'oll': 'on',\n",
       " 'witll': 'with',\n",
       " 'olles': 'ones',\n",
       " 'econolllics': 'economics',\n",
       " 'wllich': 'which',\n",
       " 'lle': 'he',\n",
       " 'olle': 'one',\n",
       " 'llis': 'his',\n",
       " 'standpoillt': 'standpoint',\n",
       " 'lleither': 'neither',\n",
       " 'llor': 'nor',\n",
       " 'halld': 'hand',\n",
       " 'alld': 'and',\n",
       " 'stalldards': 'standards',\n",
       " 'tllat': 'that',\n",
       " 'interactioll': 'interaction',\n",
       " 'whicll': 'which',\n",
       " 'whell': 'when',\n",
       " 'natioll': 'nation',\n",
       " 'illfluence': 'influence',\n",
       " 'sallle': 'same',\n",
       " 'higllest': 'highest',\n",
       " 'scielltific': 'scientific',\n",
       " 'wllo': 'who',\n",
       " 'tllose': 'those',\n",
       " 'llim': 'him',\n",
       " 'higll': 'high',\n",
       " 'tllree': 'three',\n",
       " 'llo': 'no',\n",
       " 'lllake': 'wake',\n",
       " 'beillg': 'being',\n",
       " 'owll': 'own',\n",
       " 'llave': 'have',\n",
       " 'mell': 'men',\n",
       " 'educatioll': 'education',\n",
       " 'llot': 'not',\n",
       " 'ollly': 'only',\n",
       " 'lllatters': 'matters',\n",
       " 'recognizillg': 'recognizing',\n",
       " 'olltside': 'outside',\n",
       " 'oftell': 'often',\n",
       " 'sucll': 'such',\n",
       " 'llloral': 'moral',\n",
       " 'tllelll': 'them',\n",
       " 'lille': 'line',\n",
       " 'ecollomist': 'economist',\n",
       " 'illterest': 'interest',\n",
       " 'colllmunity': 'community',\n",
       " 'eitller': 'either',\n",
       " 'claillls': 'claims',\n",
       " 'gelleral': 'general',\n",
       " 'illterests': 'interests',\n",
       " 'gettillg': 'getting',\n",
       " 'represelltatives': 'representatives',\n",
       " 'eacll': 'each',\n",
       " 'allother': 'another',\n",
       " 'opinioll': 'opinion',\n",
       " 'llecessary': 'necessary',\n",
       " 'thall': 'than',\n",
       " 'tllan': 'than',\n",
       " 'differellces': 'differences',\n",
       " 'ougllt': 'ought',\n",
       " 'allotller': 'another',\n",
       " 'collditions': 'conditions',\n",
       " 'moderll': 'modern',\n",
       " 'sollle': 'some',\n",
       " 'importallt': 'important',\n",
       " 'represelltative': 'representative',\n",
       " 'competitioll': 'competition',\n",
       " 'llow': 'now',\n",
       " 'advallce': 'advance',\n",
       " 'governmellt': 'government',\n",
       " 'llas': 'has',\n",
       " 'expressioll': 'expression',\n",
       " 'commullity': 'community',\n",
       " 'frolll': 'from',\n",
       " 'collflict': 'conflict',\n",
       " 'withill': 'within',\n",
       " 'tllinks': 'thinks',\n",
       " 'lllore': 'more',\n",
       " 'tllis': 'this',\n",
       " 'tllere': 'there',\n",
       " 'wllole': 'whole',\n",
       " 'sllall': 'small',\n",
       " 'tlleir': 'their',\n",
       " 'beell': 'been',\n",
       " 'celltury': 'century',\n",
       " 'togetller': 'together',\n",
       " 'otllers': 'others',\n",
       " 'wallts': 'wants',\n",
       " 'ullited': 'united',\n",
       " 'selltimellt': 'sentiment',\n",
       " 'actioll': 'action',\n",
       " 'tlley': 'they',\n",
       " 'lllust': 'must',\n",
       " 'evell': 'even',\n",
       " 'spllere': 'sphere',\n",
       " 'somethillg': 'something',\n",
       " 'thelll': 'them',\n",
       " 'centllry': 'century',\n",
       " 'pllblic': 'public',\n",
       " 'sllould': 'should',\n",
       " 'prillciple': 'principle',\n",
       " 'molley': 'money',\n",
       " 'witllin': 'within',\n",
       " 'legislatioll': 'legislation',\n",
       " 'cllange': 'change',\n",
       " 'golle': 'gone',\n",
       " 'wllose': 'whose',\n",
       " 'wllell': 'when',\n",
       " 'otller': 'other',\n",
       " 'busilless': 'business',\n",
       " 'witllout': 'without',\n",
       " 'upoll': 'upon',\n",
       " 'tlling': 'thing',\n",
       " 'tllese': 'these',\n",
       " 'autllority': 'authority',\n",
       " 'lllay': 'may',\n",
       " 'illdustrial': 'industrial',\n",
       " 'natiolls': 'nations',\n",
       " 'wllat': 'what',\n",
       " 'anotller': 'another',\n",
       " 'strollg': 'strong',\n",
       " 'conceptioll': 'conception',\n",
       " 'lligher': 'higher',\n",
       " 'killd': 'kind',\n",
       " 'llistory': 'history',\n",
       " 'natiollal': 'national',\n",
       " 'wllere': 'where',\n",
       " 'sciellce': 'science',\n",
       " 'sometlling': 'something',\n",
       " 'econolllic': 'economic',\n",
       " 'tllougllt': 'thought',\n",
       " 'foundatioll': 'foundation',\n",
       " 'colllpetition': 'competition',\n",
       " 'nilleteell': 'nineteen',\n",
       " 'cllristian': 'christian',\n",
       " 'existellce': 'existence',\n",
       " 'agaill': 'again',\n",
       " 'groulld': 'ground',\n",
       " 'wlly': 'why',\n",
       " 'colllpetitioll': 'competition',\n",
       " 'qllestion': 'question',\n",
       " 'disciplille': 'discipline',\n",
       " 'solllewllat': 'somewhat',\n",
       " 'indiviclllal': 'individual',\n",
       " 'coulltry': 'country',\n",
       " 'wlletller': 'whether',\n",
       " 'clloice': 'choice',\n",
       " 'strllggle': 'struggle',\n",
       " 'tllillgs': 'things',\n",
       " 'wealtll': 'wealth',\n",
       " 'lllany': 'many',\n",
       " 'alllong': 'along',\n",
       " 'ecollomic': 'economic',\n",
       " 'llpon': 'upon',\n",
       " 'figllt': 'fight',\n",
       " 'colllparatively': 'comparitively',\n",
       " 'cllaracter': 'character',\n",
       " 'etllical': 'ethical',\n",
       " 'paill': 'pain',\n",
       " 'attelltioll': 'attention',\n",
       " 'reslllt': 'result',\n",
       " 'evollltion': 'evolution',\n",
       " 'colnpetitioll': 'competition',\n",
       " 'evoltltioll': 'evolution',\n",
       " 'lllost': 'most',\n",
       " 'higller': 'higher',\n",
       " 'associatioll': 'association',\n",
       " 'illto': 'into',\n",
       " 'wllen': 'when',\n",
       " 'ulltil': 'until',\n",
       " 'cotllpetition': 'competition',\n",
       " 'evolutioll': 'evolution',\n",
       " 'growillt': 'growth',\n",
       " 'mally': 'many',\n",
       " 'discussioll': 'discussion',\n",
       " 'filld': 'find',\n",
       " 'americall': 'american',\n",
       " 'tllelllselves': 'themselves',\n",
       " 'colllpetitive': 'competitive',\n",
       " 'developlllent': 'development',\n",
       " 'cotnpetitioll': 'competition',\n",
       " 'civilizatioll': 'civilization',\n",
       " 'wolllcl': 'would',\n",
       " 'llew': 'new',\n",
       " 'lllen': 'men',\n",
       " 'efficiellt': 'efficient',\n",
       " 'lllell': 'well',\n",
       " 'cllief': 'chief',\n",
       " 'ecollolnic': 'economic',\n",
       " 'sllch': 'such',\n",
       " 'llloclerll': 'modern',\n",
       " 'petitioll': 'petition',\n",
       " 'frequelltly': 'frequently',\n",
       " 'qllalities': 'qualitites',\n",
       " 'tllus': 'thus',\n",
       " 'tllink': 'think',\n",
       " 'colldition': 'condition',\n",
       " 'cllarity': 'charity',\n",
       " 'becallse': 'because',\n",
       " 'opportllllities': 'opportunities',\n",
       " 'extetlsioll': 'extension',\n",
       " 'certaill': 'certain',\n",
       " 'opillioll': 'opinion',\n",
       " 'secllre': 'secure',\n",
       " 'celltllry': 'century',\n",
       " 'illstitutions': 'institutions',\n",
       " 'illust': 'must',\n",
       " 'eqllality': 'equality',\n",
       " 'twelltietll': 'twentieth',\n",
       " 'alltagollistic': 'antagonistic',\n",
       " 'llniversity': 'university',\n",
       " 'bllsiness': 'business',\n",
       " 'lleed': 'need',\n",
       " 'institutioll': 'institution',\n",
       " 'institutiolls': 'institutions',\n",
       " 'pellnsylvania': 'pennsylvania',\n",
       " 'establishmellt': 'astablishment',\n",
       " 'comlllerce': 'commerce',\n",
       " 'scllool': 'school',\n",
       " 'professiollal': 'professional',\n",
       " 'sllowll': 'shown',\n",
       " 'existellee': 'existence',\n",
       " 'lllovement': 'movement',\n",
       " 'rallk': 'rank',\n",
       " 'ulliversity': 'university',\n",
       " 'appoillted': 'appointed',\n",
       " 'forlll': 'form',\n",
       " 'ullder': 'under',\n",
       " 'eolleges': 'colleges',\n",
       " 'eollege': 'college',\n",
       " 'positioll': 'position',\n",
       " 'llear': 'near',\n",
       " 'llleans': 'means',\n",
       " 'througll': 'through',\n",
       " 'systelll': 'system',\n",
       " 'illstitutiolls': 'institutions',\n",
       " 'scllools': 'schools',\n",
       " 'nulllber': 'number',\n",
       " 'callillgs': 'callings',\n",
       " 'existillg': 'existing',\n",
       " 'takillg': 'taking',\n",
       " 'tllem': 'them',\n",
       " 'yollng': 'young',\n",
       " 'youllg': 'young',\n",
       " 'tllen': 'then',\n",
       " 'collrse': 'course',\n",
       " 'wollld': 'would',\n",
       " 'fashiollecl': 'fashioned',\n",
       " 'yollllg': 'young',\n",
       " 'migllt': 'might',\n",
       " 'trainillg': 'training',\n",
       " 'eallings': 'earnings',\n",
       " 'departlllents': 'departments',\n",
       " 'movelllellt': 'movement',\n",
       " 'variolls': 'various',\n",
       " 'tllrougll': 'through',\n",
       " 'curricululll': 'curriculum',\n",
       " 'collsidered': 'considered',\n",
       " 'elelllent': 'element',\n",
       " 'opportullity': 'opportunity',\n",
       " 'trllth': 'truth',\n",
       " 'takell': 'taken',\n",
       " 'elemellt': 'element',\n",
       " 'tlleoretieally': 'theoretically',\n",
       " 'tillles': 'times',\n",
       " 'cllrricula': 'curricula',\n",
       " 'tlleory': 'theory',\n",
       " 'melltal': 'mental',\n",
       " 'organizatioll': 'organization',\n",
       " 'bankillg': 'banking',\n",
       " 'illdustry': 'industry',\n",
       " 'colltracts': 'contracts',\n",
       " 'corporatioll': 'corporation',\n",
       " 'curriculllm': 'curriculum',\n",
       " 'bellefit': 'benefit',\n",
       " 'comlnullity': 'community',\n",
       " 'lleeds': 'needs',\n",
       " 'califorllia': 'california',\n",
       " 'colllmbia': 'columbia',\n",
       " 'endowmellt': 'endowment',\n",
       " 'bolles': 'bones',\n",
       " 'studellts': 'students',\n",
       " 'alllollg': 'among',\n",
       " 'pllilosophy': 'philosophy',\n",
       " 'indllstrial': 'industrial',\n",
       " 'wllicil': 'which',\n",
       " 'frellcll': 'french',\n",
       " 'eigllteeiltll': 'eighteenth',\n",
       " 'collceivecl': 'conceived',\n",
       " 'restraillts': 'restraints',\n",
       " 'follllcl': 'found',\n",
       " 'understalld': 'understand',\n",
       " 'llegative': 'negative',\n",
       " 'thougllt': 'thought',\n",
       " 'treatlllent': 'treatment',\n",
       " 'pllilosopllical': 'philosphical',\n",
       " 'cleveloplllellt': 'development',\n",
       " 'tllought': 'thought',\n",
       " 'envirollment': 'environment',\n",
       " 'colltract': 'contract',\n",
       " 'relatiolls': 'relations',\n",
       " 'ellactment': 'enactment',\n",
       " 'qllite': 'quite',\n",
       " 'regulatiolls': 'regulations',\n",
       " 'rigllt': 'right',\n",
       " 'problelll': 'problem',\n",
       " 'llature': 'nature',\n",
       " 'lleeded': 'needed',\n",
       " 'llours': 'hours',\n",
       " 'llour': 'hour',\n",
       " 'elemellts': 'elements',\n",
       " 'hollrs': 'hours',\n",
       " 'lllade': 'made',\n",
       " 'canllot': 'cannot',\n",
       " 'pressllre': 'pressure',\n",
       " 'dollbt': 'doubt',\n",
       " 'englalld': 'england',\n",
       " 'illclustrial': 'industrial',\n",
       " 'thell': 'then',\n",
       " 'fresll': 'fresh',\n",
       " 'eollditions': 'conditions'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
