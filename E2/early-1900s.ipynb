{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4141397846.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    words =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = \n",
    "\n",
    "counter=Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(counter.items())\n",
    "d = {}\n",
    "for word in df.loc[df[1]>1,0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m d2 \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 20\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mword\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m         d2[word] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words2 = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    page = int(pagetxt[:-4])\n",
    "    year = int(year)\n",
    "    if year<1904 and year>1900 or (year==1900 and page>13):\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words2.extend([w.lower() for w in words])\n",
    "counter2=Counter(all_words2)\n",
    "df2 = pd.DataFrame(counter2.items())\n",
    "d2 = {}\n",
    "for word in df2[0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d2[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         words \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m,text)\n\u001b[1;32m     17\u001b[0m         all_words\u001b[38;5;241m.\u001b[39mextend([w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words])\n\u001b[0;32m---> 19\u001b[0m all_counter\u001b[38;5;241m=\u001b[39m\u001b[43mCounter\u001b[49m(all_words)\n\u001b[1;32m     20\u001b[0m some_counter \u001b[38;5;241m=\u001b[39m Counter(words_1900s)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(\"[A-Za-z]*ll[A-Za-z]*|[A-Za-z]*cl[A-Za-z]*\",text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>clergylnen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>otlle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>lllln</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>preparillg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>sllrely</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>college</td>\n",
       "      <td>37</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>38</td>\n",
       "      <td>0.011370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>alld</td>\n",
       "      <td>47</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>129</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2\n",
       "1206  clergylnen    1  0.000299\n",
       "1598       otlle    1  0.000299\n",
       "1599       lllln    1  0.000299\n",
       "1600  preparillg    1  0.000299\n",
       "1601     sllrely    1  0.000299\n",
       "...          ...  ...       ...\n",
       "1074     college   37  0.011071\n",
       "7           well   38  0.011370\n",
       "151         alld   47  0.014063\n",
       "6           will   57  0.017056\n",
       "0            all  129  0.038600\n",
       "\n",
       "[2413 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = pd.DataFrame(all_counter.items())\n",
    "ac[2] = ac[1].apply(lambda x: x/sum(ac[1]))\n",
    "\n",
    "sc = pd.DataFrame(some_counter.items())\n",
    "\n",
    "sc[2] = sc[1].apply(lambda x: x/sum(sc[1]))\n",
    "# sc.sort_values(1)\n",
    "sc.sort_values(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [('n', 'll'),\n",
    "         ('u', 'll'),\n",
    "         ('h', 'll'),\n",
    "         ('n', 'il'),\n",
    "         ('u','il'),\n",
    "         ('h', 'il'),\n",
    "         ('m', 'nl'),\n",
    "         ('m', 'ln'),\n",
    "         ('d', 'cl'),\n",
    "         ('w', 'vv'),\n",
    "         ('m','lll'),\n",
    "         ('n','rl'),\n",
    "         ('u','tl'),\n",
    "         ('n','tl'),\n",
    "         ]\n",
    "         \n",
    "\n",
    "pattern = \"|\".join([f\"[A-Za-z]*{char[1]}[A-Za-z]*\" for char in set(chars) ])\n",
    "\n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(pattern,text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n",
    "\n",
    "#df = new_melt.merge(ac,left_on='new_word',right_on = 'corpus_word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>old_count</th>\n",
       "      <th>full_transformation</th>\n",
       "      <th>end_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>differellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sellse</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dyllamic</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dissellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>collsistently</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75233</th>\n",
       "      <td>acllievelllellts</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>achievements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76742</th>\n",
       "      <td>colilnlissioll</td>\n",
       "      <td>1</td>\n",
       "      <td>_il-&gt;n_ln-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100186</th>\n",
       "      <td>ullclerstalldillg</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n_cl-&gt;d</td>\n",
       "      <td>understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77036</th>\n",
       "      <td>lltllllall</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168328</th>\n",
       "      <td>ftltlclalnelltal</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_cl-&gt;d_ln-&gt;m_ll-&gt;n_tl-&gt;n</td>\n",
       "      <td>fundamental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  og_word old_count             full_transformation  \\\n",
       "3              differellt         1                          _ll->n   \n",
       "4                  sellse         1                          _ll->n   \n",
       "9                dyllamic         1                          _ll->n   \n",
       "15               dissellt         1                          _ll->n   \n",
       "16          collsistently         1                          _ll->n   \n",
       "...                   ...       ...                             ...   \n",
       "75233    acllievelllellts         1        _ll->h_ll->n_ll->n_nl->m   \n",
       "76742      colilnlissioll         1        _il->n_ln->m_ll->n_nl->m   \n",
       "100186  ullclerstalldillg         1        _ll->n_ll->n_ll->n_cl->d   \n",
       "77036          lltllllall         1  _tl->u_ll->h_ll->n_ll->n_nl->m   \n",
       "168328   ftltlclalnelltal         1  _tl->u_cl->d_ln->m_ll->n_tl->n   \n",
       "\n",
       "             end_word  \n",
       "3           different  \n",
       "4               sense  \n",
       "9             dynamic  \n",
       "15            dissent  \n",
       "16       consistently  \n",
       "...               ...  \n",
       "75233    achievements  \n",
       "76742      commission  \n",
       "100186  understanding  \n",
       "77036           human  \n",
       "168328    fundamental  \n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>transformations</th>\n",
       "      <th>duplicate_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>lllally</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>nlany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>goverlllnellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>governlnent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ecollolllics</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>econonlics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>developlllellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>developnlent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>departlllellts</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>departnlents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78140</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>hmmderless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78180</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_rl-&gt;n_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78386</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_rl-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78797</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_rl-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88577</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_ll-&gt;n_rl-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               og_word                 transformations  duplicate_of\n",
       "460            lllally                    _ll->n_ll->n         nlany\n",
       "466      goverlllnellt                    _ll->n_ll->n   governlnent\n",
       "570       ecollolllics                    _ll->n_ll->n    econonlics\n",
       "575     developlllellt                    _ll->n_ll->n  developnlent\n",
       "729     departlllellts                    _ll->n_ll->n  departnlents\n",
       "...                ...                             ...           ...\n",
       "78140  llllllllderless  _ll->h_ll->n_nl->m_ll->n_nl->m    hmmderless\n",
       "78180  llllllllderless  _rl->n_ll->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78386  llllllllderless  _ll->n_rl->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78797  llllllllderless  _ll->n_nl->m_rl->n_ll->n_nl->m    mmlldeness\n",
       "88577  llllllllderless  _ll->n_nl->m_ll->n_rl->n_nl->m    mmlldeness\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_reached_elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n",
      "hi-(0)->man|hi-(0)->man\n",
      "hi-(0)->man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Transformation('hi','man','0'), Transformation('hi','man','0')]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Type\n",
    "from collections.abc import MutableSequence\n",
    "import numpy as np\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FinishedState():\n",
    "#     all_intermediate: dict[str,str] = {}\n",
    "#     def __init__(self, start,end, transformations,intermediates):\n",
    "#         self.og:str = start\n",
    "#         self.end:str = end\n",
    "#         self.transformations: TransList = transformations\n",
    "\n",
    "#     def update_intermediate(self):\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable,Set,Dict\n",
    "class Transformation(object):\n",
    "    NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def is_null(self)->bool:\n",
    "        return self.old==self.new\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "    \n",
    "    def check_transform(self,s:str)->str|None:\n",
    "        i = self.start_idx\n",
    "        if not self.old in s[i:]:\n",
    "            return None\n",
    "        return self.transform(s)\n",
    "\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return Transformation(self.old,self.new,self.start_idx)\n",
    "    \n",
    "    def __repr__(self)->str:\n",
    "        return f\"Transformation('{self.old}','{self.new}','{self.start_idx}')\"\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return f\"{self.old}-({self.start_idx})->{self.new}\"\n",
    "\n",
    "class TransList(list[Transformation]):\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return \"|\".join([str(s) for s in self])\n",
    "NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "\n",
    "class Transformation(object):\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "class Transformation(object):\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "\n",
    "class StrNode(object):\n",
    "    known_words:Set[str] = set()\n",
    "    known_transformations: dict[str,str] = {} #will be the og words that got transformed\n",
    "    @classmethod\n",
    "    def update_known_words(cls,words: Iterable[str]):\n",
    "        cls.known_words.update(words)\n",
    "\n",
    "    @classmethod\n",
    "    def from_parent(cls,parent,transformation:Transformation,check_if_finished=True): #type:ignore\n",
    "        parent_s = parent.current\n",
    "        new_str = transformation.transform(parent_s)\n",
    "        finished=False\n",
    "        if check_if_finished:\n",
    "            finished = new_str in StrNode.known_words\n",
    "        return StrNode(parent.og,new_str,parent,transformation,finished)\n",
    "\n",
    "\n",
    "    def __init__(self,start_str:str,current:str|None=None, parent= None,parent_trans:Transformation|None = None,finished=False):\n",
    "        self.og = start_str\n",
    "        self.children:list[StrNode]=[]\n",
    "        self.parent:Optional[StrNode] = parent\n",
    "        self.parent_trans:Transformation=parent_trans or Transformation(\"\",\"\")\n",
    "        self.current:str = current if current is not None else start_str\n",
    "        self.leaf:bool = finished\n",
    "        self.next:Optional[StrNode] = None\n",
    "\n",
    "    def is_root(self)->bool:\n",
    "        return self.parent is None\n",
    "\n",
    "\n",
    "    def make_children(self,t:Transformation)->list[StrNode]|StrNode #type:ignore\n",
    "        current = self.current\n",
    "        child_list:list[StrNode] = []\n",
    "\n",
    "        for i in range(len(current)):\n",
    "            new_t = t.change_start_idx(i)\n",
    "            n = StrNode.from_parent(self,new_t)\n",
    "            if n.current==current: #means no change\n",
    "                continue\n",
    "\n",
    "            if n.is_leaf():\n",
    "                print(f\"Found ending state from {self.og} to {n.current}\")\n",
    "                return n\n",
    "            if n.current in StrNode.known_transformations:\n",
    "                end_str = StrNode.known_transformations[n.current]\n",
    "                print(f\"Made known transformation from {self.og} to {n.current} to {end_str}\")\n",
    "                return StrNode(self.og,n.current,n,Transformation(n.current,end_str))\n",
    "            \n",
    "\n",
    "            child_list.append(n)\n",
    "        self.children.extend(child_list)\n",
    "\n",
    "        print(f\"Adding {len(child_list)} to children and returning new ones\")\n",
    "        return child_list\n",
    "    \n",
    "    def reset_orig_string(self):\n",
    "        self.og = self.current\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def is_leaf(self)->bool:\n",
    "        return self.leaf\n",
    "\n",
    "def get_previous_strings(finished_node:StrNode)->list[str]:\n",
    "    if not finished_node.is_leaf():\n",
    "        raise ValueError(\"we need to make sure the node is a final one\")\n",
    "    node = finished_node\n",
    "    strings = [node.current]\n",
    "    while node.parent is not None:\n",
    "        strings.append(node.current)\n",
    "        node = node.parent\n",
    "    return strings\n",
    "\n",
    "def iterate_through_changes(known_words:list[str],\n",
    "                            unknown_words:list[str],\n",
    "                            char_changes:list[tuple[str,str]],max_iterations=5):\n",
    "    \n",
    "\n",
    "    unfinished_nodes: dict[str,set[StrNode]] = {uk:set([StrNode(uk,uk,None,None,False)]) for uk in unknown_words}\n",
    "    known_mapping:dict[str,str] = {}\n",
    "    StrNode.known_words = set(known_words)\n",
    "    StrNode.known_transformations = known_mapping\n",
    "    iteration=0\n",
    "    any_change= True\n",
    "    while iteration<max_iterations and len(unknown_words)>0 and any_change:\n",
    "        iteration+=1\n",
    "        any_change = False\n",
    "        for new,old in char_changes:\n",
    "            t = Transformation(old,new)\n",
    "            for og_word,node_set in unfinished_nodes.items():\n",
    "                if og_word in known_mapping:\n",
    "                    unfinished_nodes.pop(og_word)\n",
    "                    continue\n",
    "                for node in node_set:\n",
    "                    node_str = node.current\n",
    "                    found_result = known_mapping.get(node_str)\n",
    "                    if found_result is not None:\n",
    "                        known_mapping[og_word] = found_result\n",
    "                        unfinished_nodes.pop(og_word)\n",
    "                        break\n",
    "                    children = node.make_children(t)\n",
    "                    if len(children)>0:\n",
    "                        any_change = True\n",
    "                    if isinstance(children,StrNode): #means they got finished state\n",
    "                        final:StrNode = children\n",
    "                        final_str:str = children.current\n",
    "                        known_mapping[og_word] = final_str\n",
    "                        known_mapping.update({intermediate:final_str for intermediate in get_previous_strings(final)})\n",
    "                        break\n",
    "                    else:\n",
    "                        unfinished_nodes[og_word].update(node.children)\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "            col = f\"{a}->{b}\"\n",
    "            not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "        intermediate_steps.append(not_found)\n",
    "\n",
    "        new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "        if len(new_melt)==0:\n",
    "            print(\"None left\")\n",
    "            break\n",
    "        new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "        new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "        new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "        new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "        already_made.update(new_melt['current_word'])\n",
    "        newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "        found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "        \n",
    "        reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "        step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "        new_melt['current_word'] = new_melt['new_word']\n",
    "        not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Set, Optional\n",
    "from collections import deque,defaultdict\n",
    "\n",
    "\n",
    "class Transformation:\n",
    "    def __init__(self, old: str, new: str):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "\n",
    "    def apply(self, s: str, start_idx: int) -> Optional[str]:\n",
    "        \"\"\"Applies the transformation at the given index.\"\"\"\n",
    "        if s[start_idx:].startswith(self.old):\n",
    "            return s[:start_idx] + self.new + s[start_idx + len(self.old):]\n",
    "        return None\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, known_words: Set[str]):\n",
    "        self.known_words = known_words\n",
    "        self.visited: Dict[str, str] = {}  # Tracks visited states and their closest known word.\n",
    "        self.paths: Dict[str, List[str]] = {}  # Stores paths from any word to its known word.\n",
    "\n",
    "\n",
    "    def is_known(self, word: str) -> bool:\n",
    "        \"\"\"Checks if the word is known.\"\"\"\n",
    "        return word in self.known_words\n",
    "\n",
    "    def any_previous_path_to_known(self,node:'Node')->bool:\n",
    "        path = node.get_path()\n",
    "        any_path = self.paths.keys()\n",
    "        try:\n",
    "            for p in path[1:]:\n",
    "                if p in any_path:\n",
    "                    return True\n",
    "            return False\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "    def mark_visited(self, word: str, path: List[str],real_word:bool) -> bool:\n",
    "        \"\"\"\n",
    "        Marks a word as visited.\n",
    "        If the word is already visited, returns False.\n",
    "        Otherwise, updates the path to the known word and returns True.\n",
    "        \"\"\"\n",
    "        if word in self.visited and not real_word:\n",
    "            return False\n",
    "        \n",
    "        self.visited[word] = path[-1]  # Store the last word in the path as the connection.\n",
    "        if real_word:\n",
    "            self.paths[word] = path\n",
    "        return True\n",
    "\n",
    "    def get_path_to_known(self, word: str) -> Optional[List[str]]:\n",
    "        \"\"\"Retrieves the path from the word to the known word, if available.\"\"\"\n",
    "        return self.paths.get(word)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, word: str, parent: Optional[\"Node\"], root_word:str, transformation: Optional[Transformation]):\n",
    "        self.word = word\n",
    "        self.parent = parent\n",
    "        self.root_word=root_word\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def get_path(self) -> List[str]:\n",
    "        \"\"\"Retrieves the transformation path from the root to this node.\"\"\"\n",
    "        path = []\n",
    "        node = self\n",
    "        while node:\n",
    "            path.append(node.word)\n",
    "            node = node.parent\n",
    "        return path[::-1]  # Reverse to get root-to-leaf order\n",
    "\n",
    "\n",
    "def iterate_through_changes(\n",
    "    known_words: set[str],\n",
    "    unknown_words: List[str],\n",
    "    char_changes: List[Tuple[str, str]],\n",
    "    max_iterations: int = 5): #-> Dict[str, List[str]]:\n",
    "    known_set = set(known_words)\n",
    "    graph = Graph(known_set)\n",
    "    results: Dict[str, List[str]] = {}\n",
    "    #connected_to_known:defaultdict[str,bool] =defaultdict(bool)\n",
    "\n",
    "    # Initialize the queue with all unknown words\n",
    "    queue = deque([Node(word, None, word,None) for word in unknown_words])\n",
    "    for word in unknown_words:\n",
    "        graph.mark_visited(word, [word],False)\n",
    "\n",
    "    for word in known_words:\n",
    "        graph.mark_visited(word,[word],True)\n",
    "\n",
    "    iteration = 0\n",
    "    while queue and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        next_iter_queue = deque()\n",
    "        print(f\"Iteration{iteration}: Queue of {len(queue)}\")\n",
    "        for old, new in char_changes:\n",
    "            transformation = Transformation(old, new)\n",
    "            next_char_queue = deque()\n",
    "            \n",
    "            while queue:\n",
    "                node = queue.popleft()\n",
    "                current_word = node.word\n",
    "                root = node.root_word\n",
    "                if graph.get_path_to_known(current_word) is not None or graph.get_path_to_known(root) is not None:\n",
    "                    continue\n",
    "\n",
    "                # Try applying the transformation at every valid index\n",
    "                for i in range(len(current_word) - len(old) + 1):\n",
    "                    new_word = transformation.apply(current_word, i)\n",
    "                   \n",
    "                    if not new_word:\n",
    "                        continue\n",
    "                    #print(\"Found new word:\", new_word)\n",
    "\n",
    "                    # If the new word is already connected to a known word\n",
    "                    if new_word in graph.visited:\n",
    "                        path_to_known = graph.get_path_to_known(new_word)\n",
    "                        if path_to_known:\n",
    "                            #print(f\"wow found a path from {current_word} to {new_word}\")\n",
    "                            node_path = node.get_path()\n",
    "                            full_path = node_path + path_to_known\n",
    "                            results[node_path[0]] = node.get_path() + path_to_known\n",
    "                            for i,step in enumerate(full_path):\n",
    "                                graph.paths[step] = full_path[i:]\n",
    "                            continue\n",
    "                    else:\n",
    "                        graph.mark_visited(new_word, node.get_path() + [new_word],False)\n",
    "                    next_iter_queue.append(node)\n",
    "                    next_iter_queue.append(Node(new_word, node, root, transformation))\n",
    "                next_char_queue.append(node)\n",
    "\n",
    "                    # Otherwise, mark it visited and enqueue for further exploration\n",
    "            queue = next_char_queue\n",
    "                #if graph.mark_visited(new_word, node.get_path() + [new_word]):\n",
    "        queue.clear()\n",
    "        print(f\"Queued for next iteration: {len(next_iter_queue)}\")\n",
    "        while next_iter_queue:\n",
    "\n",
    "            node = next_iter_queue.popleft()\n",
    "            if graph.any_previous_path_to_known(node):\n",
    "                continue\n",
    "            queue.append(node)\n",
    "        print(f\"After culling: \",len(queue))\n",
    "\n",
    "\n",
    "    # For any unknown word that has no transformation path, set an empty path\n",
    "    for word in unknown_words:\n",
    "        if word not in results:\n",
    "            results[word] = []\n",
    "\n",
    "    return results,graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "corrections = json.load(open('corrections.json'))\n",
    "pattern = \"|\".join([f\"[A-Za-z]*{char[0]}[A-Za-z]*\" for char in set(chars) ])\n",
    "\n",
    "chars = [\n",
    "    (\"ll\", \"n\"),\n",
    "    (\"ll\", \"u\"),\n",
    "    (\"ll\", \"h\"),\n",
    "    (\"il\", \"n\"),\n",
    "    (\"il\", \"u\"),\n",
    "    (\"il\", \"h\"),\n",
    "    (\"nl\", \"m\"),\n",
    "    (\"ln\", \"m\"),\n",
    "    (\"cl\", \"d\"),\n",
    "    (\"vv\", \"w\"),\n",
    "    (\"lll\", \"m\"),\n",
    "    (\"rl\", \"n\"),\n",
    "    (\"tl\", \"u\"),\n",
    "    (\"tl\", \"n\"),\n",
    "]\n",
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "\n",
    "\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(pattern,text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development_hospital_sometimes_healing_should_universities_undertake_departments_evolution\"\n",
    "known_words:set[str] = set(exists.split(\"_\")+list(ac['corpus_word'].astype(str)) +list(corrections.values()) +word_list)\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = list(sc.loc[sc['og_word'].isin(known_words)==False,'og_word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results,graph= iterate_through_changes(known_words,not_found,chars,max_iterations=4)\n",
    "not_found_after = [i for i,v in results.items() if len(v)==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_after = [i for i,v in results.items() if len(v)==0]\n",
    "len(not_found_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tlaat',\n",
       " 'ollore',\n",
       " 'collsequelaces',\n",
       " 'ollost',\n",
       " 'clouds',\n",
       " 'cotntnullity',\n",
       " 'clailus',\n",
       " 'antecedellts',\n",
       " 'prevellts',\n",
       " 'judgilaellt',\n",
       " 'ollaki',\n",
       " 'ooll',\n",
       " 'ollixture',\n",
       " 'coollbille',\n",
       " 'tlzat',\n",
       " 'colllmuolity',\n",
       " 'pretellds',\n",
       " 'allci',\n",
       " 'sarill',\n",
       " 'tntlst',\n",
       " 'elcconlplish',\n",
       " 'accordilg',\n",
       " 'deprivillg',\n",
       " 'silogle',\n",
       " 'lullell',\n",
       " 'econelllist',\n",
       " 'conaproollise',\n",
       " 'chanopioll',\n",
       " 'sionilar',\n",
       " 'wlaicll',\n",
       " 'comlllol',\n",
       " 'civili',\n",
       " 'tlansaction',\n",
       " 'itlerease',\n",
       " 'colntnullity',\n",
       " 'ilumecliately',\n",
       " 'correctilag',\n",
       " 'ilzterests',\n",
       " 'llecessit',\n",
       " 'seeril',\n",
       " 'eoznlllullity',\n",
       " 'profouncler',\n",
       " 'llistoryr',\n",
       " 'ldarlialllents',\n",
       " 'eollgresses',\n",
       " 'bargaills',\n",
       " 'tloe',\n",
       " 'ereatioll',\n",
       " 'ptlblie',\n",
       " 'nvestlaillstel',\n",
       " 'lnenlbel',\n",
       " 'loeallll',\n",
       " 'wlliell',\n",
       " 'aetioll',\n",
       " 'flllletioll',\n",
       " 'parliaments',\n",
       " 'exigelleies',\n",
       " 'tlleoll',\n",
       " 'eoznllloll',\n",
       " 'extellsiolls',\n",
       " 'eolllmoll',\n",
       " 'parliaulent',\n",
       " 'tllemseln',\n",
       " 'comlnolzs',\n",
       " 'killgs',\n",
       " 'avoidillg',\n",
       " 'eompellilag',\n",
       " 'opillio',\n",
       " 'wlaell',\n",
       " 'collalllon',\n",
       " 'tlaall',\n",
       " 'diserellt',\n",
       " 'comtnullity',\n",
       " 'lnealas',\n",
       " 'epreselltaties',\n",
       " 'parlialnents',\n",
       " 'recoanitioll',\n",
       " 'epreselltative',\n",
       " 'gelzerally',\n",
       " 'mallifests',\n",
       " 'cotnlllon',\n",
       " 'eneratiolls',\n",
       " 'lessellilag',\n",
       " 'systemgivillg',\n",
       " 'pllllldered',\n",
       " 'tendelley',\n",
       " 'sllos',\n",
       " 'eonneetioll',\n",
       " 'beilag',\n",
       " 'eonstitlltiolls',\n",
       " 'instrulllellts',\n",
       " 'referellee',\n",
       " 'ehallge',\n",
       " 'signifieallt',\n",
       " 'abanclotsllllent',\n",
       " 'eolntnon',\n",
       " 'sllbstitu',\n",
       " 'eollverted',\n",
       " 'wllieh',\n",
       " 'goverlllz',\n",
       " 'eommullity',\n",
       " 'maellillery',\n",
       " 'orgalliza',\n",
       " 'suell',\n",
       " 'eompetitioll',\n",
       " 'lpally',\n",
       " 'eeollotny',\n",
       " 'railroads',\n",
       " 'eonlpetillg',\n",
       " 'workswitllotlt',\n",
       " 'eollvenienee',\n",
       " 'eanllot',\n",
       " 'lllanr',\n",
       " 'vhiell',\n",
       " 'otllel',\n",
       " 'beilog',\n",
       " 'overtakell',\n",
       " 'xvill',\n",
       " 'elltrusted',\n",
       " 'illclireet',\n",
       " 'proteetiotl',\n",
       " 'eolllmereial',\n",
       " 'eolnpetition',\n",
       " 'inclividualized',\n",
       " 'eonlulereial',\n",
       " 'proulotillg',\n",
       " 'eonedellee',\n",
       " 'regulatillg',\n",
       " 'lrlunieipalities',\n",
       " 'ldllt',\n",
       " 'eolllbi',\n",
       " 'neeessarily',\n",
       " 'pursllits',\n",
       " 'theilown',\n",
       " 'llesr',\n",
       " 'cleluded',\n",
       " 'colldltions',\n",
       " 'flllfil',\n",
       " 'xnorally',\n",
       " 'rollle',\n",
       " 'alzlericall',\n",
       " 'leecls',\n",
       " 'collectivisin',\n",
       " 'allalces',\n",
       " 'cllaracters',\n",
       " 'detnallds',\n",
       " 'colllonercial',\n",
       " 'coillproulise',\n",
       " 'plovillg',\n",
       " 'ullw',\n",
       " 'derstallding',\n",
       " 'evokillg',\n",
       " 'svllatever',\n",
       " 'folloving',\n",
       " 'qllol',\n",
       " 'atioll',\n",
       " 'fllrllishes',\n",
       " 'cllanlpiolls',\n",
       " 'harmollized',\n",
       " 'cllristiallity',\n",
       " 'itrlpossible',\n",
       " 'cnildren',\n",
       " 'mollopolists',\n",
       " 'tlleologialls',\n",
       " 'togetllel',\n",
       " 'llumaol',\n",
       " 'clivil',\n",
       " 'ulllatlity',\n",
       " 'delllonracy',\n",
       " 'gallizillg',\n",
       " 'aillst',\n",
       " 'tlwis',\n",
       " 'clearcllt',\n",
       " 'llseci',\n",
       " 'lncavrorable',\n",
       " 'tliat',\n",
       " 'hulllalwity',\n",
       " 'wlloul',\n",
       " 'sillt',\n",
       " 'heavenlr',\n",
       " 'lillers',\n",
       " 'rapllael',\n",
       " 'kllosr',\n",
       " 'ecollol',\n",
       " 'colusecratioll',\n",
       " 'delatonciatioll',\n",
       " 'iglltly',\n",
       " 'ilnpl',\n",
       " 'gll',\n",
       " 'olloies',\n",
       " 'callec',\n",
       " 'titiotl',\n",
       " 'svllere',\n",
       " 'srall',\n",
       " 'coollpesitioll',\n",
       " 'nvllid',\n",
       " 'illlites',\n",
       " 'nvitll',\n",
       " 'tlze',\n",
       " 'colnpetitiolo',\n",
       " 'tllaol',\n",
       " 'crowcliilg',\n",
       " 'platitilig',\n",
       " 'colupetitiotl',\n",
       " 'slnft',\n",
       " 'iicliisiokl',\n",
       " 'lilnself',\n",
       " 'brotl',\n",
       " 'altrtlidlll',\n",
       " 'golclel',\n",
       " 'neiglll',\n",
       " 'rellderi',\n",
       " 'eolllpetition',\n",
       " 'eolltl',\n",
       " 'aclietory',\n",
       " 'eeolleiliatioll',\n",
       " 'unallitr',\n",
       " 'bascoln',\n",
       " 'milllleapolis',\n",
       " 'atlsinson',\n",
       " 'septelilber',\n",
       " 'cliainet',\n",
       " 'rlcally',\n",
       " 'wrllat',\n",
       " 'adlilires',\n",
       " 'altinclanee',\n",
       " 'cleserwrilig',\n",
       " 'lloic',\n",
       " 'cil',\n",
       " 'lillgs',\n",
       " 'cecled',\n",
       " 'desllitioll',\n",
       " 'ozzitld',\n",
       " 'rlleol',\n",
       " 'clls',\n",
       " 'strlltrt',\n",
       " 'cotlisietilla',\n",
       " 'clictiolzaries',\n",
       " 'solzllelllliilc',\n",
       " 'tllezn',\n",
       " 'elldeavorint',\n",
       " 'encleavoritlo',\n",
       " 'eotltest',\n",
       " 'villd',\n",
       " 'dictiollarr',\n",
       " 'llsts',\n",
       " 'llstvvllat',\n",
       " 'ullderstallcls',\n",
       " 'lclrce',\n",
       " 'sellsse',\n",
       " 'eolls',\n",
       " 'ebilae',\n",
       " 'cjefilli',\n",
       " 'tiolls',\n",
       " 'conapetltiola',\n",
       " 'conlflicting',\n",
       " 'comttlerce',\n",
       " 'trallsl',\n",
       " 'jacobsell',\n",
       " 'dolaolllillated',\n",
       " 'llpelitioll',\n",
       " 'colnpetitioul',\n",
       " 'trll',\n",
       " 'oollllcls',\n",
       " 'llk',\n",
       " 'stl',\n",
       " 'lilizited',\n",
       " 'collstittiollal',\n",
       " 'lzollaclaries',\n",
       " 'factlltie',\n",
       " 'elillood',\n",
       " 'zzlillc',\n",
       " 'obviralls',\n",
       " 'valli',\n",
       " 'aziallr',\n",
       " 'svllell',\n",
       " 'lclil',\n",
       " 'xllpply',\n",
       " 'illcolplete',\n",
       " 'inlperfeeit',\n",
       " 'strllgg',\n",
       " 'ttltesz',\n",
       " 'clescrilde',\n",
       " 'cotoopotofloll',\n",
       " 'exrell',\n",
       " 'wloell',\n",
       " 'llc',\n",
       " 'coillpttitioil',\n",
       " 'elelnelljc',\n",
       " 'relacler',\n",
       " 'neally',\n",
       " 'tlie',\n",
       " 'prilzciple',\n",
       " 'oltltior',\n",
       " 'wllerevel',\n",
       " 'lfotllil',\n",
       " 'cotllci',\n",
       " 'lnutalilfll',\n",
       " 'colrlletitiolz',\n",
       " 'alllat',\n",
       " 'tllexl',\n",
       " 'iilciple',\n",
       " 'fainiliar',\n",
       " 'natlll',\n",
       " 'reslllti',\n",
       " 'stlrvi',\n",
       " 'ellvirollinellt',\n",
       " 'fclllziliar',\n",
       " 'olletllocls',\n",
       " 'pearallce',\n",
       " 'strl',\n",
       " 'rollsseall',\n",
       " 'clescriptiosls',\n",
       " 'collcepticall',\n",
       " 'htl',\n",
       " 'glacliatol',\n",
       " 'sllonv',\n",
       " 'eattlres',\n",
       " 'wllerebr',\n",
       " 'strotlbest',\n",
       " 'clltzllinbest',\n",
       " 'tllllillld',\n",
       " 'qllal',\n",
       " 'mwallace',\n",
       " 'attelltiool',\n",
       " 'allilncals',\n",
       " 'atllotoilt',\n",
       " 'llgble',\n",
       " 'cls',\n",
       " 'lnaximutn',\n",
       " 'luillillltlln',\n",
       " 'stlhetfillg',\n",
       " 'xvatcll',\n",
       " 'aailalal',\n",
       " 'cclll',\n",
       " 'lllerelr',\n",
       " 'tllc',\n",
       " 'offsldril',\n",
       " 'colnpaniolzs',\n",
       " 'lnl',\n",
       " 'artlollg',\n",
       " 'bxistellce',\n",
       " 'xvinislll',\n",
       " 'weapolls',\n",
       " 'orgallie',\n",
       " 'prilllitize',\n",
       " 'aililnals',\n",
       " 'eolle',\n",
       " 'tnigntily',\n",
       " 'ullceasillt',\n",
       " 'ellds',\n",
       " 'grall',\n",
       " 'lelllx',\n",
       " 'rlerar',\n",
       " 'ldeginnilags',\n",
       " 'alliluate',\n",
       " 'illd',\n",
       " 'lldes',\n",
       " 'bradllally',\n",
       " 'colllel',\n",
       " 'svithitl',\n",
       " 'tllajc',\n",
       " 'falltll',\n",
       " 'iolcreasillb',\n",
       " 'cllik',\n",
       " 'ltlasred',\n",
       " 'conclitio',\n",
       " 'llllllllderless',\n",
       " 'installces',\n",
       " 'sidetlt',\n",
       " 'leclared',\n",
       " 'cohlpetitioll',\n",
       " 'lliaolself',\n",
       " 'sllrprised',\n",
       " 'filad',\n",
       " 'profolll',\n",
       " 'illapressioll',\n",
       " 'lllysteries',\n",
       " 'allel',\n",
       " 'reconciliations',\n",
       " 'eacly',\n",
       " 'atlilllals',\n",
       " 'adattls',\n",
       " 'pursllilag',\n",
       " 'colulllon',\n",
       " 'gollen',\n",
       " 'agailn',\n",
       " 'zalitlli',\n",
       " 'illsllite',\n",
       " 'rollps',\n",
       " 'szlall',\n",
       " 'illiolaty',\n",
       " 'lzatioll',\n",
       " 'coln',\n",
       " 'etitioll',\n",
       " 'walitll',\n",
       " 'pllldllc',\n",
       " 'llulllallitariaoli',\n",
       " 'gtllells',\n",
       " 'uleolll',\n",
       " 'splle',\n",
       " 'luilder',\n",
       " 'ecolne',\n",
       " 'walittless',\n",
       " 'ecotlomio',\n",
       " 'lterlaational',\n",
       " 'igllest',\n",
       " 'inclisticltlal',\n",
       " 'eratioll',\n",
       " 'cleo',\n",
       " 'avvorld',\n",
       " 'goetlle',\n",
       " 'apprellelesioll',\n",
       " 'sollae',\n",
       " 'lessells',\n",
       " 'ilacreasing',\n",
       " 'cliscourages',\n",
       " 'inarl',\n",
       " 'vllile',\n",
       " 'increasilog',\n",
       " 'idellce',\n",
       " 'luoderll',\n",
       " 'cinrilization',\n",
       " 'nllo',\n",
       " 'conlparisons',\n",
       " 'xtvritll',\n",
       " 'srolnell',\n",
       " 'blltland',\n",
       " 'uloclern',\n",
       " 'tllrollt',\n",
       " 'lntimely',\n",
       " 'llomilliolls',\n",
       " 'aioderll',\n",
       " 'establislles',\n",
       " 'fitlaess',\n",
       " 'possildle',\n",
       " 'svhile',\n",
       " 'deterluille',\n",
       " 'fllrllislles',\n",
       " 'percelltat',\n",
       " 'tllerebv',\n",
       " 'fsdllud',\n",
       " 'spoils',\n",
       " 'isslles',\n",
       " 'stlrival',\n",
       " 'lcnowll',\n",
       " 'extellels',\n",
       " 'coltlpetil',\n",
       " 'hll',\n",
       " 'corresponclilzg',\n",
       " 'portllllity',\n",
       " 'stlrvirral',\n",
       " 'utacler',\n",
       " 'sstelll',\n",
       " 'killel',\n",
       " 'llel',\n",
       " 'rlls',\n",
       " 'alullace',\n",
       " 'pllrest',\n",
       " 'llosrever',\n",
       " 'investigatilzg',\n",
       " 'outlines',\n",
       " 'gallizatioll',\n",
       " 'colulili',\n",
       " 'tnucll',\n",
       " 'stitiltioll',\n",
       " 'dil',\n",
       " 'ectl',\n",
       " 'overcroxtwdilag',\n",
       " 'valls',\n",
       " 'ceilin',\n",
       " 'aoltl',\n",
       " 'oranizatioll',\n",
       " 'ldllysicialls',\n",
       " 'cllaslces',\n",
       " 'coticlitions',\n",
       " 'deville',\n",
       " 'walllile',\n",
       " 'znibllt',\n",
       " 'rollts',\n",
       " 'xarotlld',\n",
       " 'ild',\n",
       " 'conclitiolas',\n",
       " 'ily',\n",
       " 'ellts',\n",
       " 'stlt',\n",
       " 'estioll',\n",
       " 'alliluals',\n",
       " 'elevatiolls',\n",
       " 'combillations',\n",
       " 'colubillations',\n",
       " 'combinatiolls',\n",
       " 'neall',\n",
       " 'coznpetitiorl',\n",
       " 'wllete',\n",
       " 'cotupetitiotl',\n",
       " 'lletllod',\n",
       " 'owllel',\n",
       " 'nallagetllel',\n",
       " 'illclustl',\n",
       " 'terlus',\n",
       " 'clisti',\n",
       " 'fteretlce',\n",
       " 'socialilstic',\n",
       " 'nlnental',\n",
       " 'llppl',\n",
       " 'tssioll',\n",
       " 'dellla',\n",
       " 'lllaental',\n",
       " 'nailltellallce',\n",
       " 'zlally',\n",
       " 'illdividllallv',\n",
       " 'lllelst',\n",
       " 'irrialtioll',\n",
       " 'clellts',\n",
       " 'irligation',\n",
       " 'colllpetitio',\n",
       " 'llollopols',\n",
       " 'peronaoletlt',\n",
       " 'llclerstalld',\n",
       " 'alnotlt',\n",
       " 'rebioll',\n",
       " 'sllpplieel',\n",
       " 'divideolcls',\n",
       " 'lvestlnetlt',\n",
       " 'latiollal',\n",
       " 'lililliam',\n",
       " 'atlatzzic',\n",
       " 'govelnillelltal',\n",
       " 'llolv',\n",
       " 'ilaovelnellt',\n",
       " 'approaclleswi',\n",
       " 'reaclli',\n",
       " 'opldorttlnities',\n",
       " 'lllovelnelltvs',\n",
       " 'llistol',\n",
       " 'nlents',\n",
       " 'centl',\n",
       " 'clereloldnlent',\n",
       " 'institlltiolas',\n",
       " 'colnpetitio',\n",
       " 'otllicll',\n",
       " 'nallicll',\n",
       " 'jllicll',\n",
       " 'savillgs',\n",
       " 'balllss',\n",
       " 'ecollollaic',\n",
       " 'instittl',\n",
       " 'perlxrlitted',\n",
       " 'illstitutioi',\n",
       " 'lnul',\n",
       " 'opporctlnity',\n",
       " 'lltiest',\n",
       " 'colltrolled',\n",
       " 'furllishes',\n",
       " 'vllinks',\n",
       " 'ellt',\n",
       " 'erforlll',\n",
       " 'plalles',\n",
       " 'llilagle',\n",
       " 'slnpathy',\n",
       " 'clisplacine',\n",
       " 'colllldetitioll',\n",
       " 'coluzetitiotl',\n",
       " 'llss',\n",
       " 'ldeetl',\n",
       " 'luall',\n",
       " 'ecoslolllic',\n",
       " 'proclacillt',\n",
       " 'comptitioll',\n",
       " 'tninoletl',\n",
       " 'lllative',\n",
       " 'prillciles',\n",
       " 'psycholocically',\n",
       " 'ecoololllically',\n",
       " 'nlally',\n",
       " 'splleres',\n",
       " 'tlleself',\n",
       " 'ridellillb',\n",
       " 'llutnanity',\n",
       " 'attailltxlent',\n",
       " 'ribhtly',\n",
       " 'sllffieiellt',\n",
       " 'tnealls',\n",
       " 'vlpbuilding',\n",
       " 'edtlca',\n",
       " 'svorld',\n",
       " 'annoullceinent',\n",
       " 'untiljilly',\n",
       " 'zzlollographs',\n",
       " 'appellded',\n",
       " 'colulnbiaulliversity',\n",
       " 'dartluouth',\n",
       " 'alnos',\n",
       " 'nallce',\n",
       " 'verlllont',\n",
       " 'aiiciligan',\n",
       " 'illinois',\n",
       " 'ollteollle',\n",
       " 'teellriieal',\n",
       " 'tetldelley',\n",
       " 'eivilized',\n",
       " 'eoulltries',\n",
       " 'belgillm',\n",
       " 'teaelling',\n",
       " 'ulliversitr',\n",
       " 'lollclon',\n",
       " 'satisfaetioll',\n",
       " 'faelllty',\n",
       " 'lnellt',\n",
       " 'aeeordill',\n",
       " 'strikil',\n",
       " 'belgillnl',\n",
       " 'inoxrelllellt',\n",
       " 'sellools',\n",
       " 'colllluercial',\n",
       " 'seiellees',\n",
       " 'colnollereial',\n",
       " 'elatilng',\n",
       " 'comlllel',\n",
       " 'educalioll',\n",
       " 'appellcled',\n",
       " 'conlulissiollers',\n",
       " 'fehrtlartr',\n",
       " 'igillal',\n",
       " 'lonclon',\n",
       " 'londoll',\n",
       " 'lldelshochschule',\n",
       " 'consttlaires',\n",
       " 'lvuvaill',\n",
       " 'dispositiolls',\n",
       " 'eolllltries',\n",
       " 'ulliversites',\n",
       " 'etioll',\n",
       " 'beeallse',\n",
       " 'eertaill',\n",
       " 'bracle',\n",
       " 'eolninereial',\n",
       " 'cielllaild',\n",
       " 'illnovavion',\n",
       " 'eireumstallees',\n",
       " 'eomlllereial',\n",
       " 'quiekll',\n",
       " 'oleecls',\n",
       " 'edlleatioll',\n",
       " 'eomll',\n",
       " 'llilldrallee',\n",
       " 'intelleetual',\n",
       " 'meclioerity',\n",
       " 'clefeets',\n",
       " 'steatly',\n",
       " 'eontinlled',\n",
       " 'qlliekly',\n",
       " 'bocliees',\n",
       " 'lenrellclers',\n",
       " 'boarcls',\n",
       " 'tlhe',\n",
       " 'unclertalze',\n",
       " 'sitiolls',\n",
       " 'acluate',\n",
       " 'meantillle',\n",
       " 'developillg',\n",
       " 'cllarmed',\n",
       " 'colunlunity',\n",
       " 'orlater',\n",
       " 'bralclles',\n",
       " 'usilless',\n",
       " 'pursuillg',\n",
       " 'srell',\n",
       " 'callint',\n",
       " 'claitned',\n",
       " 'luakillg',\n",
       " 'relltlelnen',\n",
       " 'traillino',\n",
       " 'tllenllore',\n",
       " 'bellclles',\n",
       " 'xvllile',\n",
       " 'cotlrses',\n",
       " 'gllments',\n",
       " 'llnclertalce',\n",
       " 'gllzzlellt',\n",
       " 'luatly',\n",
       " 'cotnlllercial',\n",
       " 'tlaese',\n",
       " 'lllllediate',\n",
       " 'ldellefit',\n",
       " 'stuclies',\n",
       " 'dtless',\n",
       " 'illstit',\n",
       " 'tioll',\n",
       " 'elrcll',\n",
       " 'tlaollc',\n",
       " 'lneclici',\n",
       " 'llearcr',\n",
       " 'llowes',\n",
       " 'rhicll',\n",
       " 'clepartrnellt',\n",
       " 'tlaeir',\n",
       " 'harnessitlg',\n",
       " 'patiellts',\n",
       " 'vasllillg',\n",
       " 'pestles',\n",
       " 'ldinclillg',\n",
       " 'clishes',\n",
       " 'ivell',\n",
       " 'gertlan',\n",
       " 'llighel',\n",
       " 'intelleet',\n",
       " 'eanclidate',\n",
       " 'objeetioll',\n",
       " 'reeomnlenclec',\n",
       " 'eurrieululll',\n",
       " 'desile',\n",
       " 'whiell',\n",
       " 'eurriellluln',\n",
       " 'traillil',\n",
       " 'eellters',\n",
       " 'marlufaeturer',\n",
       " 'finalleially',\n",
       " 'orgallizing',\n",
       " 'allc',\n",
       " 'fillanee',\n",
       " 'eollebe',\n",
       " 'slloulel',\n",
       " 'whicla',\n",
       " 'svllile',\n",
       " 'alnericai',\n",
       " 'clrafted',\n",
       " 'clerks',\n",
       " 'stittltiollss',\n",
       " 'railwavs',\n",
       " 'advallceci',\n",
       " 'ldrincil',\n",
       " 'trallspol',\n",
       " 'tatiotl',\n",
       " 'ellaployes',\n",
       " 'rectiolls',\n",
       " 'nlnercial',\n",
       " 'traillizag',\n",
       " 'svillillg',\n",
       " 'sselld',\n",
       " 'lligllel',\n",
       " 'eparillg',\n",
       " 'elllployts',\n",
       " 'cornwell',\n",
       " 'eolnonullity',\n",
       " 'toclern',\n",
       " 'seellre',\n",
       " 'tnell',\n",
       " 'eolning',\n",
       " 'slleeeed',\n",
       " 'eolllplete',\n",
       " 'collllllel',\n",
       " 'statilag',\n",
       " 'eontailled',\n",
       " 'cleveloplnelat',\n",
       " 'eolne',\n",
       " 'eclueatioll',\n",
       " 'eolllllluolity',\n",
       " 'aiidreeiatioll',\n",
       " 'wolld',\n",
       " 'illsists',\n",
       " 'aspil',\n",
       " 'eclueated',\n",
       " 'ellltivated',\n",
       " 'inereasilog',\n",
       " 'resllltvs',\n",
       " 'wlliel',\n",
       " 'ecllleatioll',\n",
       " 'intelleetllal',\n",
       " 'moclels',\n",
       " 'eollllnullity',\n",
       " 'mallufaetul',\n",
       " 'clireetion',\n",
       " 'accumulatillg',\n",
       " 'edlleation',\n",
       " 'ecltleation',\n",
       " 'ealling',\n",
       " 'eentllry',\n",
       " 'noldocly',\n",
       " 'colllltl',\n",
       " 'sellool',\n",
       " 'pllyrsieian',\n",
       " 'elergylllall',\n",
       " 'tecllllieal',\n",
       " 'plallned',\n",
       " 'currieululn',\n",
       " 'llapha',\n",
       " 'eallses',\n",
       " 'stlbjeet',\n",
       " 'irly',\n",
       " 'edueatioll',\n",
       " 'inollograplls',\n",
       " 'physieiall',\n",
       " 'reeogllize',\n",
       " 'faeilities',\n",
       " 'lleriean',\n",
       " 'lloev',\n",
       " 'ftlnetion',\n",
       " 'satisfaetoriln',\n",
       " 'sllolllci',\n",
       " 'eolllparatively',\n",
       " 'branelles',\n",
       " 'eollrse',\n",
       " 'eollsequently',\n",
       " 'eallnot',\n",
       " 'oeeasioll',\n",
       " 'partielllar',\n",
       " 'brallelles',\n",
       " 'inelllcled',\n",
       " 'eurrielllllm',\n",
       " 'seiellee',\n",
       " 'mathenlatllies',\n",
       " 'lneclieal',\n",
       " 'praetieally',\n",
       " 'diseiplille',\n",
       " 'illcludes',\n",
       " 'banling',\n",
       " 'allce',\n",
       " 'tlleirgeneralaspects',\n",
       " 'sllldjects',\n",
       " 'ulechanisln',\n",
       " 'coznlllercial',\n",
       " 'raplly',\n",
       " 'colulnercial',\n",
       " 'fllrtllel',\n",
       " 'presentillg',\n",
       " 'boolkeepillg',\n",
       " 'accolillts',\n",
       " 'lllecllanistn',\n",
       " 'foliowillg',\n",
       " 'departnellts',\n",
       " 'tatioll',\n",
       " 'tlleol',\n",
       " 'aucliting',\n",
       " 'oally',\n",
       " 'attelltiol',\n",
       " 'undertalillg',\n",
       " 'lligl',\n",
       " 'rnell',\n",
       " 'plltti',\n",
       " 'rollllg',\n",
       " 'allllollllces',\n",
       " 'scl',\n",
       " 'llentiolaed',\n",
       " 'alltage',\n",
       " 'eolnmercial',\n",
       " 'inforl',\n",
       " 'clefilaite',\n",
       " 'ehallee',\n",
       " 'ullix',\n",
       " 'scollolny',\n",
       " 'parallelint',\n",
       " 'forlol',\n",
       " 'existillb',\n",
       " 'wiscollsin',\n",
       " 'liclligan',\n",
       " 'dartlllollth',\n",
       " 'llowerler',\n",
       " 'colllpleted',\n",
       " 'ellally',\n",
       " 'vanderbilt',\n",
       " 'traillillgortlledeveloplllent',\n",
       " 'wiclelled',\n",
       " 'ttlrotlgll',\n",
       " 'vlllcler',\n",
       " 'illflllellee',\n",
       " 'wllel',\n",
       " 'ditioll',\n",
       " 'hllllclrecrs',\n",
       " 'lotllag',\n",
       " 'nell',\n",
       " 'otlle',\n",
       " 'preparillg',\n",
       " 'ulliversi',\n",
       " 'ollany',\n",
       " 'ourmoclern',\n",
       " 'llnivelsity',\n",
       " 'mhartoll',\n",
       " 'xperililellt',\n",
       " 'naturallt',\n",
       " 'halldillg',\n",
       " 'tllorllsoll',\n",
       " 'edmtllld',\n",
       " 'aclnlinistl',\n",
       " 'govertllalellt',\n",
       " 'edlllund',\n",
       " 'ricllluin',\n",
       " 'lellgthelled',\n",
       " 'instrlletors',\n",
       " 'nvhartoll',\n",
       " 'lgeell',\n",
       " 'instrtletion',\n",
       " 'alhartoll',\n",
       " 'follonvillg',\n",
       " 'willianl',\n",
       " 'nvisconsill',\n",
       " 'selectillg',\n",
       " 'engilleerillgy',\n",
       " 'jahrbuciler',\n",
       " 'cincinllati',\n",
       " 'commerclal',\n",
       " 'lllakint',\n",
       " 'ldeclaration',\n",
       " 'inoclerr',\n",
       " 'glallclest',\n",
       " 'clocalilellts',\n",
       " 'sometllillz',\n",
       " 'trlltlls',\n",
       " 'ullalienal',\n",
       " 'lilderty',\n",
       " 'flortllerlrlore',\n",
       " 'oovernlnellt',\n",
       " 'riglltes',\n",
       " 'gorrernllletlt',\n",
       " 'clerines',\n",
       " 'llbel',\n",
       " 'colllxnon',\n",
       " 'illtelligenl',\n",
       " 'ositioll',\n",
       " 'cleellleci',\n",
       " 'placillg',\n",
       " 'clestinies',\n",
       " 'tlleless',\n",
       " 'ltlnlall',\n",
       " 'arllicll',\n",
       " 'eatlles',\n",
       " 'olloll',\n",
       " 'stnitll',\n",
       " 'xvealtll',\n",
       " 'rtiolls',\n",
       " 'fizlcls',\n",
       " 'llilosophr',\n",
       " 'tnacle',\n",
       " 'walllen',\n",
       " 'silnplicltwt',\n",
       " 'tllouaht',\n",
       " 'buncile',\n",
       " 'lilherty',\n",
       " 'preselltec',\n",
       " 'tllouo',\n",
       " 'reldllblic',\n",
       " 'vealtll',\n",
       " 'xvitll',\n",
       " 'statesrnall',\n",
       " 'envirotltnellt',\n",
       " 'allged',\n",
       " 'briclc',\n",
       " 'statesinall',\n",
       " 'tlaeory',\n",
       " 'reaelled',\n",
       " 'forefatllers',\n",
       " 'svllieh',\n",
       " 'llotieed',\n",
       " 'bellefieellee',\n",
       " 'inaslnuell',\n",
       " 'eaell',\n",
       " 'halllperillg',\n",
       " 'sholllc',\n",
       " 'elearly',\n",
       " 'elleony',\n",
       " 'clireeting',\n",
       " 'xvell',\n",
       " 'svllicll',\n",
       " 'illterestilag',\n",
       " 'oadenillg',\n",
       " 'illdon',\n",
       " 'allotlle',\n",
       " 'itil',\n",
       " 'tllolnas',\n",
       " 'altovetller',\n",
       " 'acllieveci',\n",
       " 'gleell',\n",
       " 'lottl',\n",
       " 'tstrclllous',\n",
       " 'xrorcls',\n",
       " 'orfreeclotn',\n",
       " 'fleecloll',\n",
       " 'eeclozn',\n",
       " 'elljoated',\n",
       " 'somethillt',\n",
       " 'doitlt',\n",
       " 'solnetllillt',\n",
       " 'solnetlaillg',\n",
       " 'hioll',\n",
       " 'fellowtlle',\n",
       " 'ullicll',\n",
       " 'lloeasure',\n",
       " 'freecloul',\n",
       " 'naeastlre',\n",
       " 'tllelllfselxres',\n",
       " 'concerllint',\n",
       " 'ttzollgllt',\n",
       " 'terlminatillg',\n",
       " 'entrelne',\n",
       " 'slllitli',\n",
       " 'lilosophy',\n",
       " 'llteellth',\n",
       " 'philosopllyr',\n",
       " 'celltur',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_after\n",
    "level_2_chars = [\n",
    "    ('i':'l'),\n",
    "    ('c','e'),\n",
    "    ('e','c'),\n",
    "    ('l','t'),\n",
    "    ('t','l'),\n",
    "    ('ttl','m'),\n",
    "    ('v','y')\n",
    "    ('lil','m')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allcl', 'alld', 'and']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['allcl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import networkx as nx\n",
    "from networkx import DiGraph\n",
    "chars = [\n",
    "    (\"ll\", \"n\"),\n",
    "    (\"ll\", \"u\"),\n",
    "    (\"ll\", \"h\"),\n",
    "    (\"il\", \"n\"),\n",
    "    (\"il\", \"u\"),\n",
    "    (\"il\", \"h\"),\n",
    "    (\"nl\", \"m\"),\n",
    "    (\"ln\", \"m\"),\n",
    "    (\"cl\", \"d\"),\n",
    "    (\"vv\", \"w\"),\n",
    "    (\"lll\", \"m\"),\n",
    "    (\"rl\", \"n\"),\n",
    "    (\"tl\", \"u\"),\n",
    "    (\"tl\", \"n\"),\n",
    "    ('lil','m'),\n",
    "    ('lz','h'),\n",
    "    ('lz','n'),\n",
    "#level2 = \"hla_lan_hlz_eo_ec_ce_nlz\"\n",
    "    ('la', 'n'),\n",
    "    ('la', 'h'),\n",
    "    ('o','e'),\n",
    "    ('c','e'),\n",
    "    ('e','c'),\n",
    "    (\"s$\",\"\"), # ones like these will remove any case of a pattern\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])-np.array([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n = np.array(range(len(node_word)))\n",
    "n[np.array([*node_word.__iter__()])=='h']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hnnndcnc'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>,\n",
       " <str_ascii_iterator at 0x170626440>]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "import more_itertools as mit\n",
    "node_word ='millilllum'\n",
    "old='ll'\n",
    "new = 'n'\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "hanmer\n",
      "3\n",
      "hamner\n"
     ]
    }
   ],
   "source": [
    "def apply_t(s,old,new,i)->str|None:\n",
    "    if i==-1:\n",
    "        return re.sub(old,new,s)\n",
    "    return s[:i] + new + s[i + len(old):] \n",
    "node_word = \"hammer\"\n",
    "old = 'm'\n",
    "new='n'\n",
    "for i in np.array(range(len(node_word)))[np.array([*node_word.__iter__()])==old] if new!=\"\" else [-1]:\n",
    "    print(i)\n",
    "    new_word = apply_t(node_word,old,new,i)\n",
    "    print(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(len(node_word)))[np.array([*node_word.__iter__()])==old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function findall in module re:\n",
      "\n",
      "findall(pattern, string, flags=0)\n",
      "    Return a list of all non-overlapping matches in the string.\n",
      "\n",
      "    If one or more capturing groups are present in the pattern, return\n",
      "    a list of groups; this will be a list of tuples if the pattern\n",
      "    has more than one group.\n",
      "\n",
      "    Empty matches are included in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re.finditer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration: 1\n",
      "Starting nodes and edges:  [240500      0]\n",
      "In results: 0 out of 2930\n",
      "Replacing 'll' with 'n'\n",
      "Added 2269 Nodes, 2378 Edges, and 400 Results\n",
      "In results: 400 out of 2930\n",
      "Replacing 'll' with 'u'\n",
      "Added 3192 Nodes, 3241 Edges, and 139 Results\n",
      "In results: 539 out of 2930\n",
      "Replacing 'll' with 'h'\n",
      "Added 4325 Nodes, 4369 Edges, and 159 Results\n",
      "In results: 698 out of 2930\n",
      "Replacing 'il' with 'n'\n",
      "Added 1473 Nodes, 1520 Edges, and 31 Results\n",
      "In results: 729 out of 2930\n",
      "Replacing 'il' with 'u'\n",
      "Added 1581 Nodes, 1617 Edges, and 12 Results\n",
      "In results: 741 out of 2930\n",
      "Replacing 'il' with 'h'\n",
      "Added 1681 Nodes, 1710 Edges, and 18 Results\n",
      "In results: 759 out of 2930\n",
      "Replacing 'nl' with 'm'\n",
      "Added 1915 Nodes, 1933 Edges, and 149 Results\n",
      "In results: 908 out of 2930\n",
      "Replacing 'ln' with 'm'\n",
      "Added 1044 Nodes, 1851 Edges, and 167 Results\n",
      "In results: 1075 out of 2930\n",
      "Replacing 'cl' with 'd'\n",
      "Added 985 Nodes, 1041 Edges, and 184 Results\n",
      "In results: 1259 out of 2930\n",
      "Replacing 'vv' with 'w'\n",
      "Added 17 Nodes, 17 Edges, and 12 Results\n",
      "In results: 1271 out of 2930\n",
      "Replacing 'lll' with 'm'\n",
      "Added 346 Nodes, 1117 Edges, and 18 Results\n",
      "In results: 1289 out of 2930\n",
      "Replacing 'rl' with 'n'\n",
      "Added 535 Nodes, 542 Edges, and 23 Results\n",
      "In results: 1312 out of 2930\n",
      "Replacing 'tl' with 'u'\n",
      "Added 1959 Nodes, 2052 Edges, and 82 Results\n",
      "In results: 1394 out of 2930\n",
      "Replacing 'tl' with 'n'\n",
      "Added 1742 Nodes, 1789 Edges, and 110 Results\n",
      "In results: 1504 out of 2930\n",
      "Replacing 'lil' with 'm'\n",
      "Added 125 Nodes, 507 Edges, and 1 Result\n",
      "In results: 1505 out of 2930\n",
      "Replacing 'lz' with 'h'\n",
      "Added 320 Nodes, 320 Edges, and 3 Results\n",
      "In results: 1508 out of 2930\n",
      "Replacing 'lz' with 'n'\n",
      "Added 294 Nodes, 294 Edges, and 13 Results\n",
      "In results: 1521 out of 2930\n",
      "Replacing 'la' with 'n'\n",
      "Added 1241 Nodes, 1266 Edges, and 30 Results\n",
      "In results: 1551 out of 2930\n",
      "Replacing 'la' with 'h'\n",
      "Added 1330 Nodes, 1336 Edges, and 14 Results\n",
      "In results: 1565 out of 2930\n",
      "Replacing 'o' with 'e'\n",
      "Added 14131 Nodes, 14149 Edges, and 16 Results\n",
      "In results: 1581 out of 2930\n",
      "Replacing 'c' with 'e'\n",
      "Added 10606 Nodes, 10897 Edges, and 13 Results\n",
      "In results: 1594 out of 2930\n",
      "Replacing 'e' with 'c'\n",
      "Added 71850 Nodes, 82363 Edges, and 127 Results\n",
      "In results: 1721 out of 2930\n",
      "Replacing 's$' with ''\n",
      "Added 11479 Nodes, 111942 Edges, and 104 Results\n",
      "___\n",
      "Iteration node and edge differece: [134440 248251]\n",
      "Current iteration: 2\n",
      "Starting nodes and edges:  [374940 248251]\n",
      "In results: 1825 out of 2930\n",
      "Replacing 'll' with 'n'\n",
      "Added 11292 Nodes, 63909 Edges, and 51 Results\n",
      "In results: 1876 out of 2930\n",
      "Replacing 'll' with 'u'\n",
      "Added 10812 Nodes, 64296 Edges, and 1 Result\n",
      "In results: 1877 out of 2930\n",
      "Replacing 'll' with 'h'\n",
      "Added 10871 Nodes, 65913 Edges, and 7 Results\n",
      "In results: 1884 out of 2930\n",
      "Replacing 'il' with 'n'\n",
      "Added 2598 Nodes, 20013 Edges, and 0 Results\n",
      "In results: 1884 out of 2930\n",
      "Replacing 'il' with 'u'\n",
      "Added 890 Nodes, 19921 Edges, and 0 Results\n",
      "In results: 1884 out of 2930\n",
      "Replacing 'il' with 'h'\n",
      "Added 890 Nodes, 19829 Edges, and 0 Results\n",
      "In results: 1884 out of 2930\n",
      "Replacing 'nl' with 'm'\n",
      "Added 12584 Nodes, 38903 Edges, and 31 Results\n",
      "In results: 1915 out of 2930\n",
      "Replacing 'ln' with 'm'\n",
      "Added 1445 Nodes, 21251 Edges, and 7 Results\n",
      "In results: 1922 out of 2930\n",
      "Replacing 'cl' with 'd'\n",
      "Added 19304 Nodes, 22079 Edges, and 14 Results\n",
      "In results: 1936 out of 2930\n",
      "Replacing 'vv' with 'w'\n",
      "Added 0 Nodes, 20 Edges, and 0 Results\n",
      "In results: 1936 out of 2930\n",
      "Replacing 'lll' with 'm'\n",
      "Added 0 Nodes, 15490 Edges, and 0 Results\n",
      "In results: 1936 out of 2930\n",
      "Replacing 'rl' with 'n'\n",
      "Added 89 Nodes, 4551 Edges, and 0 Results\n",
      "In results: 1936 out of 2930\n",
      "Replacing 'tl' with 'u'\n",
      "Added 64 Nodes, 12986 Edges, and 0 Results\n",
      "In results: 1936 out of 2930\n",
      "Replacing 'tl' with 'n'\n",
      "Added 88 Nodes, 12972 Edges, and 1 Result\n",
      "In results: 1937 out of 2930\n",
      "Replacing 'lil' with 'm'\n",
      "Added 0 Nodes, 4975 Edges, and 0 Results\n",
      "In results: 1937 out of 2930\n",
      "Replacing 'lz' with 'h'\n",
      "Added 0 Nodes, 4357 Edges, and 0 Results\n",
      "In results: 1937 out of 2930\n",
      "Replacing 'lz' with 'n'\n",
      "Added 0 Nodes, 4357 Edges, and 0 Results\n",
      "In results: 1937 out of 2930\n",
      "Replacing 'la' with 'n'\n",
      "Added 522 Nodes, 4636 Edges, and 1 Result\n",
      "In results: 1938 out of 2930\n",
      "Replacing 'la' with 'h'\n",
      "Added 384 Nodes, 4548 Edges, and 0 Results\n",
      "In results: 1938 out of 2930\n",
      "Replacing 'o' with 'e'\n",
      "Added 44028 Nodes, 132021 Edges, and 2 Results\n",
      "In results: 1940 out of 2930\n",
      "Replacing 'c' with 'e'\n",
      "Added 3299 Nodes, 159319 Edges, and 0 Results\n",
      "In results: 1940 out of 2930\n",
      "Replacing 'e' with 'c'\n",
      "Added 250448 Nodes, 534645 Edges, and 16 Results\n",
      "In results: 1956 out of 2930\n",
      "Replacing 's$' with ''\n",
      "Added 5224 Nodes, 375320 Edges, and 2 Results\n",
      "___\n",
      "Iteration node and edge differece: [ 374832 1606311]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G = DiGraph()\n",
    "G2=DiGraph()\n",
    "for word in known_words:\n",
    "    G.add_node(word,\n",
    "               og=word,\n",
    "               final=word\n",
    "               ,finished=True\n",
    "               ,originally_known=True,\n",
    "               #singular = s_less\n",
    "               )\n",
    "    \n",
    "for word in not_found:\n",
    "\n",
    "\n",
    "    G.add_node(word,\n",
    "               og=word,\n",
    "               final=None,\n",
    "               finished=False,\n",
    "               originally_known=False,\n",
    "               #singular = s_less\n",
    "               )\n",
    "\n",
    "def apply_t(s,old,new,i)->str|None:\n",
    "    if i==-1:\n",
    "        return re.sub(old,new,s)\n",
    "    return s[:i] + new + s[i + len(old):] \n",
    "\n",
    "\n",
    "def update_self_and_preds(G:DiGraph,node,end_word:str|None=None)->None:\n",
    "    final=end_word or G.nodes[node]['final']\n",
    "    updated_info = {'finished':True,'final':final}\n",
    "    preds=[ p for p in G.predecessors(node) if not G.nodes[p]['finished']]\n",
    "    results = {**{p:final for p in preds},node:final}\n",
    "    nx.set_node_attributes(G,{p:updated_info for p in results.keys()})\n",
    "    #return preds\n",
    "made_change=True\n",
    "G2 = DiGraph()\n",
    "results = {}\n",
    "max_iteration = 2\n",
    "current_iter = 0\n",
    "deep=True\n",
    "deep=False\n",
    "dead_chars=[]\n",
    "while (deep or current_iter<max_iteration):\n",
    "    made_change=False\n",
    "    current_iter+=1\n",
    "    starting_n_e = np.array([G.number_of_nodes(),G.number_of_edges()])\n",
    "    print(f\"Current iteration: {current_iter}\")\n",
    "    print(\"Starting nodes and edges: \", starting_n_e)\n",
    "    for old,new in chars:\n",
    "        start_result = len(results)\n",
    "        start_nodes = G.number_of_nodes()\n",
    "        start_edges = G.number_of_edges()\n",
    "        print(f\"In results: {len(results)} out of {len(not_found)}\")\n",
    "\n",
    "        print(f\"Replacing '{old}' with '{new}'\")\n",
    "        G2.update(G)\n",
    "        #print(\"Starting num:\",G.number_of_nodes(), G.number_of_edges())\n",
    "        for node_word in G2:\n",
    "            data = G.nodes[node_word]\n",
    "            og = data['og']\n",
    "            #data = info['attr']\n",
    "            final = data['final']\n",
    "            if final is not None:\n",
    "                if not data['originally_known']:\n",
    "                    update_self_and_preds(G,node_word)\n",
    "                    results.update({og:final})\n",
    "\n",
    "                \n",
    "                continue\n",
    "            if og in results: #means that it wasn't marked as finished but we don't care because it's not the path to success\n",
    "                continue\n",
    "            for i in mit.iter_index(mit.sliding_window(node_word,len(old)),tuple(old)) if new!=\"\" else [-1]:\n",
    "                new_word = apply_t(node_word,old,new,i)\n",
    "                if not new_word in G:\n",
    "                    G.add_node(new_word,og=og,final=None,finished=False,originally_known=False)\n",
    "\n",
    "                if G.nodes[new_word]['finished']:\n",
    "                    made_change=True\n",
    "                    end_word = G.nodes[new_word]['final']\n",
    "                    update_self_and_preds(G,node_word,end_word)\n",
    "                    results.update({og:end_word})\n",
    "                    break\n",
    "                if not G.has_edge(node_word,new_word):\n",
    "                        G.add_edge(node_word,new_word,old=old,new=new,idx=i)\n",
    "        \n",
    "        char_edge_diff= G.number_of_edges() - start_edges\n",
    "\n",
    "        char_node_diff = G.number_of_nodes() - start_nodes\n",
    "        result_diff=len(results) -start_result\n",
    "        print(f\"Added {char_node_diff} Node{'s' if char_node_diff!=1 else \"\"}, {char_edge_diff} Edge{'s' if char_edge_diff!=1 else \"\"}, and {result_diff} Result{'s' if result_diff!=1 else \"\"}\")\n",
    "\n",
    "        if result_diff==0:\n",
    "            dead_chars.append(old)\n",
    "        elif\n",
    "\n",
    "    ending_n_e = np.array([G.number_of_nodes(), G.number_of_edges()])\n",
    "    diff=ending_n_e - starting_n_e\n",
    "    print(\"___\")\n",
    "    print(f\"Iteration node and edge differece: {diff}\")\n",
    "    if diff.sum()==0:\n",
    "        break\n",
    "\n",
    "if not made_change:\n",
    "    print(f\"No more changes made after iteration {current_iter}\")\n",
    "still_out_there = [w for w in not_found if w not in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<str_ascii_iterator at 0x170640c40>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # print(iter(old))\n",
    "    # print(window==iter(old))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "node_word='tllatl'\n",
    "print(old)\n",
    "def apply_t(s,old,new,i)->str|None:\n",
    "    if i==-1:\n",
    "        return re.sub(old,new,s)\n",
    "    assert s[i:].startswith(old)\n",
    "    return s[:i] + new + s[i + len(old):] \n",
    "iterator = it.repeat([*iter(node_word)], len(old))\n",
    "for i in it.compress(range(len(node_word)),[map(lambda x: x==iter(old),mit.sliding_window(iter(node_word),len(old)))]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tlaat\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(node_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_t(s,old,new,i)->str|None:\n",
    "    if s[i:].startswith(old):\n",
    "        print(f\"{s[i:]} starts with '{old}'\")\n",
    "        print(s[:i] + new + s[i + len(old):])\n",
    "        #print(s[i + len(old):])\n",
    "        return s[:i] + new + s[i + len(old):]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "ss starts with 's'\n",
      "his\n",
      "3\n",
      "s starts with 's'\n",
      "his\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while i<10:\n",
    "    try:\n",
    "        print(i)\n",
    "        s = apply_t('hiss',\"s\",\"\",i)\n",
    "\n",
    "    \n",
    "    except IndexError:\n",
    "        break\n",
    "    else:\n",
    "        #print(s)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stanliesse'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\"(\\w+)s$\",'stanliesses').group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tlaat',\n",
       " 'ollore',\n",
       " 'collsequelaces',\n",
       " 'ollost',\n",
       " 'clouds',\n",
       " 'cotntnullity',\n",
       " 'clailus',\n",
       " 'antecedellts',\n",
       " 'prevellts',\n",
       " 'judgilaellt',\n",
       " 'ollaki',\n",
       " 'ooll',\n",
       " 'ollixture',\n",
       " 'coollbille',\n",
       " 'tlzat',\n",
       " 'colllmuolity',\n",
       " 'pretellds',\n",
       " 'allci',\n",
       " 'sarill',\n",
       " 'tntlst',\n",
       " 'elcconlplish',\n",
       " 'accordilg',\n",
       " 'deprivillg',\n",
       " 'silogle',\n",
       " 'lullell',\n",
       " 'econelllist',\n",
       " 'conaproollise',\n",
       " 'chanopioll',\n",
       " 'sionilar',\n",
       " 'wlaicll',\n",
       " 'comlllol',\n",
       " 'civili',\n",
       " 'tlansaction',\n",
       " 'itlerease',\n",
       " 'colntnullity',\n",
       " 'ilumecliately',\n",
       " 'correctilag',\n",
       " 'ilzterests',\n",
       " 'llecessit',\n",
       " 'seeril',\n",
       " 'eoznlllullity',\n",
       " 'profouncler',\n",
       " 'llistoryr',\n",
       " 'ldarlialllents',\n",
       " 'eollgresses',\n",
       " 'bargaills',\n",
       " 'tloe',\n",
       " 'ereatioll',\n",
       " 'ptlblie',\n",
       " 'nvestlaillstel',\n",
       " 'lnenlbel',\n",
       " 'loeallll',\n",
       " 'wlliell',\n",
       " 'aetioll',\n",
       " 'flllletioll',\n",
       " 'parliaments',\n",
       " 'exigelleies',\n",
       " 'tlleoll',\n",
       " 'eoznllloll',\n",
       " 'extellsiolls',\n",
       " 'eolllmoll',\n",
       " 'parliaulent',\n",
       " 'tllemseln',\n",
       " 'comlnolzs',\n",
       " 'killgs',\n",
       " 'avoidillg',\n",
       " 'eompellilag',\n",
       " 'opillio',\n",
       " 'wlaell',\n",
       " 'collalllon',\n",
       " 'tlaall',\n",
       " 'diserellt',\n",
       " 'comtnullity',\n",
       " 'lnealas',\n",
       " 'epreselltaties',\n",
       " 'parlialnents',\n",
       " 'recoanitioll',\n",
       " 'epreselltative',\n",
       " 'gelzerally',\n",
       " 'mallifests',\n",
       " 'cotnlllon',\n",
       " 'eneratiolls',\n",
       " 'lessellilag',\n",
       " 'systemgivillg',\n",
       " 'pllllldered',\n",
       " 'tendelley',\n",
       " 'sllos',\n",
       " 'eonneetioll',\n",
       " 'beilag',\n",
       " 'eonstitlltiolls',\n",
       " 'instrulllellts',\n",
       " 'referellee',\n",
       " 'ehallge',\n",
       " 'signifieallt',\n",
       " 'abanclotsllllent',\n",
       " 'eolntnon',\n",
       " 'sllbstitu',\n",
       " 'eollverted',\n",
       " 'wllieh',\n",
       " 'goverlllz',\n",
       " 'eommullity',\n",
       " 'maellillery',\n",
       " 'orgalliza',\n",
       " 'suell',\n",
       " 'eompetitioll',\n",
       " 'lpally',\n",
       " 'eeollotny',\n",
       " 'railroads',\n",
       " 'eonlpetillg',\n",
       " 'workswitllotlt',\n",
       " 'eollvenienee',\n",
       " 'eanllot',\n",
       " 'lllanr',\n",
       " 'vhiell',\n",
       " 'otllel',\n",
       " 'beilog',\n",
       " 'overtakell',\n",
       " 'xvill',\n",
       " 'elltrusted',\n",
       " 'illclireet',\n",
       " 'proteetiotl',\n",
       " 'eolllmereial',\n",
       " 'eolnpetition',\n",
       " 'inclividualized',\n",
       " 'eonlulereial',\n",
       " 'proulotillg',\n",
       " 'eonedellee',\n",
       " 'regulatillg',\n",
       " 'lrlunieipalities',\n",
       " 'ldllt',\n",
       " 'eolllbi',\n",
       " 'neeessarily',\n",
       " 'pursllits',\n",
       " 'theilown',\n",
       " 'llesr',\n",
       " 'cleluded',\n",
       " 'colldltions',\n",
       " 'flllfil',\n",
       " 'xnorally',\n",
       " 'rollle',\n",
       " 'alzlericall',\n",
       " 'leecls',\n",
       " 'collectivisin',\n",
       " 'allalces',\n",
       " 'cllaracters',\n",
       " 'detnallds',\n",
       " 'colllonercial',\n",
       " 'coillproulise',\n",
       " 'plovillg',\n",
       " 'ullw',\n",
       " 'derstallding',\n",
       " 'evokillg',\n",
       " 'svllatever',\n",
       " 'folloving',\n",
       " 'qllol',\n",
       " 'atioll',\n",
       " 'fllrllishes',\n",
       " 'cllanlpiolls',\n",
       " 'harmollized',\n",
       " 'cllristiallity',\n",
       " 'itrlpossible',\n",
       " 'cnildren',\n",
       " 'mollopolists',\n",
       " 'tlleologialls',\n",
       " 'togetllel',\n",
       " 'llumaol',\n",
       " 'clivil',\n",
       " 'ulllatlity',\n",
       " 'delllonracy',\n",
       " 'gallizillg',\n",
       " 'aillst',\n",
       " 'tlwis',\n",
       " 'clearcllt',\n",
       " 'llseci',\n",
       " 'lncavrorable',\n",
       " 'tliat',\n",
       " 'hulllalwity',\n",
       " 'wlloul',\n",
       " 'sillt',\n",
       " 'heavenlr',\n",
       " 'lillers',\n",
       " 'rapllael',\n",
       " 'kllosr',\n",
       " 'ecollol',\n",
       " 'colusecratioll',\n",
       " 'delatonciatioll',\n",
       " 'iglltly',\n",
       " 'ilnpl',\n",
       " 'gll',\n",
       " 'olloies',\n",
       " 'callec',\n",
       " 'titiotl',\n",
       " 'svllere',\n",
       " 'srall',\n",
       " 'coollpesitioll',\n",
       " 'nvllid',\n",
       " 'illlites',\n",
       " 'nvitll',\n",
       " 'tlze',\n",
       " 'colnpetitiolo',\n",
       " 'tllaol',\n",
       " 'crowcliilg',\n",
       " 'platitilig',\n",
       " 'colupetitiotl',\n",
       " 'slnft',\n",
       " 'iicliisiokl',\n",
       " 'lilnself',\n",
       " 'brotl',\n",
       " 'altrtlidlll',\n",
       " 'golclel',\n",
       " 'neiglll',\n",
       " 'rellderi',\n",
       " 'eolllpetition',\n",
       " 'eolltl',\n",
       " 'aclietory',\n",
       " 'eeolleiliatioll',\n",
       " 'unallitr',\n",
       " 'bascoln',\n",
       " 'milllleapolis',\n",
       " 'atlsinson',\n",
       " 'septelilber',\n",
       " 'cliainet',\n",
       " 'rlcally',\n",
       " 'wrllat',\n",
       " 'adlilires',\n",
       " 'altinclanee',\n",
       " 'cleserwrilig',\n",
       " 'lloic',\n",
       " 'cil',\n",
       " 'lillgs',\n",
       " 'cecled',\n",
       " 'desllitioll',\n",
       " 'ozzitld',\n",
       " 'rlleol',\n",
       " 'clls',\n",
       " 'strlltrt',\n",
       " 'cotlisietilla',\n",
       " 'clictiolzaries',\n",
       " 'solzllelllliilc',\n",
       " 'tllezn',\n",
       " 'elldeavorint',\n",
       " 'encleavoritlo',\n",
       " 'eotltest',\n",
       " 'villd',\n",
       " 'dictiollarr',\n",
       " 'llsts',\n",
       " 'llstvvllat',\n",
       " 'ullderstallcls',\n",
       " 'lclrce',\n",
       " 'sellsse',\n",
       " 'eolls',\n",
       " 'ebilae',\n",
       " 'cjefilli',\n",
       " 'tiolls',\n",
       " 'conapetltiola',\n",
       " 'conlflicting',\n",
       " 'comttlerce',\n",
       " 'trallsl',\n",
       " 'jacobsell',\n",
       " 'dolaolllillated',\n",
       " 'llpelitioll',\n",
       " 'colnpetitioul',\n",
       " 'trll',\n",
       " 'oollllcls',\n",
       " 'llk',\n",
       " 'stl',\n",
       " 'lilizited',\n",
       " 'collstittiollal',\n",
       " 'lzollaclaries',\n",
       " 'factlltie',\n",
       " 'elillood',\n",
       " 'zzlillc',\n",
       " 'obviralls',\n",
       " 'valli',\n",
       " 'aziallr',\n",
       " 'svllell',\n",
       " 'lclil',\n",
       " 'xllpply',\n",
       " 'illcolplete',\n",
       " 'inlperfeeit',\n",
       " 'strllgg',\n",
       " 'ttltesz',\n",
       " 'clescrilde',\n",
       " 'cotoopotofloll',\n",
       " 'exrell',\n",
       " 'wloell',\n",
       " 'llc',\n",
       " 'coillpttitioil',\n",
       " 'elelnelljc',\n",
       " 'relacler',\n",
       " 'neally',\n",
       " 'tlie',\n",
       " 'prilzciple',\n",
       " 'oltltior',\n",
       " 'wllerevel',\n",
       " 'lfotllil',\n",
       " 'cotllci',\n",
       " 'lnutalilfll',\n",
       " 'colrlletitiolz',\n",
       " 'alllat',\n",
       " 'tllexl',\n",
       " 'iilciple',\n",
       " 'fainiliar',\n",
       " 'natlll',\n",
       " 'reslllti',\n",
       " 'stlrvi',\n",
       " 'ellvirollinellt',\n",
       " 'fclllziliar',\n",
       " 'olletllocls',\n",
       " 'pearallce',\n",
       " 'strl',\n",
       " 'rollsseall',\n",
       " 'clescriptiosls',\n",
       " 'collcepticall',\n",
       " 'htl',\n",
       " 'glacliatol',\n",
       " 'sllonv',\n",
       " 'eattlres',\n",
       " 'wllerebr',\n",
       " 'strotlbest',\n",
       " 'clltzllinbest',\n",
       " 'qllal',\n",
       " 'mwallace',\n",
       " 'attelltiool',\n",
       " 'allilncals',\n",
       " 'atllotoilt',\n",
       " 'llgble',\n",
       " 'cls',\n",
       " 'lnaximutn',\n",
       " 'luillillltlln',\n",
       " 'stlhetfillg',\n",
       " 'xvatcll',\n",
       " 'aailalal',\n",
       " 'cclll',\n",
       " 'lllerelr',\n",
       " 'tllc',\n",
       " 'offsldril',\n",
       " 'colnpaniolzs',\n",
       " 'lnl',\n",
       " 'artlollg',\n",
       " 'bxistellce',\n",
       " 'xvinislll',\n",
       " 'weapolls',\n",
       " 'orgallie',\n",
       " 'prilllitize',\n",
       " 'aililnals',\n",
       " 'eolle',\n",
       " 'tnigntily',\n",
       " 'ullceasillt',\n",
       " 'ellds',\n",
       " 'grall',\n",
       " 'lelllx',\n",
       " 'rlerar',\n",
       " 'ldeginnilags',\n",
       " 'alliluate',\n",
       " 'illd',\n",
       " 'lldes',\n",
       " 'bradllally',\n",
       " 'colllel',\n",
       " 'svithitl',\n",
       " 'tllajc',\n",
       " 'falltll',\n",
       " 'iolcreasillb',\n",
       " 'cllik',\n",
       " 'ltlasred',\n",
       " 'conclitio',\n",
       " 'llllllllderless',\n",
       " 'installces',\n",
       " 'sidetlt',\n",
       " 'leclared',\n",
       " 'cohlpetitioll',\n",
       " 'lliaolself',\n",
       " 'sllrprised',\n",
       " 'filad',\n",
       " 'profolll',\n",
       " 'illapressioll',\n",
       " 'lllysteries',\n",
       " 'allel',\n",
       " 'reconciliations',\n",
       " 'eacly',\n",
       " 'atlilllals',\n",
       " 'adattls',\n",
       " 'pursllilag',\n",
       " 'colulllon',\n",
       " 'gollen',\n",
       " 'agailn',\n",
       " 'zalitlli',\n",
       " 'illsllite',\n",
       " 'rollps',\n",
       " 'szlall',\n",
       " 'illiolaty',\n",
       " 'lzatioll',\n",
       " 'coln',\n",
       " 'etitioll',\n",
       " 'walitll',\n",
       " 'pllldllc',\n",
       " 'llulllallitariaoli',\n",
       " 'gtllells',\n",
       " 'uleolll',\n",
       " 'splle',\n",
       " 'luilder',\n",
       " 'ecolne',\n",
       " 'walittless',\n",
       " 'ecotlomio',\n",
       " 'lterlaational',\n",
       " 'igllest',\n",
       " 'inclisticltlal',\n",
       " 'eratioll',\n",
       " 'cleo',\n",
       " 'avvorld',\n",
       " 'goetlle',\n",
       " 'apprellelesioll',\n",
       " 'sollae',\n",
       " 'lessells',\n",
       " 'ilacreasing',\n",
       " 'cliscourages',\n",
       " 'inarl',\n",
       " 'vllile',\n",
       " 'increasilog',\n",
       " 'idellce',\n",
       " 'luoderll',\n",
       " 'cinrilization',\n",
       " 'nllo',\n",
       " 'conlparisons',\n",
       " 'xtvritll',\n",
       " 'srolnell',\n",
       " 'blltland',\n",
       " 'uloclern',\n",
       " 'tllrollt',\n",
       " 'lntimely',\n",
       " 'llomilliolls',\n",
       " 'aioderll',\n",
       " 'establislles',\n",
       " 'fitlaess',\n",
       " 'possildle',\n",
       " 'svhile',\n",
       " 'deterluille',\n",
       " 'fllrllislles',\n",
       " 'percelltat',\n",
       " 'tllerebv',\n",
       " 'fsdllud',\n",
       " 'spoils',\n",
       " 'isslles',\n",
       " 'stlrival',\n",
       " 'lcnowll',\n",
       " 'extellels',\n",
       " 'coltlpetil',\n",
       " 'hll',\n",
       " 'corresponclilzg',\n",
       " 'portllllity',\n",
       " 'stlrvirral',\n",
       " 'utacler',\n",
       " 'sstelll',\n",
       " 'killel',\n",
       " 'llel',\n",
       " 'rlls',\n",
       " 'alullace',\n",
       " 'pllrest',\n",
       " 'llosrever',\n",
       " 'investigatilzg',\n",
       " 'outlines',\n",
       " 'gallizatioll',\n",
       " 'colulili',\n",
       " 'tnucll',\n",
       " 'stitiltioll',\n",
       " 'dil',\n",
       " 'ectl',\n",
       " 'overcroxtwdilag',\n",
       " 'valls',\n",
       " 'ceilin',\n",
       " 'aoltl',\n",
       " 'oranizatioll',\n",
       " 'ldllysicialls',\n",
       " 'cllaslces',\n",
       " 'coticlitions',\n",
       " 'deville',\n",
       " 'walllile',\n",
       " 'znibllt',\n",
       " 'rollts',\n",
       " 'xarotlld',\n",
       " 'ild',\n",
       " 'conclitiolas',\n",
       " 'ily',\n",
       " 'ellts',\n",
       " 'stlt',\n",
       " 'estioll',\n",
       " 'alliluals',\n",
       " 'elevatiolls',\n",
       " 'combillations',\n",
       " 'colubillations',\n",
       " 'combinatiolls',\n",
       " 'neall',\n",
       " 'coznpetitiorl',\n",
       " 'wllete',\n",
       " 'cotupetitiotl',\n",
       " 'lletllod',\n",
       " 'owllel',\n",
       " 'nallagetllel',\n",
       " 'illclustl',\n",
       " 'terlus',\n",
       " 'clisti',\n",
       " 'fteretlce',\n",
       " 'socialilstic',\n",
       " 'nlnental',\n",
       " 'llppl',\n",
       " 'tssioll',\n",
       " 'dellla',\n",
       " 'lllaental',\n",
       " 'nailltellallce',\n",
       " 'zlally',\n",
       " 'illdividllallv',\n",
       " 'lllelst',\n",
       " 'irrialtioll',\n",
       " 'clellts',\n",
       " 'irligation',\n",
       " 'colllpetitio',\n",
       " 'llollopols',\n",
       " 'peronaoletlt',\n",
       " 'llclerstalld',\n",
       " 'alnotlt',\n",
       " 'rebioll',\n",
       " 'sllpplieel',\n",
       " 'divideolcls',\n",
       " 'lvestlnetlt',\n",
       " 'latiollal',\n",
       " 'lililliam',\n",
       " 'atlatzzic',\n",
       " 'govelnillelltal',\n",
       " 'llolv',\n",
       " 'ilaovelnellt',\n",
       " 'approaclleswi',\n",
       " 'reaclli',\n",
       " 'opldorttlnities',\n",
       " 'lllovelnelltvs',\n",
       " 'llistol',\n",
       " 'nlents',\n",
       " 'centl',\n",
       " 'clereloldnlent',\n",
       " 'institlltiolas',\n",
       " 'colnpetitio',\n",
       " 'otllicll',\n",
       " 'nallicll',\n",
       " 'jllicll',\n",
       " 'savillgs',\n",
       " 'balllss',\n",
       " 'ecollollaic',\n",
       " 'instittl',\n",
       " 'perlxrlitted',\n",
       " 'illstitutioi',\n",
       " 'lnul',\n",
       " 'opporctlnity',\n",
       " 'lltiest',\n",
       " 'colltrolled',\n",
       " 'furllishes',\n",
       " 'vllinks',\n",
       " 'ellt',\n",
       " 'erforlll',\n",
       " 'plalles',\n",
       " 'llilagle',\n",
       " 'slnpathy',\n",
       " 'clisplacine',\n",
       " 'colllldetitioll',\n",
       " 'coluzetitiotl',\n",
       " 'llss',\n",
       " 'ldeetl',\n",
       " 'luall',\n",
       " 'ecoslolllic',\n",
       " 'proclacillt',\n",
       " 'comptitioll',\n",
       " 'tninoletl',\n",
       " 'lllative',\n",
       " 'prillciles',\n",
       " 'psycholocically',\n",
       " 'ecoololllically',\n",
       " 'splleres',\n",
       " 'tlleself',\n",
       " 'ridellillb',\n",
       " 'llutnanity',\n",
       " 'attailltxlent',\n",
       " 'ribhtly',\n",
       " 'sllffieiellt',\n",
       " 'tnealls',\n",
       " 'vlpbuilding',\n",
       " 'edtlca',\n",
       " 'svorld',\n",
       " 'annoullceinent',\n",
       " 'untiljilly',\n",
       " 'zzlollographs',\n",
       " 'appellded',\n",
       " 'colulnbiaulliversity',\n",
       " 'dartluouth',\n",
       " 'alnos',\n",
       " 'nallce',\n",
       " 'verlllont',\n",
       " 'aiiciligan',\n",
       " 'illinois',\n",
       " 'ollteollle',\n",
       " 'teellriieal',\n",
       " 'tetldelley',\n",
       " 'eivilized',\n",
       " 'eoulltries',\n",
       " 'belgillm',\n",
       " 'teaelling',\n",
       " 'ulliversitr',\n",
       " 'lollclon',\n",
       " 'satisfaetioll',\n",
       " 'faelllty',\n",
       " 'lnellt',\n",
       " 'aeeordill',\n",
       " 'strikil',\n",
       " 'belgillnl',\n",
       " 'inoxrelllellt',\n",
       " 'sellools',\n",
       " 'colllluercial',\n",
       " 'seiellees',\n",
       " 'colnollereial',\n",
       " 'elatilng',\n",
       " 'comlllel',\n",
       " 'educalioll',\n",
       " 'appellcled',\n",
       " 'conlulissiollers',\n",
       " 'fehrtlartr',\n",
       " 'igillal',\n",
       " 'lonclon',\n",
       " 'londoll',\n",
       " 'lldelshochschule',\n",
       " 'consttlaires',\n",
       " 'lvuvaill',\n",
       " 'dispositiolls',\n",
       " 'eolllltries',\n",
       " 'ulliversites',\n",
       " 'etioll',\n",
       " 'beeallse',\n",
       " 'eertaill',\n",
       " 'bracle',\n",
       " 'eolninereial',\n",
       " 'cielllaild',\n",
       " 'illnovavion',\n",
       " 'eireumstallees',\n",
       " 'eomlllereial',\n",
       " 'quiekll',\n",
       " 'oleecls',\n",
       " 'edlleatioll',\n",
       " 'eomll',\n",
       " 'llilldrallee',\n",
       " 'intelleetual',\n",
       " 'meclioerity',\n",
       " 'clefeets',\n",
       " 'steatly',\n",
       " 'eontinlled',\n",
       " 'qlliekly',\n",
       " 'bocliees',\n",
       " 'lenrellclers',\n",
       " 'boarcls',\n",
       " 'tlhe',\n",
       " 'unclertalze',\n",
       " 'sitiolls',\n",
       " 'acluate',\n",
       " 'meantillle',\n",
       " 'developillg',\n",
       " 'cllarmed',\n",
       " 'colunlunity',\n",
       " 'orlater',\n",
       " 'bralclles',\n",
       " 'usilless',\n",
       " 'pursuillg',\n",
       " 'srell',\n",
       " 'callint',\n",
       " 'claitned',\n",
       " 'luakillg',\n",
       " 'relltlelnen',\n",
       " 'traillino',\n",
       " 'tllenllore',\n",
       " 'bellclles',\n",
       " 'xvllile',\n",
       " 'cotlrses',\n",
       " 'gllments',\n",
       " 'llnclertalce',\n",
       " 'gllzzlellt',\n",
       " 'luatly',\n",
       " 'cotnlllercial',\n",
       " 'tlaese',\n",
       " 'lllllediate',\n",
       " 'ldellefit',\n",
       " 'stuclies',\n",
       " 'dtless',\n",
       " 'illstit',\n",
       " 'tioll',\n",
       " 'elrcll',\n",
       " 'tlaollc',\n",
       " 'lneclici',\n",
       " 'llearcr',\n",
       " 'llowes',\n",
       " 'rhicll',\n",
       " 'clepartrnellt',\n",
       " 'tlaeir',\n",
       " 'harnessitlg',\n",
       " 'patiellts',\n",
       " 'vasllillg',\n",
       " 'pestles',\n",
       " 'ldinclillg',\n",
       " 'clishes',\n",
       " 'ivell',\n",
       " 'gertlan',\n",
       " 'llighel',\n",
       " 'intelleet',\n",
       " 'eanclidate',\n",
       " 'objeetioll',\n",
       " 'reeomnlenclec',\n",
       " 'eurrieululll',\n",
       " 'desile',\n",
       " 'whiell',\n",
       " 'eurriellluln',\n",
       " 'traillil',\n",
       " 'eellters',\n",
       " 'marlufaeturer',\n",
       " 'finalleially',\n",
       " 'orgallizing',\n",
       " 'allc',\n",
       " 'fillanee',\n",
       " 'eollebe',\n",
       " 'slloulel',\n",
       " 'whicla',\n",
       " 'svllile',\n",
       " 'alnericai',\n",
       " 'clrafted',\n",
       " 'clerks',\n",
       " 'stittltiollss',\n",
       " 'railwavs',\n",
       " 'advallceci',\n",
       " 'ldrincil',\n",
       " 'trallspol',\n",
       " 'tatiotl',\n",
       " 'ellaployes',\n",
       " 'rectiolls',\n",
       " 'nlnercial',\n",
       " 'traillizag',\n",
       " 'svillillg',\n",
       " 'sselld',\n",
       " 'lligllel',\n",
       " 'eparillg',\n",
       " 'elllployts',\n",
       " 'cornwell',\n",
       " 'eolnonullity',\n",
       " 'toclern',\n",
       " 'seellre',\n",
       " 'tnell',\n",
       " 'eolning',\n",
       " 'slleeeed',\n",
       " 'eolllplete',\n",
       " 'collllllel',\n",
       " 'statilag',\n",
       " 'eontailled',\n",
       " 'cleveloplnelat',\n",
       " 'eolne',\n",
       " 'eclueatioll',\n",
       " 'eolllllluolity',\n",
       " 'aiidreeiatioll',\n",
       " 'wolld',\n",
       " 'illsists',\n",
       " 'aspil',\n",
       " 'eclueated',\n",
       " 'ellltivated',\n",
       " 'inereasilog',\n",
       " 'resllltvs',\n",
       " 'wlliel',\n",
       " 'ecllleatioll',\n",
       " 'intelleetllal',\n",
       " 'moclels',\n",
       " 'eollllnullity',\n",
       " 'mallufaetul',\n",
       " 'clireetion',\n",
       " 'accumulatillg',\n",
       " 'edlleation',\n",
       " 'ecltleation',\n",
       " 'ealling',\n",
       " 'eentllry',\n",
       " 'noldocly',\n",
       " 'colllltl',\n",
       " 'sellool',\n",
       " 'pllyrsieian',\n",
       " 'elergylllall',\n",
       " 'tecllllieal',\n",
       " 'plallned',\n",
       " 'currieululn',\n",
       " 'llapha',\n",
       " 'eallses',\n",
       " 'stlbjeet',\n",
       " 'irly',\n",
       " 'edueatioll',\n",
       " 'inollograplls',\n",
       " 'physieiall',\n",
       " 'reeogllize',\n",
       " 'faeilities',\n",
       " 'lleriean',\n",
       " 'lloev',\n",
       " 'ftlnetion',\n",
       " 'satisfaetoriln',\n",
       " 'sllolllci',\n",
       " 'eolllparatively',\n",
       " 'branelles',\n",
       " 'eollrse',\n",
       " 'eollsequently',\n",
       " 'eallnot',\n",
       " 'oeeasioll',\n",
       " 'partielllar',\n",
       " 'brallelles',\n",
       " 'inelllcled',\n",
       " 'eurrielllllm',\n",
       " 'seiellee',\n",
       " 'mathenlatllies',\n",
       " 'lneclieal',\n",
       " 'praetieally',\n",
       " 'diseiplille',\n",
       " 'illcludes',\n",
       " 'banling',\n",
       " 'allce',\n",
       " 'tlleirgeneralaspects',\n",
       " 'sllldjects',\n",
       " 'ulechanisln',\n",
       " 'coznlllercial',\n",
       " 'raplly',\n",
       " 'colulnercial',\n",
       " 'fllrtllel',\n",
       " 'presentillg',\n",
       " 'boolkeepillg',\n",
       " 'accolillts',\n",
       " 'lllecllanistn',\n",
       " 'foliowillg',\n",
       " 'departnellts',\n",
       " 'tatioll',\n",
       " 'tlleol',\n",
       " 'aucliting',\n",
       " 'oally',\n",
       " 'attelltiol',\n",
       " 'undertalillg',\n",
       " 'lligl',\n",
       " 'rnell',\n",
       " 'plltti',\n",
       " 'rollllg',\n",
       " 'allllollllces',\n",
       " 'scl',\n",
       " 'llentiolaed',\n",
       " 'alltage',\n",
       " 'eolnmercial',\n",
       " 'inforl',\n",
       " 'clefilaite',\n",
       " 'ehallee',\n",
       " 'ullix',\n",
       " 'scollolny',\n",
       " 'parallelint',\n",
       " 'forlol',\n",
       " 'existillb',\n",
       " 'wiscollsin',\n",
       " 'liclligan',\n",
       " 'dartlllollth',\n",
       " 'llowerler',\n",
       " 'colllpleted',\n",
       " 'ellally',\n",
       " 'vanderbilt',\n",
       " 'traillillgortlledeveloplllent',\n",
       " 'wiclelled',\n",
       " 'ttlrotlgll',\n",
       " 'vlllcler',\n",
       " 'illflllellee',\n",
       " 'wllel',\n",
       " 'ditioll',\n",
       " 'hllllclrecrs',\n",
       " 'lotllag',\n",
       " 'nell',\n",
       " 'otlle',\n",
       " 'preparillg',\n",
       " 'ulliversi',\n",
       " 'ollany',\n",
       " 'ourmoclern',\n",
       " 'llnivelsity',\n",
       " 'mhartoll',\n",
       " 'xperililellt',\n",
       " 'naturallt',\n",
       " 'halldillg',\n",
       " 'tllorllsoll',\n",
       " 'edmtllld',\n",
       " 'aclnlinistl',\n",
       " 'govertllalellt',\n",
       " 'edlllund',\n",
       " 'ricllluin',\n",
       " 'lellgthelled',\n",
       " 'instrlletors',\n",
       " 'nvhartoll',\n",
       " 'lgeell',\n",
       " 'instrtletion',\n",
       " 'alhartoll',\n",
       " 'follonvillg',\n",
       " 'willianl',\n",
       " 'nvisconsill',\n",
       " 'selectillg',\n",
       " 'engilleerillgy',\n",
       " 'jahrbuciler',\n",
       " 'cincinllati',\n",
       " 'commerclal',\n",
       " 'lllakint',\n",
       " 'ldeclaration',\n",
       " 'inoclerr',\n",
       " 'glallclest',\n",
       " 'clocalilellts',\n",
       " 'sometllillz',\n",
       " 'trlltlls',\n",
       " 'ullalienal',\n",
       " 'lilderty',\n",
       " 'flortllerlrlore',\n",
       " 'oovernlnellt',\n",
       " 'riglltes',\n",
       " 'gorrernllletlt',\n",
       " 'clerines',\n",
       " 'llbel',\n",
       " 'colllxnon',\n",
       " 'illtelligenl',\n",
       " 'ositioll',\n",
       " 'cleellleci',\n",
       " 'placillg',\n",
       " 'clestinies',\n",
       " 'tlleless',\n",
       " 'ltlnlall',\n",
       " 'arllicll',\n",
       " 'eatlles',\n",
       " 'olloll',\n",
       " 'stnitll',\n",
       " 'xvealtll',\n",
       " 'rtiolls',\n",
       " 'fizlcls',\n",
       " 'llilosophr',\n",
       " 'tnacle',\n",
       " 'walllen',\n",
       " 'silnplicltwt',\n",
       " 'tllouaht',\n",
       " 'buncile',\n",
       " 'lilherty',\n",
       " 'preselltec',\n",
       " 'tllouo',\n",
       " 'reldllblic',\n",
       " 'vealtll',\n",
       " 'xvitll',\n",
       " 'statesrnall',\n",
       " 'envirotltnellt',\n",
       " 'allged',\n",
       " 'briclc',\n",
       " 'statesinall',\n",
       " 'tlaeory',\n",
       " 'reaelled',\n",
       " 'forefatllers',\n",
       " 'svllieh',\n",
       " 'llotieed',\n",
       " 'bellefieellee',\n",
       " 'inaslnuell',\n",
       " 'eaell',\n",
       " 'halllperillg',\n",
       " 'sholllc',\n",
       " 'elearly',\n",
       " 'elleony',\n",
       " 'clireeting',\n",
       " 'xvell',\n",
       " 'svllicll',\n",
       " 'illterestilag',\n",
       " 'oadenillg',\n",
       " 'freedotll',\n",
       " 'illdon',\n",
       " 'allotlle',\n",
       " 'itil',\n",
       " 'tllolnas',\n",
       " 'altovetller',\n",
       " 'acllieveci',\n",
       " 'gleell',\n",
       " 'lottl',\n",
       " 'tstrclllous',\n",
       " 'xrorcls',\n",
       " 'orfreeclotn',\n",
       " 'fleecloll',\n",
       " 'eeclozn',\n",
       " 'elljoated',\n",
       " 'somethillt',\n",
       " 'doitlt',\n",
       " 'solnetllillt',\n",
       " 'solnetlaillg',\n",
       " 'hioll',\n",
       " 'fellowtlle',\n",
       " 'ullicll',\n",
       " 'lloeasure',\n",
       " 'freecloul',\n",
       " 'naeastlre',\n",
       " 'tllelllfselxres',\n",
       " 'concerllint',\n",
       " 'ttzollgllt',\n",
       " 'terlminatillg',\n",
       " 'entrelne',\n",
       " 'slllitli',\n",
       " 'lilosophy',\n",
       " 'llteellth',\n",
       " 'philosopllyr',\n",
       " 'celltur',\n",
       " 'illllabiteci',\n",
       " ...]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "still_out_there\n",
    "w=\"prevents_pretends_depriving_antecedents_parliaments\"\n",
    "level2 = \"hla_lan_hlz_eo_ec_ce_nlz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8655290102389078"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)/len(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'og': 'and', 'final': 'and', 'finished': True, 'neigh': 'horse'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nx.set_node_attributes(G,'horse','neigh')\n",
    "G2.update(G)\n",
    "G2.nodes['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mudlark\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\n",
    "    (\"ll\", \"n\"),\n",
    "    (\"ll\", \"u\"),\n",
    "    (\"ll\", \"h\"),\n",
    "    (\"il\", \"n\"),\n",
    "    (\"il\", \"u\"),\n",
    "    (\"il\", \"h\"),\n",
    "    (\"nl\", \"m\"),\n",
    "    (\"ln\", \"m\"),\n",
    "    (\"cl\", \"d\"),\n",
    "    (\"vv\", \"w\"),\n",
    "    (\"lll\", \"m\"),\n",
    "    (\"rl\", \"n\"),\n",
    "    (\"tl\", \"u\"),\n",
    "    (\"tl\", \"n\"),\n",
    "]\n",
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "word_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "word_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1: Queue of 2273\n",
      "Queued for next iteration: 18142\n",
      "After culling:  18099\n",
      "Iteration2: Queue of 18099\n",
      "Queued for next iteration: 125100\n",
      "After culling:  124385\n",
      "Iteration3: Queue of 124385\n",
      "Queued for next iteration: 1242140\n",
      "After culling:  1239694\n",
      "Iteration4: Queue of 1239694\n",
      "Queued for next iteration: 19582804\n",
      "After culling:  19580630\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "corrections = json.load(open('corrections.json'))\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development_hospital_sometimes_healing_should_universities_undertake_departments_evolution\"\n",
    "known_words:set[str] = set(exists.split(\"_\")+list(ac['corpus_word'].astype(str)) +list(corrections.values()) +word_list)\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = list(sc.loc[sc['og_word'].isin(known_words)==False,'og_word'])\n",
    "results,graph= iterate_through_changes(known_words,not_found,chars,max_iterations=4)\n",
    "not_found = [i for i,v in results.items() if len(v)==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llletllod': 'llletllod',\n",
       " 'differellt': 'differellt',\n",
       " 'sellse': 'sellse',\n",
       " 'illaterial': 'illaterial',\n",
       " 'diminisll': 'diminisll',\n",
       " 'otlly': 'otlly',\n",
       " 'dynalllic': 'dynalllic',\n",
       " 'dyllamic': 'dyllamic',\n",
       " 'ollore': 'ollore',\n",
       " 'thorougllly': 'thorougllly',\n",
       " 'dissellt': 'dissellt',\n",
       " 'collsistently': 'collsistently',\n",
       " 'borll': 'borll',\n",
       " 'collsequelaces': 'collsequelaces',\n",
       " 'llight': 'llight',\n",
       " 'collnected': 'collnected',\n",
       " 'prepossessiolls': 'prepossessiolls',\n",
       " 'examille': 'examille',\n",
       " 'conditioll': 'conditioll',\n",
       " 'observatioll': 'observatioll',\n",
       " 'jlldgments': 'jlldgments',\n",
       " 'criticislll': 'criticislll',\n",
       " 'ollost': 'ollost',\n",
       " 'intervelltion': 'intervelltion',\n",
       " 'weigll': 'weigll',\n",
       " 'sall': 'sall',\n",
       " 'methocls': 'methocls',\n",
       " 'bllt': 'bllt',\n",
       " 'ftllfillment': 'ftllfillment',\n",
       " 'comlllllnity': 'comlllllnity',\n",
       " 'ulldertake': 'ulldertake',\n",
       " 'icleals': 'icleals',\n",
       " 'clouds': 'clouds',\n",
       " 'chatllpion': 'chatllpion',\n",
       " 'cotntnullity': 'cotntnullity',\n",
       " 'clailus': 'clailus',\n",
       " 'illissioll': 'illissioll',\n",
       " 'etllics': 'etllics',\n",
       " 'judgmellt': 'judgmellt',\n",
       " 'llational': 'llational',\n",
       " 'antecedellts': 'antecedellts',\n",
       " 'growll': 'growll',\n",
       " 'llilnself': 'llilnself',\n",
       " 'envirollmellt': 'envirollmellt',\n",
       " 'nearsiglltedness': 'nearsiglltedness',\n",
       " 'astiglllatisill': 'astiglllatisill',\n",
       " 'ellable': 'ellable',\n",
       " 'hellry': 'hellry',\n",
       " 'disinterestedlless': 'disinterestedlless',\n",
       " 'canclid': 'canclid',\n",
       " 'illtentioll': 'illtentioll',\n",
       " 'prevellts': 'prevellts',\n",
       " 'judgilaellt': 'judgilaellt',\n",
       " 'sllggests': 'sllggests',\n",
       " 'uncler': 'uncler',\n",
       " 'circutllstallces': 'circutllstallces',\n",
       " 'ollaki': 'ollaki',\n",
       " 'llg': 'llg',\n",
       " 'judglllellts': 'judglllellts',\n",
       " 'clailll': 'clailll',\n",
       " 'ooll': 'ooll',\n",
       " 'ollixture': 'ollixture',\n",
       " 'cleceptioll': 'cleceptioll',\n",
       " 'coollbille': 'coollbille',\n",
       " 'botll': 'botll',\n",
       " 'illdependent': 'illdependent',\n",
       " 'attelllpt': 'attelllpt',\n",
       " 'eminellt': 'eminellt',\n",
       " 'johll': 'johll',\n",
       " 'assulllption': 'assulllption',\n",
       " 'colllmuolity': 'colllmuolity',\n",
       " 'pretellds': 'pretellds',\n",
       " 'jllst': 'jllst',\n",
       " 'reforlller': 'reforlller',\n",
       " 'everytlling': 'everytlling',\n",
       " 'allci': 'allci',\n",
       " 'sarill': 'sarill',\n",
       " 'visiollary': 'visiollary',\n",
       " 'lllealls': 'lllealls',\n",
       " 'collcrete': 'collcrete',\n",
       " 'sentimellt': 'sentimellt',\n",
       " 'wllolly': 'wllolly',\n",
       " 'illdividual': 'illdividual',\n",
       " 'workillg': 'workillg',\n",
       " 'recognitioll': 'recognitioll',\n",
       " 'permissioll': 'permissioll',\n",
       " 'deprivillg': 'deprivillg',\n",
       " 'cllallces': 'cllallces',\n",
       " 'grollp': 'grollp',\n",
       " 'balallce': 'balallce',\n",
       " 'annillilation': 'annillilation',\n",
       " 'predolninallce': 'predolninallce',\n",
       " 'iclelltified': 'iclelltified',\n",
       " 'cllance': 'cllance',\n",
       " 'collflicting': 'collflicting',\n",
       " 'fulldalnental': 'fulldalnental',\n",
       " 'outlilled': 'outlilled',\n",
       " 'ollr': 'ollr',\n",
       " 'showll': 'showll',\n",
       " 'colltribllte': 'colltribllte',\n",
       " 'neecls': 'neecls',\n",
       " 'lnall': 'lnall',\n",
       " 'conclusiolls': 'conclusiolls',\n",
       " 'lullell': 'lullell',\n",
       " 'econelllist': 'econelllist',\n",
       " 'illottlent': 'illottlent',\n",
       " 'adjllstlnent': 'adjllstlnent',\n",
       " 'conaproollise': 'conaproollise',\n",
       " 'positiolls': 'positiolls',\n",
       " 'chanopioll': 'chanopioll',\n",
       " 'llilll': 'llilll',\n",
       " 'wlaicll': 'wlaicll',\n",
       " 'comlllol': 'comlllol',\n",
       " 'llniotls': 'llniotls',\n",
       " 'frotll': 'frotll',\n",
       " 'trallsaction': 'trallsaction',\n",
       " 'reglllator': 'reglllator',\n",
       " 'reasoll': 'reasoll',\n",
       " 'owller': 'owller',\n",
       " 'alld': 'alld',\n",
       " 'sllowed': 'sllowed',\n",
       " 'colntnullity': 'colntnullity',\n",
       " 'ilumecliately': 'ilumecliately',\n",
       " 'accolllpanied': 'accolllpanied',\n",
       " 'poillt': 'poillt',\n",
       " 'illfluellce': 'illfluellce',\n",
       " 'forlllation': 'forlllation',\n",
       " 'lls': 'lls',\n",
       " 'adoptioll': 'adoptioll',\n",
       " 'illorality': 'illorality',\n",
       " 'aclvocacy': 'aclvocacy',\n",
       " 'ratller': 'ratller',\n",
       " 'llecessit': 'llecessit',\n",
       " 'governlllent': 'governlllent',\n",
       " 'clifferellt': 'clifferellt',\n",
       " 'recogllition': 'recogllition',\n",
       " 'clas': 'clas',\n",
       " 'aillls': 'aillls',\n",
       " 'eoznlllullity': 'eoznlllullity',\n",
       " 'profouncler': 'profouncler',\n",
       " 'stucly': 'stucly',\n",
       " 'collstitlltiollal': 'collstitlltiollal',\n",
       " 'llistoryr': 'llistoryr',\n",
       " 'ldarlialllents': 'ldarlialllents',\n",
       " 'eollgresses': 'eollgresses',\n",
       " 'collstlmtllation': 'collstlmtllation',\n",
       " 'bargaills': 'bargaills',\n",
       " 'ereatioll': 'ereatioll',\n",
       " 'parlialnellt': 'parlialnellt',\n",
       " 'nvestlaillstel': 'nvestlaillstel',\n",
       " 'illterchange': 'illterchange',\n",
       " 'eilliglltened': 'eilliglltened',\n",
       " 'loeallll': 'loeallll',\n",
       " 'wlliell': 'wlliell',\n",
       " 'llollle': 'llollle',\n",
       " 'aetioll': 'aetioll',\n",
       " 'esselltial': 'esselltial',\n",
       " 'flllletioll': 'flllletioll',\n",
       " 'tlleil': 'tlleil',\n",
       " 'exigelleies': 'exigelleies',\n",
       " 'ellabled': 'ellabled',\n",
       " 'tlleoll': 'tlleoll',\n",
       " 'eoznllloll': 'eoznllloll',\n",
       " 'extellsiolls': 'extellsiolls',\n",
       " 'eolllmoll': 'eolllmoll',\n",
       " 'fallell': 'fallell',\n",
       " 'llad': 'llad',\n",
       " 'additioll': 'additioll',\n",
       " 'tllemseln': 'tllemseln',\n",
       " 'origillate': 'origillate',\n",
       " 'killgs': 'killgs',\n",
       " 'avoidillg': 'avoidillg',\n",
       " 'eompellilag': 'eompellilag',\n",
       " 'autlloritative': 'autlloritative',\n",
       " 'opillio': 'opillio',\n",
       " 'wlaell': 'wlaell',\n",
       " 'parliamellt': 'parliamellt',\n",
       " 'illtellded': 'illtellded',\n",
       " 'fullction': 'fullction',\n",
       " 'clifferent': 'clifferent',\n",
       " 'tllal': 'tllal',\n",
       " 'collalllon': 'collalllon',\n",
       " 'tlaall': 'tlaall',\n",
       " 'vvllat': 'vvllat',\n",
       " 'extensioll': 'extensioll',\n",
       " 'll': 'll',\n",
       " 'diserellt': 'diserellt',\n",
       " 'comtnullity': 'comtnullity',\n",
       " 'illforlnation': 'illforlnation',\n",
       " 'wllicll': 'wllicll',\n",
       " 'collgressional': 'collgressional',\n",
       " 'epreselltaties': 'epreselltaties',\n",
       " 'formatioll': 'formatioll',\n",
       " 'sentilnellt': 'sentilnellt',\n",
       " 'lllaking': 'lllaking',\n",
       " 'opilliolls': 'opilliolls',\n",
       " 'accompallied': 'accompallied',\n",
       " 'sallltary': 'sallltary',\n",
       " 'thillk': 'thillk',\n",
       " 'recoanitioll': 'recoanitioll',\n",
       " 'collvictioll': 'collvictioll',\n",
       " 'epreselltative': 'epreselltative',\n",
       " 'utterallces': 'utterallces',\n",
       " 'collstituellts': 'collstituellts',\n",
       " 'tllall': 'tllall',\n",
       " 'gelzerally': 'gelzerally',\n",
       " 'educatiollal': 'educatiollal',\n",
       " 'incidellt': 'incidellt',\n",
       " 'clistrict': 'clistrict',\n",
       " 'mallifests': 'mallifests',\n",
       " 'appropriatioll': 'appropriatioll',\n",
       " 'stalld': 'stalld',\n",
       " 'illcreasingly': 'illcreasingly',\n",
       " 'bellalf': 'bellalf',\n",
       " 'llloderll': 'llloderll',\n",
       " 'patcllwork': 'patcllwork',\n",
       " 'demallds': 'demallds',\n",
       " 'llotoriotls': 'llotoriotls',\n",
       " 'parliamelltary': 'parliamelltary',\n",
       " 'glorificatioll': 'glorificatioll',\n",
       " 'idealizatioll': 'idealizatioll',\n",
       " 'cotnlllon': 'cotnlllon',\n",
       " 'eneratiolls': 'eneratiolls',\n",
       " 'illlmediately': 'illlmediately',\n",
       " 'passillg': 'passillg',\n",
       " 'lessellilag': 'lessellilag',\n",
       " 'systemgivillg': 'systemgivillg',\n",
       " 'persolls': 'persolls',\n",
       " 'tllayor': 'tllayor',\n",
       " 'ordillary': 'ordillary',\n",
       " 'pllllldered': 'pllllldered',\n",
       " 'tendelley': 'tendelley',\n",
       " 'sllos': 'sllos',\n",
       " 'eonneetioll': 'eonneetioll',\n",
       " 'eonstitlltiolls': 'eonstitlltiolls',\n",
       " 'instrulllellts': 'instrulllellts',\n",
       " 'providillg': 'providillg',\n",
       " 'referellee': 'referellee',\n",
       " 'argumellt': 'argumellt',\n",
       " 'ehallge': 'ehallge',\n",
       " 'signifieallt': 'signifieallt',\n",
       " 'trelld': 'trelld',\n",
       " 'abanclotsllllent': 'abanclotsllllent',\n",
       " 'clebate': 'clebate',\n",
       " 'sllbstitu': 'sllbstitu',\n",
       " 'partisall': 'partisall',\n",
       " 'eollverted': 'eollverted',\n",
       " 'wllieh': 'wllieh',\n",
       " 'prevellted': 'prevellted',\n",
       " 'goverlllz': 'goverlllz',\n",
       " 'lellt': 'lellt',\n",
       " 'eommullity': 'eommullity',\n",
       " 'improvelnellts': 'improvelnellts',\n",
       " 'maellillery': 'maellillery',\n",
       " 'orgalliza': 'orgalliza',\n",
       " 'dllrillg': 'dllrillg',\n",
       " 'suell': 'suell',\n",
       " 'eompetitioll': 'eompetitioll',\n",
       " 'lpally': 'lpally',\n",
       " 'lilles': 'lilles',\n",
       " 'eall': 'eall',\n",
       " 'eeollotny': 'eeollotny',\n",
       " 'eonlpetillg': 'eonlpetillg',\n",
       " 'workswitllotlt': 'workswitllotlt',\n",
       " 'expellse': 'expellse',\n",
       " 'climinished': 'climinished',\n",
       " 'eollvenienee': 'eollvenienee',\n",
       " 'eanllot': 'eanllot',\n",
       " 'lllanr': 'lllanr',\n",
       " 'eoll': 'eoll',\n",
       " 'dallger': 'dallger',\n",
       " 'elllarge': 'elllarge',\n",
       " 'vhiell': 'vhiell',\n",
       " 'detrimellt': 'detrimellt',\n",
       " 'otllel': 'otllel',\n",
       " 'overtakell': 'overtakell',\n",
       " 'xvill': 'xvill',\n",
       " 'elltrusted': 'elltrusted',\n",
       " 'tllein': 'tllein',\n",
       " 'illclireet': 'illclireet',\n",
       " 'eolllmereial': 'eolllmereial',\n",
       " 'inclividualized': 'inclividualized',\n",
       " 'selfisllness': 'selfisllness',\n",
       " 'lllelch': 'lllelch',\n",
       " 'ulllimited': 'ulllimited',\n",
       " 'proulotillg': 'proulotillg',\n",
       " 'eonedellee': 'eonedellee',\n",
       " 'illclividual': 'illclividual',\n",
       " 'illitiative': 'illitiative',\n",
       " 'regulatillg': 'regulatillg',\n",
       " 'givillg': 'givillg',\n",
       " 'ulldreamed': 'ulldreamed',\n",
       " 'ldllt': 'ldllt',\n",
       " 'eolllbi': 'eolllbi',\n",
       " 'llatiollal': 'llatiollal',\n",
       " 'recogllitioll': 'recogllitioll',\n",
       " 'strengtll': 'strengtll',\n",
       " 'pursllits': 'pursllits',\n",
       " 'lllember': 'lllember',\n",
       " 'federatioll': 'federatioll',\n",
       " 'llesr': 'llesr',\n",
       " 'represellt': 'represellt',\n",
       " 'fulldamental': 'fulldamental',\n",
       " 'boullded': 'boullded',\n",
       " 'beyolld': 'beyolld',\n",
       " 'cleluded': 'cleluded',\n",
       " 'hallds': 'hallds',\n",
       " 'colldltions': 'colldltions',\n",
       " 'flllfil': 'flllfil',\n",
       " 'xnorally': 'xnorally',\n",
       " 'rollle': 'rollle',\n",
       " 'ruilled': 'ruilled',\n",
       " 'alzlericall': 'alzlericall',\n",
       " 'leecls': 'leecls',\n",
       " 'indllstry': 'indllstry',\n",
       " 'goverlllllent': 'goverlllllent',\n",
       " 'collectivisin': 'collectivisin',\n",
       " 'allalces': 'allalces',\n",
       " 'cllaracters': 'cllaracters',\n",
       " 'detnallds': 'detnallds',\n",
       " 'colllpromise': 'colllpromise',\n",
       " 'ullclerstalldillg': 'ullclerstalldillg',\n",
       " 'bargaill': 'bargaill',\n",
       " 'colllonercial': 'colllonercial',\n",
       " 'illethods': 'illethods',\n",
       " 'coillproulise': 'coillproulise',\n",
       " 'convictioll': 'convictioll',\n",
       " 'successflll': 'successflll',\n",
       " 'lllan': 'lllan',\n",
       " 'ecollomists': 'ecollomists',\n",
       " 'collditiolls': 'collditiolls',\n",
       " 'treatmellt': 'treatmellt',\n",
       " 'plovillg': 'plovillg',\n",
       " 'ullw': 'ullw',\n",
       " 'derstallding': 'derstallding',\n",
       " 'lleecls': 'lleecls',\n",
       " 'evokillg': 'evokillg',\n",
       " 'svllatever': 'svllatever',\n",
       " 'kllowledge': 'kllowledge',\n",
       " 'breadtll': 'breadtll',\n",
       " 'llotlling': 'llotlling',\n",
       " 'toucllillg': 'toucllillg',\n",
       " 'sll': 'sll',\n",
       " 'folloving': 'folloving',\n",
       " 'qllol': 'qllol',\n",
       " 'atioll': 'atioll',\n",
       " 'fllrllishes': 'fllrllishes',\n",
       " 'cllanlpiolls': 'cllanlpiolls',\n",
       " 'dolllillated': 'dolllillated',\n",
       " 'harmollized': 'harmollized',\n",
       " 'elelnellts': 'elelnellts',\n",
       " 'cllristiallity': 'cllristiallity',\n",
       " 'lllatl': 'lllatl',\n",
       " 'conclitions': 'conclitions',\n",
       " 'cullilillg': 'cullilillg',\n",
       " 'absorbillg': 'absorbillg',\n",
       " 'feeclillg': 'feeclillg',\n",
       " 'warpillg': 'warpillg',\n",
       " 'bidclillg': 'bidclillg',\n",
       " 'politicialls': 'politicialls',\n",
       " 'mollopolists': 'mollopolists',\n",
       " 'tlleologialls': 'tlleologialls',\n",
       " 'bellillcl': 'bellillcl',\n",
       " 'togetllel': 'togetllel',\n",
       " 'llumaol': 'llumaol',\n",
       " 'clivil': 'clivil',\n",
       " 'ulllatlity': 'ulllatlity',\n",
       " 'delllonracy': 'delllonracy',\n",
       " 'gallizillg': 'gallizillg',\n",
       " 'maclliller': 'maclliller',\n",
       " 'llt': 'llt',\n",
       " 'aillst': 'aillst',\n",
       " 'utterallce': 'utterallce',\n",
       " 'clearcllt': 'clearcllt',\n",
       " 'sioll': 'sioll',\n",
       " 'opillioil': 'opillioil',\n",
       " 'llseci': 'llseci',\n",
       " 'lllanifestatioll': 'lllanifestatioll',\n",
       " 'alltic': 'alltic',\n",
       " 'everybocly': 'everybocly',\n",
       " 'cllll': 'cllll',\n",
       " 'illg': 'illg',\n",
       " 'celltllries': 'celltllries',\n",
       " 'pllysical': 'pllysical',\n",
       " 'allead': 'allead',\n",
       " 'hulllalwity': 'hulllalwity',\n",
       " 'stalldard': 'stalldard',\n",
       " 'lllode': 'lllode',\n",
       " 'livillg': 'livillg',\n",
       " 'comllloll': 'comllloll',\n",
       " 'colllfortable': 'colllfortable',\n",
       " 'wlloul': 'wlloul',\n",
       " 'sillt': 'sillt',\n",
       " 'ollce': 'ollce',\n",
       " 'olltburst': 'olltburst',\n",
       " 'writtell': 'writtell',\n",
       " 'cllristiall': 'cllristiall',\n",
       " 'lillers': 'lillers',\n",
       " 'pllilosopllers': 'pllilosopllers',\n",
       " 'eartll': 'eartll',\n",
       " 'rapllael': 'rapllael',\n",
       " 'worsllip': 'worsllip',\n",
       " 'kllosr': 'kllosr',\n",
       " 'meallwhile': 'meallwhile',\n",
       " 'tllou': 'tllou',\n",
       " 'parellt': 'parellt',\n",
       " 'ecollol': 'ecollol',\n",
       " 'slle': 'slle',\n",
       " 'colusecratioll': 'colusecratioll',\n",
       " 'cailnibalistll': 'cailnibalistll',\n",
       " 'llalld': 'llalld',\n",
       " 'lllese': 'lllese',\n",
       " 'worcls': 'worcls',\n",
       " 'sturcly': 'sturcly',\n",
       " 'alnericall': 'alnericall',\n",
       " 'delatonciatioll': 'delatonciatioll',\n",
       " 'iglltly': 'iglltly',\n",
       " 'gll': 'gll',\n",
       " 'olloies': 'olloies',\n",
       " 'callec': 'callec',\n",
       " 'cellters': 'cellters',\n",
       " 'svllere': 'svllere',\n",
       " 'lnell': 'lnell',\n",
       " 'lllel': 'lllel',\n",
       " 'srall': 'srall',\n",
       " 'coollpesitioll': 'coollpesitioll',\n",
       " 'nvllid': 'nvllid',\n",
       " 'illlites': 'illlites',\n",
       " 'nvitll': 'nvitll',\n",
       " 'tllaol': 'tllaol',\n",
       " 'tlleft': 'tlleft',\n",
       " 'recollciliatioll': 'recollciliatioll',\n",
       " 'crowcliilg': 'crowcliilg',\n",
       " 'llpoll': 'llpoll',\n",
       " 'sicle': 'sicle',\n",
       " 'iicliisiokl': 'iicliisiokl',\n",
       " 'altrtlidlll': 'altrtlidlll',\n",
       " 'golclel': 'golclel',\n",
       " 'lllle': 'lllle',\n",
       " 'neiglll': 'neiglll',\n",
       " 'ollrselves': 'ollrselves',\n",
       " 'rellderi': 'rellderi',\n",
       " 'eolllpetition': 'eolllpetition',\n",
       " 'sllell': 'sllell',\n",
       " 'eolltl': 'eolltl',\n",
       " 'aclietory': 'aclietory',\n",
       " 'eeolleiliatioll': 'eeolleiliatioll',\n",
       " 'ulldoubted': 'ulldoubted',\n",
       " 'utlqtlestiolled': 'utlqtlestiolled',\n",
       " 'unallitr': 'unallitr',\n",
       " 'cllal': 'cllal',\n",
       " 'milllleapolis': 'milllleapolis',\n",
       " 'stolle': 'stolle',\n",
       " 'cliainet': 'cliainet',\n",
       " 'rlcally': 'rlcally',\n",
       " 'wrllat': 'wrllat',\n",
       " 'corclially': 'corclially',\n",
       " 'arclently': 'arclently',\n",
       " 'sollrce': 'sollrce',\n",
       " 'altinclanee': 'altinclanee',\n",
       " 'cleserwrilig': 'cleserwrilig',\n",
       " 'cilildrell': 'cilildrell',\n",
       " 'lloic': 'lloic',\n",
       " 'lillgs': 'lillgs',\n",
       " 'allcl': 'allcl',\n",
       " 'cecled': 'cecled',\n",
       " 'desllitioll': 'desllitioll',\n",
       " 'rlleol': 'rlleol',\n",
       " 'clls': 'clls',\n",
       " 'cl': 'cl',\n",
       " 'cotllpetitioll': 'cotllpetitioll',\n",
       " 'strlltrt': 'strlltrt',\n",
       " 'cotlisietilla': 'cotlisietilla',\n",
       " 'clictiolzaries': 'clictiolzaries',\n",
       " 'solzllelllliilc': 'solzllelllliilc',\n",
       " 'lell': 'lell',\n",
       " 'tllezn': 'tllezn',\n",
       " 'elldeavorint': 'elldeavorint',\n",
       " 'encleavoritlo': 'encleavoritlo',\n",
       " 'colll': 'colll',\n",
       " 'villd': 'villd',\n",
       " 'cellttlry': 'cellttlry',\n",
       " 'dictiollarr': 'dictiollarr',\n",
       " 'cle': 'cle',\n",
       " 'llsts': 'llsts',\n",
       " 'llstvvllat': 'llstvvllat',\n",
       " 'ullderstallcls': 'ullderstallcls',\n",
       " 'lclrce': 'lclrce',\n",
       " 'sellsse': 'sellsse',\n",
       " 'llell': 'llell',\n",
       " 'consiclers': 'consiclers',\n",
       " 'eolls': 'eolls',\n",
       " 'elllploylnellt': 'elllploylnellt',\n",
       " 'utlcler': 'utlcler',\n",
       " 'etlougll': 'etlougll',\n",
       " 'cjefilli': 'cjefilli',\n",
       " 'tiolls': 'tiolls',\n",
       " 'salld': 'salld',\n",
       " 'arllled': 'arllled',\n",
       " 'llarles': 'llarles',\n",
       " 'trallsl': 'trallsl',\n",
       " 'jacobsell': 'jacobsell',\n",
       " 'talkillg': 'talkillg',\n",
       " 'crilllillal': 'crilllillal',\n",
       " 'strllt': 'strllt',\n",
       " 'conflictillg': 'conflictillg',\n",
       " 'dolaolllillated': 'dolaolllillated',\n",
       " 'llpelitioll': 'llpelitioll',\n",
       " 'trll': 'trll',\n",
       " 'oollllcls': 'oollllcls',\n",
       " 'llk': 'llk',\n",
       " 'collstittiollal': 'collstittiollal',\n",
       " 'statllte': 'statllte',\n",
       " 'rllggle': 'rllggle',\n",
       " 'lzollaclaries': 'lzollaclaries',\n",
       " 'factlltie': 'factlltie',\n",
       " 'pllrstlit': 'pllrstlit',\n",
       " 'elillood': 'elillood',\n",
       " 'alllell': 'alllell',\n",
       " 'qllalificatioll': 'qllalificatioll',\n",
       " 'zzlillc': 'zzlillc',\n",
       " 'silllple': 'silllple',\n",
       " 'obviralls': 'obviralls',\n",
       " 'difficlllties': 'difficlllties',\n",
       " 'valli': 'valli',\n",
       " 'aziallr': 'aziallr',\n",
       " 'svllell': 'svllell',\n",
       " 'lnelltioned': 'lnelltioned',\n",
       " 'tearillg': 'tearillg',\n",
       " 'lclil': 'lclil',\n",
       " 'illsufficiellt': 'illsufficiellt',\n",
       " 'xllpply': 'xllpply',\n",
       " 'stlcll': 'stlcll',\n",
       " 'illcolplete': 'illcolplete',\n",
       " 'pictllre': 'pictllre',\n",
       " 'strllgg': 'strllgg',\n",
       " 'clescrilde': 'clescrilde',\n",
       " 'cotoopotofloll': 'cotoopotofloll',\n",
       " 'llollg': 'llollg',\n",
       " 'exrell': 'exrell',\n",
       " 'wloell': 'wloell',\n",
       " 'lli': 'lli',\n",
       " 'llc': 'llc',\n",
       " 'clo': 'clo',\n",
       " 'iclea': 'iclea',\n",
       " 'coillpttitioil': 'coillpttitioil',\n",
       " 'elelnelljc': 'elelnelljc',\n",
       " 'orcler': 'orcler',\n",
       " 'relacler': 'relacler',\n",
       " 'neally': 'neally',\n",
       " 'tllilld': 'tllilld',\n",
       " 'licll': 'licll',\n",
       " 'wllerevel': 'wllerevel',\n",
       " 'lfotllil': 'lfotllil',\n",
       " 'cotllci': 'cotllci',\n",
       " 'ollt': 'ollt',\n",
       " 'fllndal': 'fllndal',\n",
       " 'lnutalilfll': 'lnutalilfll',\n",
       " 'colrlletitiolz': 'colrlletitiolz',\n",
       " 'alllat': 'alllat',\n",
       " 'tllexl': 'tllexl',\n",
       " 'eqllally': 'eqllally',\n",
       " 'natlll': 'natlll',\n",
       " 'reslllti': 'reslllti',\n",
       " 'ellvirollinellt': 'ellvirollinellt',\n",
       " 'partictllar': 'partictllar',\n",
       " 'fclllziliar': 'fclllziliar',\n",
       " 'olletllocls': 'olletllocls',\n",
       " 'pearallce': 'pearallce',\n",
       " 'epocll': 'epocll',\n",
       " 'makillg': 'makillg',\n",
       " 'origill': 'origill',\n",
       " 'brollgllt': 'brollgllt',\n",
       " 'llard': 'llard',\n",
       " 'crllel': 'crllel',\n",
       " 'rollsseall': 'rollsseall',\n",
       " 'clescriptiosls': 'clescriptiosls',\n",
       " 'collcepticall': 'collcepticall',\n",
       " 'tootll': 'tootll',\n",
       " 'ritll': 'ritll',\n",
       " 'ravill': 'ravill',\n",
       " 'allill': 'allill',\n",
       " 'glacliatol': 'glacliatol',\n",
       " 'sllonv': 'sllonv',\n",
       " 'wllerebr': 'wllerebr',\n",
       " 'clltzllinbest': 'clltzllinbest',\n",
       " 'lleed': 'lleed',\n",
       " 'turll': 'turll',\n",
       " 'tllllillld': 'tllllillld',\n",
       " 'qllal': 'qllal',\n",
       " 'mwallace': 'mwallace',\n",
       " 'lollg': 'lollg',\n",
       " 'attelltiool': 'attelltiool',\n",
       " 'paillless': 'paillless',\n",
       " 'allloilg': 'allloilg',\n",
       " 'allilncals': 'allilncals',\n",
       " 'atllotoilt': 'atllotoilt',\n",
       " 'llgble': 'llgble',\n",
       " 'cls': 'cls',\n",
       " 'elljoylnent': 'elljoylnent',\n",
       " 'luillillltlln': 'luillillltlln',\n",
       " 'stlhetfillg': 'stlhetfillg',\n",
       " 'xvatcll': 'xvatcll',\n",
       " 'exceptiollal': 'exceptiollal',\n",
       " 'cclll': 'cclll',\n",
       " 'concltlcle': 'concltlcle',\n",
       " 'otllerwise': 'otllerwise',\n",
       " 'sllbsequent': 'sllbsequent',\n",
       " 'fllrtller': 'fllrtller',\n",
       " 'lllerelr': 'lllerelr',\n",
       " 'tllc': 'tllc',\n",
       " 'artlollg': 'artlollg',\n",
       " 'bxistellce': 'bxistellce',\n",
       " 'xvinislll': 'xvinislll',\n",
       " 'weapolls': 'weapolls',\n",
       " 'llulnan': 'llulnan',\n",
       " 'llasten': 'llasten',\n",
       " 'orgallie': 'orgallie',\n",
       " 'emergellce': 'emergellce',\n",
       " 'prilllitize': 'prilllitize',\n",
       " 'apparelltly': 'apparelltly',\n",
       " 'eolle': 'eolle',\n",
       " 'ullceasillt': 'ullceasillt',\n",
       " 'evollltioll': 'evollltioll',\n",
       " 'acllievement': 'acllievement',\n",
       " 'ellds': 'ellds',\n",
       " 'grall': 'grall',\n",
       " 'lelllx': 'lelllx',\n",
       " 'apprellelld': 'apprellelld',\n",
       " 'lllall': 'lllall',\n",
       " 'ftltlclalnelltal': 'ftltlclalnelltal',\n",
       " 'alliluate': 'alliluate',\n",
       " 'lligller': 'lligller',\n",
       " 'illd': 'illd',\n",
       " 'lldes': 'lldes',\n",
       " 'slaugllter': 'slaugllter',\n",
       " 'bradllally': 'bradllally',\n",
       " 'clisllonorable': 'clisllonorable',\n",
       " 'colllel': 'colllel',\n",
       " 'woll': 'woll',\n",
       " 'belollt': 'belollt',\n",
       " 'ecollolllic': 'ecollolllic',\n",
       " 'illdllstry': 'illdllstry',\n",
       " 'foulld': 'foulld',\n",
       " 'colltinlled': 'colltinlled',\n",
       " 'plalle': 'plalle',\n",
       " 'recellt': 'recellt',\n",
       " 'llollorable': 'llollorable',\n",
       " 'wllereby': 'wllereby',\n",
       " 'secllred': 'secllred',\n",
       " 'tllajc': 'tllajc',\n",
       " 'lla': 'lla',\n",
       " 'falltll': 'falltll',\n",
       " 'outsicle': 'outsicle',\n",
       " 'sillce': 'sillce',\n",
       " 'begillnillg': 'begillnillg',\n",
       " 'iolcreasillb': 'iolcreasillb',\n",
       " 'illtellsity': 'illtellsity',\n",
       " 'cllik': 'cllik',\n",
       " 'lllally': 'lllally',\n",
       " 'ullwllolesollle': 'ullwllolesollle',\n",
       " 'conclitio': 'conclitio',\n",
       " 'llllllllderless': 'llllllllderless',\n",
       " 'installces': 'installces',\n",
       " 'tll': 'tll',\n",
       " 'plll': 'plll',\n",
       " 'leclared': 'leclared',\n",
       " 'goverlllnellt': 'goverlllnellt',\n",
       " 'cohlpetitioll': 'cohlpetitioll',\n",
       " 'lliaolself': 'lliaolself',\n",
       " 'sllrprised': 'sllrprised',\n",
       " 'profolll': 'profolll',\n",
       " 'illapressioll': 'illapressioll',\n",
       " 'pregllant': 'pregllant',\n",
       " 'llleaning': 'llleaning',\n",
       " 'lllysteries': 'lllysteries',\n",
       " 'allel': 'allel',\n",
       " 'revealillg': 'revealillg',\n",
       " 'llulnallity': 'llulnallity',\n",
       " 'eacly': 'eacly',\n",
       " 'alnollg': 'alnollg',\n",
       " 'atlilllals': 'atlilllals',\n",
       " 'elllargelnellt': 'elllargelnellt',\n",
       " 'pursllilag': 'pursllilag',\n",
       " 'colulllon': 'colulllon',\n",
       " 'grollps': 'grollps',\n",
       " 'gollen': 'gollen',\n",
       " 'comltloll': 'comltloll',\n",
       " 'llotice': 'llotice',\n",
       " 'pernlallent': 'pernlallent',\n",
       " 'tllell': 'tllell',\n",
       " 'cliscover': 'cliscover',\n",
       " 'embracillg': 'embracillg',\n",
       " 'zalitlli': 'zalitlli',\n",
       " 'illsllite': 'illsllite',\n",
       " 'rollps': 'rollps',\n",
       " 'llaving': 'llaving',\n",
       " 'szlall': 'szlall',\n",
       " 'illiolaty': 'illiolaty',\n",
       " 'lzatioll': 'lzatioll',\n",
       " 'etitioll': 'etitioll',\n",
       " 'cloes': 'cloes',\n",
       " 'alolle': 'alolle',\n",
       " 'walitll': 'walitll',\n",
       " 'sympatlly': 'sympatlly',\n",
       " 'pllldllc': 'pllldllc',\n",
       " 'clirected': 'clirected',\n",
       " 'llulllallitariaoli': 'llulllallitariaoli',\n",
       " 'gtllells': 'gtllells',\n",
       " 'lless': 'lless',\n",
       " 'uleolll': 'uleolll',\n",
       " 'becollles': 'becollles',\n",
       " 'splle': 'splle',\n",
       " 'illay': 'illay',\n",
       " 'llloclern': 'llloclern',\n",
       " 'pllilantllropy': 'pllilantllropy',\n",
       " 'attellcls': 'attellcls',\n",
       " 'potellt': 'potellt',\n",
       " 'igllest': 'igllest',\n",
       " 'inclisticltlal': 'inclisticltlal',\n",
       " 'altruistll': 'altruistll',\n",
       " 'eratioll': 'eratioll',\n",
       " 'llealing': 'llealing',\n",
       " 'beilevolellce': 'beilevolellce',\n",
       " 'sometillles': 'sometillles',\n",
       " 'llurllanitarian': 'llurllanitarian',\n",
       " 'sllould': 'sllould',\n",
       " 'weaklless': 'weaklless',\n",
       " 'cleo': 'cleo',\n",
       " 'goetlle': 'goetlle',\n",
       " 'llospital': 'llospital',\n",
       " 'sllcll': 'sllcll',\n",
       " 'apprellelesioll': 'apprellelesioll',\n",
       " 'tllrotlgll': 'tllrotlgll',\n",
       " 'sollae': 'sollae',\n",
       " 'illclividuals': 'illclividuals',\n",
       " 'individllals': 'individllals',\n",
       " 'behilld': 'behilld',\n",
       " 'milcllless': 'milcllless',\n",
       " 'lessells': 'lessells',\n",
       " 'reprodllction': 'reprodllction',\n",
       " 'cloe': 'cloe',\n",
       " 'extellt': 'extellt',\n",
       " 'pllts': 'pllts',\n",
       " 'cliscourages': 'cliscourages',\n",
       " 'vllile': 'vllile',\n",
       " 'attitucle': 'attitucle',\n",
       " 'towarcls': 'towarcls',\n",
       " 'crimillal': 'crimillal',\n",
       " 'inclillation': 'inclillation',\n",
       " 'cletain': 'cletain',\n",
       " 'idellce': 'idellce',\n",
       " 'malacly': 'malacly',\n",
       " 'sanitatioll': 'sanitatioll',\n",
       " 'lneasllres': 'lneasllres',\n",
       " 'luoderll': 'luoderll',\n",
       " 'nllo': 'nllo',\n",
       " 'xtvritll': 'xtvritll',\n",
       " 'sllperiority': 'sllperiority',\n",
       " 'strellgth': 'strellgth',\n",
       " 'srolnell': 'srolnell',\n",
       " 'toclay': 'toclay',\n",
       " 'inllabit': 'inllabit',\n",
       " 'blltland': 'blltland',\n",
       " 'ullited': 'ullited',\n",
       " 'uloclern': 'uloclern',\n",
       " 'tllrollt': 'tllrollt',\n",
       " 'llleall': 'llleall',\n",
       " 'particlllar': 'particlllar',\n",
       " 'llomilliolls': 'llomilliolls',\n",
       " 'aioderll': 'aioderll',\n",
       " 'establislles': 'establislles',\n",
       " 'consciollsly': 'consciollsly',\n",
       " 'uncollsciollsly': 'uncollsciollsly',\n",
       " 'collstitllte': 'collstitllte',\n",
       " 'elllillent': 'elllillent',\n",
       " 'fitlless': 'fitlless',\n",
       " 'ullfavorable': 'ullfavorable',\n",
       " 'metllods': 'metllods',\n",
       " 'establislled': 'establislled',\n",
       " 'attailled': 'attailled',\n",
       " 'deterluille': 'deterluille',\n",
       " 'sllrvive': 'sllrvive',\n",
       " 'illustratioll': 'illustratioll',\n",
       " 'fllrllislles': 'fllrllislles',\n",
       " 'livelillood': 'livelillood',\n",
       " 'coilsiclerable': 'coilsiclerable',\n",
       " 'percelltat': 'percelltat',\n",
       " 'adlnissioll': 'adlnissioll',\n",
       " 'tllerebv': 'tllerebv',\n",
       " 'fsdllud': 'fsdllud',\n",
       " 'illtense': 'illtense',\n",
       " 'colltest': 'colltest',\n",
       " 'isslles': 'isslles',\n",
       " 'lcnowll': 'lcnowll',\n",
       " 'extellels': 'extellels',\n",
       " 'ioll': 'ioll',\n",
       " 'hll': 'hll',\n",
       " 'metllocls': 'metllocls',\n",
       " 'proclllces': 'proclllces',\n",
       " 'corresponclilzg': 'corresponclilzg',\n",
       " 'reslllts': 'reslllts',\n",
       " 'llallel': 'llallel',\n",
       " 'bitterlless': 'bitterlless',\n",
       " 'collsonallce': 'collsonallce',\n",
       " 'dellland': 'dellland',\n",
       " 'portllllity': 'portllllity',\n",
       " 'clifference': 'clifference',\n",
       " 'collle': 'collle',\n",
       " 'utacler': 'utacler',\n",
       " 'sstelll': 'sstelll',\n",
       " 'killel': 'killel',\n",
       " 'trlle': 'trlle',\n",
       " 'sllccess': 'sllccess',\n",
       " 'llel': 'llel',\n",
       " 'collfornlity': 'collfornlity',\n",
       " 'ller': 'ller',\n",
       " 'icleas': 'icleas',\n",
       " 'rlls': 'rlls',\n",
       " 'alullace': 'alullace',\n",
       " 'selectioll': 'selectioll',\n",
       " 'llatt': 'llatt',\n",
       " 'ecollolllics': 'ecollolllics',\n",
       " 'natllre': 'natllre',\n",
       " 'collsists': 'collsists',\n",
       " 'tllel': 'tllel',\n",
       " 'esselltially': 'esselltially',\n",
       " 'operatioll': 'operatioll',\n",
       " 'pllrest': 'pllrest',\n",
       " 'llosrever': 'llosrever',\n",
       " 'prevellt': 'prevellt',\n",
       " 'attaillillg': 'attaillillg',\n",
       " 'developlllellt': 'developlllellt',\n",
       " 'mailltain': 'mailltain',\n",
       " 'depelld': 'depelld',\n",
       " 'lllind': 'lllind',\n",
       " 'milld': 'milld',\n",
       " 'collsiderations': 'collsiderations',\n",
       " 'gallizatioll': 'gallizatioll',\n",
       " 'tnucll': 'tnucll',\n",
       " 'stitiltioll': 'stitiltioll',\n",
       " 'ligllt': 'ligllt',\n",
       " 'illfected': 'illfected',\n",
       " 'valls': 'valls',\n",
       " 'oranizatioll': 'oranizatioll',\n",
       " 'ldllysicialls': 'ldllysicialls',\n",
       " 'clanger': 'clanger',\n",
       " 'cllaslces': 'cllaslces',\n",
       " 'dlle': 'dlle',\n",
       " 'coticlitions': 'coticlitions',\n",
       " 'llnder': 'llnder',\n",
       " 'tllorollghly': 'tllorollghly',\n",
       " 'conclition': 'conclition',\n",
       " 'deville': 'deville',\n",
       " 'walllile': 'walllile',\n",
       " 'colilnlissioll': 'colilnlissioll',\n",
       " 'znibllt': 'znibllt',\n",
       " 'clevise': 'clevise',\n",
       " 'wotlld': 'wotlld',\n",
       " 'rollts': 'rollts',\n",
       " 'xarotlld': 'xarotlld',\n",
       " 'provicle': 'provicle',\n",
       " 'conclitiolas': 'conclitiolas',\n",
       " 'ellts': 'ellts',\n",
       " 'estioll': 'estioll',\n",
       " 'lllity': 'lllity',\n",
       " 'featllre': 'featllre',\n",
       " 'alliluals': 'alliluals',\n",
       " 'colltinually': 'colltinually',\n",
       " 'elevatiolls': 'elevatiolls',\n",
       " 'lnealls': 'lnealls',\n",
       " 'bellind': 'bellind',\n",
       " 'subsistellce': 'subsistellce',\n",
       " 'lloble': 'lloble',\n",
       " 'combillations': 'combillations',\n",
       " 'colubillations': 'colubillations',\n",
       " 'combinatiolls': 'combinatiolls',\n",
       " 'neall': 'neall',\n",
       " 'wllete': 'wllete',\n",
       " 'lllllst': 'lllllst',\n",
       " 'lletllod': 'lletllod',\n",
       " 'owllel': 'owllel',\n",
       " 'sllip': 'sllip',\n",
       " 'nallagetllel': 'nallagetllel',\n",
       " 'illclustl': 'illclustl',\n",
       " 'clisti': 'clisti',\n",
       " 'cli': 'cli',\n",
       " 'wllid': 'wllid',\n",
       " 'llppl': 'llppl',\n",
       " 'tssioll': 'tssioll',\n",
       " 'dellla': 'dellla',\n",
       " 'lllaental': 'lllaental',\n",
       " 'nailltellallce': 'nailltellallce',\n",
       " 'conclitiolls': 'conclitiolls',\n",
       " 'zlally': 'zlally',\n",
       " 'illdividllallv': 'illdividllallv',\n",
       " 'lllelst': 'lllelst',\n",
       " 'fllrllislled': 'fllrllislled',\n",
       " 'irrialtioll': 'irrialtioll',\n",
       " 'illllstratioll': 'illllstratioll',\n",
       " 'careflll': 'careflll',\n",
       " 'clellts': 'clellts',\n",
       " 'irritatioll': 'irritatioll',\n",
       " 'illtinlately': 'illtinlately',\n",
       " 'prodllce': 'prodllce',\n",
       " 'colllpetitio': 'colllpetitio',\n",
       " 'llollopols': 'llollopols',\n",
       " 'wllolesolne': 'wllolesolne',\n",
       " 'alollg': 'alollg',\n",
       " 'llclerstalld': 'llclerstalld',\n",
       " 'silllply': 'silllply',\n",
       " 'rebioll': 'rebioll',\n",
       " 'sllpplieel': 'sllpplieel',\n",
       " 'divideolcls': 'divideolcls',\n",
       " 'lnllst': 'lnllst',\n",
       " 'llolclers': 'llolclers',\n",
       " 'latiollal': 'latiollal',\n",
       " 'ecollotllic': 'ecollotllic',\n",
       " 'lililliam': 'lililliam',\n",
       " 'clitiolls': 'clitiolls',\n",
       " 'lllailltellance': 'lllailltellance',\n",
       " 'govelnillelltal': 'govelnillelltal',\n",
       " 'llolv': 'llolv',\n",
       " 'ilaovelnellt': 'ilaovelnellt',\n",
       " 'approaclleswi': 'approaclleswi',\n",
       " 'tllotlt': 'tllotlt',\n",
       " 'llope': 'llope',\n",
       " 'reaclli': 'reaclli',\n",
       " 'colilpetitioll': 'colilpetitioll',\n",
       " 'lllovelnelltvs': 'lllovelnelltvs',\n",
       " 'clrawillg': 'clrawillg',\n",
       " 'borlle': 'borlle',\n",
       " 'lllilld': 'lllilld',\n",
       " 'ullderstalld': 'ullderstalld',\n",
       " 'llistol': 'llistol',\n",
       " 'clereloldnlent': 'clereloldnlent',\n",
       " 'follnd': 'follnd',\n",
       " 'institlltiolas': 'institlltiolas',\n",
       " 'sllllt': 'sllllt',\n",
       " 'lilllit': 'lilllit',\n",
       " 'otllicll': 'otllicll',\n",
       " 'nevertlleless': 'nevertlleless',\n",
       " 'follllclations': 'follllclations',\n",
       " 'nallicll': 'nallicll',\n",
       " 'jllicll': 'jllicll',\n",
       " 'savillgs': 'savillgs',\n",
       " 'balllss': 'balllss',\n",
       " 'acllievelllellts': 'acllievelllellts',\n",
       " 'ecollollaic': 'ecollollaic',\n",
       " 'jtlriclical': 'jtlriclical',\n",
       " 'oxilllation': 'oxilllation',\n",
       " 'illstitutioi': 'illstitutioi',\n",
       " 'acljustlllellts': 'acljustlllellts',\n",
       " 'movemellt': 'movemellt',\n",
       " 'illstitutional': 'illstitutional',\n",
       " 'lllovemellts': 'lllovemellts',\n",
       " 'lltiest': 'lltiest',\n",
       " 'clelicate': 'clelicate',\n",
       " 'riglltly': 'riglltly',\n",
       " 'colltrolled': 'colltrolled',\n",
       " 'furllishes': 'furllishes',\n",
       " 'maxillluln': 'maxillluln',\n",
       " 'millimtltll': 'millimtltll',\n",
       " 'eviclence': 'eviclence',\n",
       " 'llltra': 'llltra',\n",
       " 'illasmllcll': 'illasmllcll',\n",
       " 'lllass': 'lllass',\n",
       " 'vllinks': 'vllinks',\n",
       " 'qllietly': 'qllietly',\n",
       " 'sllblllit': 'sllblllit',\n",
       " 'accotlllt': 'accotlllt',\n",
       " 'vilicll': 'vilicll',\n",
       " 'bicls': 'bicls',\n",
       " 'religioll': 'religioll',\n",
       " 'ellt': 'ellt',\n",
       " 'erforlll': 'erforlll',\n",
       " 'plalles': 'plalles',\n",
       " 'llilagle': 'llilagle',\n",
       " 'clisplacine': 'clisplacine',\n",
       " 'colllldetitioll': 'colllldetitioll',\n",
       " 'llss': 'llss',\n",
       " 'lnerciflll': 'lnerciflll',\n",
       " 'rell': 'rell',\n",
       " 'orgallic': 'orgallic',\n",
       " 'tuall': 'tuall',\n",
       " 'icleal': 'icleal',\n",
       " 'luall': 'luall',\n",
       " 'ecoslolllic': 'ecoslolllic',\n",
       " 'proclacillt': 'proclacillt',\n",
       " 'comptitioll': 'comptitioll',\n",
       " 'lllative': 'lllative',\n",
       " 'prillciles': 'prillciles',\n",
       " 'psycholocically': 'psycholocically',\n",
       " 'etller': 'etller',\n",
       " 'ecoololllically': 'ecoololllically',\n",
       " 'ellgage': 'ellgage',\n",
       " 'nlally': 'nlally',\n",
       " 'splleres': 'splleres',\n",
       " 'tlleself': 'tlleself',\n",
       " 'ridellillb': 'ridellillb',\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_counts = sc[sc['og_word'].isin(not_found)].sort_values('old_count',ascending=False)\n",
    "not_found_counts.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class FinalStrNode(StrNode):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  og_str,\n",
    "#                  current_str,\n",
    "#                  parent_node:FinalStrNode,\n",
    "#                  child_node:FinalStrNode,\n",
    "#                  path_to_end:Optional[TransList] = None,\n",
    "#                  end_str:str):\n",
    "#         self.children = [child_node] if child_node is not None else []\n",
    "#         self.parent:Optional[StrNode] = parent_node\n",
    "#         self.parent_trans:Transformation|None =parent_t\n",
    "#         self.current:str = current\n",
    "#         self.end_str = end_str\n",
    "#         self.leaf = self.children==[]\n",
    "#         self.path_to_end = path_to_end\n",
    "#         self.next = child_node\n",
    "\n",
    "#     def get_path_to_end(self)->TransList:\n",
    "#         if self.path_to_end is not None:\n",
    "#             return self.path_to_end\n",
    "#         node = self\n",
    "#         ts = TransList()\n",
    "#         while node.current!=self.end_str:\n",
    "#             child = node.next\n",
    "#             ts.append(child.parent_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: prev_steps, dtype: object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_melt['prev_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>old_count</th>\n",
       "      <th>prev_steps</th>\n",
       "      <th>current_word</th>\n",
       "      <th>transformation</th>\n",
       "      <th>new_word</th>\n",
       "      <th>in_other</th>\n",
       "      <th>any_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llletllod</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>nletnod</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>nletnod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>illaterial</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>inaterial</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>inaterial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollore</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>onore</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>onore</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dissellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>collsistently</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "      <td>ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507145</th>\n",
       "      <td>hotlle</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>honle</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>honle</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507146</th>\n",
       "      <td>predominantly</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>predominanny</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>predominanny</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507147</th>\n",
       "      <td>cotllplacency</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>conlplacency</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>conlplacency</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507148</th>\n",
       "      <td>rtller</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>rnler</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>rnler</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507149</th>\n",
       "      <td>dotllinatioll</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;n_tl-&gt;n_tl-&gt;n</td>\n",
       "      <td>donlinatioll</td>\n",
       "      <td>tl-&gt;n</td>\n",
       "      <td>donlinatioll</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189037 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              og_word  old_count          prev_steps  current_word  \\\n",
       "0           llletllod          1  _ll->n_ll->n_ll->n       nletnod   \n",
       "1          illaterial          1  _ll->n_ll->n_ll->n     inaterial   \n",
       "2              ollore          1  _ll->n_ll->n_ll->n         onore   \n",
       "3            dissellt          1  _ll->n_ll->n_ll->n       dissent   \n",
       "4       collsistently          1  _ll->n_ll->n_ll->n  consistently   \n",
       "...               ...        ...                 ...           ...   \n",
       "507145         hotlle          1  _tl->n_tl->n_tl->n         honle   \n",
       "507146  predominantly          1  _tl->n_tl->n_tl->n  predominanny   \n",
       "507147  cotllplacency          1  _tl->n_tl->n_tl->n  conlplacency   \n",
       "507148         rtller          1  _tl->n_tl->n_tl->n         rnler   \n",
       "507149  dotllinatioll          1  _tl->n_tl->n_tl->n  donlinatioll   \n",
       "\n",
       "       transformation      new_word  in_other  any_found  \n",
       "0               ll->n       nletnod     False      False  \n",
       "1               ll->n     inaterial     False      False  \n",
       "2               ll->n         onore     False      False  \n",
       "3               ll->n       dissent     False      False  \n",
       "4               ll->n  consistently     False      False  \n",
       "...               ...           ...       ...        ...  \n",
       "507145          tl->n         honle     False      False  \n",
       "507146          tl->n  predominanny     False      False  \n",
       "507147          tl->n  conlplacency     False      False  \n",
       "507148          tl->n         rnler     False      False  \n",
       "507149          tl->n  donlinatioll     False      False  \n",
       "\n",
       "[189037 rows x 8 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_melt\n",
    "'material_dissent_consistently_domination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cum_ct'] = df.groupby('corpus_word')['corp_count'].transform('sum')\n",
    "new = new_melt[new_melt['in_other']==False]\n",
    "for i,(b,a) in enumerate(chars):\n",
    "    col = f\"{a}->{b}\"\n",
    "    new[col] = new['new_word'].apply(lambda x: x.replace(a,b) if a in x else None)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ll-&gt;n</th>\n",
       "      <th>ll-&gt;u</th>\n",
       "      <th>ll-&gt;h</th>\n",
       "      <th>il-&gt;n</th>\n",
       "      <th>il-&gt;u</th>\n",
       "      <th>il-&gt;h</th>\n",
       "      <th>nl-&gt;m</th>\n",
       "      <th>ln-&gt;m</th>\n",
       "      <th>cl-&gt;d</th>\n",
       "      <th>vv-&gt;w</th>\n",
       "      <th>lll-&gt;m</th>\n",
       "      <th>rl-&gt;n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nletnod</td>\n",
       "      <td>uletuod</td>\n",
       "      <td>hlethod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>llletllod</td>\n",
       "      <td>metllod</td>\n",
       "      <td>llletllod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttmity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "      <td>opporttlnity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>different</td>\n",
       "      <td>differeut</td>\n",
       "      <td>differeht</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "      <td>differellt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sense</td>\n",
       "      <td>seuse</td>\n",
       "      <td>sehse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "      <td>sellse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>funest</td>\n",
       "      <td>fuuest</td>\n",
       "      <td>fuhest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "      <td>fullest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>wan</td>\n",
       "      <td>wau</td>\n",
       "      <td>wah</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>dearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "      <td>clearness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>interlaced</td>\n",
       "      <td>intenaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>fearlessly</td>\n",
       "      <td>feanessly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbunding</td>\n",
       "      <td>upbuuding</td>\n",
       "      <td>upbuhding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "      <td>upbuilding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2780 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ll->n         ll->u         ll->h         il->n         il->u  \\\n",
       "2          nletnod       uletuod       hlethod     llletllod     llletllod   \n",
       "3     opporttlnity  opporttlnity  opporttlnity  opporttlnity  opporttlnity   \n",
       "4        different     differeut     differeht    differellt    differellt   \n",
       "5            sense         seuse         sehse        sellse        sellse   \n",
       "7           funest        fuuest        fuhest       fullest       fullest   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2918           wan           wau           wah          wall          wall   \n",
       "2919     clearness     clearness     clearness     clearness     clearness   \n",
       "2920    interlaced    interlaced    interlaced    interlaced    interlaced   \n",
       "2921    fearlessly    fearlessly    fearlessly    fearlessly    fearlessly   \n",
       "2922    upbuilding    upbuilding    upbuilding     upbunding     upbuuding   \n",
       "\n",
       "             il->h         nl->m        ln->m         cl->d         vv->w  \\\n",
       "2        llletllod     llletllod    llletllod     llletllod     llletllod   \n",
       "3     opporttlnity  opporttlnity  opporttmity  opporttlnity  opporttlnity   \n",
       "4       differellt    differellt   differellt    differellt    differellt   \n",
       "5           sellse        sellse       sellse        sellse        sellse   \n",
       "7          fullest       fullest      fullest       fullest       fullest   \n",
       "...            ...           ...          ...           ...           ...   \n",
       "2918          wall          wall         wall          wall          wall   \n",
       "2919     clearness     clearness    clearness      dearness     clearness   \n",
       "2920    interlaced    interlaced   interlaced    interlaced    interlaced   \n",
       "2921    fearlessly    fearlessly   fearlessly    fearlessly    fearlessly   \n",
       "2922     upbuhding    upbuilding   upbuilding    upbuilding    upbuilding   \n",
       "\n",
       "            lll->m         rl->n  \n",
       "2          metllod     llletllod  \n",
       "3     opporttlnity  opporttlnity  \n",
       "4       differellt    differellt  \n",
       "5           sellse        sellse  \n",
       "7          fullest       fullest  \n",
       "...            ...           ...  \n",
       "2918          wall          wall  \n",
       "2919     clearness     clearness  \n",
       "2920    interlaced     intenaced  \n",
       "2921    fearlessly     feanessly  \n",
       "2922    upbuilding    upbuilding  \n",
       "\n",
       "[2780 rows x 12 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 'll', 'u': 'll', 'm': 'nl', 'h': 'll', 'd': 'cl', 'l': 'i', 'w': 'vv'}\n"
     ]
    }
   ],
   "source": [
    "chars = [\"nll\",'ull','mlll','hll',\"dcl\",\"mrn\",'li','mln','mnl',\"wvv\"]\n",
    "cd = {}\n",
    "for c in chars:\n",
    "    cd[c[0]] = c[1:]\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = d\n",
    "def correct_word(word):\n",
    "    lower_word = word.lower()\n",
    "    if lower_word in corr:\n",
    "        corrected = corr[lower_word]\n",
    "        # Preserve capitalization\n",
    "        if word.istitle():\n",
    "            return corrected.capitalize()\n",
    "        elif word.isupper():\n",
    "            return corrected.upper()\n",
    "        else:\n",
    "            return corrected\n",
    "    return word\n",
    "\n",
    "# Correct text function\n",
    "def correct_text(text):\n",
    "    # Use regex to handle punctuation and retain word boundaries\n",
    "    return  re.sub(r'\\b\\w+\\b', lambda match: correct_word(match.group()), text)\n",
    "    \n",
    "\n",
    "\n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "new_folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/changed'\n",
    "os.makedirs(new_folder,exist_ok=True)\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        new = re.sub(r\"\\b(\\w+)(cl)\\b\",lambda match:match.group(1)+\"d\",text)\n",
    "        with open(path,'w') as f:\n",
    "            f.write(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellod ancly meowd'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"hellocl ancly meowcl\"\n",
    "re.sub(r\"\\b(\\w+)(cl)\\b\",lambda match:match.group(1)+\"d\",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betweell': 'between',\n",
       " 'ecollomics': 'economics',\n",
       " 'influellce': 'influence',\n",
       " 'opillion': 'opinion',\n",
       " 'mealls': 'means',\n",
       " 'presellt': 'present',\n",
       " 'ill': 'in',\n",
       " 'amollg': 'among',\n",
       " 'tlle': 'the',\n",
       " 'comlllercial': 'commercial',\n",
       " 'conditiolls': 'conditions',\n",
       " 'oll': 'on',\n",
       " 'witll': 'with',\n",
       " 'olles': 'ones',\n",
       " 'econolllics': 'economics',\n",
       " 'wllich': 'which',\n",
       " 'lle': 'he',\n",
       " 'olle': 'one',\n",
       " 'llis': 'his',\n",
       " 'standpoillt': 'standpoint',\n",
       " 'lleither': 'neither',\n",
       " 'llor': 'nor',\n",
       " 'halld': 'hand',\n",
       " 'alld': 'and',\n",
       " 'stalldards': 'standards',\n",
       " 'tllat': 'that',\n",
       " 'interactioll': 'interaction',\n",
       " 'whicll': 'which',\n",
       " 'whell': 'when',\n",
       " 'natioll': 'nation',\n",
       " 'illfluence': 'influence',\n",
       " 'sallle': 'same',\n",
       " 'higllest': 'highest',\n",
       " 'scielltific': 'scientific',\n",
       " 'wllo': 'who',\n",
       " 'tllose': 'those',\n",
       " 'llim': 'him',\n",
       " 'higll': 'high',\n",
       " 'tllree': 'three',\n",
       " 'llo': 'no',\n",
       " 'lllake': 'wake',\n",
       " 'beillg': 'being',\n",
       " 'owll': 'own',\n",
       " 'llave': 'have',\n",
       " 'mell': 'men',\n",
       " 'educatioll': 'education',\n",
       " 'llot': 'not',\n",
       " 'ollly': 'only',\n",
       " 'lllatters': 'matters',\n",
       " 'recognizillg': 'recognizing',\n",
       " 'olltside': 'outside',\n",
       " 'oftell': 'often',\n",
       " 'sucll': 'such',\n",
       " 'llloral': 'moral',\n",
       " 'tllelll': 'them',\n",
       " 'lille': 'line',\n",
       " 'ecollomist': 'economist',\n",
       " 'illterest': 'interest',\n",
       " 'colllmunity': 'community',\n",
       " 'eitller': 'either',\n",
       " 'claillls': 'claims',\n",
       " 'gelleral': 'general',\n",
       " 'illterests': 'interests',\n",
       " 'gettillg': 'getting',\n",
       " 'represelltatives': 'representatives',\n",
       " 'eacll': 'each',\n",
       " 'allother': 'another',\n",
       " 'opinioll': 'opinion',\n",
       " 'llecessary': 'necessary',\n",
       " 'thall': 'than',\n",
       " 'tllan': 'than',\n",
       " 'differellces': 'differences',\n",
       " 'ougllt': 'ought',\n",
       " 'allotller': 'another',\n",
       " 'collditions': 'conditions',\n",
       " 'moderll': 'modern',\n",
       " 'sollle': 'some',\n",
       " 'importallt': 'important',\n",
       " 'represelltative': 'representative',\n",
       " 'competitioll': 'competition',\n",
       " 'llow': 'now',\n",
       " 'advallce': 'advance',\n",
       " 'governmellt': 'government',\n",
       " 'llas': 'has',\n",
       " 'expressioll': 'expression',\n",
       " 'commullity': 'community',\n",
       " 'frolll': 'from',\n",
       " 'collflict': 'conflict',\n",
       " 'withill': 'within',\n",
       " 'tllinks': 'thinks',\n",
       " 'lllore': 'more',\n",
       " 'tllis': 'this',\n",
       " 'tllere': 'there',\n",
       " 'wllole': 'whole',\n",
       " 'sllall': 'small',\n",
       " 'tlleir': 'their',\n",
       " 'beell': 'been',\n",
       " 'celltury': 'century',\n",
       " 'togetller': 'together',\n",
       " 'otllers': 'others',\n",
       " 'wallts': 'wants',\n",
       " 'ullited': 'united',\n",
       " 'selltimellt': 'sentiment',\n",
       " 'actioll': 'action',\n",
       " 'tlley': 'they',\n",
       " 'lllust': 'must',\n",
       " 'evell': 'even',\n",
       " 'spllere': 'sphere',\n",
       " 'somethillg': 'something',\n",
       " 'thelll': 'them',\n",
       " 'centllry': 'century',\n",
       " 'pllblic': 'public',\n",
       " 'sllould': 'should',\n",
       " 'prillciple': 'principle',\n",
       " 'molley': 'money',\n",
       " 'witllin': 'within',\n",
       " 'legislatioll': 'legislation',\n",
       " 'cllange': 'change',\n",
       " 'golle': 'gone',\n",
       " 'wllose': 'whose',\n",
       " 'wllell': 'when',\n",
       " 'otller': 'other',\n",
       " 'busilless': 'business',\n",
       " 'witllout': 'without',\n",
       " 'upoll': 'upon',\n",
       " 'tlling': 'thing',\n",
       " 'tllese': 'these',\n",
       " 'autllority': 'authority',\n",
       " 'lllay': 'may',\n",
       " 'illdustrial': 'industrial',\n",
       " 'natiolls': 'nations',\n",
       " 'wllat': 'what',\n",
       " 'anotller': 'another',\n",
       " 'strollg': 'strong',\n",
       " 'conceptioll': 'conception',\n",
       " 'lligher': 'higher',\n",
       " 'killd': 'kind',\n",
       " 'llistory': 'history',\n",
       " 'natiollal': 'national',\n",
       " 'wllere': 'where',\n",
       " 'sciellce': 'science',\n",
       " 'sometlling': 'something',\n",
       " 'econolllic': 'economic',\n",
       " 'tllougllt': 'thought',\n",
       " 'foundatioll': 'foundation',\n",
       " 'colllpetition': 'competition',\n",
       " 'nilleteell': 'nineteen',\n",
       " 'cllristian': 'christian',\n",
       " 'existellce': 'existence',\n",
       " 'agaill': 'again',\n",
       " 'groulld': 'ground',\n",
       " 'wlly': 'why',\n",
       " 'colllpetitioll': 'competition',\n",
       " 'qllestion': 'question',\n",
       " 'disciplille': 'discipline',\n",
       " 'solllewllat': 'somewhat',\n",
       " 'indiviclllal': 'individual',\n",
       " 'coulltry': 'country',\n",
       " 'wlletller': 'whether',\n",
       " 'clloice': 'choice',\n",
       " 'strllggle': 'struggle',\n",
       " 'tllillgs': 'things',\n",
       " 'wealtll': 'wealth',\n",
       " 'lllany': 'many',\n",
       " 'alllong': 'along',\n",
       " 'ecollomic': 'economic',\n",
       " 'llpon': 'upon',\n",
       " 'figllt': 'fight',\n",
       " 'colllparatively': 'comparitively',\n",
       " 'cllaracter': 'character',\n",
       " 'etllical': 'ethical',\n",
       " 'paill': 'pain',\n",
       " 'attelltioll': 'attention',\n",
       " 'reslllt': 'result',\n",
       " 'evollltion': 'evolution',\n",
       " 'colnpetitioll': 'competition',\n",
       " 'evoltltioll': 'evolution',\n",
       " 'lllost': 'most',\n",
       " 'higller': 'higher',\n",
       " 'associatioll': 'association',\n",
       " 'illto': 'into',\n",
       " 'wllen': 'when',\n",
       " 'ulltil': 'until',\n",
       " 'cotllpetition': 'competition',\n",
       " 'evolutioll': 'evolution',\n",
       " 'growillt': 'growth',\n",
       " 'mally': 'many',\n",
       " 'discussioll': 'discussion',\n",
       " 'filld': 'find',\n",
       " 'americall': 'american',\n",
       " 'tllelllselves': 'themselves',\n",
       " 'colllpetitive': 'competitive',\n",
       " 'developlllent': 'development',\n",
       " 'cotnpetitioll': 'competition',\n",
       " 'civilizatioll': 'civilization',\n",
       " 'wolllcl': 'would',\n",
       " 'llew': 'new',\n",
       " 'lllen': 'men',\n",
       " 'efficiellt': 'efficient',\n",
       " 'lllell': 'well',\n",
       " 'cllief': 'chief',\n",
       " 'ecollolnic': 'economic',\n",
       " 'sllch': 'such',\n",
       " 'llloclerll': 'modern',\n",
       " 'petitioll': 'petition',\n",
       " 'frequelltly': 'frequently',\n",
       " 'qllalities': 'qualitites',\n",
       " 'tllus': 'thus',\n",
       " 'tllink': 'think',\n",
       " 'colldition': 'condition',\n",
       " 'cllarity': 'charity',\n",
       " 'becallse': 'because',\n",
       " 'opportllllities': 'opportunities',\n",
       " 'extetlsioll': 'extension',\n",
       " 'certaill': 'certain',\n",
       " 'opillioll': 'opinion',\n",
       " 'secllre': 'secure',\n",
       " 'celltllry': 'century',\n",
       " 'illstitutions': 'institutions',\n",
       " 'illust': 'must',\n",
       " 'eqllality': 'equality',\n",
       " 'twelltietll': 'twentieth',\n",
       " 'alltagollistic': 'antagonistic',\n",
       " 'llniversity': 'university',\n",
       " 'bllsiness': 'business',\n",
       " 'lleed': 'need',\n",
       " 'institutioll': 'institution',\n",
       " 'institutiolls': 'institutions',\n",
       " 'pellnsylvania': 'pennsylvania',\n",
       " 'establishmellt': 'astablishment',\n",
       " 'comlllerce': 'commerce',\n",
       " 'scllool': 'school',\n",
       " 'professiollal': 'professional',\n",
       " 'sllowll': 'shown',\n",
       " 'existellee': 'existence',\n",
       " 'lllovement': 'movement',\n",
       " 'rallk': 'rank',\n",
       " 'ulliversity': 'university',\n",
       " 'appoillted': 'appointed',\n",
       " 'forlll': 'form',\n",
       " 'ullder': 'under',\n",
       " 'eolleges': 'colleges',\n",
       " 'eollege': 'college',\n",
       " 'positioll': 'position',\n",
       " 'llear': 'near',\n",
       " 'llleans': 'means',\n",
       " 'througll': 'through',\n",
       " 'systelll': 'system',\n",
       " 'illstitutiolls': 'institutions',\n",
       " 'scllools': 'schools',\n",
       " 'nulllber': 'number',\n",
       " 'callillgs': 'callings',\n",
       " 'existillg': 'existing',\n",
       " 'takillg': 'taking',\n",
       " 'tllem': 'them',\n",
       " 'yollng': 'young',\n",
       " 'youllg': 'young',\n",
       " 'tllen': 'then',\n",
       " 'collrse': 'course',\n",
       " 'wollld': 'would',\n",
       " 'fashiollecl': 'fashioned',\n",
       " 'yollllg': 'young',\n",
       " 'migllt': 'might',\n",
       " 'trainillg': 'training',\n",
       " 'eallings': 'earnings',\n",
       " 'departlllents': 'departments',\n",
       " 'movelllellt': 'movement',\n",
       " 'variolls': 'various',\n",
       " 'tllrougll': 'through',\n",
       " 'curricululll': 'curriculum',\n",
       " 'collsidered': 'considered',\n",
       " 'elelllent': 'element',\n",
       " 'opportullity': 'opportunity',\n",
       " 'trllth': 'truth',\n",
       " 'takell': 'taken',\n",
       " 'elemellt': 'element',\n",
       " 'tlleoretieally': 'theoretically',\n",
       " 'tillles': 'times',\n",
       " 'cllrricula': 'curricula',\n",
       " 'tlleory': 'theory',\n",
       " 'melltal': 'mental',\n",
       " 'organizatioll': 'organization',\n",
       " 'bankillg': 'banking',\n",
       " 'illdustry': 'industry',\n",
       " 'colltracts': 'contracts',\n",
       " 'corporatioll': 'corporation',\n",
       " 'curriculllm': 'curriculum',\n",
       " 'bellefit': 'benefit',\n",
       " 'comlnullity': 'community',\n",
       " 'lleeds': 'needs',\n",
       " 'califorllia': 'california',\n",
       " 'colllmbia': 'columbia',\n",
       " 'endowmellt': 'endowment',\n",
       " 'bolles': 'bones',\n",
       " 'studellts': 'students',\n",
       " 'alllollg': 'among',\n",
       " 'pllilosophy': 'philosophy',\n",
       " 'indllstrial': 'industrial',\n",
       " 'wllicil': 'which',\n",
       " 'frellcll': 'french',\n",
       " 'eigllteeiltll': 'eighteenth',\n",
       " 'collceivecl': 'conceived',\n",
       " 'restraillts': 'restraints',\n",
       " 'follllcl': 'found',\n",
       " 'understalld': 'understand',\n",
       " 'llegative': 'negative',\n",
       " 'thougllt': 'thought',\n",
       " 'treatlllent': 'treatment',\n",
       " 'pllilosopllical': 'philosphical',\n",
       " 'cleveloplllellt': 'development',\n",
       " 'tllought': 'thought',\n",
       " 'envirollment': 'environment',\n",
       " 'colltract': 'contract',\n",
       " 'relatiolls': 'relations',\n",
       " 'ellactment': 'enactment',\n",
       " 'qllite': 'quite',\n",
       " 'regulatiolls': 'regulations',\n",
       " 'rigllt': 'right',\n",
       " 'problelll': 'problem',\n",
       " 'llature': 'nature',\n",
       " 'lleeded': 'needed',\n",
       " 'llours': 'hours',\n",
       " 'llour': 'hour',\n",
       " 'elemellts': 'elements',\n",
       " 'hollrs': 'hours',\n",
       " 'lllade': 'made',\n",
       " 'canllot': 'cannot',\n",
       " 'pressllre': 'pressure',\n",
       " 'dollbt': 'doubt',\n",
       " 'englalld': 'england',\n",
       " 'illclustrial': 'industrial',\n",
       " 'thell': 'then',\n",
       " 'fresll': 'fresh',\n",
       " 'eollditions': 'conditions'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
