
## Economics-1969-0


### ---Economics-1969-0-01.txt---
Adam Smith, who has strong claim to
being both the Adam and the Smith of
systematic economics, was a professor of
moral philosophy and it was at that forge
that economics was made. Even when I
was a student, economics was still part of
the moral sciences tripos at Cambridge
University. It can claim to be a moral sci-
ence, therefore, from its origin, if for no
other reason. Nevertheless, for many
economists the very term "moral science"
will seem like a contradiction. We are
strongly imbued today with the view that
science should be wertfrei and we believe
that science has achieved its triumph pre-
cisely because it has escaped the swad-
dling clothes of moral judgment and has
only been able to take off into the vast
universe of the "is" by escaping from the
treacherous launching pad of the "ought."
Even economics, we learn in the history of
thought, only became a science by escap-
ing from the casuistry and moralizing of
medieval thought. Who, indeed, would
want to exchange the delicate rationality
of the theory of equilibrium price, for the
unoperational vaporings of a "just price"
controversy? In the battle between mech-
anism and moralism generally mechanism
has won hands down, and I shall not be
surprised if the very title of my address
does not arouse musty fears of sermoniz-
ing in the minds of many of my listeners.
Let me first explain, then, what I mean
by moral and by moral science. A moral,
or ethical proposition, is a statement
about a rank order of preference among
alternatives, which is intended to apply to
more than one person. A preference which
applies to one person only is a "taste."
Statements of this kind are often called
"value judgments." If someone says, "I
prefer A to B," this is a personal value
judgment, or a taste. If he says, "A is bet-
ter than B," there is an implication that
he expects other people to prefer A to B
also, as well as himself. A moral proposi-
tion then is a "common value."
Every culture, or subculture, is defined
by a set of common values, that is, gener-
ally agreed upon preferences. Without a
core of common values a culture cannot
exist, and we classify society into cultures
and subcultures precisely because it is
possible to identify groups who have com-
mon values.
Most tastes are in fact also common
values and have been learned by the pro-
cess by which all learning is done, that is,
by mutation and selection. The most ab-
surd of all pieces of ancient wisdom is
surely the Latin tag de gustibus non dis-
putandum. In fact, we spend most of our
lives disputing about tastes. If we want to
be finicky about definitions we might turn
the old tag around and say where there is
disputing, we are not talking about tastes.
Nevertheless, even personal tastes are
learned, in the matrix of a culture or a
subculture in which we grow up, by very
much the same kind of process by which
we learn our common values. Purely per-
sonal tastes, indeed, can only survive in a
culture which tolerates them, that is,
which has a common value that private
tastes of certain kinds should be allowed.
One of the most peculiar illusions of


### ---Economics-1969-0-04.txt---
economists is a doctrine that might be
called the Immaculate Conception of the
Indifference Curve, that is, that tastes are
simply given, and that we cannot inquire
into the process by which they are
formed. This doctrine is literally "for the
birds," whose tastes are largely created
for them by their genetic structures, and
can therefore be treated as a constant in
the dynamics of bird societies. In human
society, however, the genetic component
of tastes is very small indeed. We start off
with a liking for milk, warmth, and dry-
ness and a dislike for being hungry, cold,
and wet, and we do have certain latent
drives which may guide the formation of
later preferences in matters of sex, occu-
pation, or politics, but by far and away
the largest part of human preferences are
learned, again by means of a mutation-se-
lection process. It was, incidentally, Veb-
len's principal, and still largely unrecog-
nized, contribution to formal economic
theory, to point out that we cannot as-
sume that tastes are given in any dynamic
theory, in the sense that in dynamics we
cannot afford to neglect the processes by
which cultures are created and by which
preferences are learned.
I am prepared indeed to go much fur-
ther and to say that no science of any
kind can be divorced from ethical consid-
erations, as defined above. The proposi-
tions of science are no more immaculately
conceived than the preferences of individ-
uals. Science is a human learning process
wlhich arises in certain subcultures in
human society and not in others, and a
subculture as we have seen is a group of
people defined by the acceptance of cer-
tain common values, that is, an ethic
which permits extensive communication
among them.
The scientific subculture is no exception
to this rule. It is characterized by a strong
common value system. A high value, for
instance, is placed on veracity, on curios-  ity, on measurement, on quantification, on
careful observation and experiment, and
on objectivity. Without this common
value structure the epistemological pro-
cess of science would not have arisen; in-
deed it did not arise in certain societies
where conditions might otherwise have
been favorable but where some essential
common values of the scientific subcul-
tures did not exist. The question as to ex-
actly what values and ethical propositions
are essential to the scientific subculture
may be in some dispute. The fact that
there are such values cannot be disputed.
It is indeed one of the most perplexing
questions in intellectual history as to why
the scientific subculture developed in the
time and place that it did in Western Eu-
rope. The common values that are prereq-
uisite to it are rather rare among human
subcultures. The common values, for in-
stance, of the military or the people that
run the international system are quite dif-
ferent from those of science. In this sense,
therefore, science has an essential ethical
basis.
This means that even the epistemologi-
cal content of science, that is, what scien-
tists think they know, has an ethical com-
ponent. The proposition, for instance, that
water consists of two molecules of hydro-
gen and one of oxygen is not usually
thought of as a proposition with high ethi-
cal content. Nevertheless, any student in
chemistry who decides that he prefers to
think of hydrogen as dephlogisticated
water will soon find out that chemistry is
not just a matter of personal taste. The
fact that there is no dispute going on
about any particular scientific proposition
does not mean to say that it is a matter of
taste; it simply means that the dispute
about it has been resolved through the ap-
plication of certain common values and
ethical presuppositions.
There is however a fundamental sense
in which the epistemological process even


### ---Economics-1969-0-05.txt---
in the physical and biological sciences is
now running into situations which have
strong ethical implications outside the
scientific subculture. The myth that sci-
ence is simply discovering knowledge
about an objectively unchangeable world
may have had some validity in the early
stages of science but as the sciences de-
velop this myth becomes less and less
valid. The learning process of science is
now running into two serious difficulties.
The first might be called the generalized
Heisenberg principle. When we are trying
to obtain knowledge about a system by
changing its inputs and outputs of infor-
mation, these inputs and outputs will
change the system itself, and under some
circumstances they may change it radi-
cally. My favorite illustration of the Hei-
senberg principle is that of a man who in-
quires through the door of the bedroom
where his friend is sick, "How are you?"
whereupon the friend replies "Fine," and
the effort kills him. In the social sciences
of course the generalized Heisenberg prin-
ciple predominates because knowledge of
the social sciences is an essential part of
the social system itself, hence objectivity
in the sense of investigating a world which
is unchanged by the investigation of it is
an absurdity.
The second difficulty is that as science
develops it no longer merely investigates
the world; it creates the world which it is
investigating. We see this even in the
physical sciences where the evolution of
the elements has now been resumed in this
part of the universe after some six billion
years. We are increasingly going to see
this in the biological sciences, which will
only find out about the evolutionary pro-
cess by actively engaging in it, and chang-
ing its course. In the social sciences one
can defend the proposition that most of
what we can really know is what we cre-
ate ourselves and that prediction in social
systems can be achieved only by setting
up consciously created systems which will
make the predictions come true. Knowl-
edge of random systems can only be ob-
tained by destroying them, that is, by tak-
ing the randomness out of them. There is
a great deal of evidence, for instance, that
the fluctuations of prices in organized
commodity or secuirity markets are essen-
tially random in nature. All we can possi-
bly discover therefore by studying these
fluctuations is what bias there might be in
the dice. If we want to predict the future
of prices in such a market we will have to
control it, that is, we will have to set up a
system of counterspeculation which will
guarantee a given future course of prices.
The gold standard is a primitive example
of such a system in which it is possible to
predict that the price of gold will lie
within the gold points as long as the sys-
tem remains intact. Similarly, we can pre-
dict the inside temperature of a house
with an effective furnace and thermostat
much better than we can predict the
outside temperature simply because we
control one and not the other.
We cannot escape the proposition that
as science moves from pure knowledge to-
ward control, that is, toward creating
what it knows, what it creates becomes a
problem of ethical choice, and will depend
upon the common values of the societies
in which the scientific subculture is
embedded, as well as of the scientific sub-
culture. Under these circumstances sci-
ence cannot proceed at all without at least
an implicit ethic, that is, a subculture with
appropriate common values. The problem
exists in theory even in what might be de-
scribed as the objective phase of science,
that is, the phase in which it is simply in-
vestigating "what is," because the ques-
tion of the conditions under which igno-
rance is bliss is not an empty one. The as-
sumption which is almost universal in aca-
demic circles that ignorance cannot possi-
bly be bliss might under some circum-


### ---Economics-1969-0-06.txt---
stances be proved wrong by the very
methods of science itself. As long as sci-
ence is investigating an unchanging world,
however, this problem does not become
acute, for if knowledge does not change
the world, then all ignorance does for us is
to prevent us from satisfying our idle
curiosity. When, however, knowledge
changes the world the question of the con-
tent of the common values, both of the
subculture which is producing knowledge
and of the total society in which that sub-
culture is embedded, becomes of acute im-
portance. Under these circumstances the
concept of a value-free science is absurd,
for the whole future of science may well
rest in our ability to resolve the ethical
conflicts which the growth of knowledge is
now creating. Science could create an ethi-
cal dynamic which would bring it to an
end.
Let us return then to economics as a
moral science, not merely in the sense in
which all science is "affected with an ethi-
cal interest," but in the quite specific
sense of asking whether economics itself
can be of assistance in resolving ethical
disputes, especially those which arise out
of the continued increase of knowledge.
Economics specializes in the study of
that part of the total social system which
is organized through exchange and which
deals with exchangeables. This to my
mind is a better definition of economics
than those which define it as relating to
scarcity or allocation, for the allocation of
scarce resources is a universal problem
which applies to political decisions and
political structures through coercion,
threat, and even to love and community,
just as it does to exchange. I have else-
where distinguished three groups of social
organizers which I have called the threat
system, the exchange system, and the inte-
grative system. Economics clearly occu-
pies the middle one of these three. It
edges over towards the integrative system  insofar as it has some jurisdiction over the
study of the system of one-way transfers
of exchangeables, which I have called the
"cgrants economy," for the grant, or one-
way transfer, is a rough measure of an in-
tegrative relationship. On the other side,
economics edges towards an area between
the threat system and the exchange sys-
tem which might be described as the study
of strategy or bargaining.
To complete the circle there is also an
area, between the threat system and the
integrative system, of legitimated threat
which is the principal organizer of politi-
cal activity and the main subject matter
of political science. All these systems are
linked together dynamically through the
process of human learning which is the
main dynamic factor in all social systems.
Part of this learning process is the learn-
ing of common values and moral choices,
without which no culture and no social
system is possible. The process by which
we learn otr preference structures indeed
is a fundamental key to the total dynam-
ics of society.
Economics, as such, does not contribute
very much to the formal study of human
learning, though some philosophical econ-
omists like Frederick Hayek [4] have
made some interesting contributions to
this subject. Our main contribution as
economists is in the description of what is
learned; the preference functions which
embody what is learned in regard to
values, and the production functions
which describe the results of the learning
of technology. XVe may not have thought
much about the genetics of knowledge,
but we have thought about its description,
and this is a contribution not to be de-
spised.
Thus, economics suggests the proposi-
tion that actual choices depend not only
on preferences but on opportunities, and
that under some circumstances quite small
changes in either preferences or opportu-


### ---Economics-1969-0-07.txt---
nities may result in large changes in ac-
tual choices made. This proposition ap-
plies just as much to ethical choices and
common values as it does to private
tastes. It throws a good deal of light also
on what might be called the evolutionary
ecology of ethical systems. Successful eth-
ical systems tend to create subcultures,
and these subcultures tend to perpetuate
and propagate the ethical systems which
created them. This principle helps to ex-
plain the persistent division of mankind
into sects, nations, and ideological groups.
If we were to map the ethical preference
systems of the individuals who comprise
mankind, we would not find a uniform
distribution but we would find a very
sharp clustering into cultures and subcul-
tures with relatively empty spaces be-
tween the clusters. All the members of a
single sect, for instance, tend to think
rather alike in matters of ethical judg-
ment and differentiate themselves sharply
from the ethical judgments of other sects.
Individuals tend to be attracted to one or
another of these clusters, leaving the so-
cial space between them relatively empty,
like space between the stars. The reasons
for this phenomenon lie deep in the dy-
namics of the human learning process, for
our preferences are learned mainly from
those with whom we have the most com-
munication. This principle accounts for
the perpetuation of such clusters, though
it does not necessarily account for their
original formation, which exhibits many
puzzling phenomena. The splitting of
these clusters in a kind of mitosis is also
an important and very puzzling phenome-
non. Once we realize, however, that these
are highly sensitive systems as economic
analysis suggests, we can see how wide
divergences might arise. Thus, the actual
difference in preferences and even oppor-
tunities between, shall we say, the social-
ist countries and the capitalist countries,
may in fact be quite small, but this differ-
ence is enough to produce a very wide
difference in the choices made.
Economics has made its own attempt to
solve some of the problems involved in the
moral judglnent in what we know as wel-
fare economics. I believe this attempt has
been a failure, though a reasonably glo-
rious one, and we should take a brief look
at it. Welfare economics attempts to ask
the question "What do we mean when we
say that one state of a social system is
better than another in strictly economic
terms?" The most celebrated answer
given is the Paretian optimum, which
states in effect that Condition A of a so-
cial system is economically superior to
Condition B, if nobody feels worse off in
A than in B, and if at least one person
feels better off. "Better off" or "worse off"
are measured of course by preferences, so
that we could restate the condition as say-
ing that State A is superior to State B if
one or more persons prefer A and if no-
body prefers B. If we permit internal re-
distributions within the system, that is,
compensation, the range of possible supe-
rior states is considerably broadened.
From this simple principle a wide range of
applications has been found possible in a
stirring intellectual drama which might
well be subtitled "Snow White (the fairest
of all) and the Seven Marginal Condi-
tions."
Many, if not most, economists accept
the Paretian optimum as almost self-evi-
dent. Nevertheless, it rests on an ex-
tremely shaky foundation of ethical prop-
ositions. The more one examines it, for in-
stance, the more clear it becomes that
economists must be extraordinarily nice
people even to have thought of such a
thing, for it implies that there is no malev-
olence anywhere in the system. It im-
plies, likewise, that there is no benevo-
lence, the niceness of economists not quite
extending as far as good will. It assumes
selfishness, that is, the independence of in-


### ---Economics-1969-0-08.txt---
dividual preference functions, such that it
makes no difference to me whether I per-
ceive you as either better off or worse off.
Anything less descriptive of the human
condition could hardly be imagined. The
plain fact is that our lives are dominated
by precisely this interdependence of utility
functions which the Paretian optimum
denies. Selfishness, or indifference to the
welfare of others, is a knife edge between
benevolence on the one side and malevo-
lence on the other. It is something that is
very rare. We may feel indifferent towards
those whom we do not know, with whom
we have no relationships of any kind, but
towards those with whom we have rela-
tionships, even the frigid relationship of
exchange, we are apt to be either benevo-
lent or malevolent. We either rejoice when
they rejoice, or we rejoice when they
mourn.
The almost complete neglect by econo-
mists of the concepts of malevolence and
benevolence cannot be explained by their
inability to handle these concepts with
their usual tools. There are no mathemati-
cal or conceptual difficulties involved in
inter-relating utility functions, provided
that we note that it is the perceptions that
matter [2]. The familiar tools of our
trade, the indifference map, the Edge-
worth box, and so on, can easily be ex-
panded to include benevolence or malevo-
lence, and indeed without this expansion
many phenomena, such as one-way trans-
fers, cannot be explained. Perhaps the
main explanation of ouLr neglect of these
concepts is the fact that we have concen-
trated so heavily on exchange as the ob-
ject of our study, and exchange frequently
takes place under conditions of at least
relative indifference or selfishness, though
I argue that there is a minimum degree of
benevolence even in exchange without
which it cannot be legitimated and cannot
operate as a social organizer. We ex-
change courtesies, smiles, the time of day
and so on with the clerk in the store, as
well as exchanging money for commodi-
ties. The amount of benevolence which ex-
changers feel towards each other need not
be large, but a certain minimum is essen-
tial. If exchangers begin to feel malevo-
lent toward each other exchange tends to
break down, or can only be legitimated
under conditions of special ritual, such as
silent trade or collective bargaining.
Nevertheless, economists can perhaps
be excused for abstracting from benevo-
lence and malevolence, simply because
their peculiar baby, which is exchange,
tends to be that social organizer which lies
between these two extremes, and which
produces, if not selfishness, at least low
levels of malevolence and benevolence.
The threat system constantly tends to
produ-ce malevolence simply because of
the learning process which it engenders. A
threatener may begin by feeling benevo-
lent toward the threatened-"I am doing
this for your own good"-but threats al-
most invariably tend to produce malevo-
lence on the part of the threatened to-
wards the threatener, and this is likely to
produce a type of behavior which will in
turn produce malevolence on the part of
the threatener towards the threatened.
This can easily result in a cumulative pro-
cess of increasing malevolence which may
or may not reach some kind of equilib-
rium. The breakup of communities into
factions and into internal strife frequently
follows this pattern. At the other end of
the scale, the integrative system tends to
produce benevolence and those institu-
tions which are specialized in the integra-
tive system, such as the family, the
church, the lodge, the club, the aluimni as-
sociation, and so on, tend also to create
and organize benevolence, even beyond
the circle of their members. This is partly
because benevolence seems to be an im-
portaint element in establishing a satisfac-
tory personal identity, especially after the


### ---Economics-1969-0-09.txt---
threat system has been softened by the
development of exchange. Those who live
under threat, who generally occupy the
lower end of the social scale, as well as
those who live by threat at the upper end,
tend to find their personal identities
through malevolence and through the de-
velopment of counter-threat or through
the displacement of hatred onto weaker
objects, such as children and animals.
Once this state is passed, however, and so-
ciety is mainly organized by exchange,
there seems to be a strong tendency to
miove towards the integrative system and
the integrative institutions. The Rotary
Club is a logical extension of a business-
oriented society, but it is not one that
would necessarily have occurred to econo-
mists.
Oddly enough, it is not welfare econom-
ics with its elegant casuistry, subtle dis-
tinctions, and its ultimately rather im-
plausible recommendations, which has
made the greatest impact on the develop-
ment of common values and ethical propo-
sitions. The major impact of economics on
ethics, it can be argued, has come because
it has developed broad, aggregative con-
cepts of general welfare which are subject
to quantification. We can see this process
going right back to Adam Smith, where
the idea of what we would today call per
capita real income, as the principal mea-
sure of national well-being, has made a
profound impact on subsequent thinking
and policy. The development of the con-
cept of a gross national product and its
various modifications and components as
statistical measures of economic success,
likewise, has had a great impact in creat-
ing common values for the objectives of
economic policy. Another, less fortunate,
example of a measure which profoundly
affected economic policy was the develop-
ment of the parity index by the Bureau of
Agricultural Economics in the United
States Department of Agriculture. As a  measure of the terms of trade -of agricul.
ture, this became an important symbol.
"A hundred per cent of parity" became
the avowed goal of agricultural policy,
even though there is very little reason to
suppose that the terms of trade of a given
historic period, in this case the period
1909-14, have any ultimate validity as
an ideal. Because of differing rates of
change in productivity in different parts
of the economy, we should expect the
terms of trade of different sectors to
change. If, for instance, productivity in
agriculture rises faster than in the rest of
the economy, as it has done in the last
thirty years, we would expect the terms of
trade of agriculture to "worsen" without
any worsening of the incomes of farmers,
and without any sense of social injustice.
Even though economic measurement
may be abused, its effect on the formation
of moral judgments is great, and on the
whole I believe beneficial. The whole idea
of cost-benefit analysis, for instance, in
terms of monetary units, say "real" dol-
lars of constant purchasing power, is of
enormous importance in the evaluation of
social choices and even of social institut-
ions. We can grant, of course, that the
"real" dollar which is oddly enough a
strictly imaginary one, is a dangerously
imperfect measure of the quality of hu-
man life and human values. Neverthe-
less, it is a useful first approximation,
and in these matters of evaluation of diffi-
cult choices it is extremely useful to have
some first approximation that we can then
modify. Without this, indeed, all evalua-
tion is random selection by wild hunches.
It is true, of course, that cost-benefit anal-
ysis of all sorts of things, whether of
water projects, other pork barrel items, or
in more recent years weapon systems, can
be manipulated to meet the previous prej-
udices of people who are trying to influ-
ence the decisions. Nevertheless, the fun-
damental principle that we should count


### ---Economics-1969-0-10.txt---
all costs, whether easily countable or not,
and evaluate all rewards, however hard
they are to evaluate, is one which emerges
squarely out of economics and which is at
least a preliminary guideline in the forma-
tion of the moral judgment, in what might
be called the "economic ethic."
Nevertheless, the economic ethic, or the
total cost-benefit principle, is subject to
sharp challenge. Two principal criticisms
have been made of it, the first of which I
think is probably not valid, and the sec-
ond of which may be valid under limited
circumstances. The criticism that I think
is not valid is that cost-benefit analyses in
particular, or economic principles in gen-
eral, imply selfish motivation and an in-
sensitivity to the larger issues of malevo-
lence, benevolence, the sense of commu-
nity and so on. It is quite true, as shown
above, that economists have neglected the
problem of malevolence and benevolence.
Nevertheless, our attitudes towards others
can be measured at least as well as we can
measure other preferences, either by some
principle of "revealed preference" or by
direct questioning. It is entirely within the
competence of economics, for instance, to
develop a concept of the "rate of benevo-
lence" which is the quantity of exchange-
ables, as measured in real dollars, which a
person would be willing to sacrifice in
order to contemplate an increase of one
real dollar in the welfare of another per-
son. If the rate of benevolence is zero, of
course, we have indifference or pure self-
ishness; if the rate of benevolence is nega-
tive we have malevolence, in which case
people need compensation in order to con-
template without loss the increased wel-
fare of an enemy, or in reverse would be
willing to damage themselves in order to
damage another. The rate of malevolence
then would be the amount in real dollars
one would be prepared to damage one's
self in order to damage another person to
the extent of one dollar. These rates of
malevolence incidentally are frequently
quite high. It apparently costs the United
States about four dollars to do one dollar's
worth of damage in Vietnam, in which
case our rate of benevolence towards
North Vietnam is at least minus four. In
determining cost-benefit analysis we can
easily include rates of benevolence and
malevolence, adding the benefits and sub-
tracting the costs to those toward whom
we are benevolent, multiplied of course by
the rate of benevolence, and subtracting
the benefits and adding the costs, simi-
larly modifed, to those towards whom we
are malevolent.
The concept of a rate of benevolence, in-
cidentally, is at least a partial solution to
the perplexing question of interpersonal
comparisons of utility around which econ-
omists have been doing a ritual dance for
at least three generations. Any decision
involving other people obviously involves
these interpersonal comparisons. They are
made, of course, inside the mind of the de-
cision-maker and what his rates of benev-
olence or malevolence are likely to be is
determined by the whole social process in
which he is embedded. Surely something
can be said about this. We are, for in-
stance, likely to be more benevolent to
people who are going to vote for us and
perhaps malevolent to people who are
going to vote against us. The economic
theory of democracy indeed as developed
by Anthony Downs and others is a very
good example of what I have sometimes
called "economics imperialism," which is
an attempt on the part of economics to
take over all the other social sciences.
The second attack on the "economic
ethic" is more fundamental and harder to
repulse. This is the attack from the side
of what I have elsewhere called the "he-
roic ethic" [1]. In facing decisions, espe-
cially those which involve other people, as


### ---Economics-1969-0-11.txt---
virtually all decisions do, we are faced
with two very different framneworks of
judgment. The first of these is the eco-
nomic ethic of total cost-benefit analysis.
It is an ethic of being sensible, rational,
whatever we want to call it. It is an ethic
of calculation. We cannot indeed count
the cost without counting. Hence, it is an
ethic which depends on the development
of measurement and numbers, even if
these are ordinal numbers. This type of
decision-making, however, does not ex-
haust the immense complexities of the
human organism, and we have to recog-
nize that there is in the world another
type of decision-making, in which the de-
cision-maker elects something, not be-
cause of the effects that it will have, but
because of what he "is," that is, how he
perceives his own identity.
This "heroic" ethic takes three major
forms-the military, the religious, and the
sporting. The heroic ethic "theirs not to
reason why, theirs but to do and die" is so
fundamental to the operation of the mili-
tary that attempts to apply an economic
ethic to it in the form of cost-benefit anal-
ysis or programmed budgeting, or even
strategic science as practiced by Herman
Kahn, T. C. Schelling, or even Robert
McNamara, are deeply threatening to the
morale and the legitimacy of the whole
military system. Religion, likewise, is an
essentially heroic enterprise, even though
there is a strong streak of spiritual cost-
benefit analysis in it. The enormous role
which religion has played in the history of
mankind, for good or ill, is based on the
appeal which it has to the sense of iden-
tity and the sense of the heroic even in or-
dinary people. "Here I stand and I can do
no other" said Luther; "To give and not to
count the cost, to labor and ask for no re-
ward" is the prayer of St. Francis. "Do
your own thing" is the motto of our new
secular Franciscans, the Hippies. In our  national religion, President Kennedy said,
"Ask not what your country can do for
you, ask only what you can do for your
country." We find the same principle in
poetry, in art, in architecture, which are
constantly striving to disengage them-
selves from the chilling embrace of cost-
benefit analysis. I cannot resist quoting
here in full what has always seemed to me
one of the finest expressions in English
poetry of the heroic critique of economics
-Wordsworth's extraordinary sonnet on
King's College Chapel, Cambridge (Eccle-
siastical Sonnet, Number XLIII):
INSIDE OF KING'S COLLEGE CHAPEL,
CAMBRIDGE
Tax not the royal Saint with vain expense,
With ill-matched aims the Architect who
planned-
Albeit labouring for a scanty band
Of white-robed Scholars only-this immense
And glorious Work of fine intelligence!
Give all thou canst; high Heaven rejects the
lore
Of nicely-calculated less or more;
So deemed the man who fashioned for the sense
These lofty pillars, spread that branching roof
Self-poised, and scooped into ten thousand
cells,
Where light and shade repose, where music
dwells
Lingering-and wandering on as loth to die;
Like thoughts whose very sweetness yieldeth
proof
That they were born for immortality.
Okay, boys, bring out your cost-benefit
analysis now! There is a story, for the
truth of which I will not vouch, that
Keynes once asked the chaplain of King's
College if he could borrow the chapel for
a few days. The chaplain was overjoyed
at this evidence of conversion of a noted
infidel until it turned out that Keynes had
got stuck with a load of wheat in the
course of his speculations in futures con-


### ---Economics-1969-0-12.txt---
tracts and wanted to use the chapel for
storage.
The "lore of nicely-calculated less or
more," of course, is economics. I used to
think that high heaven rejected this be-
cause its resources were infinite and there-
fore did not need to be economized. I have
since come to regard this view as theologi-
cally unsound for reasons which I cannot
go into lhere, but also for a more funda-
mental reason. High Heaven, at least as it
exists and propagates itself in the minds
of men, is nothing if not heroic. The
power of religion in human history has
arisen more than anything from its capac-
ity to give identity to its practitioners and
to inspire them with behavior which arises
out of this perceived identity. In extreme
form, this gives rise to the saints and mar-
tyrs of all faiths, religious or secular, but
it also gives rise to a great deal of quiet
heroism, for instance, in jobs, in marriage,
in child rearing and in the humdrum tasks
of daily life, without which a good deal of
the economy might well fall apart.
A good deal of the criticism of econom-
ics from both left and right arises from
dissatisfaction with its implied neglect of
the heroic. There is a widespread feeling
that trade is somehow dirty, and that mer-
chants are somewhat undesirable charac-
ters, and that especially the labor market
is utterly despicable as constituting the
application of the principle of prostitution
to virtually all areas of human life. This
sentiment is not something which econo-
mists can neglect. We have assumed all
too easily in economics that because some-
thing paid off it was therefore automati-
cally legitimate. Unfortunately, the dy-
namics of legitimacy are more complex
than this. Frequently it is negative pay-
offs, that is, sacrifices, rather than positive
payoffs, which establish legitimacy. It has
been the precise weakness of the institu-
tions that we think primarily of as eco-
nomic, that is, associated with exchange,
such as the stock market, the banking sys-
tem, organized commodity markets and so
on, as Schumpeter pointed out, that they
easily lose their legitimacy if they are not
supported by other elements and institu-
tions in the society which can sustain
them as integral parts of a larger commu-
nity. On the right also we find national-
ists, fascists, and the military, attacking
the economic man and economic motiva-
tion from the point of view of the heroic
ethic. It is a wonder indeed that economic
institutions can survive at all, when eco-
nomic man is so universally unpopular.
No one in his senses would want his
daughter to marry an economic man, one
who counted every cost and asked for
every reward, was never afflicted with
mad generosity or uncalculating love, and
who never acted out of a sense of inner
identity and indeed had no inner identity
even if he was occasionally affected by
carefully calculated considerations of be-
nevolence or malevolence. The attack on
economics is an attack on calculatedness
and the very fact that we think of the cal-
culating as cold suggests how exposed
economists are to romantic and heroic
criticism.
My personal view is that, especially at
his present stage or development, man re-
quires both heroic and economic elements
in his institutions, in his learning pro-
cesses and in his decision-making and the
problem of maintaining them in proper
balance and tension is one of the major
problems of maturation, both of the indi-
vidual person and of societies. Economic
man is a clod, heroic man is a fool, but
somewhere between the clod and the fool,
human man, if the expression may be par-
doned, steers his tottering way.
Let me conclude by stealing another
idea from economics and applying it to
general moral science. This is the concept


### ---Economics-1969-0-13.txt---
of a production function, some sort of lim-
ited relationship between inputs and out-
puts as expressed in the great biblical
principle that grapes are not gathered
from thorns, or figs from thistles (Mat-
thew 7:16). There are production func-
tions not only for grapes and figs, but also
for goods and bads, and indeed for the ul-
timate Good. We dispute about what is
good, about what outputs we want as a re-
sult of the inputs we put in. We dispute
also however about the nature of the pro-
duction functions themselves, what inputs
in fact will produce what outputs. In the
case of physical production functions the
problems can be resolved fairly easily by
experimenting, even though there are
some pretty doubtful cases, as in the case
of cloud seedings, which do not seem to be
demonstrably more effective than rain
dances. In the case of moral production
functions, however, the functions them-
selves are much in dispute, and there may
indeed be more disputation about the pro-
duction functions than there is about the
nature of the desired outputs themselves.
I was impressed some years ago, when en-
gaged in a long arduous seminar with
some young Russians and young Ameri-
cans with how easy it was to agree on ulti-
mate goals, even across these widely di-
vergent ideologies, and how extraordinar-
ily hard it was to agree about the inputs
which are likely to produce these ultimate
goals.
There is a problem here in human
learning of how do we get to know the
moral production functions in the complex
melee of social, political, and economic
life, when it seems to be pervaded
throughout with a note of almost cosmic
irony in which almost everything we do
turns out different from what we expect
because of our ignorance, so that both the
bad and the good we do is all too often
unintentional. I cannot solve this eniste-
mological problem in one short paper, but
I recommend it as a major intellectual
challenge to the moral sciences. What I
am concerned with here is with economics
as an input into this moral production
function. Does economics, as George Stig-
ler has suggested, make people conserva-
tive [3]? If so, it is perhaps because it
simply points out the difficulties and dan-
gers of heroic action and makes people ap-
preciate the productivity of the common-
place, of exchange and finance, of bankers
and businessmen, even of the middle class
which our heroic young so earnestly de-
spise. Perhaps this is why so many young
radiCals today have abandoned economics
as a poisoned apple of rationality which
corrupts the pure and heroic man of their
identities and sympathlies. Economics is a
reconciler, it brings together the ideologies
of East and West, it points up the many
common problems which they have, it is
corrosive of ideologies and disputes that
are not worth their costs. Even as it acts
as a reconciler, however, does it not un-
dermine that heroic demand for social mu-
tation which will not be stilled in the
voices of our young radicals?
I confess I have been deeply disturbed
when I have asked myself these questions
and I have no easy answers to them. Nev-
ertheless, I am not sorry that I became an
economist, for to belong to a body of peo-
ple who have never even thought of intro-
ducing malevolence into their social
theory is somehow in this day and age a
little cheering. The anxieties, the moral
anguish, and the intense dispute which
has racked the American Economic Asso-
ciation this year and which is symbolized
by the question as to whether we should
move our meeting from Chicago is symp-
tomatic of the fact that not even the study
of economics can turn people into purely
economic men. Strangely enough it was
the mathematical economists and eco-


### ---Economics-1969-0-14.txt---
nometricians who were most heroically
moved by a sense of outrage against their
personal identity, and who were least af-
fected by the cost-benefit analysis. In this
year of crisis I havte also learned some-
thing about myself-that it is easier to
make heroic decisions as a member of the
committee than it is as a sole decision-
maker and that heroism is much less ap-
propriate in political than it is in personal
decisions. The lessons of this year, there-
fore, are that the study of economics does
not produce clods, even if perhaps the
American Economic Association does not
produce undue heroics. So we can hope at
least that economics is one of the inputs
that helps to make us human. If so, the
benefits of this strange activity will be
well worth its undoubted cost, even if in
our heroic mood we dare not calculate
them.
## Economics-1970-0


### ---Economics-1970-0-03.txt---
Much of mankind's accumulated knowl-
edge performs functions other than that of
increasing our command over goods and
services in the usual sense of these words.
The value of such knowledge is not in-
strumental in an economic-technological
context. It is equally clear that contribu-
tors to the growth of knowledge have all
along been motivated largely by a desire to
improve their understanding of the world
into which they were born. "From science
to engineering and from engineering to
more goods and services" would be an un-
duly drab account of man's quest for knowl-
edge.
Yet in societies of various types, finan-
cial and other incentives have become
established for directing inventive and ed-
ucational abilities to specific tasks carry-
ing economic promise. Moreover, for sev-
eral centuries the Western conception of
knowledge that is valuable for its own
sake has been appreciably influenced by
the ideals of natural scientists and mathe-
maticians. It is a fact of crucial importance
that this has created a cultural environ-
ment in which a reasonably high degree of
correlation may be found between the ac-
cumulation of knowledge per se and sub-
sequent technological applications. The
methods of measuring the economic yield
of new knowledge and of measuring the
trend of that yield have many inevitable
limitations reflecting the indirectness of
the relation of the knowledge-acquisition
process to its economic consequences. My
paper will be concerned with these yields
and trends.
The inputs which in this study will be
regarded as progress-generating will be so
defined because they increase the economic
productivity of inputs at large. Our pro-
gress-inputs could be viewed as producing
intangible capital that is instrumental to
the production of goods and services and
also intangible consumer capital serving as
a source of direct satisfaction. But this is
merely a simile because the properties of
this intangible investment militate against
treating it as output in the sense proper.
The "intangible investment" results in an
increase of the value of terms which in
static versions of neoclassical production
functions would be parameters. The pro-
gress-generating inputs of each period may
then be viewed as producing additional
output indirectly, via their effect on such
terms of otherwise conventionally defined
production functions. In my appraisal,
interpreting the progress-generating inputs
of any period, and their immediate results,
in this distinctive fashion describes the
most convenient way of separating them
out for specific analysis.
As I shall show later, however, very
similar results are obtained in an analyti-
cal framework of different character in
which practically all long-ruIn increase in
output per man-hour is interpreted as de-
veloping from additional per capita knowl-


### ---Economics-1970-0-04.txt---
edge.' Even what in the usual neoclassical
model is considered mere factor-substitu-
tion is in this alternative framework viewed
as implying the invention of new types of
goods, viz. of less labor-intensive equip-
ment. I will explain later why I will
merely keep an eye on the conclusions ob-
tainable from this construction which is
neither neoclassical nor Cambridgeian,
and why the main part of my analysis
will move in the framework usually re-
ferred to as neoclassical.2 Objections raised
against the neoclassical models are quite
inconclusive in their present form, be-
cause the question is not whether the as-
sumptions underlying such models are
"'realistic" (a good photograph of reality),
but whether in the real world these as-
sumptions are violated in such respects
and to such an extent as to render the
analytical results misleading. This the cri-
tics have so far not even tried to show.
I. A Ratio of Benefit-Streamt to Cost and the
Corresponding Average Social
Rate of Return
The costs of generating progress consist
of the costs of producing new knowledge,
and the costs of increased per-capita knowl-
edge-distribution, and of the extra-costs of
chiangeovers from the use of old to the use of
new knowledge. This seems a reasonable
way of looking at our problem, because
if knowledge in use remained constant
per capita, the rate of progress would be



### ---Economics-1970-0-05.txt---
zero. Whether we wish to distinguish the
specific costs of changeovers as a separate
subcategory is a terminological question,
since technological knowledge is not even
truly acquired before it is introduced on
an industrial scale. But at any rate the
changeover-costs belong among the costs
of progress, and they are quantitatively
significanit though they are frequently
overlooked when benefits are weighed
against costs. The costs of progress so con-
ceived are the costs of those inputs which
in this paper are referred to as "progress-
generating." These inputs become com-
bined with hiuman talent which is no easier
to define and is certainly no less essential
than are the Ricardian "original" and "in-
destructible" powers of the soil.
We may express, as a proportion of the
value of a year's output, the cost of the
goods and services representing the prog-
ress-generating input for the year; and on
the benefit-side, we may set against this
cost the proportion in which technological
progress increases the output flow an-
nually.3 On specific simplifying assump-
tions, the progress-induced proportionate
addition to output will remain permanent
and independent of the output-base. With
a deduction on the productivity-side to
allow for the continuing need to keep per
capita education at any once-attained
higher level,4 we then arrive at the ratio of
an economic benefit-stream to cost; and
after multiplying by 100, we obtain a
magnitude that comes close to what the
economist may consider a measure of the
average social rate of return from the
progress-generating activities of the period
in question.6 Such a concept of an average
rate of return can not, of course, guide us
to the core of the ultimately relevant prob-
lems of resource-allocation, but the con-
cept will nevertheless be found useful.
Even on assumptions assuring constant
proportionate additions to the output-flow
the delayed start of the benefit stream will
subsequently require allowances in the
nature of discounts, yet for reasons ex-
plained in Appendix A and in Section VI,
this difficulty will not prove critical.6 We
will also have to try to get rid of the effect
of cyclical and erratic forces on our yearly
data.
The simlplifying assumptions required for
defining average social rates of return in
terms of constant proportionate additions
to output are indeed specific. But analysis
based on these assumptions has led to
reasonably realistic results in a good many
other respects. I shall make these assump-
tions which should assure at least rough
comparability of the benefit-cost ratios so
obtained with analogous ratios for physical
capital formation on a more-or-less given
level of technological knowledge.7 The
"stepping up" of the absolute contribution
of technological progress when future in-
puts (other than progress-generating ones)
raise the output-base must not be allowed
to destroy the comparability of progress-
returns with the returns from investment
in the usual sense. This must be watched
in formulating the assumptions needed for
the justification of such comparisons.



### ---Economics-1970-0-06.txt---
The required simplifying assumptions
are reasonably well satisfied in the macro-
economic Cobb-Douglas framework. The
CES model also acquires the needed prop-
erties if we work into it a mechanism of
induced invention and of distributive-
shares equilibrium.8 This is explained in
Appendix A. In Sections III and IV we
shall return to the question how much
similarity of the real world with such
models is implied in my paper.
I should add that on both sides of my
benefit-cost ledger I will have to disregard
problems of considerable importance which
either cannot be articulated sufficiently
well, or, if capable of articulation, can
be appraised only in very vague terms. I
will not be able to consider the question
whether all-too-rapid change does not re-
duce our well-being "in a fundamental
sense," or, on the other hand, whether at a
stagnant or near-stagnant level of tech-
nology the institutions of Western nations
would be workable at all. Nor will I try to
explore the relationship of technological
progress to population growth and to its
specific consequences.
II. Two Versions of the Social Benefit-
Cost Ratio, and their Meaning
A substantial part of the progress-gen-
erating costs of each period is incurred by
decision makers subjected to the criterion
of private economic yield. The progress-
costs falling in this category consist mainly
of the costs of privately financed research
and development (R & D) and of the extra
costs of changing over to new industrial
processes. Though we are concerned here
with the problem of social yield, we should
obviously include these private yield-ori-
ented costs in the cost-base of our benefit-
cost ratio.
Another large part of the progress-gen-
erating expenses is incurred by agencies
not institutionally subjected to criteria of
economic yield. The government-financed
R & D9 and that financed by other non-
profit institutions belong here, and so does
almost all of the cost of increased per
capita education.10 This does not mean
that the nonprofit institutions incurring
these costs are under no political or quasi-
political" pressure to keep costs down per
unit of service; what it does mean is that
these costs create net income by definition,
i.e., that their net-income-creating prop-
erty does not depend on whether they
generate offsetting revenues. Nonprofit in-
stitutions, most prominently illustrated by
governments, but illustrated also by pri-
vate teaching organizations, can have def-
cits but these deficits are not usually
viewed as negative income such as would
cancel any part of the incomes created by
the institutions. In the language of na-
tional accounting, the services of these in-
stitutions are valued at cost, though, when
appraising the worth of the services, any
individual may find this valuation uncon-
vincing. In this regard such costs are
treated differently from those of firms,
e.g., differently from that R & D compo-
nent which is financed by industry.'2 The


### ---Economics-1970-0-07.txt---
costs of industry show in losses-in de-
ductions from net income-unless they are
recovered through revenue from sales in
markets.
This difference in accounting methods
corresponds to differences in the strength
of the argument for including the two
types of progress-generating expense in the
costs that make up the denominator of our
ratio of benefit-stream to costs. Where the
expenses need not be recovered through
revenues generated by them, groups of de-
cision makers were given legal authority to
proceed on the assumption that the knowl-
edge so produced or distributed has con-
siderable nonmarket value, i.e., value which
is not measured as part of the economic
benefit-stream. As a rule this is true even
where a nonprofit organization13 makes its
services available through sales in markets,
as is the case in a subsector of the educa-
tion sector. Even these nonprofit organiza-
tions are heavily subsidized and/or the
acquisition of the type of service they offer
has been made compulsory by a political
decision limiting the market decision of the
customers to the choice of a source of
supply. The question arises therefore
whether the practice of valuation at cost
to the nonprofit institution, without regard
to recovery of the cost through revenue,
should for our purpose be taken at its face
value in the sense that we net out, and thus
exclude from the cost-side of our social
benefit-cost ledger, the costs of all items
that the national accountant treats as if
they created equivalent values by defini-
tion. In a preliminary step let us do so,
but before trying to appraise the merits
and deficiencies of this version of our ratio,
let us take a look also at another way of
going about the matter.
We may, alternatively, decide to include
in our cost-base the costs of nonprofit in-
stitutions along with those of the profit-
seeking ones and thus obtain a ratio based
on all-inclusive costs. This ratio will, of
course, come out lower than the first.
We must remember, however, that even
the cost-base which we call "all-inclusive"
excludes items which are interpreted here
not as costs of progress-generating inputs
but as expenditures influencing the ef-
fectiveness of such inputs.14 In the first
place, we shall have to limit ourselves to
the analysis of American data; hence the
costs incurred abroad belong among those
automatically excluded. Secondly, medical
expenses, other health-related components
of the consumer budget, and types of
public investment bearing on the effec-
tiveness of progress-generating inputs are
excluded (netted out) even from our larger
cost-base because it is implied that these
expenses become justified by the specific
output which they buy, aside from their
effect on productivity-gains. The same is
not "automatically" taken for granted for
any part of the input we define as progress-
generating. No part of that input is ex-
cluded from our larger cost-base, and while
part of it is excluded from our smaller
base, we emphasize that both bases re-
quire attention in our analysis. Thereby we
leave a range open for personal (subjective)
valuation of the contribution of progress-
generating inputs aside from their con-
tribution to measurable productivity
gains.
The proposition suggests itself that the

### ---Economics-1970-0-08.txt---
average social benefit-cost ratio which a
person is willing to accept as relevant to his
behavior as a voter, adviser, or adminis-
trator is unlikely to fall significantly out-
side the range bounded by the two ratios
we have defined. Our lower ratio involv-
ing our all-inclusive cost-base completely
disregards the value of new knowledge
per se and also its instrumental value for
the performance of services made available
to the public through channels other than
those of the market. Our higher ratio in-
volving merely the costs of the institution-
ally profit-oriented progress-inputs implies
that the given scale of the progress-gen-
erating activities of governments and other
nonprofit organizations would be justi-
fiable even if these activities had no favor-
able effect whatever on the market sector;
in view of the actual scale of these activi-
ties in the contemporary American econ-
omy, such a judgment would, I think, be
interpreted by most individuals as describ-
ing valuation at, or near, the upper limit
of the range of reasonable valuations. Thus,
for what we may consider typical valu-
ation, our lower boundary seems convinc-
ing as such, and our upper boundary seems
not far off the mark as such.
Can these propositions concerning alter-
natively computed ratios of social benefit
stream to cost provide guidance for the
appraisal of the results of the American
progress-generating activities? I suggest
that the answer is in the affirmative,
though it must be recognized that an af-
firmative answer implies a rather modest
interpretation of what it means to be
guided in one's behavior by an estimated
rate of return. Such a limitation is inherent
in any analysis that focuses on average
rates of return for successive periods. Yet
there is good reason for choosing this focus
in the central part of the present analysis.
We are concerned here with activities
for which the marginal social returns, and
hence the ultimately relevant social allo-
cation criteria, are not capable of being
estimated by examining private or national
accounts. Even with regard to the progress-
generating inputs financed by profit-seek-
ing institutions, significant external effects
and shifts in competitive positions create
differentials between social returns and the
private marginal returns of the innovating
firms. For the diffusion of knowledge in the
market sector reduces their profits, while
gains in competitive position achieved dur-
ing the intervening period may prove en-
during. These gains increase the private
returns. At the same time, the spillover
effect of the progress-activities originating
in the nonprofit institutions expresses it-
self in part in private market-returns. As
for the progress-generating activities of
nonprofit institutions, obviously there ex-
ists no way of approximating from ac-
counting data the value of their nonmarket
contribution or that of their spillover effect
on the market economy. When appraising
marginal social returns each individual is
entitled to his own standards, and where
the problem is one of politically determined
inputs, individual valuations will not lead
to the quantity-adjustments which would
work toward equalization of returns at the
margin."5
In such circumstances only one state-
ment can be made about the marginal
criteria of desirable allocation on a reason-
ably "objective" (or general) level of dis-
course. The statement is that once a very
large number of individual preferences con-
cerning the ranking of the specific objectives
of the progress-activities have been bridged


### ---Economics-1970-0-09.txt---
by political or quasipolitical compromise, it
is in the common interest of the commun-
ity to avoid waste. The content of the
political compromise plays a significant
role in shaping the waste-avoidance prob-
lem with which the private as well as the
public sector is faced. Given some specific
compromise on the priority-rankings, the
avoidance of waste requires the solution of
technical problems that are far from trivial
from a professional point of view. Yet any
substantive suggestion on how to satisfy
the marginal criteria of socially desirable
allocation for the progress-inputs inev-
itably implies distinctly personal prefer-
ences which need to be reconciled with the
preferences of others. Preferences of this
sort are essentially preferences of an in-
dividual for one variety of political com-
promise ("as if" utility function) rather
than another."6
This very high degree of subjectivity
does not attach to all substantive propos-
sitions that may be developed on the yield
of the progress-effort. It is possible to sug-
gest substantive propositions not only
about the average social rate of return
from each period's progress-activities but
also about tlle algebraic sign of the dif-
ference between the average and the mar-
ginal social rate to which a much lesser
degree of subjectivity attaches. Event if an
individual were in a position to exert de-
cisive influence on the composition of the
progress-generating inputs-or if for any
reason he ideiitified himself fully with po-
litically determined priority-rankings-he
would still be apt to find a considerable
gap between the average and the marginal
social rates from the progress-activities of
a period, provided that these activities are
pursued on a significant scale. The gap
between average and marginal rates de-
velops because high talent shades over
into lesser talent, and because the solution
of problems is an inherently sequential pro.
cess. This is ain essential property-we
may perhaps say a Schumpeterian property
-of the progress-generating activities. By
way of "transitivity," the following propo-
sitions follow from the average-marginal
gap in the progress activities:
a) Each person has reason to consider it
a necessary condition of his approval of a
set of allocative decisions that by his
standards the average social rate of return
from the progress-activities should exceed
the marginal social rate of return from
physical investment "at a given level of
technological knowledge";
b) the necessary condition requires also
that the average rate of progress-return
should exceed the marginal market rate
from the current flow of physical invest-
ment, since we may assume that this
market rate is no higher than the marginal
social rate from physical investment;
c) finally, no undue stretching is in-
volved in extending this condition to the
requirement that the average rate of prog-
ress-return should exceed the rate of re-
turn on the capital stock-say, the alge-
braic product of the share of capital in in-
come with the ratio of yearly output to
capital"7-since we may assume that nor-
mally this rate is not very different from
the marginal market rate on physical in-
vestment.
It therefore seems reasonable to con-
clude that from each individual's point of
view it is a necessary condition of good
allocation that by his standards the aver-
age social rate of return from the progress-
generating activities of the successive
periods should tend to exceed the profit
rate on physical capital, i.e., should exceed
the rate which in traditional theory is in-
terpreted as the net marginal productivity


### ---Economics-1970-0-10.txt---
of capital. About the relationship between
the average rate from the progress-activi-
ties and the conventionally estimated mar-
ginal product of capital it is possible to
make reasonably "objective" numerical
statements, though unfortunately not very
precise ones, because some statements that
can be made about the average rates from
the progress-activities imply merely value
judgments that are very widely shared.
In particular, a great many individuals
would agree that an unduly strict cri-
terion of overall social profitability, and
hence of required average social rates of
return, is set by charging the full cost of
the knowledge-acquisition activities of
governments and of teaching and research
institutions to measured productivity
trends, as if the nonmarket contribu-
tion of these activities were zero. At the
same time, most individuals would, I
think, agree that it is useful to inquire into
the question of average social rates of re-
turn also by valuing the nonmarket con-
tribution of the politically or quasi-polit-
ically determined progress-inputs at full
cost to the nonprofit institutions as if no
favorable effect on the market-sector were
required to justify these inputs on their
present scale. I surmise that the valuation
convincing to most persons would be lo-
cated either within, or not significantly
outside, the range described by these two
frames of reference for valuation. In this
sense, our two benefit-cost ratios describe a
range which should be of some use to most
decision makers, particularly because the
usefulness of the framework is admittedly
limited. A verdict of social profitability as
expressed by adequate average rates of
return is compatible with anyone's per-
sonal judgment that the progress-activities
could be made even more profitable by
changing the controversial content of
political compromises concerning the com-
position of the inputs. While the present
paper will not lose sight of these highly
controversial questions involving mar-
ginality, I will try to separate these from
the problems that can be analyzed on a
reasonably "objective" level. In practice,
this objectivity becomes reduced by the
need to fill in gaps in the available data by
operations that at times become very
speculative.
More ambitious contributions of other
authors are revealing in many ways but
they do not remove the limitations we
need to observe in our present context. For
example, from empirical investigations one
may conclude that additional education-
education at the margin-is profitable by
market criteria alone, even without regard
to socially desirable external effects and to
the nonmarket value which is acquired.'8
This is a significant result, and it has im-
portant applications, but it cannot be put
to use in our present analysis. Additional
education is profitable very largely be
cause our technology is becoming increas-
ingly complex, a process which in turn
presupposes additional education. Recog-
nition of this takes us back to the problem
of the social worth of the activities that
lead to the increasing complexity of our
technological and organizational methods.
III. The Residual: A Roundabout Way of
Measuring Productivity-Increases
The method here to be used for estimat-
ing productivity gains leads to higher
estimates than do some procedures that
have occasionally been suggested. Yet I
feel that the method needs to be defended
not so much against methods that attrib-
ute a smaller component of growth to
progress, but against methods that attrib-
ute to progress an even larger growth-
component. As concerns the United States,
an argument could be made for the view
that practically all long-run increase in
output per man-hour (or possibly more
than this) involves invention and/or


### ---Economics-1970-0-11.txt---
additional knowledge-distribution because
even insofar as the neoclassical approach
attributes a growth-component to mere
factor-substitution-i.e., insofar as physi-
cal investment exceeds the equivalent of
mere "widening"-such investment pre-
supposes the invention of new equipment
of lesser labor-intensity.'9 Practically all
long-run increase of output per man-hour
(and even the prevention of some decrease
resulting from land-scarcity) requires at
least some amount of additional per capita
knowledge which may or may not express
itself in the production of new types of
equipment20; the reverse proposition that
making use of new ideas requires new capi-
tal goods is hazy because new capital goods
result from new ideas applied to already
existing types of equipment. If one wanted
to follow through consistently the implica-
tions of the conception that all long-run
increase in man-hour output reflects tech-
nological progress, one would arrive at even
higher productivity-gains than those which
we shall assume (though at more costly
ones); the progress-generated productiv-
ity-gains so defined would show a rising
tendency, as will ours; and these progress-
gains too would point to high but some-
what declining rates of social return, simi-
lar to ours.2' We will not follow through all
the implications of this "inclusive" con-
ception of progress though one of its several
implications will be carried over into the
framework I am using because in mine, too,
economies of scale will become merged
with "progress." My main reason for not
following through all the implications of
the most inclusive conception is that some
possible ways of increasing man-hour
output require new ideas only in a very
modest sense of this term, i.e., require
merely somewhat trivial new ideas (re-
sulting in slow changes of the physical
composition of the capital stock). Thisis
what in my appraisal justifies the "neo-
classical" procedure of attributing part of
the increase in output per man-hour to
changes in input-proportions aside from
technological progress. But this way of
looking at the problem still leaves one with
a preference for principles that lead to
higher progress-estimates than do the prin-
ciples suggested in some other contribu-
tions to growth theory.
My analysis will rely on the method of
the Residual as it is employed by John
Kendrick for measuring the proportionate
rate of increase of productivity. From this
productivity-increase I will derive the
magnitude I consider the benefit resulting
from the progress-generating costs.
As is well known, the method of the
Residual attributes to technological ad-
vance that increase in output which is not
attributed to the increase in physical
inputs given their base-period productivities.
The measurement of productivity assumes
measurement of the price-corrected market



### ---Economics-1970-0-12.txt---
value of output, and in the United States
this is practically the same thing as to say
that we are concerned here with a Residual
observed as a proportion of the privately
produced output.22 The procedure has the
implication that the analysis of the de-
terminants of technological progress is as
yet in a tentative stage, so that if for ex-
ample R & D, the increase of per capita
education, the extra-inputs needed for
industrial changeovers, and some other
items to be discussed in this paper make up
the identifiable progress-inputs (as I
suggest they do), we cannot at present
expect good results from regressing output
on all these specific inputs along with the
conventional inputs specified in the pro-
duction functions. I feel convinced that
realism does require recognizing this limi-
tation but that this does not mean that we
are left with no good argument for relating
the Residual to the inputs and costs I
defined as progress-generating.
Regression analysis of cross-sections of
individual industry groups and of firms
enabled investigators to obtain confirma-
tion of the hypothesis that productivity-
increases, as estimated by the method of
the Residual, are positively correlated with
R & D-intensity.23 On the other hand,
spillover effects from the public into the
private sector, the diffusion of knowledge
within the private sector, and the nar-
rowness of the concept of R & D-intensity
as compared to our concept of progress-
generating input make it desirable to ask
the question of the relationship of the
Residual to progress-inputs also in broader
intertemporal terms. When the question is
so posed, it calls for exploring whether the
time-sequence of productivity increases, as
measured by the Residual, bears an un-
derstandable relation to the time-sequence
of progress-generating inputs. We shall see
that this is indeed the case, but in such
work there is at present only limited room
for regression analysis and for "testing" in
the technical sense. This is because for
some purposes for which time-sequence
comparisons of productivity increase with
inputs are used it is advisable to rely on a
rather small number of typical values of
the variables for successive periods of
considerable duration; high serial correla-
tion and lags reduce the usefulness of data
reflecting yearly changes.24 Emphasis will


### ---Economics-1970-0-13.txt---
therefore be placed on tendencies observ-
able by comparing typical data for a
limited number of consecutive periods, and
importance will be attributed to the fact
that when the Residual is used as a point of
departure for estimating benefits, and the
costs are defined as those of our progress-
generatinog inputs, the benefit-trends and
cost-trends show a fairly consistent rela-
tionship that "makes sense."
The method of the Residual can be em-
ployed in different ways. Kendrick has
measured a magnitude he calls total factor
productivity, this being a productivity
measure from which he excludes the conse-
quences of allocational shifts among sectors
(his industry groupings). Hence here the
shifts, which in fact have favored the
higher-productivity sectors (industry
groups), are made to express themselves as
increases of weighted physical inputs rather
than of productivity. Further, Kendrick
has measured a magnitude which he calls
"output per unit of total input" and which
differs from his "total factor productivity"
only in that it registers the results of the
intersector shifts as productivity-increases
rather than as increase of weighted input-
quantity. Both concepts relate to the pri-
vate domestic economy.
Both measures used by Kendrick regis-
ter larger productivity-increases than those
consistent with the usual two-factor class-
room models, because his input-estimates
include estimates of farm land and of real
estate (site land) as part of his estimate of
capital. The relative fixity of this input
reduces the growth-rates of physical in-
puts, thus increasing the Residual. Aside
from this, some technical considerations
suggest that, by their own standards, the
Kendrick measures of productivity-gains
err somewhat on the high side but other
considerations point in the opposite direc-
tion.
From 1900 to 1929, factor productivity,
including the favorable effect of inter-
group shifts, rose at an annual compound
rate of 1.8 percent (during the last ten
years of the period it rose at 2.0 percent);
from 1929 to 1948 the rise occurred at the
rate of 2.3 percent; from 1948 to 1966 at
2.8 percent, with no acceleration during
these past eighteen years. If we exclude
from the productivity-increase the favor-
able effect of Kendrick's intergroup shifts,
we obtain somewhat smaller productivity
increases but broadly similar trends for
these, except that some further accelera-


### ---Economics-1970-0-14.txt---
tion is observed for the comparison of
1957-1966 with 1948-1957.25 Kendrick's
published series end with estimated values
for 1957, but I made use of his somewhat
revised figure for 1957 and of his figures for
later years, i.e., of unpublished data he
kindly let me see, though with emphasis
on their preliminary character.
Thus, from the period 1929-1948 to the
present, the rate of increase of productivity
has risen by about 20 percent of itself; or
by about 30 percent, if the effects of the
intergroup shifts are excluded from the
productivity-increase. From the opening
decades of the century to the present, the
rate of productivity-increase has risen by
about 60 percent (a figure which becomes
75 percent with exclusion of the intergroup
shifts) .26
Indications of a rising tendency of the
rate of productivity-increase are consis-
tent, though the rise is small as compared
to the rise of the recorded progress-gen-
erating inputs, particularly of R & D, in
relation to output. The discrepancy be-
comes significantly reduced by reasonable
allowance for progress-inputs that are not
recorded as such.
IV. The Framework for Productivity and
Benefit Measurement: How Serious
are its Pitfalls?
1. Using the All-Inclusive Cost-Base Re-
quires a Deduction on the Productivity-Side.
We start with a pitfall for the avoidance
of which a definite prescription can be
given. If we say, as we do when using our
all-inclusive cost-base, that productivity-
increases cost us inter alia the inputs
needed for increased per capita education,
then we are implying that on the benefit-
side the bulk of this particular cost must
be deducted from the productivity-in-
creases. The reason is that a once-attained
higher level of per capita education must
subsequently be maintained to keep the
level of knowledge from becoming reduced.
In this regard the characteristics of educa-
tion are different from those of R & D or
from those of the costs of changeovers.
What needs to be deducted on the bene-
fit-side is the "bulk" of the cost that had
been entered for education-not the entire
cost-because we are relating our magni-
tudes to output, and constancy per unit of
the population means a gradual reduction
per unit of output. However, on reasonable
quantitative assumptions the "discounted
value" of the difference between these two
growth rates is small, and hence I will
indeed deduct the bulk.27
2. The Embodiment-Disembodiment Issue,
the Quality-Quantity Controversy and the
Importance of "Dimensions of Improve-
ment."'
We shall now consider the main problem
of the present section. Our reasoning can
be Dlaced into frameworks of different


### ---Economics-1970-0-15.txt---
kinds as long as these have enough in
common with the models discussed in
Appendix A. For us the essential property
of these constructs is that they are models
of disembodied progress in which the
elasticities of output with respect to the
inputs are reasonably well approximated
by the distributive shares of the inputs,
and in which distributive shares remain
reasonably stable. To the extent that these
assumptions are unrealistic our analysis
needs to be adjusted, and in Section III, I
have already pointed out that one type of
adjustment does not change the conclu-
sions very much. What should we think of
the "disembodiment" implication of our
framework, i.e., of the implication that
progress leads inter alia to the production
of new types of goods rather than depends
on new equipment?
Models of so-called embodied progress do
not seem convincing to me on logical
grounds, and to my knowledge, no claim of
empirical superiority has been made, let
alone established, for these frameworks. As
I said, all progress is necessarily disem-
bodied in the sense that new ideas must
always be put into effect with reliance on
the initially given resources. This is an
essential constraint under which all econo-
mies operate. Improved production with
the initially given resources then leads to
more and better capital goods-hence to
the replacement of old with superior equip-
ment and structures ("obsolescence")-
and it yields more and better consumer
goods. But all this represents forward, not
backward, embodiment.
For various purposes it has proved re-
warding to interpret progress as "factor-
augmenting"; yet even if progress is inter-
preted as purely capital-augmenting, this
alone does not change the framework into
one of embodied progress. Using a frame-
work in which some input is "augmented"
merely means expressing the productivity-
increase of that input as the equivalent of a
specific quantity-increase and expressing
the productivity-increases of other inputs
as resulting from complementarity. No
empirical superiority has been claimed for
this degree of unilateral emphasis on
capital-i.e., for assuming pure capital-
augmentation-but at any rate more is
needed for obtaining "embodiment," in a
distinctive sense of the term.
If the embodiment hypothesis is not to
lose what I consider its essential charac-
teristic, the additional assumption must be
made that each period's capital-goods
output can become subject merely to a
single dose of augmentation which de-
scribes a specific level of technology; and
that only the next period's capital goods-
the next vintage-can become subject to
the next dose. This, I submit, is an un-
convincing assumption if we take into
account why next period's capital goods-
next period's equipment-models-are su-
perior to this period's equipment-models.
They are superior because this period's
initially given equipment-models and labor
perform better than how these inputs
would have performed without the new
ideas. So why should the possibilities with
a period's capital goods-a given vintage
become exhausted during a specific period
for which a specific level of technological
knowledge is defined? If the possibilities do
not become exhausted in this fashion, then
a level of technological knowledge ceases
to be uniquely described by (or embodied
into) a specific vintage of capital goods.
In the absence of strong empirical sup-
port for the hypothesis of pure capital-
augmentation and of the required addi-
tional assumption, I have fewer misgivings
about disembodiment than about embodi-
ment. Yet while so-called embodiment
makes too much of the role of new physical
capital formation in bringing about prog-
ress, disembodiment implies overlooking
its progress-promoting effect which prob-
ably does exist. The existence of this ef-


### ---Economics-1970-0-16.txt---
fect complicates matters, and I shall soon
return to this difficulty.
We must be mindful also of another
property of the framework here employed.
We are implying, as does the method of the
Residual in general, that it is advisable to
try to translate quality-improvements of
consumer goods into additional quantities
and yet to express productivity-increases
of capital goods and of inputs in general as
quality-improvements for given physical
quantities.
In my appraisal there is no reason to
become disturbed about this lack of sym-
metry between the interpretation of im-
provements of inputs and that of improve-
ments of consumer goods. The alternative
would be that of lumping together our
"progress-generating inputs" with the
other inputs, and of interpreting the re-
search worker not as one who increases the
productivity, and hence the quality of the
inputs with which measured output is
produced, but as one who has the same
kind of productivity in the production of
measured output as do (say) production
workers.28 However, for my present pur-
pose it would be wrong to cut the story
short in this fashion. I am concerned with
the question how the social yield of pro-
gress-inputs compares with that of other
inputs, and this concern calls for placing
emphasis on the indirectness with which
the progress-inputs produce additional
measured oUtput.29 Thus, for the present
purpose it is useful to have a framework
in which the progress-inputs increase the
" quality" of the other inputs and in which
the other inputs produce quantities of
output.
In practice the effort to let the produc-
tivity-increases of inputs express them-
selves in quality-changes for given physical
quantities, and to translate the quality-
improvements of consumer goods into
quantities, gives rise to many procedural
difficulties and the methods for taking care
of these are admittedly very imperfect. In
particular, it has been argued that the
quantitative allowances for the improve-
ment of consumer-good quality are not
only very crude (which they certainly are),
but in all probability also insufficient. In a
general way it makes good sense to suspect
that the allowances are quantitatively
insufficient, but we should nevertheless
note that the standard of living of Western
countries is rising rapidly, and it is par-
ticularly true at higher levels of income
that the market basket illustrates in-
stances of consistent quality-deterioration
as well as of improvement. Nevertheless,
for consumer goods I shall make an allow-
ance for the assumed underestimate of net
quality improvement (see Appendix C).
Last but not least, an inevitable imper-
fection of frameworks of the kind here
employed results from two-way interac-
tions between physical capital formation
and technological progress. As I said above,
my misgivings about the method by
which vintage models deal with this rela-
tionship does not mean that I consider it
harmless to disregard the interactions.
Starting with initially given resources,
the chances of substantial and continued
improvement are undoubtedly greater if
the processes used are rich in changeable
properties-i.e., in what I elsewhere called
dimensions of improvement-than if these
processes offer improvement possibilities
only in a few directions; and the use of a
large variety of instruments of production
opens up a large number of dimensions of
potential improvement. In another study
I found strong indications that the results
of learning-by-doing are significantly in-
fluenced by differences in the available


### ---Economics-1970-0-17.txt---
number of dimensions of improvement.30
So physical capital formation helps the
improvement process, if for no other rea-
son than because it increases the number
of directions in which improvement can
proceed. The interaction is mutual: we
have seen that without any technological
progress whatever, net physical capital
formation could not exceed the equivalent
of the growth of other inputs because less
labor-intensive machines are different ma-
chines. Some readers might therefore pre-
fer the alternative framework outlined at
the outset of Section III (see also fn. 21).
On the whole, I do not believe that we
would become guilty of gross error by dis-
regarding these mutual interactions when
using our framework for distinguishing
between progress-generating activities and
physical investment provided we stay
aware of the fact that large changes in the
scale on which either of these activities is
pursued have implications for the condi-
tions under which it is possible to engage
in the other type of activity. Of this we
must remain aware.
V. Progress-Generating Inputs and Costs:
The Significance of the
"Unrecorded" Items3"
From 1953 to 1966 total recorded R & D
rose from $5.2 billion to $22.2 billion, and
this represents a better than twofold in-
increase when R & D is expressed as a
proportion of the privately produced
GNP. This proportion rose from 1.6 per-
cent to 3.3 percent.32 While an appreciable
part of this increase was "real"-i.e.,
"physical"- considerable importance at-
taches to changes in relative values.
The question of the weight of the real-
input component versus the relative-valua-
tion component of the increase of the ratio
of R & D-cost to private GNP is discussed
quantitatively in Appendix B. This ques-
tion is of some importance because the
relative-valuation component represents
in part rent-formation-a mere transfer of
income-rather than a rise of social costs.
However, in any event, even the relative-
valuation component represents in good
part rising social costs, because the rela-
tively-rising salaries of research workers
(and also of teachers) have attracted into
the progress activities individuals whose
qualifications and productivity would be
higher also in other occupations. This must
have been the driving force of the transfer.
Such a phenomenon is accompanied by
rent-formation, but I suspect that in the
progress-activities-particularly in reseach
and higher education-the rent-formation
accompanying the rise of social costs is
smaller than in the types of activity mostly
referred to when the nature of the transfer-
rent problem is illustrated.33


### ---Economics-1970-0-18.txt---
We have just seen that from 1953 to
1966 the ratio of total recorded R & D cost
to private GNP rose by more than 100
percent. For the period 1929-1953 only
sporadic and incomplete data are avail-
able, but there is good reason to conclude
that during this period there occurred a
very significant increase of R & D inputs in
relation to real private GNP, and that in
terms of undeflated values the increase was
even more substantial than in real terms
(see Appendix B). These increases are out
of line with the rise of the rate of produc-
tivity-increase. The latter is a 60 percent
or, at most, a 75 percent increase even if we
go back to 1900-1929 and thus compare
the pre-1929 period with the present.34
The efficiency of the edutcational com-
plement of research would to some extent
become adjusted to the requirements set
by new knowledge-production even if
per capita knowledge inputs did not rise in
quantity. In reality the quantity of these
inputs has risen appreciably. Partly from
HEW data and partly from those of Fritz
Machlup, I infer that from the calendar
year 1953 to 1966 the cost of increased per
capita education rose from the equivalent
of 0.3 percent of private GNP to the
equivalent of about 0.5 percent (see Ap-
pendix B). Increased education works it-
self out with significant lags, but an ap-
preciable rate of increase dates back far
into the past. Therefore, trend-appraisals
are not appreciably distorted if we asso-
ciate 0.3 percent with the 1953 benefit, and
0.5 percent with the 1966 benefit, though
the levels of the rates of progress-return
are somewhat distorted-i.e., are calcu-
lated as if the lag did not exist-a fact that
need not disturb us much because the
smaller cost of the past, which in view of
the lag would represent a more appro-
priate present charge, arose correspond-
ingly earlier and for that reason should be
viewed as the equivalent of more than the
undiscounted figure suggests.35
As for the industry-financed (institu-
tionally profit-oriented) R & D, this rose
from $2.2 billions in 1953 to $7.2 billions in
1966. When expressed in relation to private
GNP we obtain a rise from 0.7 percent to
1.1 percent. In Appendix B it is shown that
the post-1953 rise of this particular propor-
tion is likely to have been mainly (perhaps
entirely) the result of the increase in the
relative prices of R & D inputs. That is to
say, here the relative-valuation component
accounts for practically the entire effect,
while for total R & D, the real-input com-
ponent also was significant (even for 1953-
1966).
Regardless of whether we are interested
in yields on our all-inclusive cost-base or in
yields on a cost-base limited to institu-
tionally yield-oriented progress-inputs, ex-
clusive concern on the cost-side with
recorded R & D and with increased per
capita education would lead to the twin
conclusions that yields have been declining
steeply and that they nevertheless still are
at a "perplexing" level. Such calculations
are misleading because they disregard the
fact that obsolescence in the conventional
sense, as well as some costs of a character
similar to that of obsolescense, and also
some costs of a different kind, are omitted
from the recorded progress-generating costs.
This is so even if for the present purpose we
regard the education costs in Machlup's
broadened sense as "recorded." Many of
the unrecorded costs, including obsoles-
cense itself, fall in the category which in
Section I, I called costs of changeovers to

### ---Economics-1970-0-19.txt---
new methods. Their weight is substantial,
but for a given rate of technological prog-
ress these costs are unlikely to change
much in relation to private GNP. Hence
allowances for these costs reduce not
merely the rates of return but also their
downtrend.
It is easy to become misled into the
belief that the method of the Residual
automatically implies proper recognition
of obsolescence. In a sense it does recognize
obsolescence but it does not do so in the
sense relevant to our problem. The method
is not intended to, and it does not, take
account of the fact that in any of the "base
periods" with which the "present period"
is compared, the now old technology was
new.36 Hence at that time the now old
technology gave rise to obsolescence and
it required various instrumental activities
that represented costs of changing over to
new methods. These costs would not have
been incurred in the base-period and they
would not be incurred now if there had
been no technological advance in either
period. In a continuously progressing
economy the inputs used for the obsoles-
cence-component of capital-replacement
are continuously withheld from the pro-
duction of consumer goods or from net
investment (or from the public-sector
counterparts of these). 37
A list of the items that may be regarded
as unrecorded costs is presented in Appen-
dix C, along with explanations. In spite
of the large number of items on the list,
we may take it for granted that only one
item-conventional obsolescence-corre-
sponds individually to an appreciable pro-
portion of private GNP. As for the other
items, in some cases it is doubtful whether
they have a legitimate place on the list and
at any rate, even their joint weight cannot
be appreciable when expressed in relation
to private GNP. Among the items listed
in Appendix C there are only a few that
would be suspect, even at first sight, of
possessing large weight. Item 5 of the
Appendix-the cessation of learning-by-
doing with the old equipment and for the
old product when new methods are intro-
duced-belongs among the suspects, but
in reality it is unlikely to be of great quan-
titative importance because in each period
the discarded methods are apt to be those
for which learning-by-doing has largely
run its course. Item 6-the technical im-
perfections of recording-must have been
large in the early decades, but we are con-
cerned here mainly with the post-1953
period, and our few references to pre-1953
periods were based on attempts to get
indirectly at what now would be "recorded"
R & D. For the present purpose I shall
assume that a deliberately high estimate is
obtained of the joint weight of the un-
recorded costs other than obsolescence in the
usual sense if these other costs are put
at 2 percent in relation to private GNP;
and that a deliberately low estimate is
obtained by putting these items at 1 per-
cent.
What mainly matters is obsolescence in
the usual sense. The fact that we consider a
component of capital consumption a cost
even though we are moving in a GNP
framework may seem paradoxical, but for
no good reason, because while for our
periods GNP may safely be used as a
proxy for NNP, we must take into account
that if capital consumption had all along
been smaller, then any given GNP would
have been a proxy for a higher NNP.
Experts have repeatedly expressed the
view that practically all of the capital
consumption and replacement, which cor-


### ---Economics-1970-0-20.txt---
responds to more than 10 percent of GNP,38
reflects obsolescence, i.e., a result of tech-
nological progress. Such a statement needs
to be reinterpreted for our purpose. If the
service lives of capital goods were to be
prolonged significantly, then, unless the
equipment-goods and the construction
industry were to raise their costs and sell-
ing prices for the sake of durability, the
users of capital goods would be spending
more on repairs and maintenance. The
question here is: how much more? This, I
believe, has remained an unexplored ques-
tion which would deserve a research effort.
In the absence of dependable information,
I suggest two guidelines for the present
purpose. I will base my subsequent rea-
soning more on the second than on the
first of these.
1) By assuming that total capital con-
sumption typically amounts to about 12
percent as expressed in relation to private
GNP, and by charging one-fourth of this to
technological advance for obsolescence, one
is unlikely to overcharge the progress-
account. One way of visualizing the im-
plications of a charge of such size-3 per-
cent of private GNP-is to note that it is
consistent with the hypothesis that in
order to arrive at a doubling of the useful
service lives, the users of capital goods
would have to increase their present ex-
penditures on current repairs and main-
tenance by the equivalent of about 50
percent of what would then become their
reduced current capital-consumption cost.39
For structures which represent a very
weighty component of the capital stock,
this is quite likely to be an overstatement
of the costs of extending the now usual ser-
vice lives, hence an understatement of the
costs to be set against technological ad-
vance and against the rise of living stan-
dards in which it expresses itself. The same
may be true of some types of equipment,
but there undoubtedly exist types for
which these numerical assumptions under-
state the costs of the extension of service
life, and thus overstate the cost of progress.
On the whole, charging 3 percent of private
GNP is unlikely to err (or to err much) on
the high side of costs, and this charge
might well err on the low side. As long as
we try not to overcharge we may add
merely 1 percent of the private GNP for
unrecorded costs other than obsolescence,
i.e., for the other costs listed in Appendix C.
We arrive at 4 percent of private GNP for
what I consider a "moderate" estimate of
the unrecorded costs, though I will not
build much on this figure.
2) An immoderate overstatement of the
obsolescence-cost of progress would be
obtained by charging to progress the
entire capital-consumption-i.e., about 12
percent of private GNP-and by adding 2


### ---Economics-1970-0-21.txt---
percent for the other unrecorded costs,
thus obtaining a charge corresponding to
14 percent of private GNP. But it will
prove to be important to take a look also
at the progress-yields obtained on this
immoderate assumption. I will build on
the fact that the 14 percent charge is ex-
cessive by a significant margin.
VI. Levels and Trends of "Objective" Yields
and Observations on Matters Calling
for Subjective Appraisal
The method by which the quantitative
yield-appraisals were obtained is based
on the discussion in Sections III and V
and the details are explained in the foot-
note below.40 Note that on the productiv-
ity-side we rely on Kendrick's estimate of
annual productivity-increase including the
effect of intergroup shifts (2.8 percent),
but the reader can convince himself that
the result would be influenced little by
the use of estimates that exclude the in-
tersector effect (for the most recent period
this would have been an increase of 2.6
percent p.a.). To me it seems reasonable to
relate also the intersector effect to prog-
ress-generating inputs.41
Many statements one would like to be
able to make about these results would be
much too risky for presentation. But there
are two statements which I consider to be
safe.
The first of these is that the present
average social rate of return from the
progress-activities is substantially in ex-
cess of 13 percent on the all-inclusive
cost-base, and substantially in excess of
18 percent on the cost-base limited to
institutionally profit-oriented progress-in-
puts ("reduced" cost-base). The rates of
13 percent and of 18 percent would imply
charging all capital consumption to prog-
ress, as if extension of service-life were
entirely costless ad infinitum except for
continued maintenance costs at the now
usual level. If we charged one-fourth of the
capital consumption to progress, and made
a moderate charge also for other unre-
corded costs, we would obtain a 31 percent
rate of return on the all-inclusive cost-base,
and a 55 percent rate on the reduced cost-
base. These particular charges rest on



### ---Economics-1970-0-22.txt---
guesswork (I believe of a plausible kind),
but it may be regarded as a fact that 13
percent and 18 percent understate the
average rate of progress-return by a sub-
stantial margin and this will prove signifi-
cant for the present analysis.
The second statement I consider to be
reasonably safe is that the rates of return
show some degree of downward tendency
in the long run (see here also Appendix B).
The qualifications one might want to add
to this statement are not sufficiently
persuasive to arouse much suspicion in the
diagnosis that such a tendency is observ-
able, though I would not want to assert
that my figures give an accurate idea of
the extent to which a downtrend has mani-
fested itself. On what I defined as the re-
duced cost-base this downward tendency
has been very mild, but it would not
entirely disappear on any cost-base that to
me seems reasonably chosen.
The suggestion of a long-run downward
tendency of the average rate of return is
not misleading, because the long-run in-
crease of the costs of progress-inputs has
all along exceeded the rise of the produc-
tivity-gains when both are expressed in
relation to the same output-base. In par-
ticular, the approximately constant up-
trend of productivity during the post-war
decades has been associated with increas-
ing progress-costs even if we consider
merely the costs of the privately financed
progress-inputs. The second half of the
present decade does not fit well into the
pattern, but it is too early to try to inter-
pret the record of the very recent infla-
tionary years, not only because the rate of
resource-utilization in the American econ-
omy has risen suddenly but also because
the rate of increase of the progress-inputs
has been tapering off. This tapering off
occurred partly because the rate of in-
crease of space research tapered off and
then space research reached a peak in 1966;
and partly because even more recently
there also took place anti-inflationary
downward revisions of government pro-
grams (which is not to say that the rate of
increase of R & D might not have declined
even aside from these circumstances).
Consequently it is to early to ask whether
in the mid-sixties the downward tendency
of our benefit-cost ratios was or was not
interrupted, but further productivity-
increases would have to assume a very
unlikely course to invalidate the conclu-
sion that there did occur some degree of
long-run decline, even with reasonable
allowances for lags.
We should note that the downward
tendency of the progress-yields would be
slightly smaller than our figures suggest if
we assumed a small rise of the rate of
increase of factor productivity from 1953
to 1966. In fact there is valid reason for
assuming a small acceleration of progress
but, as concerns the downward tendency
of the yields, allowance for this would
make little difference, because such a
modification would call at the same time
for a small increase of our charge for the
unrecorded costs.42


### ---Economics-1970-0-23.txt---
A downtrend of rates of return in the
progress-generating activities is, of course,
not the same phenomenon as the pre-
viously discussed gap between the average
and the marginal rate on the progress-
inputs of single periods; the downtrend
over time calls for a different interpreta-
tion. It may be interpreted as meaning
that researchers, teachers and other work-
ers engaged in knowledge-acquisition and
distribution activities of growing complex-
ity have increased the efficiency of their
own group somewhat less than would have
been required for unchanging performance
at unchanging costs. Even the relative-
valuation (or relative-wage) component of
a downtrend can in good part be so inter-
preted, because while this component
becomes enlarged by rent-formation, it
nevertheless is true that the relative in-
crease of the incomes of progress-workers
typically results from the need to use very
highly qualified personnel on a rising
scale."' Trying to avoid a downtrend
of the rates of return on these particular
inputs by limiting the scale of the progress-
activies of each successive period accord-
ingly would in the long run prove incom-
patible with a nondiminishing rate of tech-
nological advance in the economy at large.
In view of the scarcity of the ultimate re-
sources needed for any economic process-
including the process of self-improvement
of progress-workers-a secular downward
tendency of yields should indeed be ex-
pected, and Kenneth Arrow was right in
reminding us at last year's annual meeting
that "eternal exponential technological
growth is just as unreasonable as eternal
exponential population growth."44 But it is
equally true and important that such a
slow, secular downward tendency of the
progress-yields may become interrupted
for very long periods. Recurring "break-
throughs" play an important role in the
history of the sciences.
Quite aside from the question of a down-
ward tendency with the actually observed
composition of the progress-activities, we
should recall that, given the present scale
of these activities, even a person in full
agreement with the community-decisions
concerning composition would in all prob-
ability have to consider the marginal social
rates of return of each period lower than
our average rates. This gap arises partly
because high-quality personnel is limited,
and partly because the solution of problems
presupposes the solution of earlier ones.
The least promising project of any period
is apt to be appreciably less promising
than the period's average project. But as
I said in Section II, I am abstaining here
from efforts to apply formal analysis to the
problem of marginal rates, since each in-
dividual is entitled to his own marginal
calculus and in most of the area in which
this paper has been moving individual
valuations become submerged in compro-
mise rather than become validated at the
margin by means of purchase, sale and
production.45 This is why I have so far


### ---Economics-1970-0-24.txt---
focused on average rates of return and on
"necessary conditions," using what I be-
lieve to be very widely shared assumptions
as to the meaning of low and of high valu-
ation of controversial nonmarket contribu-
tions.
At this point, attention should be di-
rected at those aspects of our problem
which call for highly subjective judgment.
My illustrations will be found in Appendix
D, which contains observations on signifi-
cant structural and allocational problems
within the area of R & D. Prominent
among these problems is that of "concen-
tration" in several senses of this term. As
for educational policy, it has become all too
obvious that the future of Western civili-
zation depends on the personal attitudes
millions of individuals will develop to
structural problems belonging in that sec-
tor of the progress-generating activities.
We may now return to our point of de-
parture. As long as we want to remain on a
level of reasonable objectivity, we can only
try to play into the hands of those who
must make their own value judgments. On
alternative cost-bases it is possible to make
reasonable statements of fairly general
validity on the social profitability of the
progress-generating activities as a whole
and on the trends of this profitability. For
the time being the average social yields
are high on both our cost-bases, very much
higher than 13 percent and 18 percent,
respectively, as was seen. It should of
course not be overlooked that a waiting
period of considerable duration elapses be-
tween some progress-generating inputs and
the onset of their yield. But this is true
only of part of the progress-inputs as we
have defined them. Furthermore, when
comparing these yields with yields from
plhysical capital formation, another lag-
adjustment is also needed, and as ex-
plained in Appendix A, this works in the
opposite direction (in favor of the progress-
inputs). We should remember also that
while on the one hand the lag between
progress-inputs and their results would call
for upward revaluation of the inputs in
relation to their results, on the other hand,
earlier progress-inputs have all along been
smaller progress-inputs.
At any event, regardless of what lag-
adjustment we make within reason, the
average social rate of return-even the
rate on the all-inclusive cost-base-satis-
fies our necessary condition with ease. This
"real rate" is at present much higher than
the marginal rate from physical invest-
ment at a more or less given level of knowl-
edge. The latter rate should be estimated
at less than 10 percent; a good case can be
made for estimating it at a figure located
in the range between 5 percent and 10 per-
cent.46 Moreover, the rates on progress-
inputs suggested by our analysis are ap-
preciably higher also than the typical pre-
tax corporate profit-rates, a fact which is
worth noting even though no comparabil-
ity is claimed for our rates of return with
accounting profits.47


### ---Economics-1970-0-25.txt---
For an appreciable period to come, even
a slow downtrend of the progress-yields
would leave a significant differential be-
tween the average social rate of return
from the progress-activities and the con-
ventionally defined marginal rate of re-
turn from physical investment. One is
tempted to add that, given the size of this
differential, it should be possible to pro-
mote the gradual shifting of a larger pro-
portion of our inputs into the various prog-
ress-activities without forcing the marginal
social rates on these below the marginal
rates on physical investment (the latter
being an activity which does not come in
fixed proportions with technological prog-
ress). In my appraisal, this statement, too,
makes very good sense. But even if most
people should agree with this statement,
and yet there should be substantial dis-
agreement on the nature of the projects
that satisfy the marginal criteria, the pos-
sibility of increasing the weight of the new-
knowledge sector would still depend on
how well the political mechanism is cap-
able of bridging the differences. In view of
this, I will end with a question in bargain-
ing theory: Is it realistic to expect that the
propensity to reach compromises can be
increased by making the bargaining parties
aware of the fact that the joint payoff on
reaching agreement is high?


### ---Economics-1970-0-26.txt---



### ---Economics-1970-0-27.txt---



### ---Economics-1970-0-28.txt---



### ---Economics-1970-0-29.txt---


### ---Economics-1970-0-30.txt---
While, as was said, the typical govern-
ment-financed proportion of the industry-
performed R & D has been roughly 55 per-
cent, the government-financed proportion of
the R & D performed by Aircraft and Mis-
siles has exceeded 80 percent (except for a
recent small decline), and the government-
financed proportion of the R & D performed
by Electrical Equipment and Communica-
tion has amounted to about two-thirds, with
the result that about 80 percent of the
government funds used for the industrially
performed R & D have had the purpose of
financing the R & D activities of the two
industries that lead the list of performers.
Concentration by industry is smaller for
privately financed R & D than for the govern-
ment-financed component, though the five
leaders listed above remain the same in-
dustries for the privately financed com-
ponent (not in the identical order and with a
much more even distribution among them).
The five account for about 75 percent of the
privately financed performance. Concen-
tration by industry has been noted fre-
quently, and a look at the figures makes it
self-explanatory why this degree of concen-
tration should have been noted with critical
overtones. On the other hand, we must re-
member that the government finances pri-
vately performed R & D mainly when the
latter promotes the feasibility and the
efficiency of activities to be performed in the
public sector. The government could of
course extend the scope of its research-
financing, partly by a broader interpretation
of this same objective, and partly by sub-
sidizing the research of various industries on
other grounds (e.g. because of favorable
external eff ects expected of specific
changes).59 Indeed, "strong cases" of this
sort may now be receiving more considera-
tion than they have in the past. Rightly so,
though any attempt to put such a scheme
into effect on a scale comparable to that of
programs oriented to the needs of the govern-
ment itself would carry political arbitrariness,
and so-called favoritism, much further than
is inevitable anyhow in an economy with a
large public sector. One would hope that the
possibility of policies involving less concen-
tration by industry will be explored carefully,
even if only limited success can be expected.
As for R & D concentration within indi-
vidual industries-concentration of "re-
search intensity" by firms-this too raises
problems of concern to all of us believing in
the merits of competition. The concern is
legitimate, despite the fact that with respect
to concentration in this sense the findings
are less conclusive than with respect to con-
centration by industry. Over significant
size-ranges, the relationship between size and
research-intensity is very different in differ-
ent industries, particularly in the region of
firms of considerable size. Of the various
methods of aggregation that may be tried,
some lead to a presumption that "in the
aggregate" there exist size-ranges in which
research-intensity-R & D per unit of some
measure of scale of operations-declines with
rising size, and that research-intensity is
pulled up again at the upper end of observed
sizes-perhaps pulled up to a maximum-by
a very small number of "largest" companies
operating in specific industries.
In view of the magnitude of the R & D
totals-$22.2 billions for 1966 and probably
about $25 billions for 1968, i.e., of late about
3 percent of the total GNP-all these prob-
lems of composition and structure deserve
considerable attention. We should develop
our reaction to them in terms of our personal
values. I will add that the largest part of the
total R & D falls in the NSF category labelled
"development"; the next largest, but dis-
tinctly smaller component is labelled "ap-
plied research"; and what is labelled "basic
research" accounts for no more than about
15 percent (a proportion to which this com-
ponent has gradually risen from less than 10
percent). I do not consider this classification
particularly revealing, though it is essential
to bear in mind that the prior insights from
which "problem-oriented" research could
fruitfully develop have all along resulted
"Census industries," and are not even always put to-
gether from Census industries defined on the same digit  level.
59 See Richard R. Nelson, Merton J. Peck, Edward
J. Kalachek, Chapters 8 and 9.


### ---Economics-1970-0-31.txt---
from work that was not focused on "prac-
tical" objectives.
Considering that some observers minimize
the significance of R & D for progress largely
because of the alleged insignificance of the
spillover effect originating in the present
type of defense and space programs, I will
end by noting that even in the peak year of
expenditures on space-research, nearly one-
half of the recorded R & D (a very large sum)
fell in neither of these two categories.
## Economics-1971-0


### ---Economics-1971-0-03.txt---
Economics today rides the crest of
intellectual respectability and popular
acclaim. The serious attention with which
our pronouncements are received by the
general public, hard-bitten politicians, and
even skeptical businessmen is second only
to that which was given to physicists and
space experts a few years ago when the
round trip to the moon seemed to be our
only truly national goal. The flow of
learned articles, monographs, and text-
books is swelling like a tidal wave; Eco-
nometrica, the leading journal in the field
of mathematical economics, has just
stepped up its publication schedule from
four to six issues per annum.
And yet an uneasy feeling about the
present state of our discipline has been
growing in some of us who have watched
its unprecedented development over the
last three decades. This concern seems to
be shared even by those who are them-
selves contributing successfully to the
present boom. They play the game with
professional skill but have serious doubts
about its rules.
Much of current academic teaching and
research has been criticized for its lack of
relevance, that is, of immediate practical
impact. In a nearly instant response to
this criticism, research projects, seminars
aind undergraduate courses have been
set up on poverty, on city and small town
slums, on pure water and fresh air. In an
almost Pavlovian reflex, whenever a new
complaint is raised, President Nixon ap-
points a commission and the university
announces a new course. Far be it from
me to argue that the fire should not be
shifted when the target moves. The trouble
is caused, however, not by an inadequate
selection of targets, but rather by our
inability to hit squarely any one of them.
The uneasiness of which I spoke before is
caused not by the irrelevance of the practi-
cal problems to which present day econo-
mists address their efforts, but rather by
the palpable inadequacy of the scientific
means with which they try to solve them.
If this simply were a sign of the overly
high aspiration level of a fast developing
discipline, such a discrepancy between ends
and means should cause no worry. But I
submit that the consistently indifferent
performance in practical applications is in
fact a symptom of a fundamental imbal-
ance in the present state of our discipline.
The weak and all too slowly growing empir-
ical foundation clearly cannot support
the proliferating superstructure of pure, or
should I say, speculative economic theory.
Much is being made of the widespread,
nearly mandatory use by modern eco-
nomic theorists of mathematics. To the
extent to which the economic phenomena
possess observable quantitative dimen-
sions, this is indisputably a major forward
step. Unfortunately, any one capable of
learning elementary, or preferably ad-
vanced calculus and algebra, and acquiring
acquaintance with the specialized termi-
nology of economics can set himself up as a
theorist. Uncritical enthusiasm for math-
ematical formulation tends often to con-


### ---Economics-1971-0-04.txt---
ceal the ephemeral substantive content of
the argument behind the formidable front
of algebraic signs.
Professional journals have opened wide
their pages to papers written in math-
ematical language; colleges train aspiring
young economists to use this language;
graduate schools require its knowledge and
reward its use. The mathematical model-
building industry has grown into one of the
most prestigious, possibly the most presti-
gious branch of economics. Construction of
a typical theoretical model can be handled
now as a routine assembly job. All princi-
pal components such as production func-
tions, consumption and utility functions
come in several standard types; so does
the optional equipment as, for example,
"factor augmentation"-to take care of
technological change. This particular de-
vice is, incidentally, available in a simple
exponential design or with a special auto-
matic regulator known as the "Kennedy
function." Any model can be modernized
with the help of special attachments. One
popular way to upgrade a simple one-sector
model is to bring it out in a two-sector ver-
sion or even in a still more impressive form
of the "n-sector," that is, many-sector
class.
In the presentation of a new model,
attention nowadays is usually centered on
a step-by-step derivation of its formal
properties. But if the author-or at least
the referee who recommended the manu-
script for publication-is technically com-
petent, such mathematical manipulations,
however long and intricate, can even with-
out further checking be accepted as
correct. Nevertheless, they are usually
spelled out at great length. By the time it
comes to interpretation of the substantive
conclusions, the assumptions on which the
model has been based are easily forgotten.
But it is precisely the empirical validity
of these assumrptions on which the useful-
ness of the entire exercise depends.
What is really needed, in most cases, is
a very difficult and seldom very neat
assessment and verification of these as-
sumptions in terms of observed facts. Here
mathematics cannot help and because of
this, the interest and enthusiasm of the
model builder suddenly begins to flag:
"If you do not like my set of assumptions,
give me another and I will gladly make you
another model; have your pick."
Policy oriented models, in contrast to
purely descriptive ones, are gaining favor,
however nonoperational they may be.
This, I submit, is in part because the
choice of the final policy objectives-the
selection and justification of the shape of
the so-called objective function-is, and
rightly so, considered based on normative
judgment, not on factual analysis. Thus,
the model builder can secure at least some
convenient assumptions without running
the risk of being asked to justify them on
empirical grounds.
To sum up with the words of a recent
president of the Econometric Society,
" . . . the achievements of economic theory
in the last two decades are both impressive
and in many ways beautiful. But it cannot
be denied that there is something scandal-
ous in the spectacle of so many people
refining the analysis of economic states
which they give no reason to suppose will
ever, or have ever, come about.... It
is an unsatisfactory and slightly dishonest
state of affairs."
But shouldn't this harsh judgment be
suspended in the face of the impressive
volume of econometric work? The answer
is decidedly no. This work can be in
general characterized as an attempt to
compensate for the glaring weakness of
the data base available to us by the widest
possible use of more and more sophisti-
cated statistical techniques. Alongside the
mounting pile of elaborate theoretical
models we see a fast-growing stock of
equally intricate statistical tools. These


### ---Economics-1971-0-05.txt---
are intended to stretch to the limit the
meager supply of facts.
Since, as I said before, the publishers'
referees do a competent job, most model-
testing kits described in professional
journals are internally consistent. How-
ever, like the economic models they are
supposed to implement, the validity of
these statistical tools depends itself on the
acceptance of certain convenient assump-
tions pertaining to stochastic properties of
the phenomena which the particular
models are intended to explain; assump-
tions that can be seldom verified.
In no other field of empirical inquiry has
so massive and sophisticated a statistical
machinery been used with such indifferent
results. Nevertheless, theorists continue
to turn out model after model and math-
ematical statisticians to devise complicated
procedures one after another. Most of these
are relegated to the stockpile without any
practical application or after only a per-
functory demonstration exercise. Even
those used for a while soon fall out of favor,
not because the methods that supersede
them perform better, but because they
are new and different.
Continued preoccupation with imag-
inary, hypothetical, rather than with
observable reality has gradually led to a
distortion of the informal valuation scale
used in our academic community to assess
and to rank the scientific performance of its
members. Empirical analysis, according to
this scale, gets a lower rating than formal
mathematical reasoning. Devising a new
statistical procedure, however tenuous,
that makes it possible to squeeze out one
more unknown parameter from a given
set of data, is judged a greater scientific
achievement than the successful search
for additional information that would
permit us to measure the magnitude of the
same parameter in a less ingenious, but
more reliable way. This despite the fact
that in all too many instances sophisti-
cated statistical analysis is performed on a
set of data whose exact meaning and
validity are unknown to the author or
rather so well known to him that at the
very end he warns the reader not to take
the material conclusions of the entire
''exercise" seriously.
A natural Darwinian feedback operating
through selection of academic personnel
contributes greatly to the perpetuation of
this state of affairs. The scoring system
that governs the distribution of rewards
must naturally affect the make-up of the
competing teams. Thus, it is not surprising
that the younger economists, particularly
those engaged in teaching and in academic
research, seem by now quite content with a
situation in which they can demonstrate
their prowess (and incidentally, advance
their careers) by building more and more
complicated mathematical models and
devising more and more sophisticated
methods of statistical inference without
ever engaging in empirical research. Com-
plaints about the lack of indispensable pri-
mary data are heard from time to time,
but they don't sound very urgent. The
feeling of dissatisfaction with the present
state of our discipline which prompts me
to speak out so bluntly seems, alas, to be
shared by relatively few. Yet even those
few who do share it feel they can do little
to improve the situation. How could they?
In contrast to most physical sciences, we
study a system that is not only exceedingly
complex but is also in a state of constant
flux. I have in mind not the obvious change
in the variables, such as outputs, prices or
levels of employment, that our equations
are supposed to explain, but the basic
structural relationships described by the
form and the parameters of these equa-
tions. In order to know what the shape of
these structural relationships actually are
at any given time, we have to keep them
under continuous surveillance.
By sinking the foundations of our ana-


### ---Economics-1971-0-06.txt---
lytical system deeper and deeper, by
reducing, for example, cost functions to
production functions and the production
functions to some still more basic rela-
tionships eventually capable of explaining
the technological change itself, we should
be able to reduce this drift. It would,
nevertheless, be quite unrealistic to expect
to reach, in this way, the bedrock of in-
variant structural relationships (measur-
able parameters) which, once having been
observed and described, could be used
year after year, decade after decade, with-
out revisions based on repeated observa-
tion.
On the relatively shallow level where the
empirically implemented economic anal-
ysis now operates even the more invariant
of the structural relationships, in terms of
which the system is described, change
rapidly. Without a constant inflow of new
data the existing stock of factual in-
formation becomes obsolete very soon.
What a contrast with physics, biology or
even psychology where the magnitude of
most parameters is practically constant
and where critical experiments and mea-
surements don't have to be repeated every
year!
Just to keep up our very modest current
capabilities we have to maintain a steady
flow of new data. A progressive expansion
of these capabilities would be out of the
question without a continuous and rapid
rise of this flow. Moreover, the new, addi-
tional data in many instances will have to
be qualitatively different from those pro-
vided hitherto.
To deepen the foundation of our analyti-
cal system it will be necessary to reach
unhesitatingly beyond the limits of the
domain of economic phenomena as it has
been staked out up to now. The pursuit
of a more fundamental understanding of
the process of production inevitably leads
into the area of engineering sciences. To
penetrate below the skin-thin surface of
conventional consumption functions, it
will be necessary to develop a systematic
study of the structural characteristics and
of the functioning of households, an area in
which description and analysis of social,
anthropological and demographic factors
must obviously occupy the center of the
stage.
Establishment of systematic coopera-
tive relationships across the traditional
frontiers now separating economics from
these adjoining fields is hampered by the
sense of self-sufficiency resulting from what
I have already characterized as undue re-
liance on indirect statistical inference as
the principal method of empirical research.
As theorists, we construct systems in which
prices, outputs, rates of saving and in-
vestment, etc., are explained in terms of
production functions, consumption func-
tions and other structural relationships
whose parameters are assumed, at least for
arguments' sake, to be known. As econo-
metricians, engaged in what passes for
empirical research, we do not try, how-
ever, to ascertain the actual shapes of these
functions and to measure the magnitudes
of these parameters by turning up new
factual information. We make an about
face and rely on indirect statistical in-
ference to derive the unknown structural
relationships from the observed magni-
tudes of prices, outputs and other vari-
ables that, in our role as theoreticians, we
treated as unknowns.
Formally, nothing is, of course, wrong
with such an apparently circular pro-
cedure. Moreover, the model builder in
erecting his hypothetical structures is free
to take into account all possible kinds of
factual knowledge and the econometrician
in principle, at least, can introduce in the
estimating procedure any amount of what
is usually referred to as "exogenous"
information before he feeds his pro-


### ---Economics-1971-0-07.txt---
grammed tape into the computer. Such
options are exercised rarely and when they
are, usually in a casual way.
The same well-known sets of figures are
used again and again in all possible com-
binations to pit different theoretical models
against each other in formal statistical
combat. For obvious reasons a decision is
reached in most cases not by a knock-out,
but by a few points. The orderly and
systematic nature of the entire procedure
generates a feeling of comfortable self-
sufficiency.
This complacent feeling, as I said before,
discourages venturesome attempts to
widen and to deepen the empirical founda-
tions of economic analysis, particularly
those attempts that would involve crossing
the conventional lines separating ours from
the adjoining fields.
True advance can be achieved only
through an iterative process in which im-
proved theoretical formulation raises new
empirical questions and the answers to
these questions, in their turn, lead to new
theoretical insights. The "givens" of today
become the "unknowns" that will have to
be explained tomorrow. This, inciden-
tally, makes untenable the admittedly
convenient methodological position ac-
cording to which a theorist does not need
to verify directly the factual assumptions
on which he chooses to base his deductive
arguments, provided 'his empirical con-
clusions seem to be correct. The prevalence
of such a point of view is, to a large ex-
tent, responsible for the state of splendid
isolation in which our discipline nowadays
finds itself.
An exceptional example of a healthy
balance between theoretical and empirical
analysis and of the readiness of professional
economists to cooperate with experts in
the neighboring disciplines is offered by
Agricultural Economics as it developed in
this country over the last fifty years. A
unique combination of social and political
forces has secured for this area unusually
strong organizational and generous finan-
cial support. Official agricultural statistics
are more complete, reliable, and systematic
than those pertaining to any other major
sector of our economy. Close collaboration
with agronomists provides agricultural
economists with direct access to informa-
tion of a technological kind. When they
speak of crop rotation, fertilizers, or alter-
native harvesting techniques, they usually
know, sometimes from personal experience,
what they are talking about. Preoccupa-
tion with the standard of living of the rural
population has led agricultural economists
into collaboration with home economists
and sociologists, that is, with social scien-
tists of the "softer" kind. While centering
their interest on only one part of the eco-
nomic system, agricultural economists
demonstrated the effectiveness of a sys-
tematic combination of theoretical ap-
proach with detailed factual analysis. They
also were the first among economists to
make use of the advanced methods of
mathematical statistics. However, in their
hands, statistical infereince became a
complement to, not a substitute for,
empirical research.
The shift from casual empiricism that
dominates much of today's econometric
work to systematic large-scale factual
analysis will not be easy. To start with, it
will require a sharp increase in the annual
appropriation for Federal Statistical Agen-
cies. The quality of government statistics
has, of course, been steadily improving.
The coverage, however, does not keep up
with the growing complexity of our social
and economic system and our capability
of handling larger and larger data flows.
The spectacular advances in computer
technology increased the economists' po-
tential ability to make effective analytical
use of large sets of detailed data. The time


### ---Economics-1971-0-08.txt---
is past when the best that could be done
with large sets of variables was to reduce
their number by averaging them out or
what is essentially the same, combining
them into broad aggregates; now we can
manipulate complicated analytical sys-
tems without suppressing the identity of
their individual elements. There is a
certain irony in the fact that, next to the
fast-growing service industries, the areas
whose coverage by the Census is par-
ticularly deficient are the operations of
government agencies, both federal and
local.
To place all or even the major responsi-
bility for the collection of economic data
in the hands of one central organization
would be a mistake. The prevailing de-
centralized approach that permits and
encourages a great number of government
agencies, non-profit institutions and pri-
vate businesses engaged in data gathering
activities acquitted itself very well. Better
information means more detailed informa-
tion and detailed specialized information
can be best collected by those immediately
concerned with a particular field. What is,
however, urgently needed is the establish-
ment, maintenance and enforcement of
coordinated uniform classification systems
by all agencies, private as well as public,
involved in this work. Incompatible data
are useless data. How far from a tolerable,
not to say, ideal state our present economic
statistics are in this respect, can be judged
by the fact that because of differences in
classification, domestic output data cannot
be compared, for many goods, with the
corresponding export and import figures.
Neither can the official employment sta-
tistics be related without laborious adjust-
ments to output data, industry by in-
dustry. An unreasonably high proportion
of material and intellectual resources de-
voted to statistical work is now spent not
on the collection of primary information
but on a frustrating and wasteful struggle  with incongruous definitions and irreconcil-
able classifications.
Without invoking a misplaced methodo-
logical analogy, the task of securing a
massive flow of primary economic data can
be compared to that of providing the high
energy physicists with a gigantic acceler-
ator. The scientists have their machines
while the economists are still waiting for
their data. In our case not only must the
society be willing to provide year after
year the millions of dollars required for
maintenance of a vast statistical machine,
but a large number of citizens must be pre-
pared to play, at least, a passive and oc-
casionally even an active part in actual
fact-finding operations. It is as if the elec-
trons and protons had to be persuaded to
cooperate with the physicist.
The average American does not seem to
object to being interviewed, polled, and
surveyed. Curiosity, the desire to find out
how the economic system (in which most of
us are small gears, and some, big wheels)
works might in many instances provide
sufficient inducement for cooperation of
this kind.
One runs up, of course, occasionally
against the attitude that "what you don't
know can't hurt you" and that knowledge
might be dangerous: it may generate a
desire to tinker with the system. The
experience of these years seems, however,
to have convinced not only most econo-
mists-with a few notable exceptions-but
also the public at large that a lack of
economic knowledge can hurt badly. Our
free enterprise system has rightly been
compared to a gigantic computing machine
capable of solving its own problems auto-
matically. But any one who has had some
practical experience with large computers
knows that they do break down and can't
operate unattended. To keep the auto-
matic, or rather the semi-automatic, engine
of our economy in good working order we
must not only understand the general


### ---Economics-1971-0-09.txt---
principles on which it operates, but also
be acquainted with the details of its actual
design.
A new element has entered the picture
in recent years-the adoption of methods
of modern econiomic analysis by private
business. Corporate support of economic
research goes as far back as the early
1920's when Wesley Mitchell founded the
National Bureau. However, it is not this
concern for broad issues of public policies
or even the general interest in economic
growth and business fluctuations that I
have in mind, but rather the fast-spreading
use of advanced methods of Operations
Research and of so-called Systems' Anal-
ysis. Some of the standard concepts and
analytical devices of economic theory first
found their way into the curricula of our
business schools and soon after that, so-
phisticated management began to put
them into practice. While academic theo-
rists are content with the formulation of
general principles, corporate operations
researchers and practical systems' analysts
have to answer questions pertaining to
specific real situations. Demand for eco-
nomic data to be used in practical business
planning is growing at an accelerated pace.
It is a high quality demand: business users
in most instances possess first-hand techni-
cal knowledge of the area to which the data
they ask for refer. Moreover, this demand
is usually "effective." Profit-making busi-
ness is willing and able to pay the costs of
gathering the inlformation it wants to have.
This raises the thorny question of public
access to privately collected data and of
the proper division of labor and coopera-
tion between government and business in
that fast-expanding field. Under the in-
exorable pressure of rising practical de-
mand, these problems will be solved in one
way or another. Our economy will be sur-
veyed and mapped in all its many dimen-
sions on a larger and larger scale.
Economists should be prepared to take
a leading role in shaping this major social
enterprise not as someone else's spokesmen
and advisers, but on their own behalf.
They have failed to do this up to now. The
Conference of Federal Statistics Users
organized several years ago had business,
labor, and many other groups represented
among its members, but not economists as
such. How can we expect our needs to be
satisfied if our voices are not heard?
We, I mean the academic economists,
are ready to expound, to any one ready to
lend an ear, our views on problems of pub-
lic policy: give advice on the best ways to
maintain full employment, to fight infla-
tion, to foster economic growth. We should
be equally prepared to share with the
wider public the hopes and disappoint-
ments which accompany the advance of
our own often desperately difficult, but
always exciting intellectual enterprise.
This public has amply demonstrated its
readiness to back the pursuit of knowledge.
It will lend its generous support to our
venture too, if we take the trouble to
explain what it is all about.
REFERENCE
F. H. Hahn, "Some Adjustment Problems,"
Econometrica, Jan. 1970, 38, 1-2.
## Economics-1972-0


### ---Economics-1972-0-03.txt---
The world economy today is vastly
different from the 1930's, when Seymour
Harris, the chairman of this meeting, in-
fected me with his boundless enthusiasm
for economics and his steadfast confidence
in its capacity for good works. Economics
is very different, too. Both the science and
its subject have changed, and for the
better, since World War II. But there are
some notable constants. Unemployment
and inflation still preoccupy and perplex
economists, statesmen, journalists, house-
wives, and everyone else. The connection
between them is the principal domestic
economic burden of presidents and prime
ministers, and the major area of contro-
versy and ignorance in macroeconomics.
I have chosen to review economic thought
on this topic on this occasion, partly be-
cause of its inevitable timeliness, partly
because of a personal interest reaching
back to my first published work in 1941.
I. The Meanings of Full Employment
Today, as thirty and forty years ago,
economists debate how much unemploy-
ment is voluntary, how much involuntary;
how much is a phenomenon of equilibrium,
how much a symptom of disequilibrium;
how much is compatible with competition,
how much is to be blamed on monopolies,
labor unions, and restrictive legislation;
how much unemployment characterizes
"full" employment.
Full employment imagine macroeco-
nomics deprived of the concept. But
what is it? What is the proper employment
goal of policies affecting aggregate de-
mand? Zero unemployment in the monthly
labor force survey? That outcome is so
inconceivable outside of Switzerland that
it is useless as a guide to policy. Any other
numerical candidate, yes even 4 percent,
is patently arbitrary without reference to
basic criteria. Unemployment equal to
vacancies? Measurement problems aside,
this definition has the same straightfor-
ward appeal as zero unemployment, which
it simply corrects for friction.1
A concept of full employment more
congenial to economic theory is labor
market equilibrium, a volume of employ-
ment which is simultaneously the amount
employers want to offer and the amount
workers want to accept at prevailing wage
rates and prices. Forty years ago theorists
with confidence in markets could believe
that full employment is whatever volume
of employment the economy is moving
toward, and that its achievement requires
of the government nothing more than
neutrality, and nothing less
After Keynes challenged the classical
notion of labor market equilibrium and
the complacent view of policy to which it
led, full employment came to mean max;-
mum aggregate supply, the point at which
expansion of aggregate demand could not
further increase employment and output.
Full employment was also regarded as
the economy's inflation threshold. With a
deflationary gap, demand less than full
employment supply, prices would be de-
clining or at worst constant. Expansion of
aggregate demand short of full employ-
ment would cause at most a one-shot


### ---Economics-1972-0-04.txt---
increase of prices. For continiuing inflation,
the textbooks tol(I us, a necessary and
sufficient conditioin was an inflationary
gap, real aggregate (lemand in excess of
feasible supply. T he modlel was tailor-
made for wartime inflation.
Postwar experience destroyed the iden-
tification of full employmeint with the
economy's inflation threshold. The pro-
fession, the press, andI the public discovered
the "new inflation" of the 1950's, infla-
tion without beniefit of gap), labelled but
scarcely illuminated by the term "cost-
push." Subsequently the view of the world
suggested by the Phillips curve merged
demand-pull and cost-push inflation and
blurred the distinction between them.
This view containe(d no concept of full em-
ployment. In its place came the tradeoff,
along which society supposedly can choose
the least undesirable feasible combination
of the evils of unemployment and inflation.
Many economists deny the existence of
a durable Phillips tradeoff. TIheir numbers
and influence are increasing. Some of them
contendl that there is only one rate of
unemployment compatible with steady
inflation, a "natural rate" consistent with
any steadly rate of change of prices, posi-
tive, zero, or negative. The natural rate is
another full employment candidate, a
policy target at least in the passive sense
that monetary and fiscal policy makers
are advised to eschew any numerical un-
employment goal and to let the economy
gravitate to this equilibrium. So we have
come full circle. Full employment is once
again nothing but the equilibrium reached
by labor markets unaidedl andl undlistorted
by governmental fine tuning.
In discussing these issues, I shall make
the following points. First, an observed
amount of unemployment is not revealed
to be voluntary simply by the fact that
money wage rates are constant, or rising,
or even accelerating. I shall recall and ex-
tend Keynes's dlefinition of involuntary
unemployment and his explanation why
workers may accept price inflation as a
method of re(lucing real wages while re-
jecting money wage cuts. The second
point is related. Involuntary unemploy-
ment is a disequilibrium phenomenon;
the behavior, the persistence, of excess
supplies of labor depend on how and how
fast markets adjust to shocks, and on how
large and how frequent the shocks are.
Higher prices or faster inflation can
(liminish involuntary, disequilibrium un-
employment, even though voluntary, eqlui-
librium labor supply is entirely free of
money illusion.
Third, various criteria of full employ-
ment coincide in a theoretical full sta-
tionary eqjuilibrium, but diverge in per-
sistent disequilibrium. These are 1) the
natural rate of unemployment, the rate
compatible with zero or some other con-
stant inflation rate, 2) zero involuntary
unemployment, 3) the rate of unemploy-
ment needed for optimal job search and
placement, and 4) unemployment equal
to job vacancies. The first criterion dic-
tates higher unemployment than any of
the rest. Instead of commending the natu-
ral rate as a target of employment policy,
the other three criteria suggest less un-
employment and more inflation. Therefore,
fourth, there are real gains from addi-
tional employment, which must be
weighed in the social balance against the
costs of inflation. I shall conclude with a
few remarks on this choice, and on the
possibilities of improving the terms of the
tradeoff.
II. Keynesian and Classical Interpreta-
tions of Unemployment
To begin with the General Theory is not
just the ritual piety economists of my
generation owe the book that shaped their
minds. Keynes's treatment of labor mar-
ket equilibrium and disequilibrium in his
first chapter is remarkably relevant today.


### ---Economics-1972-0-05.txt---
Keynes attacked what he called the
classical presumption that persistent un-
employment is voluntary unemployment.
The presumption he challenged is that in
competitive labor markets actual em-
ployment and unemployment reveal work-
ers' true preferences between work and
alternative uses of time, the presumption
that no one is fully or partially unem-
ployed whose real wage per hour exceeds
his marginal valuation of an hour of free
time. Orthodox economists found the ob-
served stickiness of money wages to be
persuasive evidence that unemployment,
even in the Great Depression, was volun-
tary. Keynes found decisive evidence
against this inference in the willingness of
workers to accept a larger volume of em-
ployment at a lower real wage resulting
from an increase of prices.
Whenever unemployment could be re-
duced by expansion of aggregate demand,
Keynes regarded it as involuntary. He ex-
pected expansion to raise prices and lower
real wages, but this expectation is not
crucial to his argument. Indeed, if it is pos-
sible to raise employment without reduction
in the real wage, his case for calling the un-
employment involuntary is strengthened.
But why is the money wage so stubborn
if more labor is willingly available at the
same or lower real wage5? Consider first
some answers Keynes did not give. He did
not appeal to trade union monopolies or
minimum wage laws. He was anxious, per-
haps over-anxious, to meet his putative
classical opponents on their home field,
the competitive economy\ He did not rely
on any failure of workers to perceive what
a rise in prices does to real wages. The un-
employed take new jobs, the employed
hold old ones, with eyes open. Otherwise
the new situation would be transient.
Instead, Keynes emphasized the insti-
tutional fact that wages are bargained
and set in the monetary unit of account.
Money wage rates are, to use an unKeynes-
ian term, "administered prices." I'hat is,
they are not set and reset in daily auctions
but posted and fixed for finite periods of
time. This observation led Keynes to his
central explanation: Workers, individually
and in groups, are more concerned with
relative than absolute real wages. They
may withdraw labor if their wages fall
relatively to wages elsewhere, even though
they would not withdraw any if real wages
fall uniformly everywhere. Labor markets
are decentralized, and there is no way
money wages can fall in any one market
without impairing the relative status of
the workers there. A general rise in prices
is a neutral and universal method of re-
ducing real wages, the only method in a
decentralized and uncontrolled economy.
Inflation would not be needed, we may
infer, if by government compulsion, econ-
omy-wide bargaining, or social compact,
all money wage rates could be scaled down
together.
Keynes apparently meant that relative
wages are the arguments in labor supply
functions. But Alchian (pp. 27-52 in Phelps
et al.) and other theorists of search ac-
tivity have offered a somewhat different
interpretation, namely that workers whose
money wages are reduced will quit their
jobs to seek employment in other markets
where they think, perhaps mistakenly,
that wages remain high.
Keynes's explanation of money wage
stickiness is plausible and realistic. But two
related analytical issues have obscured the
message. Can there be involuntary unem-
ployment in an equilibrium, a proper, full-
fledged neoclassical equilibrium? Does the
labor supply behavior described by Keynes
betray "money illusion"? Keynes gave a
loud yes in answer to the first question,
and this seems at first glance to compel an
affirmative answer to the second.
An economic theorist can, of course,
commit no greater crime than to assume
money illusion. Comparative statics is a


### ---Economics-1972-0-06.txt---
nonhistorical exercise, in which different
price levels are to be viewed as alternative
rather th bn sequential. Compare two
situations that differ only in the scale of
exogenous monetary variables; imagine,
for example, that all such magnitudes are
ten times as high in one situation as in the
other. All equilibrium prices, including
money wage rates, should differ in the
same proportion, while all real magnitudes,
including employment, should be the same
in the two equilibria. To assume instead
that workers' supply decisions vary with
the price level is to say that they would
behave differently if the unit of account
were, and always had been, dimes instead
of dollars. Surely Keynes should not be
interpreted to attribute to anyone money
illusion in this sense. He was not talking
about so strict and static an equilibrium.
Axel Leijonhufvud's illuminating and
perceptive interpretation of Keynes argues
convincingly that, in chapter 1 as through-
out the General Theory, what Keynes calls
equilibrium should be viewed as persistent
disequilibrium, and what appears to be
comparative statics is really shrewd and
incisive, if awkward, dynamic analysis.
Involuntary unemployment means that
labor markets are not in equilibrium. The
resistance of money wage rates to excess
supply is a feature of the adjustment pro-
cess rather than a symptom of irrational-
ity.
The other side of Keynes's story is that
in depressions money wage deflation, even
if it occurred more speedily, or especially
if it occurred more speedily, would be at
best a weak equilibrator and quite possibly
a source of more unemployment rather
than less. In contemporary language, the
perverse case would arise if a high and
ever-increasing real rate of return on
money inhibited real demand faster than
the rising purchasing power of monetary
stocks stimulated demand. To pursue this
Keynesian theme further here would be a
digression.
What relevance has this excursion into
depression economics for contemporary
problems of unemployment and wage in-
flation? The issues are remarkably similar,
even though events and Phillips have
shifted attention from levels to time rates
of change of wages and prices. Phillips
curve doctrine2 is in an important sense
the postwar analogue of Keynesian wage
and employment theory, while natural
rate doctrine is the contemporary version
of the classical position Keynes was op-
posing.
Phillips curve doctrine implies that
lower unemployment can be purchased at
the cost of faster inflation. Let us adapt
Keynes's test for involuntary unemploy-
ment to the dynamic terms of contem-
porary discussion of inflation, wages, and
unemployment. Suppose that the current
rate of unemployment continues. Asso-
ciated with it is a path of real wages,
rising at the rate of productivity growth.
Consider an alternative future, with un-
employment at first declining to a rate one
percentage point lower and then remaining
constant at the lower rate. Associated
with the lower unemployment alternative
will be a second path of real wages. Even-
tually this real wage path will show, at
least to first approximation, the same rate
of increase as the first one, the rate of
productivity growth. But the paths may
differ because of the transitional effects of
increasing the rate of employment. The
growth of real wages will be retarded in
the short run if additional employment
lowers labor's marginal productivity. In
any case, the test question is whether with
full information about the two alterna-
tives labor would accept the second one-


### ---Economics-1972-0-07.txt---
whether, in other words, the additional
employment would be willingly supplied
aloing the second real wage path. If the
answer is affirmative, then that one per-
centage point of unemployment is in-
voluntary.
For Keynes's reasons, a negative an-
swer cannot necessarily be inferred from
failure of money wage rates to fall or even
decelerate. Actual unemployment and the
real wage path associated with it are not
necessarily an equilibrium. Rigidities in
the path of money wage rates can be ex-
plained by workers' preoccupation with
relative wages and the absence of any
cetntral economy-wide mechanism for alter-
ing all money wages together.
According to the natural rate hypothe-
sis, there is just one rate of unemployment
compatible with stea(ly wage and price
inflation, andl this is in the long run com-
patible with any constant rate of change of
prices, positive, zero, or negative. Only
at the natural rate of unemployment are
workers content with current and prospec-
tive real wages, content to have their real
wages rise at the rate of growth of pro-
ductivity. Along the feasible path of real
wages they would not wish to accept any
larger volume of employment. Lower un-
employment, therefore, can arise only from
economy-wide excess demand for labor
and must generate a gap between real
wages (lesired and real wages earned. The
gap evokes increases of money wages de-
signed to raise real wages faster than pro-
ductivity. But this intention is always
frustrated, the gap is never closed, money
wages and prices accelerate. By sym-
metrical argument, unemployment above
the natural rate signifies excess supply in
labor markets and ever accelerating de-
flation. Older classical economists regarded
constancy of money wage rates as indica-
tive of full employment equilibrium, at
which the allocation of time between work
and other pursuits is revealed as voluntary
and optimal. Their successors make the
same claims for the natural rate of un-
employment, except that in the equilib-
rium money wages are not necessarily
constant but growing at the rate of pro-
ductivity gain plus the experienced and
expected rate of inflation of prices.
III. Is Zero-Inflation Unemployment
Voluntary and Optimal?
There are, then, two conflicting inter-
pretations of the welfare value of employ-
ment in excess of the level consistent with
price stability. One is that additional
employment does not produce enough to
compensate workers for the value of other
uses of their time. The fact that it gener-
ates inflation is taken as prima facie
evidence of a welfare loss. The alternative
view, which I shall argue, is that the re-
sponses of money wages and prices to
changes in aggregate demand reflect
mechanics of adjustment, institutional
constraints, and relative wage patterns
and reveal nothing in particular about
individual or social valuations of unem-
ployed time vis-a-vis the wages of em-
ployment.
On this rostrum four years ago, Milton
Friedman identified the noninflationary
natural rate of unemployment with "equi-
librium in the structure of real wage
rates" (p. 8). "The 'natural rate of unem-
ployment,' " he said, ". . . is the level
that would be ground out by the Walrasian
system of general equilibrium equations,
provided that there is embedded in them
the actual structural characteristics of the
labor and commodity markets, including
market imperfections, stochastic variabil-
ity in demands and supplies, the costs of
getting information about job vacancies
and labor availabilities, the costs of mo-
bility, and so on." Presumably this
Walrasian equilibrium also has the usual
optimal properties; at any rate, Friedman
advised the monetary authorities not to
seek to improve upon it. But in fact we
know little about the existence of a


### ---Economics-1972-0-08.txt---
Walrasian equilibrium that allows for all
the imperfections and frictions that ex-
plain why the natural rate is bigger than
zero, ancl eveni less about the optimality
of such an equilibriunm if it exists.
In the new microeconomics of labor
markets and inflatioin, the principal activ-
ity whose marginal value sets the reserva-
tion price of employment is job search.
It is not pure leisure, for in principle per-
sons who choose that option are not re-
ported as unemployed; however, there may
be a leisure component in job seeking.
A crucial assumption of the theory is
that search is significantly more efficient
when the searcher is unemployed, but
almost no evidence has been advanced on
this point. Members of our own profession
are adept at seeking and finding new jobs
without first leaving their old ones or
abandoning not-in-labor-force status. We
do not know how many quits and new hires
in manufacturing are similar transfers, but
some of them must be; if all reported
accessions were hires of unemployed work-
ers, the mean duration of unemployment
would be only about half what it is in fact.
In surveys of job mobility among blue
collar workers in 1946-47 (see Lloyd
Reynolds, pp. 2 14-15, and Herbert Parnes,
pp. 158-59), 25 percent of workers who
quit had new jobs lined up in advance.
Reynolds found that the main obstacle
to mobility without unemployment was
not lack of information or time, but simply
"anti-pirating" collusion by employers.
A considerable amount of search activ-
ity by unemployed workers appears to be
an unpro(luctive consequence of dissatis-
faction and frustration rather than a
rational quest for improvement. This was
the conclusion of Reynolds' survey twenty-
five years ago, p. 215, and it has been re-
emphasized for the contemporary scene by
Robert Hall, and by Peter Doeringer and
Michael Piore for what they term the
secondary labor force. Reynolds found
that quitting a job to look for a new one
while unemployed actually yielded a better
job in only a third of the cases. Lining up a
new job in advance was a more successful
strategy: two-thirds of such changes
turned out to be improvements. Today,
according to the dual labor market hy-
pothesis, the basic reason for frequent and
long spells of unemployment in the secon-
dary labor force is the shortage of good jobs.
In any event, the contention of some
natural rate theorists is that employment
beyond the natural rate takes time that
would be better spent in search activity.
Why do workers accept such employment?
An answer to this question is a key ele-
ment in a theory that generally presumes
that actual behavior reveals true prefer-
ences. The answer giveIn is that workers
accept the additional employment only
because they are victims of inflation illu-
sion. One form of inflation illusion is over-
estimation of the real wages of jobs they
now hold, if they are employed, or of jobs
they find, if they are unemployed and
searching. If they did not under-estimate
price inflation, employed workers would
more often quit to search, and unemployed
workers would search longer.
The force of this argument seems to me
diluted by the fact that price inflation
illusion affects equally both sides of the
job seeker's equation. He over-estimates
the real value of an immediate job, but he
also over-estimates the real values of jobs
he might wait for. It is in the spirit of this
theorizing to assume that money interest
rates respond to the same correct or in-
correct inflationary expectations. As a
first approximation, inflation illusion has
no substitution effect on the margin be-
tween working and waiting.
It does have an income effect, causing
workers to exaggerate their real wealth.
In which direction the income effect
would work is not transparent. 1)oes
greater wealth, or the illusion of greater


### ---Economics-1972-0-09.txt---
wealth, make people more choosy about
jobs, more inclined to quit and to wait?
Or less choosy, more inclined to stay in
the job they have or to take the first one
that comes along? I should have thought
more selective rather than less. But natu-
ral rate theory must take the opposite
view if it is to explain why under-estima-
tion of price inflation bamboozles workers
into holding or taking jobs that they do
not reallv want.
Another form of alleged inflation illu-
sion refers to wages rather than prices.
Workers are myopic anl (1o not perceive
that wages elsewhere are, or soon will be,
rising as fast as the money wage of the
job they now hold or have just found.
Consequently they under-estimate the
advantages of quitting and searching.
This explanationi is convincing only to the
extent that the payoff to search activity
is determined by wage differentials. The
payoff also depends on the probabilities of
getting jobs at quoted wages, therefore on
the balance between vacancies and job
seekers. Workers know that perfectly well.
Quit rates are an index of volunitary
search activity. They do not diminish
when unemployment is low and wage
rates are rapidly rising. They increase,
quite understandably. This fact contra-
dicts the inflation illusion story, both
versions. 1 conclude that it is not possible
to regard fluctuations of unemployment
on either side of the zero-inflation rate as
mainly voluntary, albeit mistaken, exten-
sions and contractions of search activity.
The new microeconomics of job search
(see Edmund Phelps et al.), is neverthe-
less a valuable contribution to under-
standing of frictional unemployment. It
provides reasons why some unemployment
is voluntary, and why some unemploy-
ment is socially efficient.
Does the market produce the optimal
amount of search unemployment? Is the
natural rate optimal? I do not believe the
new microeconomics has yet answered
these questions.
An omniscient and beneficent economic
dictator would not place every new job
seeker immediately in any job at hand.
Such a policy would create many mis-
matches, sacrificing efficiency in production
or necessitating costly job-to-job shifts later
on. The hypothetical planner would prefer
to keep a queue of workers unemployed,
so that he would have a larger choice of
jobs to which to assign them. But he would
not make the queue too long, because
workers in the queue are not producing
anything.
Of course he could shorten the queue of
unemployed if he could dispose of more
jobs and lengthen the queue of vacancies.
With enough jobs of various kinds, he
would never lack a vacancy for which any
worker who happens to come along has
comparative advantage. But because of
limited capital stocks and interdependence
among skills, jobs cannot be indefinitely
multiplied without lowering their marginal
productivity. Our wise and benevolent
planner would not place people in jobs
yielding less than the marginal value of
leisure. Given this constraint on the
number of jobs, he would always have to
keep some workers waiting, and some jobs
vacant. But he certainly would be in-
efficient if he had fewer jobs, filled and
vacant, than this constraint. This is the
common sense of Beveridge's rule-that
vacancies should not be less than unem-
ployment.
Is the natural rate a market solution of
the hypothetical planner's operations re-
search problem?/ According to search
theory, an unemployed worker considers
the probabilities that he can get a better
job by searching longer and balances the
expected discounted value of waiting
against the loss of earnings. The employed
worker makes a similar calculation when
he considers quitting, also taking into ac-


### ---Economics-1972-0-10.txt---
count the once and for all costs of move-
ment. These calculations are like those of
the planner, but witlh an important differ-
ence. An individual does not initernalize
all the considerations the planner takes
into account. The external effects are the
familiar ones of congestion theory. A
worker decidling to join a queue or to stay
in one consi(lers the probabilities of getting
a job, but not the effects of his decision on
the probabilities that others face. He
lowers those probabilities for people in
the queue he joins and raises them for per-
sons waiting for the kind of job he vacates
or turns (lown. tI0oo many persons are
unemployed waiting for good jobs, while
less desirable ones go begging. How-
ever, externial effects also occur in the
(lecisions of employers whether to fill a
vacancy with the applicant at hand or to
wait for someone more qualified. It is not
obvious, at least to me, whether the mar-
ket is biased toward excessive or inadle-
quate search. But it is doubtful that it
produces the optimal amounit.
Empirically the proposition that in the
United States the zero-inflation rate of
unemployment reflects voluntary and effi-
cienit job-seeking activity strains credulity.
If there were a natural rate of unemploy-
ment in the United States, what would it
be? It is hard to say because virtually all
econometric Phillips curves allow for a
whole menu of steady inflation rates. But
estimates constrained to produce a vertical
long-run Phillips curve suggest a natural
rate between 5 and 6 percent of the labor
force.3
So let us consider some of the features of
an overall unemployment rate of 5 to 6 per-
cent. First, about 40 percent of accessions
in manufacturing are rehires rather than
new hires. Temporarily laid off by their
employers, these workers had been await-
ing recall and were scarcely engaged in
voluntary search activity. Their unem-
ployment is as much a deadweight loss as
the disguised unemployment of redundant
workers oni payrolls. This number declines
to 25-30 percent when unemployment is
4 percent or below. Likewise, a 5-6 perceint
unemployment rate means that voluntary
quits amount only to about a third of
separations, layoffs to two-thir(-ds. The pro-
portions are rever-sed at low unemploy-
ment rates.
Second, the unemployment statistic is
not an exhaustive count of those with time
and inceintive to search. An additional
3 percent of the labor force are involun-
tarily confinedI to part-time work, atid an-
other 3 4 of t percent are out of the labor
force because they "could not find job" or
"think no work available"---discouraged
by market con(litions rather than personal
incapacities.
Third, with unemployment of 5-6 per-
cent the number of reported vacancies is
less than 1/ 2 of 1 percent. Vacancies ap-
pear to be understated relative to unem-
ployment, but they rise to l2 percent when
the unemployment rate is below 4 per-
cent. At 5-6 percent unemployment, the
economy is clearly capable of generating
many more jobs with marginal produc-
tivity high enough so that people prefer
them to leisure. TI he capital stock is Ino
limitation, siince 5-6 percent unemploy-
ment has beeni associated with more than
20 percent excess capacity. Mioreover,
when more jobs are createdI by expansion
of demand, with or without inflation, labor
force participation increases; this would
hardly occur if the aclditional jobs were low
in quality and productivity. As the parable
of the central employment plannier indi-
cates, there will be excessive waiting for
jobs if the roster of jobs an(d the meniu of
vacancies are suboptimal.
In summary, labor markets charac-
terized by 5-6 percent unemployment do
not display the symptoms one would ex-


### ---Economics-1972-0-11.txt---
pect if the unemployment were voluntary
search activity. Even if it were voluntary,
search activity on such a large scale would
surely be socially wasteful. The only
reason anyone might regard so high an
unemployment rate as an equilibrium
and social optimum is that lower rates
cause accelerating inflation. B3 ut this is
almost tautological. TIhe inferences of equi-
librium anid optimality would be more
conivincing if they were corroboratecI by
direct evidence.
IV. Why is There Inflation without
Aggregate Excess Demand?
Zero-inflation unemployment is not
wholly voluntary, not optimal, I might
eveni say not natural. In other words, the
economy has an inflationary bias: WNhen
labor markets provide as many jobs as
there are willing workers, there is inflation,
perhaps accelerating inflation. Why?
The Phillips curve has been an empirical
finding in search of a theory, like Piran-
dello characters in search of an author.
One rationalization might be termecl a
theory of stochastic macro-equilibrium:
stochastic, because random intersectoral
shocks keep individual labor markets in
diverse states of disequilibrium; macro-
equilibrium, because the perpetual flux
of particular markets produces fairly
defnite aggregate outcomes of unemploy-
ment and wages. Stimulated by Phillips's
1958 findings, Richard Lipsey proposed a
model of this kind in 1960, and it has
since been elaborated by Archibald, pp.
212-23 and Holt, pp. 53-123 and 224-56
in Phelps et. al., and others. I propose
now to sketch a theory in the same
spirit.
It is an essential feature of the theory
that economy-wide relations among em-
ployment, wages, and prices are aggrega-
tions of diverse outcomes in heterogeneous
markets. The myth of macroeconomics is
that relations among aggregates are en-
larged analogues of relations among cor-
responding variables for individual house-
holds, firms, industries, markets. The myth
is a harmless and useful simplification in
many contexts, but sometimes it misses
the essence of the phenomenon.
Unemployment is, in this model as in
Keynes reinterpreted, a disequilibrium phe-
nomenon. Money wages do not adjust
rapidly enough to clear all labor markets
every clay. Excess supplies in labor mar-
kets take the form of unemployment, and
excess demands the form of unfilled
vacancies. At any moment, markets vary
widlely in excess demand or supply, and
the economy as a whole shows both
vacancies and unemployment.
The overall balance of vacancies and
unemployment is determined by aggregate
demand, and is therefore in principle sub-
ject to control by overall monetary and
fiscal policy. Higher aggregate demand
means fewer excess supply markets and
more excess demand markets, accordingly
less unemployment and more vacancies.
In any particular labor market, the rate
of increase of money wages is the sum of
two components, an equilibrium compo-
nent and a disequilibrium component. The
first is the rate at which the wage would
increase were the market in equilibrium,
with neither vacancies nor unemployment.
The other component is a function of ex-
cess demand and supply-a monotonic
function, positive for positive excess de-
mand, zero for zero excess demand, non-
positive for excess supply. I begin with
the disequilibrium component.
Of course the disequilibrium compo-
nents are relevant only if disequilibria
persist. Why aren't they eliminated bv the
very adjustments they set in motion ?
Workers will move from excess supply
markets to excess demand markets, and
from low wage to high wage markets.
Unless they overshoot, these movements
are equilibrating. The theory therefore


### ---Economics-1972-0-12.txt---
requires that new disequilibria are always
arising. Aggregate demand may be stable,
but beneath its stability is never-ending
flux: new products, new processes, new
tastes and fashions, new developments of
land and niatural resources, obsolescent
industries and (leclining areas.
The overlap of vacancies and unem-
ployment--say, the sum of the two for
any given difference between them--is a
measure of the heterogeneity or disper-
sion of individual markets. The amount of
(lispersion (lepen(1s directly on the size of
those shocks of demand anid technology
that keep markets in perpetual disequilib-
riumn, and inversely on the responsive mo-
bility of labor. The one increases, the other
diminishes the frictional component of
unemployment, that is, the number of un-
filled vacancies coexisting with any given
unemployment rate.
A central assumptioin of the theory is
that the functions relating wage change
to excess demand or supply are non-linear,
specifically that unemployment retards
money wages less than vacancies acceler-
ate them. Noinlinearity in the response of
wages to excess demand has several im-
portant implications. First, it helps to
explain the characteristic observed curva-
ture of the Phillips curve. Each successive
increment of unemployment has less effect
in reducing the rate of inflation. Linear
wage response, on the other hand, would
mean a linear Phillips relation.
Second, given the overall state of aggre-
gate demand, economy-wide vacancies less
unemployment, wage inflation will be
greater the larger the variance among
markets in excess (lemand and supply.
As a number of recent empirical studies,
have confirmed (see George Perry and
Charles Schultze), dispersion is infla-
tionary. Of course, the rate of wage
inflation will depend not only on the
overall (lispersion of excess demands and
supplies across markets but also on the
particular markets where the excess sup-
plies and demands happen to fall. An un-
lucky random (Irawing might put the
excess demands in highly responsive mar-
kets and the excess supplies in especially
unresponsive ones.
Third, the nonlinearity is an explana-
tion of inflationary bias, in the following
sense. Even when aggregate vacancies are
at most equal to unemployment, the aver-
age disequilibrium component will be
positive. Full employment in the sense of
equality of vacancies and unemployment
is not compatible with price stability.
Zero inflation requires unemployment in
excess of vacancies.
Criteria that coincide in full long-run
equilibrium zero inflation and zero ag-
gregate excess demand diverge in sto-
chastic macro-equilibrium. Full long-run
equilibrium in all markets would show no
unemployment, no vacancies, no unantici-
pated inflation. But with unending sec-
toral flux, zero excess (lemand spells in-
flation and zero inflation spells net excess
supply, unemployment in excess of va-
cancies. In these circumstances neither
criterion can be justified simply because it
is a property of full long-run equilibrium.
Both criteria automatically allow for fric-
tional unemployment incident to the re-
quired movements of workers between
markets; the no-inflation criterion requires
enough additional unemployment to wipe
out inflationary bias.
' I turn now to the equilibrium compo-
nent, the rate of wage increase in a market
with neither excess demand nor excess
supply. It is reasonable to suppose that the
equilibrium component depends on the
trend of wages of comparable labor else-
where. A "competitive wage," one that
reflects relevant trends fully, is what em-
ployers will offer if they wish to maintain
their share of the volume of employment.
TI his will happen where the rate of growth
of marginal revenue product the com-


### ---Economics-1972-0-13.txt---
pound of productivity increase and price
inflation-is the same as the trend in
wages. But in some markets the equilib-
rium wage will be rising faster, and in
others slower, than the economy-wide
wage trend.
A "natural rate" result follows if actual
wage increases feed fully into the equilib-
rium components of future wage increases.
There will be acceleration whenever the
non-linear disequilibrium effects are on
average positive, and steady inflation, that
is stochastically steady inflation, only at
unemployment rates high enough to make
the disequilibrium effects wash out. Phil-
lips tradeoffs exist in the short run, and
the time it takes for them to evaporate
depends on the lengths of the lags with
which today's actual wage gains become
tomorrow's standards.
A rather minor modification may pre-
serve Phillips tradeoffs in the long run.
Suppose there is a floor on wage change in
excess supply markets, independent of the
amount of excess supply and of the past
history of wages and prices. Suppose, for
example, that wage change is never nega-
tive; it is either zero or what the response
function says, whichever is algebraically
larger. So long as there are markets where
this floor is effective, there can be determi-
nate rates of economy-wide wage inflation
for various levels of aggregate demand.
Markets at the floor do not increase their
contributions to aggregate wage inflation
when overall demand is raised. Nor is their
contribution escalated to actual wage
experience. But the frequency of such
markets diminishes, it is true, both with
overall demand and with inflation. The
floor phenomenon can preserve a Phillips
tradeoff within limits, but one that be-
comes ever more fragile and vanishes as
greater demand pressure removes markets
from contact with the zero floor. The
model implies a long-run Phillips curve
that is very flat for high unemployment
and becomes vertical at a critically low
rate of unemployment.
These implications seem plausible and
even realistic. It will be objected, however,
that any permanent floor independent of
general wage and price history and ex-
pectation must indicate money illusion.
The answer is that the floor need not be
permanent in any single market. It could
give way to wage reduction when enough
unemployment has persisted long enough.
But with stochastic intersectoral shifts of
demand, markets are always exchanging
roles, and there can always be some mar-
kets, not always the same ones, at the floor.
This model avoids the empirically ques-
tionable implication of the usual natural
rate hypothesis that unemployment rates
only slightly higher than the critical rate
will trigger ever-accelerating deflation.
Phillips curves seem to be pretty flat at
high rates of unemployment. During the
great contraction of 1930-33, wage rates
were slow to give way even in the face of
massive unemployment and substantial
deflation in consumer prices. Finally in
1932 and 1933 money wage rates fell more
sharply, in response to prolonged unem-
ployment, layoffs, shutdowns, and to
threats and fears of more of the same.
I have gone through this example to
make the point that irrationality, in the
sense that meaningless differences in
money values permanently affect individual
behavior, is not logically necessary for
the existence of a long-run Phillips trade-
off. In full long-run equilibrium in all
markets, employment and unemployment
would be independent of the levels and
rates of change of money wage rates and
prices. But this is not an equilibrium that
the system ever approaches. The economy
is in perpetual sectoral disequilibrium
even when it has settled into a stochastic
macro-equilibrium.
I suppose that one might maintain that
asymmetry in wage adjustment and tem-


### ---Economics-1972-0-14.txt---
porary resistance to money wage decline
reflect money illusion in some sense. Such
an assertion would have to be based on an
extension of the domain of well-defined
rational behavior to cover responses to
change, adjustment speeds, costs of in-
formation, costs of organizing and operat-
ing markets, and a host of other problems
in dynamic theory. These theoretical ex-
tensions are in their infancy, although
much work of interest and promise is being
done. Meanwhile, I doubt that significant
restrictions on disequilibrium adjustment
mechanisms can be deduced from first
principles.
Why are the wage aind salary rates of
employed workers so insensitive to the
availability of potential replacements?
One reason is that the employer makes
some explicit or implicit commitments in
putting a worker on the payroll in the
first place. The employee expects that his
wages and terms of employment will
steadily improve, certainly never retro-
gress. He expects that the employer will
pay him the rate prevailing for persons of
comparable skill, occupation, experience,
and seniority. He expects such commit-
ments in return for his own investments in
the job; arrangements for residence, trans-
portation, and personal life involve set-up
costs which will be wasted if the job turns
sour. The market for labor services is not
like a market for fresh produce where the
entire current supply is auctioned daily.
It is more like a rental housing market,
in which most existing tenancies are the
continuations of long-term relationships
governed by contracts or less formal under-
standings.
Employers and workers alike regard the
wages of comparable labor elsewhere as a
standard, but what determines those refer-
ence wages? There is not even an auction
where workers and employers unbound by
existing relationships and commitments
meet and determine a market-clearing
wage. If such markets existed, they would
provide competitively determined guides
for negotiated and administered wages,
just as stock exchange prices are reference
points for stock transactions elsewhere.
In labor markets the reverse is closer to
the truth. Wage rates for existing em-
ployees set the standards for new em-
ployees, too.
The equilibrium components of wage
increases, it has been argued, depend on
past wage increases throughout the econ-
omy. In those theoretical and econo-
metric models of inflation where labor
markets are aggregated into a single
market, this relationship is expressed as
an autoregressive equation of fixed struc-
ture: current wage increase depends on
past wage increases. The same description
applies when past wage increases enter in-
directly, mediated by price inflation and
productivity change. The process of mu-
tual interdependence of market wages is a
good deal more complex and less mechani-
cal than these aggregated models suggest.
Reference standards for wages differ
from market to market. The equilibrium
wage increase in each market will be some
function of past wages in all markets, and
perhaps of past prices too. But the func-
tion need not be the same in every market.
Wages of workers contiguous in geography
industry, and skill will be heavily weighted.
Imagine a wage pattern matrix of co-
efficients describing the dependence of the
percentage equilibrium wage increase in
each market on the past increases in all
other markets. The coefficients in each row
are non-negative and sum to one, but their
distribution across markets and time lags
will differ from row to row.
Consider the properties of such a system
in the absence of disequilibrium inputs.
First, the system has the "natural rate"
property that its steady state is indetermi-
nate. Any rate of wage increase that has
been occurring in all markets for a long
enough time will continue. Second, from
irregular initial conditions the system will


### ---Economics-1972-0-15.txt---
move toward one of these steady states,
but which one depends on the specifics of
the wage pattern matrix and the initial
conditions. Contrary to some pessimistic
warnings, there is nro arithmetic compul-
sion that makes the whole system gravi-
tate in the direction of its most inflationary
sectors. The ultimate steady state infla-
tion will be at most that of the market
with the highest initial inflation rate, and
at least that of the market with the lowest
initial inflation rate. It need not be equal
to the average inflation rate at the be-
ginning, but may be either greater or
smaller. Third, the adjustment paths are
likely to contain cyclical conmponents,
damped or at most of constant amplitude,
and during adjustments both individual
and average wage movements may di-
verge substantially in both directions from
their ultimate steady state value. Fourth,
since wage decisions and negotiations
occur infrequently, relative wage adjust-
ments involve a lot of catching up and
leap-frogging, and probably take a long
time. I have sketched the formal proper-
ties of a disaggregated wage pattern sys-
tem of this kind simply to stress again the
vast simplification of the one-market
myth.
A system in which only relative mag-
nitudes matter has only a neutral equilib-
rium, from which it can be permanently
displaced by random shocks. Even when a
market is in equilibrium, it may outdo the
recent wage increases in related markets. A
shock of this kind, even though it is not
repeated, raises permanently the steady
state inflation rate. This is true cost-push
-inflation generated neither by previous
inflation nor by current excess demand.
Shocks, of course, may be negative as well
as positive. For example, upward pushes
arising from adjustments in relative wage
levels will be reversed when those adjust-
ments are completed.
To the extent that one man's reference
wages are another man's wages, there is
something arbitrary and conventional,
indeterminate and unstable, in the process
of wage setting. In the same current mar-
ket circumstances, the reference pattern
might be 8 percent per year or 3 percent
per year or zero, depending on the his-
torical prelude. Market conditions, un-
employment and vacancies and their dis-
tributions, shape history and alter refer-
ence patterns. But accidental circum-
stances affecting stragetic wage settle-
ments also cast a long shadow.
Price inflation, as previously observed,
is a neutral method of making arbitrary
money wage paths conform to the realities
of productivity growth, neutral in pre-
serving the structure of relative wages.
If expansion of aggregate demand brings
both more inflation and more employ-
ment, there need be no mystery why un-
employed workers accept the new jobs,
or why employed workers do not vacate
theirs. They need not be victims of igno-
rance or inflation illusion. They genuinely
want more work at feasible real wages,
and they also want to maintain the rela-
tive status they regard as proper and just.
Guideposts could be in principle the
functional equivalent of inflation, a neu-
tral method of reconciling wage and pro-
ductivity paths. The trick is to find a
formula for mutual deescalation which
does not offend conceptions of relative
equity. No one has devised a way of
controlling average wage rates without
intervening in the competitive struggle
over relative wages. Inflation lets this
struggle proceed and blindly, impartially,
impersonally, and nonpolitically scales
down all its outcomes. There are worse
methods of resolving grotup rivalries and
social conflict.
V. The Role of Monopoly Power
Probably the most popular explanation
of the inflationary bias of the economy is
concentration of economic power in large
corporations and unions. These powerful


### ---Economics-1972-0-16.txt---
monopolies and oligopolies, it is argued,
are immune from competition in setting
wages and prices. The unions raise wages
above competitive rates, with little regard
for the unemployed and under-employed
workers knocking at the gates. Perhaps
the unions are seeking a bigger share of
the revenues of the monopolies and
oligopolies with whom they bargain. But
they don't really succeed in that objective,
because the corporations simply pass the
increased labor costs, along with mark-ups,
on to their helpless customers. The remedy,
it is argued, is either atomization of big
business and big labor or strict public
control of their prices and wages.
So simple a diagnosis is vitiated by con-
fusion between levels and rates of change.
Monopoly power is no doubt responsible
for the relatively high prices and wages of
some sectors. But can the exercise of
monopoly power generate ever-rising price
and wages? Monopolists have no reason
to hold reserves of unexploited power.
But if they did, or if events awarded them
new power, their exploitation of it would
raise their real prices and wages only
temporarily.
Particular episodes of inflation may be
associated with accretions of monopoly
power, or with changes in the strategies
and preferences of those who possess it.
Among the reasons that wages and prices
rose in the face of mass unemployment
after 1933 were NRA codes and other
early New Deal measures to suppress com-
petition, and the growth of trade union
membership and power under the pro-
tection of new federal legislation. Recently
we have witnessed substantial gains in the
powers of organized public employees.
Unions elsewhere may not have gained
power, but some of them apparently have
changed their objectives in favor of wages
at the expense of employment.
One reason for the popularity of the
monopoly power diagnosis of inflation is
the identification of administered prices
and wages with concentrations of economic
power. When price and wage increases are
the outcomes of visible negotiations and
decisions, it seems obvious that identifiable
firms and unions have the power to affect
the course of inflation. But the fact that
monopolies, oligopolies, and large unions
have discretion does not mean it is in-
variably to their advantage to use it to
raise prices and wages. Nor are admin-
istered prices and wages found only in
high concentration sectors. Very few prices
and wages in a modern economy, even in
the more competitive sectors, are deter-
mined in Walrasian auction markets.
No doubt there has been a secular in-
crease in the prevalence of administered
wages and prices, connected with the rela-
tive decline of agriculture and other sec-
tors of self-employment. This develop-
ment probably has contributed to the
inflationary bias of. the economy, by en-
larging the number of labor markets
where the response of money wages to
excess supply is slower than their response
to excess demand. The decline of agricul-
ture as a sector of flexible prices and wages
and as an elastic source of industrial labor
is probably an important reason why the
Phillips trade off problem is worse now
than in the 1920's. Sluggishness of re-
sponse to excess supply is a feature of
administered prices, whatever the market
structure, but it may be accentuated by
concentration of power per se. For ex-
ample, powerful unions, not actually
forced by competition to moderate their
wage demands, may for reasons of internal
politics be slow to respond to unemploy-
ment in their ranks.
VI. Some Reflections on Policy
If the makers of macro-economic policy
could be sure that the zero-inflation rate
of unemployment is natural, voluntary,
and optimal, their lives would be easy.


### ---Economics-1972-0-17.txt---
Friedman told us that all macro-economic
policy needs to do, all it should try to do, is
to make nominal national income grow
steadily at the natural rate of growth of
aggregate supply. This would sooner or
later result in price stability. Steady price
deflation would be even better, he said,
because it would eliminate the socially
wasteful incentive to economize money
holdings. In either case, unemployment
will converge to its natural rate, and
wages and prices will settle into steady
trends. Under this policy, whatever unem-
ployment the market produces is the cor-
rect result. No tradeoff, no choice, no
agonizing decisions.
I have argued this evening that a sub-
stantial amount of the unemployment
compatible with zero inflation is involun-
tary an(l nonoptimal. This is, in my
opinion, true whether or not the inflations
associated with lower rates of unemploy-
ment are steady or ever-accelerating.
Neither macro-economic policy makers,
nor the elected officials and electorates to
whom they are responsible, can avoid
weighing the costs of unemployment
against those of inflation. As Phelps has
pointed out, this social choice has an inter-
temporal dimension. The social costs of
involutionary unemployment are mostly
obvious and immediate. The social costs
of inflation come later.
What are they? Economists' answers
have been remarkably vague, even though
the prestige of the profession has reinforced
the popular view that inflation leads
ultimately to catastrophe. Here indeed is
aT case where abstract economic theory
has a powerful hold on public opinion
and policy. The prediction that at low
unemployment rates inflation will accel-
erate toward ultimate disaster is a theo-
retical deduction with little empirical
support. In fact the weight of econometric
evidence has been against acceleration,
let alone disaster. Yet the deduction has
been convincing enough to persuade this
country to give up billions of dollars of
annual output and to impose sweeping
legal controls on prices and wages. Seldom
has a society made such large immediate
and tangible sacrifices to avert an ill de-
fined, uncertain, eventual evil.
According to economic theory, the
ultimate social cost of anticipated in-
flation is the wasteful use of resources to
economize holdings of currency and other
noninterest-bearing means of payment.
I suspect that intelligent laymen would
be utterly astounded if they realized that
this is the great evil economists are talking
about. They have imagined a much more
devastating cataclysm, with Vesuvius
vengefully punishing the sinners below.
Extra trips between savings banks and
commercial banks? What an anti-climax!
With means of payment-currency plus
demand deposits-equal currently to 20
percent of GNP, an extra percentage point
of anticipated inflation embodied in nomi-
nal interest rates produces in principle a
social cost of 2/10 of I percent of GNP
per year. This is an outside estimate. An
unknown, but substantial, share of the
stock of money belongs to holders who are
not trying to economize cash balances and
are not near any margin where they would
be induced to spend resources for this pur-
pose. These include hoarders of large de-
nomination currency, about one-third of
the total currency in public hands, for
reasons of privacy, tax evasion, or illegal
activity. They include tradesmen and
consumers whose working balances turn
over too rapidly or are too small to justify
any effort to invest them in interest-
bearing assets. They include corporations
who, once they have been induced to
undertake the fixed costs of a sharp-pencil
money management department, are al-
ready minimizing their cash holdings.
They include businessmen who are in fact
being paid interest on demand deposits,


### ---Economics-1972-0-18.txt---
although it takes the form of preferential
access to credit and other bank services.
But, in case anyone still regards the waste
of resources in unnecessary transactions
between money and interest-bearing finan-
cial assets as one of the major economic
problems of the day, there is a simple and
straightforward remedy, the payment of
interest on demand deposits and possibly,
with ingenuity, on currency too.
The ultimate disaster of inflation would
be the breakdown of the monetary pay-
ments system, necessitating a currency
reform. Such episodes have almost invari-
ably resulted from real economic catas-
trophes-wars, defeats, revolutions, rep-
arations-not from the mechanisms of
wage-price push with which we are con-
cerned. Acceleration is a scare word, con-
veying the image of a rush into hyper-
inflation as relentlessly deterministic and
monotonic as the motion of falling bodies.
Realistic attention to the disaggregated
and stochastic nature of wage and price
movements suggests that they will show
diverse and irregular fluctuations around
trends that are difficult to discern and
extrapolate. The central trends, history
suggests, can accelerate for a long, long
time without generating hyper-inflations
destructive of the payments mechanism.
Unanticipated inflation, it is contended,
leads to mistaken estimates of relative
prices and consequently to misallocations
of resources. An example we have already
discussed is the alleged misallocation of
time by workers who over-estimate their
real wages. The same error would lead to
a general over-supply by sellers who con-
tract for future deliveries without taking
correct account of the increasing prices of
the things they must buy in order to ful-
fill the contract. Unanticipated deflation
would cause similar miscalculations and
misallocations. Indeed, people can make
these same mistakes about relative prices
even when the price level is stable. The
mistakes are more likely, or the more
costly to avoid, the greater the infla-
tionary trend. There are costs in setting
and announcing new prices. In an infla-
tionary environment price changes must
be made more frequently-a new catalog
twice a year instead of one, or some for-
mula for automatic escalation of an-
nounced prices. Otherwise, with the inter-
val between announcements unchanged,
the average misalignment of relative prices
will be larger the faster the inflation. The
same problem would arise with rapid
deflation.
Unanticipated inflation and deflation-
and unanticipated changes in relative
prices-are also sources of transfers of
wealth. I will not review here the rich and
growing empirical literature on this sub-
ject. Facile generalizations about the pro-
gressivity or equity of inflationary trans-
fers are hazardous; certainly inflation does
not merit the cliche that it is "the cruelest
tax." Let us not forget that unemployment
has distributional effects as well as dead-
weight losses.
Some moralists take the view that the
government has promised to maintain the
purchasing power of its currency, but this
promise is their inference rather than any
pledge written on dollar bills or in the
Constitution. Some believe so strongly in
this implicit contract that they are willing
to suspend actual contracts in the name of
anti-inflation.
I have long contended that the govern-
ment should make low-interest bonds of
guaranteed purchasing power available
for savers and pension funds who wish to
avoid the risks of unforeseen inflation. The
common objection to escalated bonds is
that they would diminish the built-in
stability of the system. The stability in
question refers to the effects on aggregate
real demand, ceteris paribus, of a change in
the price level. The Pigou effect tells us
that government bondholders whose
wealth is diminished by inflation will spend
less. This brake on old-fashioned gap


### ---Economics-1972-0-19.txt---
inflation will be thrown away if the bonds
are escalated. These considerations are
only remotely related to the mechanisms of
wage and price inflation we have been
discussing. In the 1970's we know that the
government can, if it wishes, control
aggregate demand-at any rate, its ability
to do so is only trivially affected by the
presence or absence of Pigou effects on
part of the government debt.
In considering the intertemporal trade-
off, we have no license to assume that the
natural rate of unemployment is inde-
pendent of the history of actual unem-
ployment. Students of human capital have
been arguing convincingly that earning
capacity, indeed transferable earning ca-
pacity, depends on experience as well as
formal education. Labor markets soggy
enough to maintain price stability may
increase the number of would-be workers
who lack the experience to fit them for
jobs that become vacant.
Macro-economic policies, monetary and
fiscal, are incapable of realizing society's
unemployment and inflation goals simul-
taneously. This dismal fact has long stimu-
lated a search for third instruments to do
the job: guideposts and incomes policies,
on the one hand, labor market and man-
power policies, on the other. Ten to fifteen
years ago great hopes were held for both.
The Commission on Money and Credit in
1961, pp. 39-40, hailed manpower policies
as the new instrument that would over-
come the unemployment-inflation di-
lemma. Such advice was taken seriously in
Washington, and an unprecedented spurt
in manpower programs took place in the
1960's. The Council of Economic Advisers
set forth wage and price guideposts in
1961-62 in the hope of "talking down" the
Phillips curve (pp. 185-90). It is discourag-
ing to find that these efforts did not keep
the problem of inflationary bias from
becoming worse than ever.
So it is not with great confidence or
optimism that one suggests measures to
mitigate the tradeoff. But some proposals
follow naturally from the analysis, and
some are desirable in themselves anyway.
First, guideposts do not wholly deserve
the scorn that "toothless jawboning" often
attracts. There is an arbitrary, imitative
component in wage settlements, and maybe
it can be influenced by national standards.
Second, it is important to create jobs for
those unemployed and discouraged workers
who have extremely low probability of
meeting normal job specifications. Their
unemployment does little to discipline
wage increases, but reinforces their de-
privation of human capital and their other
disadvantages in job markets. The Na-
tional Commission on Technology, Auto-
mation and Economic Progress pointed
out in 1966 the need for public service jobs
tailored to disadvantaged workers. They
should not be "last resort" or make-work
jobs, but regular permanent jobs capable
of conveying useful experience and in-
ducing reliable work habits. Assuming
that the additional services produced by
the employing institutions are of social
utility, it may well be preferable to employ
disadvantaged workers directly rather
than to pump up aggregate demand until
they reach the head of the queue.
Third, a number of measures could be
taken to make markets more responsive to
excess supplies. This is the kernel of truth
in the market-power explanation of in-
flationary bias. In many cases, government
regulations themselves support prices and
wages against competition. Agricultural
prices and construction wages are well-
known examples. Some trade unions follow
wage policies that take little or no account
of the interests of less senior members and
of potential members. Since unions operate
with federal sanction and protection, per-
haps some means can be found to insure
that their memberships are open and that
their policies are responsive to the un-
employed as well as the employed.
As for macro-economic policy, I have


### ---Economics-1972-0-20.txt---
argued that it should aim for unemploy-
ment lower than the zero-inflation rate.
How much lower? Low enough to equate
unemployment and vacancies? We cannot
say. In the nature of the case there is no
simple formula-conceptual, much less.
statistical-for full employment. Society
cannot escape very difficult political and
intertemporal choices. We economists can
illuminate these choices as we learn more
about labor markets, mobility, and search,
and more about the social and distributive
costs of both unemployment and inflation.
Thirty-five years after Keynes, welfare
macroeconomics is still a relevant and
challenging subject. I dare to believe it has
a bright future.
## Economics-1973-0


### ---Economics-1973-0-03.txt---
The ceremonial address of the President
of the American Economic Association is
an art form which, I imagine like most of
my predecessors, I have thoughtfully re-
viewed. On occasion, in the past, the ad-
dresses have dealt with some substantive
problem of our subject or some afflicting
problem of the economy. More often they
have dealt, always a shade critically, with
the methodology of economics. While ac-
cepting the larger science there has been
adverse comment on the detailed elements
of its practice. Economics is insufficiently
normative. Model building has become an
end, not a means. For several recent years
in succession the criticism-which in-
volved a certain element of personal intro-
spection-included an exceptionally grave
attack on mathematical economics. The
style of these addresses, I might note in
passing, is as distinctive as the subject
matter. It features the thoughtful solem-
nity of men who sense that we are speaking
for the ages. It may be worth a moment's
time, on these great occasions, to recall
that ours is a subject which features de-
feated expectations.
I am moved this evening to depart from
the established rites. I should like to con-
cern myself with basic questions of as-
sumption and structure. If this breaks with
tradition, it does not break with present
professional tendency. We meet at a time
when criticism is general when the larger
body of established theory is under exten-
sive attack. Within the last half-dozen
years what before was simply called eco-
nomics in the nonsocialist world has come
to be designated neoclassical economics
with appropriate overtures to the Key-
nesian and post-Keynesian development.
From being a general and accepted theory
of economic behavior this has become a
special and debatable interpretation of
such behavior. For a new and notably
articulate generation of economists a ref-
erence to neoclassical economics has be-
come markedly pejorative.
I would judge as well as hope that the
present attack will prove decisive. The
established theory has reserves of strength.
It sustains much minor refinement which
does not raise the question of overall
validity or usefuliness. It survives strongly
in the textbooks although even in this
stronghold one senses anxiety among the
more progressive or commercially sensi-
tive authors. Perhaps there are limits to
what the young will accept.
And the arrangements by which ortho-
doxy is conserved in the modern academy
also remain formidable. In its first half
century or so as a subject of instruction
and research, economics was subject to
censorship by outsiders. Businessmen and
their political and ideological acolytes
kept watch on departments of economics
and reacted promptly to heresy, the latter
being anything that seemed to threaten
the sanctity of property, profits, a proper
tariff policy, a balanced budget, or which
involved sympathy for unions, public
ownership, public regulation or, in any
organized way, for the poor. The grow-
ing power and self-confidence of the educa-
tional estate, the formidable and growing
complexity of our subject and, no doubt,
the increasing acceptability of our ideas
has largely relieve(d us of this intervention.


### ---Economics-1973-0-04.txt---
In leading centers of instruction faculty
responsibility is either secure or increas-
ingly so. But in place of the old censorship
has come a new despotism. That consists in
defining scientific excellence as whatever is
closest in belief and method to the
scholarly tendency of the people who are
already there. This is a pervasive and
oppressive thing not the less dangerous for
being, in the frequent case, both self-
righteous and unconscious.
But there are problems even with this
control. Neoclassical or neo-Keynesian
economics, though providing unlimited op-
portunity for demanding refinement, has
a decisive flaw. It offers no useful handle
for grasping the economic problems that
now beset the modern society. And these
problems are obtrusive-they will not lie
down and die as a favor to our profession.
No arrangement for the perpetuation of
thought is secure if that thought does not
make contact with the problems that it is
presumed to solve.
I will not omit this evening to mention
the failures of neoclassical theory. But I
want also to urge the means by which we
can reassociate ourselves with reality.
Some of this will summarize past argu-
ment, more a book that is presently to be
published. At this stage even the most con-
servative among my listeners will be re-
assured. To speak well of one's own pub-
lished and unpublished writing, whatever
one's other aberrations, is strongly in our
professional tradition.
I
The most commonplace features of neo-
classical and neo-Keynesian economics are
the assumptions by which power, and
therewith political content, is removed
from the subject. The business firm is sub-
ordinate to the instruction of the market
and, thereby, to the individual or house-
hold. The state is subordinate to the in-
struction of the citizen. There are excep-
tions but these are to the general and con-
trolling rule, and it is firmly on the rule
that neoclassical theory is positione(l. If
the business firm is subordinate to the
market--if that is its master--then it does
not have power to deploy in the economy
save as this is in the service of the market
and the consumer. And the winning of
action to influence or rig the behavior of
markets apart, it cannot bring power to
bear on the state for there the citizen is in
charge.
The decisive weakness in neoclassical
and neo-Keynesian economics is not the
error in the assumptions by which it elides
the problem of power. The capacity for
erroneous belief is very great, especially
where it coincides with convenience.
Rather in eliding power--in making eco-
nomics a nonpolitical subject---neoclassi-
cal theory, by the same process, destroys
its relation with the real world. The prob-
lems of this world, moreover, are increasing,
both in number and in the depth of their
social affliction. In consequence neoclassi-
cal and neo-Keynesian economics is rele-
gating its players to the social sidelines
where they either call no plays or urge the
wrong ones.
Specifically the exclusion of power and
the resulting political content from eco-
nomics causes it to foretell only two in-
trinsic and important economic problems.
One of these is the microeconomic problem
of market imperfection-more specifically
of monopoly or oligopoly in product or
factor markets leading to aberration in
resource and income distribution. The
other is the macroeconomic problem of un-
employment or inflation-of a deficiency
or excess in the aggregate demand for
goods and services, including that asso-
ciated with monetary effects. And on both
problems the failure is dramatic. Neo-
classical economics leads to the wrong
solution of the microeconomic problem
and to no solution of the macroeconomic


### ---Economics-1973-0-05.txt---
problem. Meanwhile it leaves a whole
galaxy of other urgent economic issues
largely untouched.
It is now the considered sense of the
community, even of economists when un-
hampered by professional doctrine, that
the most prominent areas of market
oligopoly-automobiles, rubber, chemi-
cals, plastics, alcohol, tobacco, detergents,
cosmetics, computers, bogus health rem-
edies, space adventure-are areas not of
low but of high development, not of in-
adequate but of excessive resource use.
And there is a powerful instinct that in
some areas of monopoly or oligopoly,
most notably in the production of weapons
and weapons systems, resource use is dan-
gerously vast.
In further contradiction of the estab-
lished microeconomic conclusions, we have
an increasing reaction by the community
to deficient resource use in industries that,
at least in the scale and structure of the
firm, approach the market model. Housing,
health services, and local transportation
are among the leading cases. The depriva-
tion and social distress that follow from
the poor performance of these industries
are also something that, in their nondoctri-
nal manifestation, most economists take
for granted.
The defender of the established doctrine
does, of course, argue that excess and
deprivation in resource use in the areas
just mentioned reflect consumer choice.
And in the areas of deprivation he can
rightly insist that the fault lies with firms
that, though small, are local monopolies
or reflect the monopoly power of unions.
These explanations beg two remarkably
obvious questions: Why does the modern
consumer increasingly tend to insanity,
increasingly insist on self-abuse? And why
do little monopolies perform badly and the
big ones too well?
In fact the neoclassical model has no
explanation of the most important micro-
economic problem of our time. That prob-
lem is why we have a highly unequal
development as between industries of
great market power and industries of
slight market power, with the develop-
ment, in defiance of all doctrine, greatly
favoring the first.1
The macroeconomic failure has been, if
anything, more embarrassing. Save in its
strictly mystical manifestation in one
branch of monetary theory, modern macro-
economic policy depends for its validity
and workability on the neoclassical mar-
ket. That market, whether competitive,
monopolistic, or oligopolistic, is the ulti-
mate and authoritative instruction to the
profit-maximizing firm. When output and
employment are deficient, policy requires
that aggregate demand be increased; this
is an instruction to the market to which
firms in turn respond. When the economy
is at or near the effective capacity of the
plant and the labor force and inflation is
the relevant social discomfort, the remedy
is reversed. Demand is curtailed; the result
is either an initial effect on prices or a
delayed one as surplus labor seeks em-
ployment, interest rates fall and lower
factor costs bring stable or lower prices.
Such is the accepted basis of policy. It
follows faithfully from the neoclassical
faith in the market. The practical con-
sequences of pursuing it need no elucida-
tion. It has been tried in recent years in
every developed country. The common
result has been politically unacceptable
unemployment, persistent and (in my
view) socially damaging inflation or, more
often, a combination of the two. The ex-
treme failure has been, not surprisingly,
in the most advanced industrial country,


### ---Economics-1973-0-06.txt---
the United States. But the recent experi-
ence of Britain has been almost equally
disenchanting. One gathers that there may
be Canadian politicians who now believe
that a combination of unemployment and
inflation is not the best platform on which
to fight a general election.
We should not deny ourselves either the
instruction or the amusement that comes
from the recent history of the United
States in this matter. Four years ago Mr.
Nixon came to office with a firm commit-
ment to neoclassical orthodoxy. In this he
was supported by some of its most distin-
guished and devout exponents in all the
land. His subsequent discovery that he
was a Keynesian involved no precipitate
or radical departure from this faith. The
discovery came thirty-five years after The
General Theory; as I have just noted, all
neo-Keynesian policy rests firmly on the
paramount role of the market. But then a
year and. a half ago, facing reelection, he
found that his economists' comnmitment
to neoclassical and Keynesian orthodoxy,
however admirable in the abstract, was a
luxury that he could no longer afford. He
apostatized to wage and price control; so,
with exemplary flexibility of mind, did
his economists although admittedly this
acceptance of the real world has still to
survive its critical test which is the
apostates' return to computers and class-
rooms. But our admiration for this pliabil-
ity should not keep us from recalling that,
when the President changed course, no
American economists were anywhere
working on the policy he was forced by
circumstances to adopt. And it is even
more disturbing that few are now working
on the policy which we have been forced
to follow.
More economists, in fact, are still con-
cerning themselves with the effort to re-
concile controls with the neoclassical
market. This has involved an unrewarding
combination of economics and archeology
with wishful thinking. It holds that an
inflationary momentum developed during
the late 1960's in connection with the
financing--or underfinancing of the Viet-
nam war. And inflationary expectation
became part of business and trade union
calculation. The momentum and expecta-
tion still survive. The controls are neces-
sary until these are dissipated. Then the
neoclassical and neo-Keynesian world will
return, along with the appropriate policies,
in all their quiet comfort. We may be sure
that will not happen. Nor will we expect it
to happen if we see the role of power and
political decision in modern economic be-
havior.
II
In place of the market system, we must
now assume that for approximately half of
all economic output there is a power or
planning system. (The latter term seems
to me more descriptive, less pejorative and
thus preferable.) The planning system con-
sists in the United States of, at the most,
2,000 large corporations. In their opera-
tion they have power that transcends the
market. They rival where they do not
borrow from the power of the state. My
views on these matters will be familiar at
least to some, and I shall spare myself the
pleasure of extensive repetition. I cannot
think that the power of the modern cor-
poration, the purposes for which it is used
or the associated power of the moclern
union would seem implausible or even very
novel were they not in conflict with the
vested (loctrine.
Thus we agree that the modern cor-
poration, either by itself or in conjunction
with others, has extensive influence over
its prices and its major costs. Can we
doubt that it goes beyond its prices and
the market to persuade its customers? Or
that it goes back of its costs to organize
supply? Or that from its earnings or the
possession of financial afiliates it seeks to


### ---Economics-1973-0-07.txt---
control its sources of capital? Or that its
persuasion of the consumer joined with the
similar effort of other firms and with the
more than incidental blessing of neoclassi-
cal pedagogy helps establish the values
of the community, notably the association
between well-being and the progressively
increased consumption of the products of
this part of the economy?
And as citizens, if not as scholars, we
would not deny that the modern corpora-
tion has a compelling position in the
modern state. What it needs in research
and development, technically qualified
people, public works, emergency financial
support, becomes public policy. So does the
military procurement that sustains the
demand for numerous of its products. So,
perhaps, does the foreign policy that
justifies the military procurement. And
the means by which this power is brought
to bear on the state is widely accepted. It
requires an organization to deal with an
organization. And between public and
private bureaucracies between GM and
the Department of Transportation, Gen-
eral Dynamics and the Pentagon there is
a deeply symbiotic relationship. Each of
these organizations can do much for the
other. There is even, between them, a
large and continuous interchange of execu-
tive personnel.
Finally over this exercise of power and
much enhancing it is the rich gloss of
reputability. The men who guide the
modern corporation, including the finan-
cial, legal, technical, advertising, and other
sacerdotal authorities in corporate func-
tion, are the most respectable, affluent,
and prestigious members of the national
community. They are the Establishment.
Their interest tends to become the public
interest. It is an interest that even some
economists find it comfortable and reward-
ing to avow.
That interest, needless to say, is pro-
foundly concerned with power with win-
ing acceptance by others of the collective
or corporate purpose. It does not disavow
profits. These are important for ensuring
the autonomy of the management what
I have called the technostructure and for
bringing the supply of capital within the
control of the firm. Profits are also a
source of prestige and therewith of influ-
ence. But of paramount importance is the
much more directly political goal of
growth. Such growth carries a strong eco-
nomic reward; it directly enhances the
pay, perquisites, and opportunities for
promotion of the members of the techno-
structure. And it consolidates and enhances
authority. It does this for the individual-
for the man who now heads a larger
organization or a larger part of an organi-
zation than before. And it increases the
influence of the corporation as a whole.
Neoclassical economics is not without an
instinct for survival. It rightly sees the
unmanaged sovereignty of the consumer,
the ultimate sovereignty of the citizen and
the maximization of profits and resulting
subordination of the firm to the market
as the three legs of a tripod on which it
stands. These are what exclude the role of
power in the system. All three propositions
tax the capacity for belief. That the
modern consumer is the object of a massive
management effort by the producer is not
readily denied. The methods of such man-
agement, by their nature, are embarrass-
ingly visible. It can only be argued that
somehow it all cancels out. Elections in
the United States and Canada are now
being fought on the issue of the subordina-
tion of the state to corporate interest. As
voters, economists accept the validity of
the issue. Only their teaching denies it.
But the commitment of the modern cor-
porate bureaucracy to its expansion is, per-
haps, the clearest of all. That the modern
conglomerate always pursues profit over
aggrandizement is believed by none. It is a
commonplace of these last years, strongly


### ---Economics-1973-0-08.txt---
reflected in securities' prices, that agglom-
eration has always been good for growth
but often bad for earnings.
There remains in the modern economy-
and this I stress a world of small firms
where the instruction of the market is still
paramount, where costs are given, where
the state is remote and subject through the
legislature to the traditional pressures of
economic interest groups and where profit
maximization alone is consistent with sur-
vival. We should not think of this as the
classically competitive part of the system
in contrast with the monopolistic or
oligopolistic sector from which the plan-
ning system has evolved. Rather, in its
combination of competitive and monopo-
listic structures, it approaches the entire
neoclassical model. We have, to repeat,
two systems. In one, power is still, as ever,
contained by the market. In another and
still evolving system, power extends in-
completely but comprehensively to mar-
kets, to the people who patronize them, to
the state and thus, ultimately, to resource
use. The coexistence of these two systems
becomes, in turn, a major clue to economic
performance.
III
Power being so comprehensively de-
ployed in a very large part of the total econ-
omy, there can no longer, except for rea-
sons of game-playing or more deliberate
intellectual evasion, be any separation by
economists between economics and poli-
tics. When the modern corporation ac-
quires power over markets, power in the
community, power over the state, power
over belief, it is a political instrument,
different in form and degree but not in
kind from the state itself. To hold other-
wise to deny the political character of
the modern corporation is not merely to
avoid the reality. It is to disguise the real-
ity. The victims of that disguise are those
we instruct in error. The beneficiaries are
the institutions whose power we so dis-
guise. Let there be no question: Eco-
nomics, so long as it is thus taught, be-
comes, however unconsciously, a part of an
arrangement by which the citizen or
student is kept from seeing how he is, or
will be, governed.
This does not mean that economics now
becomes a branch of political science. That
is a prospect by which we would rightly be
repelled. Political science is also the captive
of its stereotypes including that of citizen
control of the state. Also while economics
cherishes thought, at least in principle,
political science regularly accords rever-
ence to the man who knows only what has
been done before. Economics does not be-
come a part of political science. But
politics does and must become a part of
economics.
There will be fear that once we abandon
present theory, with its intellectually
demanding refinement and its increasing
instinct for measurement, we shall lose the
filter by which scholars are separated from
charlatans and windbags. These latter are
always a danger, but there is more danger
in remaining with a world that is not real.
And we shall be surprised, I think, at the
new clarity and intellectual consistency
with which we see our world, once power is
made a part of our system. To such a view
let me now turn.
IV
In the neoclassical view of the economy
a general identity of interest between
the goals of the business firm and those
of the community could be assumed. The
firm was subject to the instruction of
the community, either through the market
or the ballot box. People could not be fun-
damentally in conflict with themselves-
always given some reasonable decency in
income distribution. Once the firm in the
planning system is seen to have compre-
hensive power to pursue its own interest,


### ---Economics-1973-0-09.txt---
this assumption becomes untenable. Per-
haps by accident its interests are those of
the public but there is no organic reason
why this must be so. In the absence of
proof to the contrary, divergence of in-
terest, not identity of interest, must be
assumed.
The nature of the conflict also becomes
predictable. Growth being a principal goal
of the planning system it will be great
where power is great. And in the market
sector of the economy, growth will, at least
by comparison, be deficient. This will not,
as neoclassical doctrine holds, be because
people have an amiable tendency to mis-
understand their needs. It will be because
the system is so constructed as to serve
badly their needs and then to win greater
or less acquiescence in the result. That the
present system should lead to an excessive
output of automobiles, an improbable
effort to cover the economically developed
sections of the planet with asphalt, a lunar
preoccupation with moon exploration, a
fantastically expensive and potentially
suicidal investment in missiles, submarines,
bombers, and aircraft carriers, is as one
would expect. These are the industries
with power to command resources for
growth. And central to public purpose
to sound resource utilization will be a
cutback in such industries, as all instinct
now suggests. Thus does the introduction
of power as a comprehensive aspect of our
system correct present error. Let us not
fail to note that these are exactly the in-
dustries in which an uncomplicated neo-
classical view of monopoly and oligopoly
and of profit maximization at the expense
of ideal resource use would, of all things,
suggest an expansion of output. How
wrong are we allowed to be!
The counterpart of excessive resource
use in the planning system where power is
comprehensively deployed is a relatively
deficient resource use where power is cir-
cumscribed. Such will be the case in the
part of the economy where competition
and entrepreneurial monopoly as distinct
from great organization are the rule. And
if the product or service is closely related
to comfort or survival, the discontent will
be considerable. That housing, health
services, local transportation, some house-
hold services, are now areas of grave in-
adequacy is agreed. It is in such industries
that all modern governments seek to ex-
pand resource use. Here, in desperation,
even the devout free enterprisers accept
the need for social action, even of social-
ism.
Again, we may observe, the error of
economics is prejudicial. Although as
citizens we advocate restraint in the area
of excessive resource use, our teaching does
not. And though as citizens we urge social
action where the firm approaches the neo-
classical norm, our teaching does not. In
this latter case we not only disguise cor-
porate power but we make remedial action
in such areas as housing, health care,
transportation, also abnormal the con-
sequence of sui generis error that is never
quite explained. This is unfortunate for
here are tasks that require imagination,
pride and determination.
V
When power is admitted to our calculus,
our macroeconomic embarrassment also
disappears. Economics makes plausible
what governments are forced, in practice,
to do. Corporations have power in their
markets. So, and partly in consequence, do
unions. The competitive claims of unions
can most conveniently be resolved by pass-
ing the cost of settlement along to the
public. Measures to arrest this exercise of
power by limiting aggregate demand must
be severe. And, not surprisingly, the power
of the planning system has been brought to
bear to exclude those macroeconomic mea-
sures that have a primary effect on that
system. Thus monetary policy is entirely


### ---Economics-1973-0-10.txt---
permissible; that is at least partly because
its primary effect is on the neoclassical
entrepreneur who must borrow money.
Monetary constraint is far less painful
for the large established corporation which,
as an elementary exercise of power, has
ensured itself a supply of capital from
earnings or financial affiliates or morally
affiliated banks. The power of the planning
system in the community has also won
immunity for public expenditures impor-
tant to itself-highways, industrial re-
search, rescue loans, national defense.
These have the sanction of a higher public
purpose. A similar if still slightly less suc-
cessful effort is being made on behalf of
corporate and personal taxes. So fiscal
policy has also been accommodated to the
interests of the planning system.
Thus the inevitability of controls. The
interaction of corporate and trade union
power can be made to yield only to the
strongest fiscal and monetary restraints.
Those restraints that are available have a
comparatively benign effect on those with
power, but they weigh adversely on people
who vote. When no election is in prospect,
perhaps such a policy is possible. It will
earn applause for its respectability. But it
cannot be tolerated by anyone who must
weigh its popular effect.
As with the need for social action and
organization in the market sector there
are many reasons why it would be well
were economists to accept the inevitability
of wage and price control. It would help
keep politicians, responding to the reso-
nance of their own past instruction, from
supposing controls to be wicked and un-
natural and hence temporary and to be
abandoned whenever they seemed to be
working. This is a poor mood in which to
develop sound administration. And it
would cause economists themselves to
consider how controls can be made work-
able and how the effect on income distri-
bution can be made equitable. With con-
trols this last becomes a serious matter.
The market is no longer a disguise for
inequality, however egregious, in in-
come distribution. Much inequality must
be seen to be the result of relative power.
VI
When power is made part of our system,
yet other matters of considerable current
moment are illuminated. Thus the counter-
part of systemic differences in development
as between the planning and market sec-
tors of the economy is systemic sectoral
differences in income. In the neoclassical
system, resource mobility is assumed,
broadly speaking, to equalize inter-in-
dustry return. If there is inequality, it is
the result of barriers to movement. Now
we see that, given its comprehensive mar-
ket power, the planning system can protect
itself from adverse movements in its terms
of trade. The same power allows it to
accept unions for it need not absorb even
temporarily their demands. In the market
system, some areas of monopoly or union
power apart, there is no similar control of
the terms of trade. Given the absence of
market power there can be no similar
yielding on wage costs for there is no
similar certainty that they can be passed
on. (It is because of the character of the
industry he seeks to organize, not his
original power, that Cesar Chavez is for so
many the new Lenin.) And, in the market
system, the self-employed have the option
not present in the planning system of
reducing their own wages (and sometimes
those of families or immediate employees)
in order to survive.
Thus there is a built-in inequality in
income between the two systems. And
thus also the case for minimum wage
legislation, support to trade unions in
agriculture, price support legislation, and
most important, perhap5, a floor under
family income as antidotes to such inter-


### ---Economics-1973-0-11.txt---
industry inequality. Again this view of
matters fits our present concerns. Mini-
mum wage legislation, price support
legislation, and support to collective bar-
gaining are all questions of continuing
political controversy as they apply to
small business and agriculture. They are
not serious issues in highly organized in-
dustry in the planning system. And the
question of a floor under family income, a
matter of intense political argumeint, has
recently divided workers in the planning
system who would not be beneficiaries
from those in the market system who
would be. Again there is reassurance in a
view of the economy that prepares us for
the politics of our time.
The inclusion of power in economic cal-
culus also prepares us for the great debate
over the environment. It is the claim of
neoclassical economics that it foresaw
possible environmental consequences from
economic development-that it, some
time ago, embraced the concept of external
diseconomies of production and, by infer-
ence, of consumption. Alas, this is a modest
claim. The noninclusion of external dis-
economies was long viewed as a minor
defect of the price system-an after-
thought for an hour's classroom discus-
sion. And, as E. J. Mishan has observed,
it was largely ignored in the textbooks.
Nor does the notion of external disecon-
omies now offer a useful remedy. No one
can suppose, or really supposes, that more
than a fraction of the damage especially
that to the beauty and tranquility of our
surroundings -could be compensated in
any useful way by internalizing external
diseconomies.
If growth is the central and rewarding
purpose of the firm and if power is com-
prehensively available to impose this goal
on the society, the possibility of conflict
between private growth and public pur-
pose as regards the environment is im-
mediately plausible. So, since this power
depends extensively not on force but
persuasion, is the effort to make pollution
seem palatable or worth the cost, including
the effort to nmake advertising of remedial
action a substitute for action. And so is the
remedy to which all industrial countries
are being forced. This is not, primarily, to
internalize external diseconomies. Rather
it is to specify the legal parameters within
which growth may proceed or, as in the
case of automobile use in central cities,
airplane use over urban areas, the SST,
industrial, commercial, and residential
appropriation of countryside andI roadside,
the kinds of growth that are inconsistent
with public purpose. We would have saved
much corruption of our surroundings if
our economics had held such action to be
the predictable consequence of the pursuit
of present economic goals and not the
exceptional result of a peculiar aberration
of the price system.
We had best, in any case, have the right
guide to action for the future for there is a
strong conservative case for such guidance.
While economists toy weakly with ex-
ternal diseconomies, others are arguing
that growth itself is the villain. They are
seeking its extinction. To see environ-
mental damage as a natural consequence
of planning power and purpose and to see,
in consequence, the need for confining
growth within parameters that protect the
public interest could be important for en-
suring continued economic growth.
Finally, when power becomes part of our
system, so does Ralph Nader. We are
prepared for the explosion of concern now
called consumerism. If the consumer is the
ultimate source of authority, his abuse is
an occasional fault. He cannot be funda-
mentally at odds with an economic system
that he commands. But if the producing
firm has comprehensive power and pur-
poses of its own, there is every likelihood
of conflict. Technology is then subordinate
to the strategy of consumer persuasion.


### ---Economics-1973-0-12.txt---
Products are changed not to make them
better but to take advantage of the belief
that what is new is better. There is a
high failure rate in engineering not what is
better but what can be sold. The con-
sumer-the unpersuaded or disenchanted
consumer rebels. This is not a rebellion
against minor matters of fraud or misin-
formation. It is a major reaction against a
whole deployment of power by which the
consumer is made the instrument of pur-
poses that are not his own.
VII
There are two conclusions to which this
exercise-to which incorporation of power
into our system compels us. The first, in
a way, is encouraging. It is that econo-
mists' work is not yet done. On the con-
trary, it is just beginning. If we accept the
reality of power as part of our system, we
have years of useful work ahead of us.
And since we will be in touch with real
issues, and since issues that are real inspire
passion, our life will, again, be pleasantly
contentious, perhaps even usefully dan-
gerous.
The other conclusion concerns the state.
For when we make power and therewith
politics a part of our system, we can no
longer escape or disguise the contradictory
character of the modern state. The state is
the prime object of economic power. It is
captured. Yet on all the matters I have
mentioned the restrictions on excessive
resource use, organization to offset in-
adequate resource use, controls, action to
correct systemic inequality, protection of
the environment, protection of the con-
sumer-remedial action lies with the state.
The fox is powerful in the management of
the coop. To this management the chickens
must look for redress.
Thus perhaps our greatest question. Is
emancipation of the state from the control
of the planning system possible? No one
knows. And in the absence of knowledge
no one certainly will suggest that it will be
easy. But there is a gleam of encourage-
ment. As ever circumstances are forcing
the pace.
In the United States the recent election
was fought, all but exclusively, over issues
in which the purposes of the planning sys-
tem or its major participants diverge from
those of the public. The question of
defense expenditures is such an issue. That
of tax reform is another. The deprivation
in housing, mass transportation, health
services, city services, is yet another-one
that reflects the relative inability of these
industries to organize and command re-
sources. The question of a guaranteed
income is another such issue. Its effect, as
I have noted, is on incomes outside the
planning system on the exploited in the
market system, those who are rejected by
both. The environment is such an issue-
with its conflict between the technostruc-
ture's goal of growth and the public con-
cern for its surroundings. Only wage and
price control was not an issue in the recent
election. That was almost certainly be-
cause economists of orthodox tendency
on both sides found the prospect too em-
barrassing to discuss.
I do not mention these issues with any
purpose save to show that the questions
that emerge when power is made a part of
our calculus are present and real. We need
hardly remind ourselves that political
issues are made not by parties and politi-
cians but by circumstance.
Once power is made part of our system,
we will not of course escape the political
contention that comes from dealing with
issues that are real. This brings me to my
last point. I do not plead for partisanship
in our economics but for neutrality. But
let us be clear as to what is neutral. If the
state must be emancipated from economic
interest, a neutral economics would not
deny the need. This is what economics now


### ---Economics-1973-0-13.txt---
does. It tells the young and susceptible
and the old and vulnerable that economic
life has no content of power and politics
because the firm is safely subordinate to
the market and to the state and for this
reason it is safely at the command of the
consumer and citizen. Such an economics
is not neutral. It is the influential and in-
valuable ally of those whose exercise of
power depends on an acquiescent public.
If the state is the executive committee of
the great corporation and the planning
system, it is partly because neoclassical
economics is its instrument for neutraliz-
ing suspicion that this is so. I have spoken
of the emancipation of the state from eco-
nomic interest. For the economist there
can be no doubt as to where this task be-
gins. It is with the emancipation of eco-
nomic belief.
## Economics-1974-0


### ---Economics-1974-0-03.txt---
The content of presidential addresses to
this Association provides a fine example of
a random variable with a high variance. It
might even be a good subject for econo-
metric analysis; the variation might be
explained in terms of the economic condi-
tions of the moment, previous intellectual
investments, or even, for boldly interdis-
ciplinary analysis, the psychological states
or class origins of the speakers or the
audience. But no doubt captious theorists
like myself will object that the endogenous
variable is not cardinally measurable and
probably not even ordinally measurable;
tougher-minded econometricians will worry
about collinearity in the predetermined
variables; and practical-minded policy
analysts will see no discernible effect on
the gross national product, the price level,
or the balance of payments through effects
on either fiscal policy or the stock of
money. The last group, the policy-oriented,
are perhaps the least accurate; at least
according to Keynes, the effect of ideas on
policy is dominant, though the lag may be
as variable as and a good deal longer than
that of the stock of money on money gross
national product.
It is now more fashionable than it used
to be for statisticians to be told to take a
good look at their data before fitting
models. Taking presidential addresses as
our data, we find most frequently a review
of the speaker's main research concerns
but also expressions of methodological or
ethical concerns, historical surveys of vary-
ing degrees of erudition and humor, and,
least frequently, new points of view on sig-
nifi-cant problems of economics.
I am taking a somewhat different tack
today; it will be an expression of discon-
tents and expectations. As I shall try to
argue, the uncertainties about economics
are rooted in our need for a better under-
standing of the economics of uncertainty;
our lack of economic knowledge is, in good
part, our difficulty in modelling the ig-
norance of the economic agent.
Critical aspects of this need for reorien-
tation of theory have been recognized by
many scholars in the last quarter-century
and particularly in the last decade. I view
my remarks today as a summary and per-
spective on a widely shared development
of thinking.
The starting point of discussion must
still be the much-abused neoclassical
theory. No really cohesive alternative
which aspires to the same level of com-
pleteness exists. The neoclassical model is
founded on two concepts, which are con-
siderably different in nature. One is the
notion of the individual economic agent,
whose behavior is governed by a criterion
of optimization under constraints which
are partly peculiar to the agent, such as
production functions, and partly terms of
trade with the economic system as a whole.


### ---Economics-1974-0-04.txt---
The other is the market; here, the aggre-
gate of individual decisions is acknowl-
edged, and the terms of trade adjusted un-
til the decisions of the individuals are
mutually consistent in the aggregate, i.e.,
supply equals demand.
The neoclassical theory, especially in its
competitive form, can be and has been
given a rich formal development. Paren-
thetically, one cause for the persistence of
neoclassical theory in the face of its long
line of critics is precisely that for some
reason of mathematical structure, the neo-
classical theory is highly manipulable and
flexible; when faced with a specific issue,
it can yield meaningful implications rela-
tively easily. Although I intend to air
complaints and desires for change today,
I must express my unabashed admiration
for the accomplishments of the neoclassical
viewpoint. In its most formal statement,
we simply use for analysis the equilibrium
conditions of the individual agent and of
the market, without inquiry as to how they
come to hold. Yet even these statements
turn out to yield revealing insights in the
workings of resource allocation. Why have
medical costs risen so rapidly relative to
other prices since 1967? The upward shift
in demand due to Medicare and Medicaid
with a price-inelastic supply of physicians
and hospitals provides a simple straight-
forward answer; I cannot really imagine
how a Marxian or a neo-Ricardian would
even approach the question, though I sup-
pose they might dismiss it as unimportant.
The explanation of environmental prob-
lems as due to the nonexistence of markets
is similarly an insight of purely neoclassical
origin. The now-demonstrated fact that
flexible exchange rates are a feasible way
of conducting international finance is a
triumph of theoretical insights over prac-
tical men's convictions. More broadly, the
shifts in long-run resource allocation as
motivated by returns and, in particular,
the absence of a secular trend in techno-
logical unemployment to the perpetual
surprise of the layman fit in well with the
neoclassical formulation but have no ready
explanation in alternate models.
Of course, the implications of neoclassi-
cal theory have also been conspicuously
falsified in important ways. Most notably,
the recurrent periods of unemployment
which have characterized the history of
capitalism are scarcely compatible with a
neoclassical model of market equilibrium.
A post-Keynesian world in which unem-
ployment is avoided or kept at tolerable
levels by recurrent alterations in fiscal or
monetary policy is no more explicable by
neoclassical axioms, though the falsifica-
tion is not as conspicuous.
Inequality in economic development
among countries and among groups and
regions within a country provides a second,
somewhat complicated difficulty for neo-
classical theory. A purely neoclassical an-
swer would explain differences in per
capita income by differences in physical
and human assets per capita. This of
course raises the further question, how
this came to be, a question which would
require a fully dynamic model to answer;
but I think the more compelling problem
is that the differences in income seem
much too vast to be explained by factor
differences. Indeed, in the presence of in-
ternational trade and especially interna-
tional capital movements, wage differences
should be very strongly reduced compared
with what would occur in autarchic states
where domestic capital is the limiting fac-
tor. Hence, we come immediately to the
explanation that there are differences in
the production possibility sets of the
different countries. This conclusion is a
legitimate and important use of neoclassi-
cal analysis; but obviously it raises new
questions, to which we will return.
I pass by the whole tangle of questions
relating to the holding of money and the
general level of prices. In its pure form,


### ---Economics-1974-0-05.txt---
neoclassical theory is a theory of relative
prices. Monetary theories vaguely related
to it in spirit can be grafted on to it, but
none have succeeded in achieving a
genuine synthesis.
The two failures of the neoclassical ex-
planatory mechanism reflect on its founda-
tions in quite different ways. The existence
of unemployment is clearly a direct con-
tradiction to the notion of the smoothly
clearing market. One must of course be
aware that the official measure of unem-'
ployment is by no means a simple inequal-
ity between supply and demand; it ag-
gregates a whole range of distinct markets,
it does not separate out voluntary and in-
voluntary unemployment according to the
tests of economic theory, and it does not
take account of unfilled jobs. I do not sub-
scribe, I hasten to say, to the sometimes
expressed view that all unemployment is
essentially voluntary, an unwillingness to
search or whatnot; indeed, the official
measure may underestimate the degree of
disequilibrium in the labor market, par-
ticularly with regard both to underutiliza-
tion of advanced skills and discouraged job
seekers. With all these qualifications, it is
clear that statistical unemployment does
correspond to a disequilibrium as that
term is used in the basic neoclassical
model; there are two individuals, identical
in productive capacity and both willing
to work at a given wage, but one is working
at that wage and the other is not.
Differential levels of economic develop-
ment, on the other hand, point to a diffi-
culty with the other fundamental concept;
the conditions of optimization. If countries
differ in their production possibility sets,
then firms, occupying similar economic
positions, are facing different constraints
on their optimization. This does not con-
tradict the fundamental assumption of
optimizing behavior, but it does raise
severe questions about its interpretation.
The simplest hypothesis is to take the
technological conditions as data, possibly
varying over time due to exogenous changes
in scientific knowledge. But here we are
asserting that two contemporaries have
different access to productive knowledge.
Clearly, we are saying something about the
conditions of transmission of knowledge
across national boundaries, and of course
the same questions arise among firms or
workers within a single economy. The con-
straints upon the firm's optimization begin
to seem more like variables to be explained
than like constants exogenously given.
Let me look now at the two basic con-
cepts from the inside, from the point of
view of our direct perceptions which moti-
vate the modelling. The two are far from
parallel. The optimization by individual
agents has a sense of concreteness about it,
for all the sophisticated mathematical
ability with which we theorists endow the
agents. They behave in ways whose logic
we understand. They seek to achieve goals
which are reasonable to postulate, and we
can specify constraints which clearly are
real. It can be and has been correctly ob-
jected that our models are too simple; we
ignore other arguments in the utility func-
tion, power, status, social approval, or
whatnot that also motivate individuals,
and we ignore some constraints, capacity
for calculation and social controls. But the
model is comprehensible, and the motives
and constraints we deal with are real and
important.
The market, on the other hand, is a
much more ethereal construct. Who ex-
actly is it that is achieving the balancing of
supply and demand? Where in fact is the
information on bids and offers needed for
equilibration actually collected and stored?
Right from the beginning of neoclassical
theory, the difficulty of explaining markets
in terms of individual self-seeking be-
havior was perceived. Parenthetically, this
is one example of the superiority of neo-
classical analysis to its predecessors, de-


### ---Economics-1974-0-06.txt---
spite the current fashion for exalting
Ricardo over his successors; Ricardo im-
plicitly equated supply and demand on all
his markets without ever realizing the
problematic nature of this process. Jevons
felt obliged to enunciate explicitly a Law
of Indifference, enforced by arbitrage; but
this does not really meet the problem when
the market is out of equilibrium, for the
arbitrage might well not be feasible.
Menger, at least according to Hayek and
Streissler, concentrated on individual trades
and ignored the market completely. It is
Walras's auctioneer which has proved to
have had the most enduring effect on sub-
sequent theoretical development, and the
stability theory which flows from that con-
cept is still the subject of vigorous theo-
retical development, though very little
empirical application. What is envisioned
is a feedback mechanism in which errors
in the price are successively corrected by
reference to the disequilibria they gener-
ate. This view specifies and makes feasible
the operations of the market. But on one
hand the stability models are far from
adequate representations even of the dy-
namics of the neoclassical models and,
what may be connected, the results are by
no means necessarily favorable to the
stability of the adjustment process; and on
the other hand, the motivations for the
feedback to operate are obscure.
Let me be clear on one methodological
point. The fact that our intuitive under-
standing, our verstehen as the German
social methodologists call it, of the market
as an institution is not entirely satisfactory
does not mean that we should not use the
perfect market as a model, at least pending
further development. Certainly, as Popper
and Friedman hold, the acceptability of a
theory is to be judged by its ability to
predict and understand phenomena. The
theory of the perfect market is in an in-
teresting way complementary to Key-
nesian theory. We have never been able to
integrate Keynesian viewpoints into stan-
dard neoclassical theory, in terms of in-
dividual motivation, yet this theory, with
its various modifications, has been a most
serviceable tool of prediction and control.
In fact, it is useful in domains where com-
petitive theory fails and vice versa. Neither
theory is good, however, at predicting dy-
namic processes, the short-run changes
which are responses to disequilibria, and it
is here that the pressure for a more satis-
factory model arises.
Hold in abeyance for a moment our con-
siderations about the market. Let us return
to the optimization problem of the in-
dividual. One aspect on which we put a
good deal of weight, particularly in our less
formal discussions, is that a market system
is informationally economical. That is, we
tend to regard it as a virtue of the system
that the individual agent need not know
very much. Specifically, he is supposed to
know the motivation and production con-
ditions which define him, i.e., his utility
function and production possibility set,
together with the prices of the commodi-
ties he buys and sells. The economic sys-
tem, taken as a whole, has vastly more in it
than any one individual knows; it contains
the utility functions and production pos-
sibilities of all individual agents. Indeed,
the apparent modesty of the information
needed is one of the most appealing aspects
of the neoclassical model, both in the
descriptive sense that the individual's de-
cision problems appear manageable for him
and for the economist studying him, and
in the normative sense that the system
permits its members to spend their time
and effort at producing goods rather than
in unnecessary duplication of information.
But clearly this simplification of the in-
dividual's decision making is made possible
only because the markets have supplied
the information economized on, in the form
of prices. In equilibrium, at least, the sys-
tem as a whole gives the impression of


### ---Economics-1974-0-07.txt---
great economy in the handling of informa-
tion, presumably because transmission of
prices is in some significant sense much
cheaper than transmission of the whole set
of production possibilities and utility
functions. It is this point which emerged
in the great debate over the feasibility of
socialism begun by Ludwig von iMises's
attack and usually thought of as conclud-
ing with the work of Oskar Lange and
Abba Lerner in the 1930's; though it should
be added many of the essential points had
already been made earlier by Vilf redo
Pareto and Enrico Barone. XVhat was ar-
gued, in effect, was that a socialist system
could use the price system and therefore
achieve whatever economies in informa-
tion it does achieve; and if the equilibrium
conditions are written out they do give the
appearance of relative simplicity. But
what was left obscure is a more definite
measure of information and its costs, in
terms of which it would be possible to as-
sert the superiority of the price system
over a centralized alternative. Though I
feel that current work has brought about a
considerable clarification, we still have no
definite measure. Indeed, in some respects,
more recent developments have made the
answers less clear. Several writers, in both
Western and socialist countries, have noted
that alternative decentralized schemes
exist where quantity messages rather than
price messages are transmitted in the suc-
cessive stages of approximation and that
such schemes also have efficient equilibrium
points. Indeed, with the development of
mathematical programming and high-
speed computers, the centralized alterna-
tive no longer appears preposterous. After
all, it would appear that one could mimic
the workings of a decentralized system by
an appropriately chosen centralized al-
gorithm. While there is more to the story
than these few remarks, they do make the
point that if we are going to take informa-
tional economy seriously, we have to add
to our usual economic calculations an ap-
propriate measure of the costs of informa-
tion gathering and transmission.
But actually the comparisons between
socialist and capitalist resource allocation
systems have tended to overlook some of
the most obvious facts while examining
finer points closely. As we all know, both
production and consumption (lecisions are
in fact made with reference to the future
as well as to the present. A rational produc-
tion plan includes very importantly deci-
sions or at least plans about the future; and
similarlv with consumption plans. Invest-
ment and savings are not only integral
parts of our current decisions but in the
long run shape the possibilities for further
development. As we know, the formal neo-
classical model can be extenided to deci-
sions over time by dating commodities and
regarding the same commodity at different
dates as different commodities. All pre-
vious conclusions follow; allocative effi-
ciency, for example, is achieved with the
same appearance of informational efliciency.
But of course there is a slight problem
with this reasoning. The information
about future commodities needed includes
their prices. These prices must be those
found on a suitable market, one in which
future supply and future demand are
equated. Unfortunately, no such markets
exist. Even the futures markets in certain
commodities, limited in extent as they are,
do not in fact lead to balancing all future
decisions. Rather they balance present
commitments to the future; but it is un-
derstood by all parties that when the fu-
ture becomes the present, there will be a
spot market on which the futures commit-
ments may be undone; and indeed those
making no futures commitments at all can
enter and know now that they will be able
to enter.
Even as a graduate student, I was some-
what surprised at the emphasis on static
allocative efficiency by market socialists,


### ---Economics-1974-0-08.txt---
when the nonexistence of markets for fu-
ture goods under capitalism seemed to me
a much more obvious target.
However that may be, the nonexistence
of these markets must be faced. Now in
general equilibrium any part of the system
affects every other part in at least two
different ways. Thus, we may ask two
questions about the nonexistence of futures
goods markets: what are its implications
for the rest of the system and what are the
reasons for its nonexistence.
The implication first of all is that the
information needed by the optimizer is not
provided by an existing market. It will be
provided by a market which will exist in
the future, but that is a bit too late to help
in decisions made today. Hence, the op-
timizer must replace the market commit-
ment to buy or sell at given terms by
expectations: expectations of prices and
expectations of quantities to be bought or
sold. But he cannot know the future.
Hence, unless he deludes himself, he must
know that both sets of expectations may
be wrong. In short, the absence of the
market implies that the optimizer faces a
world of uncertainty.
The exact modelling of behavior under
uncertainty is probably not crucial to the
subsequent discussion; let us use the
conventional expected-utility hypothesis.
When there is uncertainty, risk aversion
implies that steps will be taken to reduce
risks. This partly affects decisions within
the firm, such as the holding of inventories
and preference for flexible capital equip-
ment, and partly leads to new markets
which will shift risks to those most able
and willing to bear them, particularly
through the equity market. The rich de-
velopment of inventory theory and port-
folio theory in the last twenty years or so
reflects growing understanding of these
matters.
But when we speak of expected utilities,
we need to have some probabilities. Where
do these come from? We may in the first
instance regard them as subjective. But
the economic agent observes his world and
has the opportunity to learn from his ex-
perience, for there is a considerable degree
of continuity. By Bayes' Theorem or per-
haps psychological learning theory, the
probabilities, say of future prices, will
gradually adjust so as to conform to the
facts. If indeed the econromic world ex-
hibited the same structure in some sense
from period to period, and if everybody
observed everything relevant, then the
probabilities ascribed by different individ-
uals to the same events might be expected
gradually to converge to the correct values
and therefore be the same for all. In fact,
of course, the basic economic facts are
changing, partly endogenously because of
capital accumulation in its most general
sense, partly exogenously with predictable
and unpredictable changes in technology
and tastes; equally if not more important,
though, is the fact that the dispersion of
information which is so economical implies
that different economic agents do not have
access to the same observations. Hence, it
is reasonable to infer that they will never
come into agreement as to probabilities of
future prices.
A further implication is that the past in-
fluences the future. Jevons's well-known
slogan, "bygones are forever bygones,"
ceases to be fully accurate. The past is rele-
vant because it contains information
which changes the image of the future; the
probabilities which govern future actions
are modified by observations on the past.
It follows that present decisions with im-
plications for the future are functions of
past values of variables as well as present
values.
This point of view has been exploited in
the econometric models which have used
distributed lags in explaining investment
decisions. What still needs to be exploited
more, however, is that the inference to the


### ---Economics-1974-0-09.txt---
future is necessarily uncertain, and the
decisions made still exhibit risk aversion.
Expectations for the future are related
to quantities as well as prices. The im-
portance of quantity expectations has been
stressed in macroeconomic models, even in
such pre-Keynesian concepts as the ac-
celeration principle, and most especially in
relation to inventories. It sometimes is
held that in a neoclassical world only prices
matter; in the absence of prices, presum-
ably they are replaced by price expecta-
tions. But that is not strictly true. Under
constant returns, at least, quantity in-
formation for the individual firm is needed
even when neoclassical assumptions are
strictly fulfilled. Neoclassically founded in-
vestment theories usually predict capital-
output ratios or capital-labor ratios; they
still need output forecasts explicitly or im-
plicitly. This gives considerable, perhaps
major weight to past quantity information
in predicting the future and therefore in
guiding current investment decisions. It is
perhaps along these lines that Keynesian
theory, with its overwhelming emphasis on
quantity changes as equilibrating vari-
ables, can be founded firmly on individual
optimizing behavior.
I have referred to the fact that informa-
tion is dispersed throughout the economy
but have not suggested how. In the pure
neoclassical model, each agent knows only
his own production possibilities and his
tastes, together with market information
on the rest of the economy. In the world I
have just sketched, however, any variables
which improve his ability to predict the
future have a very meaningful economic
value to him. He will seek to acquire addi-
tional information. Such information is
presumably costly; that is the basis for
such great emphasis on the value of in-
formational economy. But there is clearly
a great incentive to acquire information of
predictive value, and, as neoclassical
theory would predict, there will be an in-
centive to produce such information. We
have then an economic information in-
dustry: (lata assembly and analysis, busi-
ness journalism, economic forecasting, with
a longer-run perspective business educa-
tion. Since information as a commodity
does not satisfy all the neoclassical norms,
it is not surprising that the government
plays a large role in this process. Informa-
tion-acquisition activities and information
markets now appear on the economic land-
scape. Efficiency in the operation of firms
ceases to be purely productive efficiency;
it involves efficiency in prediction as well.
I would conjecture that the incomplete
diffusion of information -along the lines just
sketched has a good deal to do with the
operations of the securities markets and
the decisions on corporate financing. The
predominant role of internal financing and
indeed the whole special importance of the
managerial factor in corporate decision
making are clearly connected with differ-
ential access to information about the
firm.
You may have forgotten by now, but I
earlier promised to consider not only the
implications of but also the causes for the
absence of markets for future goods. One
might wonder why one should explain the
absence of a phenomenon. Sherlock Holmes
once maintained to the dimwitted local
police inspector so typical of English de-
tective stories that the significant question
in the case at hand was the dog's barking
at night. "But," said the inspector, "the
dog didn't bark." "That," said Holmes,
"is what is significant." So too is the ab-
sence of these markets significant for a full
neoclassical theory. A truncated theory of
temporary equilibrium in which markets
for future goods are replaced by some form
of expectations, themselves functions of
current prices and quantities, has indeed
been developed, though its empirical con-
tent is necessarily meager if the formation
of expectations is left unanalyzed. But the


### ---Economics-1974-0-10.txt---
true neoclassical spirit is being denied in
such a model. Although we are not usually
explicit about it, we really postulate that
when a market could be created, it will be.
I sometimes think that welfare economics
ought to be considered an empirical dis-
cipline. Implicitly, if an opportunity for a
Pareto improvement exists, then there will
be an effort to achieve it though some so-
cial device or another. In our theories and
to a considerable extent in practice, the
cheapest way in many cases is the creation
of a market; and markets do emerge. If a
market is impractical for one or another of
the reasons we usually call "market fail-
ure," then very likely some other social
device will at least be tried: government
intervention; codes of professional ethics;
or economic organizations with some
power intermediate between the competi-
tive firm and the government.
Thus, the failure of markets for future
goods must be regarded as an analytic
problem as well as a presupposition. It
seems to me there are two basic causal fac-
tors. One is that contracts are not enforce-
able without cost and forward contracts
are more costly to enforce than contem-
poraneous contracts; the other is that be-
cause of the many uncertainties about the
future, neither buyers nor sellers are will-
ing to make commitments which com-
pletely define their future actions. Let me
take these two points up in turn.
The ability to make enforceable con-
tracts is a necessary but not sufficient
condition for a market. However, there is
no way to insure complete enforceability.
An individual may make a contract which
he cannot in fact fulfill. Penalties may in-
deed be imposed on failure to live up to
one's agreement, but they are not a sub-
stitute for compliance from the viewpoint
of the other party, and there is always a
degree of cost in enforcing the penalties.
The laws of bankruptcy are a social recog-
nition that complete enforceability is im-
possible and that it is even socially desir-
able to set limits on the penalties for
failure. However, when the exchange of
values for values is simultaneous or nearly
so, the contracts may almost be self-
enforcing. If a good has been sold and not
paid for, it can be recovered; if there is a
continuing relation of buyer and seller, a
failure to settle bills can be met by refusal
to make further deliveries, in which case
the loss is minimized. With contracts ex-
tending into the distant future, on the
contrary, the possibility of failure to com-
ply becomes greater, partly because the
self-enforcement aspects become weaker,
partly because unexpected changes may
intervene to make even a sincerely in-
tended compliance difficult or impossible.
The outstanding examples of forward
contracts are credit instruments. The
buyer, who is taking the risks of default, is
motivated to protect himself by seeking
more information about the seller. The
lender wants to know the borrower's as-
sets, the prospects for changes in them,
possibly even what he is going to do with
the money. This very individualized in-
formation-seeking relation is quite far
from the arm's length impersonal model of
a market. The so-called capital markets
are in many structural aspects very differ-
ent from our model markets. It is of
course an empirical question how far their
behavior departs from the model. But
the recurrent theme of credit rationing and
availability doctrines, the essential imper-
fections of the credit market which un-
derlie monetarist theories of cyclical fluc-
tuations suggest that the incomplete en-
forceability of credit contracts and the
protective steps taken by lenders are sig-
nificant factors in explaining the working
of the market.
While the enforceability question ex-
plains why those forward contacts that are
made do not constitute a perfect market,
we need more to understand why even


### ---Economics-1974-0-11.txt---
these are so limited in their coverage of
future goods transactions. There are for-
ward contracts in money, some com-
modities, real estate, but very little else.
The explanation lies in uncertainties of
both buyers and sellers about prices and
quantities and about technology and
tastes. Using uncertainties about prices
and quantities as an explanation for mar-
ket failure is a circular argument, though
not necessarily a fallacy. That is, if all
markets for future goods existed and
cleared all transactions, then there would
be no price-quantity uncertainties. But
this much is true; if some markets for fu-
ture goods do not exist, then the agents
have uncertainties which are relevant to
their behavior on markets for complemen-
tary or substitute goods. As Hicks showed
a long time ago, complementarity and sub-
stitution can occur over time as well as
simultaneously. If, as I will argue in a
minute, uncertainty can tend to destroy
markets, then we can conclude that the
absence of some markets for future goods
may cause others to fail.
To illustrate, the demand for capital
goods at any point of time is dependent on
the prices and sales of the product at fu-
ture points of time. Therefore the demand
for future capital goods will depend on ex-
pectations about the product at some still
more removed time. If we assume only
that we will not have markets for products
at some distant point of time, then the
resulting uncertainty will reflect itself in a
failure of the market for capital goods in
the nearer future, which will in turn create
still further uncertainties.
Thus, if some markets for future goods
are nonexistent, there will be uncertainties
on the other markets; in addition, demand
and supply conditions for the future are
uncertain because of technological and
taste shifts. Assume that both buyers and
sellers are risk averters. Then without
going into details it is reasonable to con-
clude that both demand and supply will
have a downward bias as compared with
the situation in which uncertainty is ab-
sent. A buyer will be unwilling to contract
for purchase of a good if a superior or
cheaper substitute may be available; and
the seller will be unwilling to accept a
price sufficiently low to be suitable to the
buyer, particularly if he thereby precludes
himself from a possible opportunity to
shift his resources to other closely related
goods. It would seem possible, at least,
that there will be no price at which tran-
sactions in future goods will take place.
From a theoretical viewpoint, one might
say that the market is in a strange sort of
equilibrium; there is some shadowy sort of
price at which supply and demand are
equated at zero. But this price is not per-
forming much of a signalling function.
There is one ultra-neoclassical approach
to the market treatment of uncertainties,
in which I take some pride. That is the no-
tion of a contingent market. Instead of
letting uncertainty ruin existing markets,
we can take it explicitly into account by
buying and selling commitments to be
carried out only if some uncertain event
occurs. We could in principle imagine
agreements to transact which will hold if
and only a given conceivable technological
innovation does not take place, with a
second market for transactions valid if the
innovation does take place. Then we can
restore the possibility of markets.
Such contingent markets are not en-
tirely unknown; insurance contracts are
the purest example, and equity markets
and cost-plus contracts provide more
muddied illustrations. But they are rela-
tively rare. Why this should be so follows
again from the general problem of informa-
tioin costs and dispersal. If contracts are
contingent on the occurrence of some
event, then it must be verified whether or
not the event occurre(l. But this is informa-
tion, an(I as the example of a technological


### ---Economics-1974-0-12.txt---
innovation suggests, it is information
likely to be much more easily available to
one party than to the other. Hence, the
range of possible contingent contracts be-
comes limited to those for whom the events
are easily verifiable for both parties. The
implications of these limits are known in
the insurance literature as adverse selec-
tion and moral hazard, and they are of
immediate practical significance in such
matters as health insurance. But more
broadly, they so limit the scope of con-
tingent markets in practice that, as argued
before in connection with markets for fu-
ture goods, they prevent the emergence of
even technically possible markets because
of the large unresolved uncertainties.
I hope enough has been said to indicate
the widespread implications of costly, dis-
persed information for the process by
which future-oriented economic decisions
are made. Let me remark, briefly in view
of the length of time I have already taken,
that informational costs and values play a
key role in modifying the structure even of
contemporaneous transactions. The in-
dividual optimizing agent is supposed to
know at least his technology or tastes and
the prices he faces. We have already ar-
gued a good deal of uncertainty with re-
spect to the future economic implications
of present economic choices. But in addi-
tion there is the possibility that techno-
logical information, which would be useful
to him, exists somewhere in the world but
outside his firm. There are grounds for
engaging in the active pursuit of informa-
tion. We begin to enter the realm of diffu-
sion of innovations, to which some sociolo-
gists as well as economists have con-
tributed. The interesting points here are
the biasses in the information channels,
some of which, at least, can be explained
in terms of differential costs of acquiring
information. For example, the well-docu-
mented role of personal influence in ac-
cepting innovations can be interpreted as
due to a perceived high reliability of such
information; in economic terms, this means
more information per unit of expenditure
of time or money.
The terms of trade with the outside
world should not be regarded as freely
given to the firm. In a world with a large
number of commodities, even knowing the
prices of relevant commodities involves
the costly acquisition of certain kinds of
information. This remark has given rise
to a large literature on search in recent
years. One implication which has been
only slightly explored is that the concept
of the market begins to weaken, and
Jevons's Law of Indifference becomes
more of an equilibrium condition than a
statement valid about a market even in
disequilibrium. At a moment of time,
prices of what would usually be thought of
as the same commodity bought or sold by
different firms can differ because buyers or
sellers may not, in their ignorance and in
the presence of costs of search, find it
worthwhile to shop further. Obviously, the
important application of this principle
may be to the labor market. Clearly, there
are important informational differences
between the employees currently working
for a firm and potential substitutes else-
where, although these are interchangeable
in pure neoclassical theory. Indeed, there
are differences both in the information the
firm possesses about its employees as com-
pared with alternatives and the informa-
tion which employees have about the eco-
nomic opportunities and the specific pro-
duction conditions of the firm as compared
with outsiders. It appears that considera-
tions of this type must play some role in
understanding the continued possibility of
unemployment and particularly the slug-
gish response of wages to market dis-
equilibria.
I am far from exhausting the implica-
tions of an information-economical view-
point for the economic world. I look for-
ward to exciting developments in the next
decade.
## Economics-1975-0


### ---Economics-1975-0-01.txt---
I come here with no eye-opening report
from the frontiers of economics, no stirring
cry for reform of conventional economics,
no closely reasoned analysis of an eco-
nomic dilemma or puzzle, no scathing or
reproachful scolding of the profession for
its technical preciousness or moral blind-
ness, no report on painstaking research
results, no valedictory on a lifetime of
theoretical or empirical contributions. The
AEA presidential addresses have been all
of these things.
But tonight, going against our current
fashion of telling the world what's wrong
with economics, I offer a modest contribu-
tion to the immodest subject of what's
right with economics-and, in particular,
what's right with economics as a guide to
public policy. In doing so, I won't ignore
the dark side of the moon-indeed, I can't,
since I will deal at some length with the be-
deviling subject of inflation. But believing
that it is at least as reasonable to judge a
discipline by its successes as by its failures,
I intend to accentuate the positive.
I. The Critical Look Inward
In recent years, as I shall illustrate in a
moment, we have instead accentuated the
negative. In good part, this has taken the
becoming form of mea culpa or rather
nostra culpa. We have, for example, readily
confessed that the inflationary shocks of
1973-74 caught not just the economy but
the economist by surprise. On this and
other fronts, the chorus of self-criticism
has risen to a new crescendo. It is almost
as if we take pride in our humility. Nietz-
sche must have been thinking of econo-
mists when he observed that "he who
despises himself nevertheless esteems him-
self as a self-despiser."
This is not to imply that economists'
criticisms are all self-inflicted wounds. Far
from it. Often among our colleagues'
favorite targets are the shortcomings of
mainstream economics, the misuse of
modern techniques, the fallacies of con-
ventional wisdom-in each case, the target
is not the critic's but his colleagues' brand
of economics, not mea culpa but eorum
culpa.
In any event, he who comes to praise
economics risks being buried in the barrage
of indictments that economists have
brought against themselves and their
brethren. Let me give you a sampling of
some that will be ringing in my ears as I
follow the parlous path of economic virtue.
Ceremonial occasions-presidential, me-
morial, or inaugural addresses-in par-
ticular seem to evoke musings on the
troubled or even dismal state of our sci-
ence. For the AEA faithful, I need only
recall John Kenneth Galbraith condemn-
ing neoclassical and neo-Keynesian eco-
nomics for ignoring power and thus losing
contact with the real world; Wassily
Leontief attacking mathematical eco-
nomics for building a showy superstruc-
ture on weak empirical foundations and
unverified assumptions, and thus losing
contact with the real world; Kenneth


### ---Economics-1975-0-04.txt---
Boulding assailing welfare economics for
its reliance on that holiest of holies, Pareto
optimality-when in fact "our lives are
dominated by precisely this inter-depen-
dence of utility functions which the Pare-
tian optimum denies"-thus also losing
contact with the real world.
In one form or another, variations on
Leontief's lament have been heard in many
another presidential address, to wit:
By F. H. Hahn (Econometric Society,
1968), who decried "the spectacle of so
many people refining the analysis of
economic states which they give no
reason to suppose will ever, or have
ever, come about...."
By G. D. N. Worswick (Section F of
the British Association, 1971), who
viewed the performance of economics
as "curiously disappointing," suggesting
that it has "a marvelous array of pre-
tend tools which would perform wonders
if ever a set of facts should turn up in
the right form."
By E. H. Phelps Brown (Royal Eco-
nomics Society, 1971), who judged the
usefulness of current work in economics
as ''not equal to its distinction" because
it is "built upon assumptions about hu-
man behavior that are plucked from
the air."
By James H. Blackman (Southern
Economic Association, 1971), who noted
that models with sufficiently intriguing
mathematical properties can achieve
lives of their own even if they lead the
investigator further away from reality
and yet, "the profession's incentive
system tends perversely to reward this
kind of endeavor and to deflect the
attention of gifted economists from the
exploration of concrete problems and
the dirty work that entails."
By Sherman Maisel (American Fi-
nance Association, 1973), who con-
cluded that most of the literature of
monetary economics is "non-operation-
al" since its prescriptions are too often
based on limited or false assumptions,
it by-passes critical operational prob-
lems, and it ascribes too great validity
to its statistical tests.
By Barbara Bergmann (Eastern Eco-
nomic Association, 1974), who prefaced
her plea for more microsimulation to
incorporate "realistically messy infor-
mation" in our economic data base with
a few roundhouse swings at the eco-
nomics profession and the pointed ob-
servation that instead of studying the
real nature of decision making, we
typically rush to make assumptions
"whose purpose in life is to let the
theorem emerge, all neat and provable."
Another favorite line of criticism and
attack focusses on the implicit value
premises of conventional economics. Gun-
nar Myrdal and Robert Heilbroner chide
us for concealing the value judgments that
inevitably enter into our selection of prob-
lems for study, choice of approach, defi-
nition of concepts, and even gathering of
data. So a "value-free" economics is an
illusion-they urge economists to specify
their values and thus avoid biases and
make research more realistic.
Radical economists simply reject the
whole value system of conventional eco-
nomics-as they see it, the neoclassical
paradigm in its very bone and marrow
enthrones acquisitiveness and enshrines
the existing order. Paul Sweezy accuses
mainstream economists "of hiding the
facts, of making the uncontrollable appear
under control, of rationalizing a system
which condemns hundreds of millions of
people to lives of despair and starva-
tion.... "


### ---Economics-1975-0-05.txt---
Inflation is the latest source of critical
volleys, and I will get to these in due
course. Meanwhile, the sampler of eco-
nomic masochism I have already provided
should serve as ample insurance against
complacency or smugness in considering
"what's right with economics." At the
same time, it strongly suggests that eco-
nomics, more than any other social sci-
ence, is afflicted with the common scold.
1 recognize that such a quick sampling
and cryptic quotes, selected to highlight
criticism, do a certain injustice to eco-
nomics and to some of the quoted econo-
mists whose kindlier observations have
been neglected in the process. But I am
also aware that my litany omitted a num-
ber of familiar flaws, for example, our
impounding of tastes and preferences in
ceteris paribus; the shortcomings of the
maximization principle in explaining con-
sumer and producer behavior, especially in
the short run; and our limited ability to
bring the claims of future generations into
our social utility functions.
Were I to serve as defense counsel for the
profession on this wide variety of indict-
ments, I would urge that we plead guilty
or take the Fifth on some, take to the de-
fense on others, and take offense at the
rest. Having paid my respects to the critics,
I intend no point-by-point evaluation or
rebuttal. This has been ably undertaken
by others.' Rather, my object is to gain a
more balanced perspective by focussing on
the quality, role, and contributions of
economics, especially to public policy. In
that undertaking, the first step is to exam-
ine the flank we expose to the public.
II. The Economist and the Public
When we turn from inside to outside
critics, the focus changes. We may think,
rightly, that freely confessing our weak-
nesses and airing our differences stimulate
responses and adaptations that strengthen
economics. Yet, wearing our purple hearts
on our sleeves has its price. It nourishes
the darkest suspicions about our art and
supplies live ammunition to outside critics
who have declared open season on econo-
mists. Witness the open sesame to the ed-
op pages for such recent thrusts as B erg-
mann's assault on economists in general
and Friedrich von Hayek's attack on
Keynesians in particular. With everything
from off-the-cuff phrases about being
"caught with our parameters down" to
tracts for the Times, we feed the hand that
bites us.
This is not a plea to do our self-flagel-
lating in secret or to mute our disputes
and conflicts. Open controversies, openly
arrived at, are part of the therapy that
keeps our profession healthy. Rather, my
plea is to the media and the opinion makers
to understand that appearances are de-
ceiving, that hard give-and-take is indeed
a symbol of strength, and that our areas
of agreement and consensus are vastly
larger than our areas of difference.
On the first point, observers from other
disciplines are of ten astonished at how
hard economists go at each other, how
readily they run the gauntlet of their col-
leagues' criticisms with no quarter asked
and none given-and, with few excep-
tions, all this within the framework of pro-
fessional respect and friendship. As Charles
Frankel put it, unlike other social sci-
ences, economics seems to have achieved
"a working etiquette which allows people
to disagree vigorously without engaging
in recrimination about 'unscientific' or
'unprofessional' behavior" (quoted in
Johnson (1973)).
What accounts for this? Part of it, one
can unblushingly say, is simply that so
many competent, tough, and rigorously

### ---Economics-1975-0-06.txt---
trained minds have been drawn into eco-
nomics in response not just to challenging
policy problems but to the quantitative
revolution since World War II. And part
of it is that the participants can draw on a
hard core of economic theory and method-
ology, together with a growing body of
empirical knowledge, to provide standards
for testing the validity (though not neces-
sarily the relevance and reality) of ideas,
analysis, and empirical findings. The re-
sult is not only a relentless intellectual
policing of the profession that soon exposes
the fool, the quack, and the charlatan, but
a growing capacity "to participate in ad-
versary debate over public policy issues
without jeopardizing scientific integrity
and freedom" (Johnson (1973)).
That brings me to the second point, the
impression we give outsiders of a house
divided, not to say splintered. It is worth
reminding ourselves and our critics of
several factors that drive a wedge between
image and reality.
One, instead of laying aside our differ-
ences and living contentedly together, we
economists tend to lay aside our agree-
ments and live contentiously together. We
focus our private and public debates on
unsolved policy problems, tough analytical
nuts, and issues on which we have rival
theories, contradictory evidence, or strong
ideological differences. Just as these are
the questions that intrigue us, they are
the ones that attract the attention of press
and public. What we know-and they may
not is that beneath the visible tip of dis-
agreement and rivalry lies no huge iceberg
of divisiveness.
Two, it is only occasionally that our
areas of consensus are brought to the sur-
face in a newsworthy way. One such oc-
casion was the White House "summit con-
ference" on inflation last September. Two
dozen leading economists from across a
wide spectrum of American economics
(not wide enough, the radicals would say)
signed a statement which called on the
President and Congress to eliminate
twenty-two restrictive laws and practices
that inhibit competition, inflate costs, and
prop up prices. Only a tiny minority held
out (if any minority that includes Gal-
braith can be called "tiny"). Even more
striking, in a sense, was that while the
customary and largely ideological clashes
among, say, Galbraith, Milton Friedman,
and Paul Samuelson caught the public
eye, the real story lay in the minimal dis-
sent among the participants on (a) the
forecast of a soggy or sagging economy,
(b) the urgency of providing relief to the
victims of inflation and the casualties of
recession, (c) the need to ease monetary
restraint, (d) the small anti-inflationary
payoff on moderate ($5 to $10 billion)
budget cuts, and (e) the advisability of
resisting popular demands for reimposing
full-scale wage and price controls.
Three, even where disagreement flour-
ishes most visibly, perhaps, between
Keynesians and monetarists-the public
may not discern that the analytical and
empirical ties that bind us are far stronger
than the forces that divide us. Our con-
troversies take place within the context of
basic consensus on the nature and methods
of economic theory and inquiry, on the
content of the disagreement, and on the
kinds of tests that may one day resolve the
conflict. "Such disagreement within agree-
ment lies at the heart of the process of
normal development of a science" (Ben-
jamin Ward, p. 12).
Four, much of what the public perceives
as a clash of economic concepts and find-
ings is in fact a clash of ideology and
values. Given the way technical economics
and ethical preferences are packaged in
policy debates (and given our lapses in
identifying which is which), this is hardly
surprising. Thus, whoever opens the pack-
age labeled "monetarist" typically finds
not just money supply in full flower, but a


### ---Economics-1975-0-07.txt---
dedication to minimum government inter-
vention, small budgets, reliance on rules
rather than authority, and price stability.
Contrasting correlations appear in the
Keynesian package. So outsiders can be
excused for slipping into the fallacy of
association and attributing the split to
our unresolved analytical conflicts rather
than to divergent evaluations of social
priorities and competing philosophies of
government. These associational chains are
not linked together by any inexorable
logic in part, they seem to be an accident
of birth as in the case of the Chicago twins
of monetarism and laissez-faire rules. A
belief in the supremacy of monetary over
fiscal tools could quite logically go hand-in-
hand with avid interventionism. But this
escapes the jaundiced eye of the outside
observer, who takes the ideological lineup
as further evidence that economics is
riven to its core.
Five, there is an ironic but substantial
inverse correlation between the degree of
consensus among economists and the de-
gree of public acceptance of their findings.
Thus, in the macro-economic sphere of sta-
bilization policy, where debate and dis-
putes among economists flourish, their im-
print on public policy is undeniable. But in
the considerably more peaceful realm of
microeconomics and allocative. efficiency
-where a reliable analytical apparatus
coupled with solid quantitative work, es-
pecially on costs and benefits, has led the
great majority of disinterested economists
to an agreed diagnosis and prescription-
the policy box score shows few hits, fewer
runs, and lots of runners lef t on base.
Economists widely, in some cases almost
uniformly, favor tougher antitrust policy,
freer trade, deregulation of transportation,
pollution taxes in place of most prohibi-
tions, and tax reform to remove income tax
shelters. They oppose fair trade laws, re-
strictive labor and management practices,
distortive zoning laws and building codes,
import quotas, ceilings on interest rates,
maritime subsidies, and pure (or impure)
pork barrel projects.
Granted, the diffuse and inchoate con-
sumer interest has been no match for
the sharply focussed, articulate, and well-
financed efforts of producer groups. But
the economist is beginning to pick up some
allies. Public interest groups are increas-
ingly giving focus and force to the con-
sumer and general public interest. And the
march of events is providing some wind-
falls: Among the apples that have dropped
in our laps are flexible exchange rates, the
dethroning of agricultural price supports,
inroads on import quotas, and moves to
end percentage depletion. Under the pres-
sure of virulent inflation, government ac-
tions that erode productivity and boost
costs and prices are being subjected to new
and searching scrutiny. So perhaps, on
these micro-economic issues where econo-
mists sing in reasonably close harmony,
the outside world will no longer quite tune
us out. In macro-economic policy, where
cacaphony prevails, we can be sure that
the world will tune us in.
It may also be useful to draw attention
especially the attention of those who
interpret us to the public-to certain other
misperceptions and roadblocks that thwart
good economics and tend to put economists
in bad repute.
First, much of our economic analysis
and the uncommon sense growing out of it
fly in the face of "common sense," for
example: that budget deficits need not
spell inflation, nor national debt a burden
on our grandchildren; that thriftiness can
be a mixed virtue; that while exploding oil
prices inflate costs, they deflate demand;
that in an overheated economy, greater
taxes can be the lesser evil; and so on.
Behind every false dictate of common
sense lies a primitive and misbegotten
economic theory-and for most of our
pains to correct it, we can expect to get


### ---Economics-1975-0-08.txt---
the back of everyman's hand.
Second, a related cross to bear can be
characterized by Kermit Gordon's apt
phrase, "virtue is so much easier when
duty and self-interest coincide." Not only
does that foredoom action on many micro-
economic fronts, as already noted, but it
puts roadblocks in the path of efforts to
make fiscal policy a two-way street. For
forty years, Congress has enacted major
tax increases only under the whiplash of
war. The resulting reliance on tight money
to fight peacetime excess demand, coupled
with expansionary fiscal policy to fight
recession and slack, have had an unmis-
takeable ratchet effect that has tilted the
system toward tighter money and easier
budgets. (Small wonder, by the way, that
many economists and policy makers are
unwilling to give up, via indexing, the
increases in effective income tax rates
"legislated" by inflation.)
Third, the public sees economists as the
bearers of hard and unpalatable truths.
And often we are, by the very nature of
our sometimes dismal discipline. Except
when idle resources can be put to work or
productivity increased, our message is the
stern one of tradeoffs, benefits at a cost,
and no one-dimensional daydreaming.
Even worse, at times economics has to
bring the bad tidings that for some prob-
lems there are no satisfactory solutions.
For some thirty years, we have warned
that full employment, price stability, and
full freedom of economic choice cannot co-
exist in a world of strongly organized pro-
ducer groups. More recently, economic
analysis has brought home the unromantic
truth that failure to cure some of our social
ills traces less to a failure of will, or "right-
wing villains," or a calloused "establish-
ment," or powerlessness of the people,
than it does to the prosaic facts that the
problems are tough and complex and the
goals we seek may be irreconcilable-in
short, trace more to conflicts in our na-
tional objectives than to conflicts among
social groups. Welfare reform is a case in
point: no solution can simultaneously pro-
vide a decent minimum income for all,
preserve work incentives, cut no one's
benefits, and avoid huge budget costs (see
Schultze (1972); Rivlin (1973)). We may
view such work as a contribution to
straight thinking and rational choice. Our
critics are more likely to view it, at worst,
as a counsel of defeat (which it is not) or
at best a counsel of inescapable compro-
mise (which it is).
Since the foregoing misperceptions and
roadblocks thwart the translation of
good economics into good policy, one could
justify, in cold cost-benefit terms, a size-
able investment to overcome or reduce
them. The most obvious implication is
that the country needs to invest more in
formal economic education at all levels.
But an equally pressing need is for econo-
mists to invest more of their time and
effort in making themselves understood
to the public and policy maker-and that
in turn requires recognition of this skill
in the academic reward system. This
might serve as a useful antidote to the
influence of mathematics and econometrics
which, while heightening the precision of
professional thinking and internal com-
munication, have apparently dulled the
appetite and eroded the facility to com-
municate with the public in intelligible
English prose.
In a very real sense, this confronts the
press with an unusual opportunity and
challenge, perhaps even a responsibility,
to serve as a translator and interpreter of
economics and its offerings. But believing
(probably rightly) that their readers and
listeners prefer to hear of fights and
failures, crises and controversies, rather
than of quiet contributions and consensus,
the conventional or electronic press is not
very likely to rise to this challenge. So it is
still up to economists. But I must not


### ---Economics-1975-0-09.txt---
carry this too far. Just as I am eschewing
any Cassandra-like pronouncements to-
night, so I have promised myself to sup-
press the oracular and even the avuncular
(Dutch-type) mood evoked by these oc-
casions. So I shall press on.
III. Standards of Judgment
From the foregoing, it is evident that I
feel, first, that economists have gone be-
yond beguiling humility and welcome self-
criticism to the point of almost neurotic
self-rebuke, and second, that press and
public have all too lustily taken up the
cry-in part taking us at our word, in
part misinterpreting us, and in part re-
flecting their belief that, after the high
promise of the 1960's, we have failed them
in not foreseeing and forestalling the
crises of the 1970's: stagflation, energy
shortage, and the environment.
In my quest for a more balanced per-
spective on the state of economics, the
next task is to set up some standards for
judging the quality and performance of
economists. Since we have developed no
measures of output or allocative efficiency,
no capital-output or cost-benefit ratios, for
the economics "industry," I will have to
fall back on more subjective and less quan-
titative measures in judging its quality and
contributions.
My mixed bag of criteria includes (1)
the quality of inputs; (2) the demands for
our services; (3) as a proxy for a measure
of outputs, the record of accomplishment
in a given field (public finance); (4) finally,
the cruelest test, our handling of the eco-
nomics of inflation.
The potential of economics for informing
and improving public policy depends on
the stock of human capital, technology
and tools at its command. Here, economics
has no difficulty in holding its head high,
especially in terms of the striking advances
of the past three or four decades.
Harry Johnson may be a trifle extrava-
gant in his assessment that the United
States now has "perhaps fifty economic
departments of an average quality com-
parable to the average quality of the four
or five best departments in the whole
world in the pre-World War II period. . ."
(1973), but only a trifle. Another attest to
professional quality, already referred to,
might be put this way: Show me another
field that has enough inner strength to
confess so much remaining weakness (and
to carry on so much open controversy).
Humility where we have things to be
humble about (and we do) is a becoming
trait. But coupling it with pride where we
have things to be genuinely proud about
is hardly a deadly sin.
Accompanying the growth in the quan-
tity and quality of economic brainpower
have been striking advances in the tech-
niques and tools with which economists
work. For this audience, I can speak in
shorthand about the strengthened analyti-
cal base of micro- and macroeconomics;
the methodological revolution that moved
us from the rationalist-historical approach
into the age of quantification, with its
insistence on systematic measurement of
the shapes of economic functions and em-
pirical testing of hypotheses and its use of
econometrics and simulation techniques
(with a powerful assist from the com-
puter); and such conceptual advances as
those in the economics of human capital,
of cost-benefit relations, of uncertainty, of
control, of transactions and information
costs, of "second best," and of the alloca-
tion of time.
In normative economics and the analysis
of value-laden social problems, new fron-
tiers in the study of economic behavior are
being opened up by survey research tech-
niques (especially by the Michigan Survey
Research Center), by efforts to measure
nonmarket benefits or values (especially
by the National Bureau of Economic Re-


### ---Economics-1975-0-10.txt---
search) and by "controlled" social experi-
mentation (for example, by the Brookings
Institution and the University of Wiscon-
sin Institute for Research on Poverty).
These newer tools and the institutions
that nurture them constitute part of the
rich and expanding resources of econom-
ics.
Economics can also draw on a broad
data base, especially in federal statistics.
But here, the quantity, timeliness, and
even the quality of the data are not keep-
ing pace with either the problems requir-
ing analysis or the capacity of our quanti-
tative techniques. Responding to policy
needs and mounting self-criticism, the
profession has opened many new fronts in
the search for realistic micro-data to link
up with macro-data, for cross-section data
to help overcome the curse of collinearity
in time-series analysis, and for custom-
built data developed by survey and experi-
mental techniques.
That the human, analytical, and quanti-
tative resources of economics provide a
huge potential for solving problems seems
undeniable. That more of these powerful
resources than ever before are being put at
the disposal of economic policy makers
also seems undeniable. What we do not
know is what proportion is being mis-
directed into arid puzzles, sterile proofs,
and recreational mathematics while the
world's pressing economic and social prob-
lems go begging for answers. Here, we
can only match one observer's impression
against another's. The profession itself has
not come to grips with this question of
allocative efficiency.
A second test in appraising the state of
economics, one not unknown to economics,
is that of the market place. This takes
several forms, none very robust, but none
trivial. The first is the upsurge in enroll-
ments in economics courses, especially in
introductory economics, that has occurred
in the academic years 1973-74 and 1974-
75. The second is the oft-reported high
ranking of economists' salaries in business,
government, and academic life. A third
is the strong and growing demand for
economists' inputs into the policy-making
process either as staff members or as
expert witnesses for congressional com-
mittees, individual congressmen, and the
executive branch.
With students, business, and govern-
ment beating a path to our door, we can
infer that something must be right with
economics, or wrong with the economy,
or both. Either we are building a better
mousetrap or there are more and bigger
mice threatening our customers. Perhaps
it is simply that we have the only mouse-
traps in town.
But there must be more to it than that.
Take the policy maker, for example.
What he finds congenial is that he can
hand an economist a problem relating to
changes in taxation, regulations, budget
proposals, pollution control, poverty, so-
cial security, public service jobs, gasoline
taxes, oil prices, and so on and be reason-
ably sure of getting a useful appraisal of
alternative paths to his objectives, of
costs and benefits, and of distributional,
allocative, and stabilization impacts.
Many of these judgments will come with
orders of magnitude or reasonably precise
numbers attached. He may not trust our
GNP forecasts, but he has come to respect
our hardheaded analysis and numbers on
the myriad problems of economic choice
with which he is faced.
It seems fair to draw another inference:
notwithstanding the current wave of self-
criticism and public criticism, even lam-
pooning, of economists and despite our
highly visible public debates and highly
vulnerable participation in policy making,
economics continues to maintain its stand-
ing as a science. Signs of a reported crisis
of public confidence or of a "recession of
self-confidence" are few and far between.


### ---Economics-1975-0-11.txt---
Reports of the demise of our discipline are
grossly exaggerated.
IV. The "Outputs" of Public Economics
Having considered some indicators of
the quality of our inputs and of the re-
vealed preferences for our outputs, let me
continue this exercise in casual (andcon-
genial) empiricism by taking an unscien-
tific but not unrepresentative sample of
the outputs of economics, especially those
bearing on policy. For this purpose, I
draw on my chosen field of public finance,
or public economics, to illustrate the telling
conceptual and empirical advances of
economics in recent decades and the result-
ing enrichment of its offerings to the policy
maker. Indeed; such an appraisal offers so
many healthy antidotes to "what's wrong
with economics" that I was tempted to
devote my whole discourse to it tonight.
But I resisted the temptation because,
first, much of it has already been done in
carefully documented depth in survey
volumes by Brookings and the National
Bureau;2 second, I figured it might test
your patience and mine; and third, it
would have left no room for a confronta-
tion with inflation. So I offer instead a
miniaturized assessment of the achieve-
ments of public economics as viewed
through the policy prism.
Public Expenditures
Consider first the striking contributions
economics has made in the past generation
to clear thinking and better informed
decisions on public expenditures. Partly,
this reflects advances in economic science,
for example, in the theory of public goods
and human capital, and partly, creative
new applications of the economist's char-
acteristic way of looking at problems of
choice, namely, through the lens of op-
portunity costs, benefits, and alternative
paths to a stated goal.
Economics can offer much more con-
crete guidance on efficient ways of allocat-
ing resources to achieve stated govern-
mental objectives than it can on what the
public-private sector division of resources
should be. That may be a good thing in
that presidents and congressmen view the
fixing of goals for public health, housing,
welfare, and the like as what they were
elected for, yet at the same time seek, or
at least accept, economic guidance on the
choice among competing methods of
achieving these goals.
Nonetheless, rapid progress in the
theory of public goods since the appear-
ance of the Samuelson classic on "The
Pure Theory of Public Expenditures" just
twenty years ago has vastly improved on
the simplistic theory it replaced. It has
facilitated straight thinking on the deriva-
tion of conditions for efficient public-sector
allocations from private evaluations and
on the articulation of social priorities
through the political process.
Interwoven with the newer thinking
about public goods has been a resurgent
interest in externalities or spillover effects.
In a sense, the pure collective good is a
case of total externality-all of its bene-
fits are external and nonmarketable since
nobody can be excluded from them. That
may clarify thinking but gives little policy
guidance.
Yet, the externality concept translates
into hard-headed policy advice in such
disparate areas as pollution, federal aid,
and the law. When pollution became a
national concern, economists quickly drew
on their tool kit to develop proposals for
antipollution taxes (within the context of  2 See Alan Blinder and Robert Solow et al. This is the  capstone volume of the Brookings Studies on Govern-  ment Finance, directed by Joseph A. Pechman, which  has produced 35 books in the past decade. See also Carl  Shoup et al. This was one of several survey volumes un-  der the general heading, Economic Researchl: Retrospect  and Prospect, based on the Bureau's Fiftieth Anniver-
sary Colloquia.


### ---Economics-1975-0-12.txt---
target air and water quality standards).
Tax penalties of so much per unit would
put price tags on use of the public's air
and water, thus internalizing external
costs and using market incentives to ac-
complish depollution rather than relying
on the less efficient route of regulation.
When local governments supply educa-
tion and public health services to a mobile
population, many of the benefits spill over
to other units. An important rationale for
federal grants flows from these externali-
ties, namely, that to get local units to
produce enough education and health
service to achieve a national, not just a
local, cost-benefit optimum requires con-
ditional grants from the federal purse.
Further, since externalities in the form
of damage to third parties lies at the heart
of many problems in legal justice, eco-
nomics is able to make an important con-
tribution in this area.
When we turn to the empirical outputs
that are now illuminating problems of
public choice, we find the past decade
bristling with new thinking, new tech-
niques, and new measurements. These
offer the decision maker important new
guides in the seJection and evaluation of
government programs and new insights
into alternative systems of delivering
government services:
Measurement of cost-benefit ratios
has developed from the early metrics
of water projects into, first, a sophisti-
cated cost-benefit calculus for tangible
investments like dams, roads, pollution-
control projects and, second, cost-bene-
fit estimates for intangible investments
in human brainpower, skills, and health.
Shadow pricing has been one of the use-
ful tools in this connection. Cost-benefit
analysis, even with its limits of quanti-
fication and its inability to shed light
on distributional and value questions,
is an important aid to informed de-
cisions.
A related advance is the development
of new and tougher standards for judg-
ing government programs. The former
criteria centered on the question: Is the
program put into effect quickly and with
high fidelity to the congressional intent?
Now, the accountability question is:
Does it deliver the goods? Does it ac-
complish the objectives? Inputs used to
be stressed if they conformed with the
intent of the legislation, they tended to
be judged a success. But now we try to
measure outputs, a tougher and more
elusive standard. (The parallel with
judging the performance of economics
and economists is painfully obvious.)
Antipoverty programs, which were
among the first to be evaluated by these
stringent standards, seem to have borne
the brunt of the evaluation boom. By
the old inputs standard, a program like
Head Start would have fared much
better.
The reach of cost-benefit analysis will
be lengthened if a broad range of new
research efforts in nonmarket sectors of
economic activity pays off. I refer not
only to the exciting work on measure-
ment of the returns on investments in
human capital (T. W. Schultz), but to
efforts to measure the output of the
medical industry, to measure the rela-
tions between crime and punishment,
and to measure the value of nonmarket
economic activity conducted within
firms and households.
The new technique of controlled social
experimentation on proposed welfare
and housing measures, health insurance,
and education vouchers is yielding im-
portant insights. As a result of experi-
ments on negative income taxation, for
example, the equity versus efficiency, or
equality versus incentives, controversy
will never be conducted in a vacuum


### ---Economics-1975-0-13.txt---
again (Rivlin (1973)). In spite of some
limitations, the New Jersey experiment
yielded strong evidence that fears of
fatal incentive effects of a negative in-
come tax were grossly overblown.
Another focus of fruitful thinking re-
lates to alternative strategies for de-
livering social services. The in-cash
versus in-kind choice is a basic one.
Economists are predisposed toward the
in-cash approach on grounds that one
can generally depend on people to fol-
low their own best interests. But there
are significant exceptions where con-
sumer sovereignty is limited or specific
goods externalities exist or some explicit
social values take priority.
Out of economics also comes the at-
tempt to develop "market analogs" to
serve as substitutes for market incen-
tives in reconciling public with private
interests, decentralized individual de-
cisions with social goals. Pollution taxes
are a case in point. Performance stan-
dards for teacher pay would be another.
Putting medical insurance programs
on an efficiency-based reimbursement
basis would be a third. The big gap is
in the redesign of incentives and institu-
tions to guide decentralized govern-
ment decision making more systemati-
cally toward the aims of our social
programs (Schultze (1971)). Thus far,
the government, like the economics pro-
fession, is largely in the dark about its
own production function.
Taxation
What strikes an old public finance func-
tionary as forcibly as any change in the
field of public finance is the way in which
modern thinking has knocked the props
out from under the neat and primitive
theories of tax incidence of a generation
ago. The property tax provides a particu-
larly instructive case in point. The text-
books of the 1930's and 1940's told us con-
fidently that the tax on land (fixed supply)
was capitalized and on dwellings (supply-
responsive) fell like an excise tax on the
occupant, the consumer of housing ser-
vices. The policy lesson was clear: Given
the declining proportion of income spent
on housing services as income rises, the
tax was hopelessly regressive. Today? It is
recognized that the old incidence analysis
was wrong, even on its own terms.
The modern theory of incidence (de-
fined as the impact on distribution of
private real income) draws on general
equilibrium theory, distinguishes between
sources-of-income and uses-of-income ef-
fects, and disentangles the concepts of
specific, differential, and balanced-budget
incidence. The resulting analysis indicates
that much, of the aggregate burden of the
property tax falls on owners of capital
and hence tends to be progressive and
this progressivity is enhanced by the
particular "excise-type" effects of this
tax (Henry Aaron). In short, error has
been exposed and though the debate is not
over, we are now in transit toward truth.3
It is hard to put down the knee-jerk reac-
tion that prefixes "property tax" with
"regressive." And it will take some time
before policy makers accept the proposi-
tion that, at the very least, the property
tax is now in the unexpected position of
"innocent until proved guilty." But the
implications for policy are profound.
Economists have long been useful and
influential contributors to the design of the
federal tax structure and of particular
taxes. Again, elementary concepts we now
take for granted-for example, horizontal
versus vertical equity, Richard Mus-
grave's three branches of distribution, al-
3Those who view decisions to locate in a particular
community as a conscious choice of one particular  bundle of public services over others conclude that the  property tax on housing is a benefit tax, a payment for
benefits received.


### ---Economics-1975-0-14.txt---
location, and stabilization, the lagged
effect of tax changes, and automatic versus
discretionary tax changes were not even
part of our vocabulary in the pre-World
War II period. Yet, all of these are now
factored into our economic advice on
taxation.
Even more directly impinging on policy
are the empirical advances. One thinks of
searching studies of particular taxes and
tax components (especially in the Brook-
ings Studies on Government Finance),
and of the relentless identifying and quan-
tifying of federal income tax preferences
or "loopholes." Much of the thrust of
economists' recent work on these "tax
expenditures" has been (a) to identify the
beneficiaries and specify the size of the
government subsidies provided in the form
of preferential tax treatment, (b) to define
the inequities, both horizontal and verti-
cal, that they create, and (c) to estimate
the distortions in resource flows caused by
preferential treatment of oil and gas, hous-
ing, real estate partnerships, and the like,
and measure the resulting welfare loss.
Though the congressional response has
been slow and halting, progress has been
made along the lines plotted by econo-
mists, and a solid base has been laid for
the further tax reform that is surely com-
ing.
Out of the countless other advances,
one stands out, namely, the highly in-
formative work done on the distributional
impacts of taxation with the aid of the
powerful tool of micro-unit data files (for
example, the MERGE file developed by
Joseph Pechman and Benjamin Okner).
Such micro-unit files are a new-generation
statistical missile, MIRVed so that they
can simultaneously hit multiple revenue-
estimating and burden-distribution tar-
gets. With their help, for example, econo-
mists have measured the growing burden
of income, payroll, and consumption taxes
on the lower income groups and developed
techniques for removing them-most re-
cently, in the context of the impact of
inflation on the same groups.
One should add that if revolution rather
than reform becomes the order of the day
in the federal tax structure, the economist
is ever ready with reasonably sophisti-
cated analytics and a fair amount of em-
pirical information on such major alterna-
tives as a value-added tax, a progressive
expenditure tax, and a net-worth tax. One
of the next stages in tax research, a highly
complex one, will be the general equilib-
rium analysis of such sweeping changes
in the tax system as, say, the substitution
of a value-added tax for the corporate
income tax or for part of the payroll tax.
Or, if stimulation of private saving be-
comes a compelling objective, perhaps the
substitution of an expenditure tax for
part of the income tax will become a live
issue. The skills of the economist will be
front and center in any such redesign of
the tax system.
The negative income tax story is rele-
vant here. The concept and its rudimen-
tary principles were developed and dis-
cussed among economists in the early
1940's. Some of us were already using it as
a teaching device in the mid-1940's. A
quarter-century after its origin, it became
the basis for the Family Assistance Plan
developed by Mr. Nixon's economists.
And a more limited version of the plan
seems again to be rustling in the leaves.
Fiscal Policy
In the domain of fiscal policy, it is hard-
er to answer the question, "What have
you economists done for us lately?" with
a sparkling array of examples. Much of
the theoretical ferment in this field is as-
sociated with the flowering of Keynesian
macroeconomics in the late 1930's and
1940's, the very period when the micro-
economics of tax incidence and public
expenditures languished.


### ---Economics-1975-0-15.txt---
Conceptual advances have continued
throughout the past twenty-five years, but
they have been more in the nature of a
fleshing out and consolidation of the origi-
nal breakthroughs with the aid of the
powerful tools of mathematics and econo-
metrics. Multiplier analysis, for example,
has moved from the theoretical realm into
large computer models of the economy-
with the tax cut of 1964 and the surtax of
1968 providing empirical grist for the mill.
While the models differ on the exact value
of the multiplier, "a fiscal policy planner
will not often be led astray if he uses a
multiplier of 2" for government spending
(see Blinder and Solow).
Coupled with multiplier studies is the
even more subtle study of the structure
of the "outside lags," of the timing of re-
sponses in the economy to changes in
fiscal policy. Though the empirical efforts
and debates go on apace, the behavior of
the cumulative multipliers in a clutch of
economic models suggests that for any
given change in fiscal policy, "at least 75
percent, probably much more, of the ulti-
mate effect is felt within the first year
after the initiation of the policy" (Blinder
and Solow). Although intractable ques-
tions remain concerning investment re-
sponses to fiscal policy changes, enough
has been learned about aggregate demand
responses to provide two broad general-
izations about fiscal policy:
One, the conditions for intelligent
fiscal policy are met if economic f ore-
casting can answer two not-very-exact-
ing questions: Do projected economic
conditions in the ensuing six to nine
months call for restraint or stimulus?
Is the required dosage large or small?
Two, given the limited margin for
error in a high-employment economy,
it is better to rely on many smaller
monetary-fiscal moves than a few large
ones.
Implicit in these two generalizations is a
third one: Given both the internal shifts
and the external shocks with which stabi-
lization policy has to cope, a discretionary
policy that makes efficient use of feedback
information will be more effective than
an automatic policy that locks in on fixed
fiscal and monetary targets.
Development of a simplified measure of
fiscal impact revolving around the "full
employment surplus" (FES) concept is
another example of the typical process by
which economists expose error, develop ap-
proximations of truth, but continue the
vigorous debate on further improvements.
First, policy makers had to be weaned
away from the annually balanced budget
and the cyclically balanced budget as
policy targets and from actual deficits or
surpluses (especially in budgets other than
the national income accounts budget) as
measures of budget stimulus or restriction.
It was not easy. It took almost a quarter
of a century before a Democratic president
was converted (in 1961) and another
decade to capture a Republican White
House.
But success on the policy frontier has
its own pitfalls, both political and eco-
nomic. What was intended as a measure of
policy was instead taken as a goal, name-
ly, a balanced budget at full employment,
a "self-fulfilling prophecy" as the Nixon
Administration called it. This erroneously
implied that the fiscal target should re-
main fixed regardless of changes in mone-
tary policy and significant shifts in private
demand, for example, a plant-and-equip-
ment boom. Apart from trying to correct
such misconceptions, economists have had
to wrestle with the problem of the over-
statement of the full employment surplus
when inflation expands revenues faster
than expenditures, not to mention the
problem of weighting for differing multi-
pliers if tax or expenditure components
change sharply. In brief, the advances over


### ---Economics-1975-0-16.txt---
the bad old days of the annually balanced
budget are enormous, but economists are
aware of the limitations of the FES mea-
sure and are struggling to resolve them.
Just as economics relegated erroneous
budget concepts to the dustbin, so it has
cast a shadow over such former favorites
(of mine, among others) as federal capital
budgeting and the "shelf of public works."
The initial enthusiasm for the capital
budget concept (in the context of a Con-
gress seeking to balance the budget an-
nually) was dispelled by second-thought
analysis showing that (a) it rested on some
faulty parallels with private finance, (b)
the implicit fiscal policy rule of always
financing capital projects by borrowing is
in error, and (c) it would bias government
capital spending toward bricks and mortar
instead of brainpower and people. In the
public works case, the concept ran afoul
the findings of prosaic economic research:
recent studies show that the public works
program launched in 1963 to speed re-
covery was far from completed before
excess demand overtook us in the 1966-69
period. This is not to rule out the use of
certain types of "public works" that are
nimble on their feet, such as road and
forest maintenance work, for stabilization
purposes. Nor does it rule out speeding
up or delaying the launching of projects
that are to be undertaken for sound cost-
benefit reasons in any event. But it is
fair warning not to expect very much
stabilization help from the public works
sector (not to be confused with public
service employment).
In the conscious use of taxes for stabi-
lization purposes, the huge 1964 income
tax cut delivered economic expansion and
a balanced budget on schedule without in-
flation by mid-1965, just before the Viet-
nam escalation struck the economy. The
temporary 1968 surtax, buffeted by power-
ful demand forces and monetary easing,
left a more ambiguous econometric trail.
Subsequent fiscal policy thinking empha-
sizes the advantages of temporary tax
changes that embody not just income ef-
fects but intertemporal substitution effects.
For example, lowering the prices of invest-
ment goods in a recession via a clearly
temporary increase in the investment
credit, or temporary cuts in consumption
taxes on durable goods (or lacking these,
temporary purchase subsidies), would con-
stitute a powerful incentive to purchase
those goods before the price went up
again.
Further work is needed to measure the
cost-push effects of anti-inflationary tax
increases that offset part of their demand-
damping effect. In recession, the cost-
easing and demand-push effects work in
happy harmony. They work at cross pur-
poses in tax increases (though not in
expenditure cuts) to curb inflation. The
question of how large the offsetting cost-
push effects, or aggregate supply effects,
may be, is unresolved. In a high-inflation
economy, this is a serious gap in our fiscal
policy knowledge.
Other Aspects
This kaleidoscope of contributions, long
as it is, leaves out a whole string of de-
velopments in budget concepts, tech-
niques, and processes-efforts that were
crowned by the congressional budget re-
forms recently put into effect. Much of the
guidance and momentum for these reforms
was provided by economic analysis and by
a succession of five economist-budget direc-
tors throughout the 1960's. Also omitted is
the conceptual work on the economics of
the bureaucratic process, of how govern-
ment works. Other omissions include the
rebirth of interest and great advances in
the economics of state-local finance, the
rapid growth of the important new field of
urban economics-with its contributions
to regional economics, location research,
and analysis of the city as an economic sys-


### ---Economics-1975-0-17.txt---
tem and the enriched economics of fiscal
federalism. I have even eschewed an assess-
ment of revenue sharing, the rationale
and form of which were developed by
economists. With little imperialism, econo-
mists can also cite the firm quantitative
evidence being developed to demonstrate
the adverse economic effects of many pub-
lic regulatory activities.4
For all the advances, the agenda of un-
resolved conceptual questions and un-
finished empirical business is huge. But
even this truncated review of progress
and current output in public economics
makes clear that the contributions of
recent decades have enormously enriched
this field not only conceptually but as a
source of hard practical advice to decision
makers who want to shape a better tax
system, do justice to the poor, improve
social programs, reform budget procedures,
fight unemployment, and so on. And in the
process, the frontiers of normative eco-
nomics, both theoretical and empirical,
have been pushed out into the areas of
education, health, racism, crime, family
behavior, and even political behavior.
As a result, we have plunged ever deeper
into the realm of values. Not that it was
a value-free inquiry to ask the traditional
questions about the effect of a given policy
on material output. But surely the testing
of policies by the costs they incur and how
effective they are in meeting some gener-
ally accepted criteria of social welfare or
general welfare involves economics direct-
ly in value and distributional problems.
Aid it enables economics to say important
things on social policy issues within the
framework of the conventional economic
paradigm and with rigor of the non-mortis
variety.
We are becoming interdisciplinary in
spite of ourselves. When we do it, of course,
we don't think of it as cross-sterilization
of disciplines. But here is an area where
modesty becomes us. For if we confine
ourselves too narrowly to economics, we
are far too likely to attribute to economic
variables the behavior and results that are
really a response to social variables. Fear-
ing just that, one observer has been un-
kind enough to suggest that we ought to
stick to inflation problems where we all
know what to say.
V. The Economist and Inflation
Inflation may no longer be "Public
Enemy Number One" now that severe re-
cession is upon us, but it is surely "Econ-
omists' Enemy Number One." Among the
charges of, by, and against economists
that have been touched off by double-
digit inflation and reported in the public
prints are these:
Economists have confessed (I plead
guilty) that 1973 was "the year of in-
famy in inflation forecasting" and, as
already noted, that "we were caught
with our parameters down."
Aaron Gordon puts it more explicitly
when he says that "the forecasters fell
flat on their faces in predicting price
changes because they didn't have any
way of estimating sectoral supply scar-
city" and adds that we have not "even
started to develop a theory of aggregate
supply."
Leontief scolds macroeconomists more
generally: "There is a lot of fancy meth-
odology, but the macroeconomists get
indigestion if you give them facts."


### ---Economics-1975-0-18.txt---
We are reminded ad nauseam that the
"new economists" of the 1960's had
promised to fine-tune inflation out of
their full employment economy (a clear-
cut triumph of caricature over fact
since Keynesians time and again warned
of precisely the opposite danger).
Myrdal and Heilbroner have pointed
to stagflation as Exhibit A that econo-
mists typically lag rather than lead
their targets, that being "behind its
time" is "the regular methodological
weakness of establishment economics."
Von Hayek recently reentered the
fray to lay the blame for worldwide
inflation squarely at the door of econo-
mists, particularly those "who have
embraced the teachings of Lord
Keynes."
Apart from the charge that Keynesian
economists have caused inflation (which
is much like saying that the cause of forest
fires is trees), the bill of particulars against
macroeconomics runs something like this:
First, it did not forewarn the body politic
that it would have to pay such a high
price in endemic inflation for the attain-
ment of high employment. Second, its
progress in solving some important puz-
zles of endemic inflation relating, for
example, to the Phillips curve, wage infla-
tion, expectations, and uncertainty is
much too slow. Third, there is no articu-
lated genefal theory of inflation as such.
Fourth, economists failed to foresee the
1973-74 epidemic inflation because their
forecasting models lacked the central
supply and price parameters. Fifth, macro-
economics is helpless in the face of epi-
demic or external-shock inflation-indeed,
it has not satisfactorily explained the co-
existence of inflation and recession, or
stagflation. Without attempting a point-
by-point assessment of these complaints,
I will touch on all of them in the following
sympathetic interpretation of how econo-
mists are coping with inflation's tough
analytic and empirical challenges.
Addressing myself for a moment to our
reproachful public, let me simply say to
them: "We never promised you a rose
garden without thorns." Over most of the
past thirty years, macroeconomists have
warned again and again, first, that ag-
gressive fiscal and monetary policy to
manage aggregate demand was bound to
generate inflationary pressures once the
economy entered the full employment
zone, and second, that while full employ-
ment spells inflation, recessions run into
price and wage rigidities that thwart de-
flation, an asymmetry bound to produce a
ratchet effect on the price level. Keynes
himself foresaw the basic problem in his
little book, How to Pay for the War, in
1940. Abba Lerner and William Beveridge
also wrote of the problem in the early
1940's. And it has been discussed in the
stabilization theory and policy literature,
in congressional hearings, and in other
policy forums ever since.
This country finally embraced activist
fiscal policies for full employment in the
1960's, most explicitly in the 1964 tax cut.
Following the canons of Keynesian eco-
nomics, focussing on the economy's full
employment potential as their target, and
steadfastly rejecting a spate of "struc-
tural" explanations of unemployment,
economists were at first alone in prescrib-
ing tax cuts as a tonic for the stagnant
economy. Enacted early in 1964, the tax
cut delivered the promised expansion and
budget balance without inflation. By
August 1965, when Vietnam escalation
began, unemployment had been brought
to 4.4 percent with only the faintest stir-
ring of the inflationary beast (i.e., with
consumer prices rising at less than a 2 per-
cent annual rate).
In a very real sense, economists have
been victims of their own success. Macro-


### ---Economics-1975-0-19.txt---
economic policy, capped by the tax cut,
was the major force holding the postwar
economy on a vastly higher plane than
the prewar economy.5 On one hand, the
high employment, limited-recession econ-
omy forged with our macro-economic
policy tools is indeed an inflation-prone
economy the formula for successful man-
agement of high-pressure prosperity is far
more elusive than the formula for getting
there. Yet on the other hand, success bred
great expectations on the part of the public
that economics could deliver prosperity
without inflation and with ever-growing
material gains in the bargain. The message
got through that we had "harnessed the
existing economics . . . to the purposes of
prosperity, stability, and growth," and
that as to the role of the tax cut in break-
ing old molds of thinking, "nothing suc-
ceeds like success" (Heller). The Economist
unkindly corrected me: "Nothing exceeds
like success."6
To be sure, critics and converts alike
ignored our caveats that the goal of
"prosperity without a price-wage spiral"
had "eluded not only this country but all  of its industrial partners in the free world,"
that "the margin for error diminishes as
the economy reaches the treasured but
treacherous area of full employment. . .
and that "the 'new economics' promises
no money-back guarantees against occa-
sional slowdowns or even recessions"
(Heller).
All too soon, Vietnam blew the economy
off-course. Economists found that in the
political arena fiscal policy was not a two-
way street and that the much delayed sur-
tax adopted in mid-1968 was no match for
surging inflation. Nor was the induced re-
cession of 1969-70. It took a combination
of the 1971 shock therapy of tight wage-
price controls and the stimulus of tax cuts
to subdue inflation and energize expansion.
It is worth noting that economists an-
alyzed and projected the effects of this
''new economic policy" with exceptional
precision. That the tax cuts, coupled with
controls and devaluation, would generate a
surging expansion at very moderate rates
of inflation in .1972 was widely and ac-
curately forecast.
But the period from August 1971 to
January 1973 was in the nature of a re-
mission from the inflationary disease,
clearly not a cure. The 1969-70 recession
brought home the worsening problem of
persistent inflation in the face of slow-
down and recession. It presented new
empirical puzzles for the analysts of the
Phillips curve, wage equations, and expec-
tational inflation. And it began to prompt
the public mutterings that are being in-
tensified by the 1974-75 stagflation: "All
right, so you did not promise us a rose
garden without thorns-but the thorns
without the rose garden?"
Keenly aware of these problems, econo-
mists have long been at the drawing
boards on this problem of endemic infla-
tion. In a close parallel with research on
cancer, economists are working on various
pieces of the inflation puzzle and produc-


### ---Economics-1975-0-20.txt---
ing useful insights and guidance for policy
purposes. But as economists, we would be
the first to underscore that these puzzles
are far from being fitted into an articulated
and holistic theory of inflation. Inflation-
ary analysis appears as an appendage to
Keynesian and monetarist theories. But
as yet, the Keynesian apparatus cannot
tell us how any given change in aggregate
demand is divided between changes in
real output and changes in prices. Nor has
monetarist theory unlocked the puzzle of
how the effects of monetary changes are
divided between output and price level
changes. And no big breakthrough is in
sight.
Does this mean that the economist has
to stand mute in the meanwhile? Not at
all. He is pushing ahead on the various
pieces of basic research on the cancer of
inflation and isolating and prescribing
effectively for particular forms of the
cancer even without having a complete
explanation of the disease. Let me come
back to the sustained and systematic re-
search efforts on endemic inflation after
examining the 1973-74 epidemic and the
economist's responses to it. Since the
epidemic is an over-layer on the endemic
base, the distinctions won't be clear-cut-
but they are nonetheless useful for viewing
what the economist is able to contribute
to policy.
The food-fuel price bulge generated over
half of the 1973-74 inflation-and of
economists' woes as well. Yet, it is asking
a lot of economists to expect them to have
foreseen that the oil cartel would quad-
ruple oil prices, that the world would suffer
widespread and successive crop failures,
that the Peruvian anchovies would go into
hiding, and that the Soviets would "solve
our surplus grain problem" overnight.
Several unpleasant policy surprises also
beset the inflation forecasters. First, just
when a new rash of inflation was breaking
out early in 1973, the reasonably effective
Phase II controls were abruptly dropped
in favor of the weak and ineffective Phase
III. Second, six months later, after infla-
tion had changed into a commodity-driven
structural phenomenon involving a drastic
readjustment of relative prices, the White
House (to the pained surprise of econo-
mists inside and outside the administra-
tion) prescribed just the wrong medicine,
a new wage-price freeze. A third policy
surprise was that the dollar was allowed
to sink like a stone: At its low point in the
summer of 1973 (just before a substantial
rebound), relative prices of imports had
risen 10 percent in six months. About a
quarter of the 1973 inflation has been at-
tributed to these policy developments
(see William Nordhaus and John Shoven).
It is worth noting that unexpected
twists and turns of federal policy which
might be termed "internal shocks" in
contrast with the "external shocks" of the
food-fuel price explosion-are a continuing
bane of the forecaster's existence. The
about-face of the Federal Reserve in 1974
is another painful case in point. The sharp
turn from ease to tightness in the first
quarter of the year was a major factor in
transforming prospects of recovery into
recession in the second half of 1974. It is
not quite clear why economists should be
better at anticipating these shocks, es-
pecially the external ones, than society as
a whole, or other professional specialists,
or practical men of the world. Nothing in
statistical methodology or economic sci-
ence enables us to predict random shocks.
What can be expected of us is that when
they occur, we will spot them quickly,
identify them, and analyze their signifi-
cance for policy.
It is also worth remembering that
democratic governments, by their nature,
are pressure-responders rather than prob-
lem-anticipators. This carries two implica-
tions for political economists. On one
hand, if an idea's time has not yet come,


### ---Economics-1975-0-21.txt---
or if a problem has not yet become a crisis,
the economist's call for action is likely to
go unheeded. On the other, spotting
emergent problems early can perhaps
hasten an idea's time and alert the policy
makers to impending danger.
Economists can more readily be faulted
for being caught by surprise by the short-
ages of materials and primary processing
capacity that caused the economy to
bump against its ceiling sooner than ex-
pected and by the worldwide economic
boom that put severe pressure on raw
commodity supplies and prices. On the
first point, we suffered both from informa-
tion failure-the official capacity indexes
simply did not reveal how close the econ-
omy was to its output ceilings-and from
analytic limits. While identifying the
causes, economists have been unable to
pinpoint the relative significance of the
shortfall of investment that began in the
late 1960's, of underinvestment caused by
price controls, of delays induced by en-
vironmental policies, and of the surge in
foreign demand touched off by devalua-
tion. However, I should add that the
shortages problem is meat and drink for
economists, and they are responding (es-
pecially in the energy field) with new
analyses of price elasticities, investment
needs, and the like. All of a sudden, price
theory is back in vogue, and elasticities
have replaced multipliers as the badge of a
policy maker's savoir faire.
Delays in perceiving that the U.S. eco-
nomic expansion was part of a worldwide
upsurge can again be laid more to lack of
an adequate information system than to
any inability to understand the underly-
ing principles. Still, a better sense of his-
tory and of the emerging worldwide im-
balance between growing aspirations and
growing incomes on one hand and inelastic
resource supply and lagging technology
on the other would have made us more
conscious and cautious. We are consider-
ably less likely to be caught by surprise in
the future in view of the new worldwide
data networks that are being developed by
Project LINK at the University of Penn-
sylvania and by Otto Eckstein and his
colleagues at Data Resources Incorporated
(DRJ).
Without absolving economists, one
should apply this operational test: With
proper foresight, would tighter monetary
and budget policy have been able to
damp inflation? It is worth recalling, first,
that the full employment budget was
making a swing of over $10 billion towards
restraint between fiscal 1973 and fiscal
1974 (from a $2 billion deficit to a $10
billion surplus under the old 4 percent un-
employment standard) and that monetary
policy pushed interest rates into the
double-digit region; second, that there was
little that an aggregate demand squeeze
could have done to push world commodity
prices down. So the answer is clear: Even
tougher fiscal and monetary policy would
have had limited scope in holding inflation
down.
This is not to deny that generating a
larger full employment surplus would
have been the prudent course in calendar
1973. But it is worth noting that to offset
the food and fuel price explosions-which
were triggered by forces largely immune to
U.S. fiscal and monetary policy-would
have required a reduction of 3 percent in
all other prices. Such a target implies de-
pression-inducing doses of fiscal and mone-
tary restriction, an unthinkable "solu-
tion."
Looking toward the future, many econo-
mists draw the lesson not that one should
keep the economy's motor idling,' but
rather that one should provide it with
safety devices and heavy-duty shock ab-
sorbers, for example, stock-piling of food-
stuffs, oil, and basic raw materials, careful
tracking of commodity exports, distant
early warning systems to spot shortages-


### ---Economics-1975-0-22.txt---
in-the-making, and conservation and de-
velopment measures to limit dependence
on foreign raw materials cartels. In other
words, it is a call for better planning,
better data, and faster conversion of
knowledge into policy.
Another criterion of economists' re-
sponses to inflationary shocks is how
quickly they adapted (read, "disaggre-
gated") their macromodels, large and
small, to incorporate new supply and price
parameters that had previously been
judged of second or third order importance
and hence relegated to Marshall's ceteris
paribus pound. Some of the mongrel pups
impounded there turned out to be full
blooded huskies, for example, food prices,
the exchange value of the dollar, oil and
other raw material supplies and prices. At
first most economists were slow and the big
models sluggish in their responses. After
all, for two decades prices had moved in
tandem with wages, with a year-by-year
percentage-point differential of 23+ 1. So
most models relied on wage trends, with
some adjustment for productivity and
capacity behavior, to give them a fix on
price trends. Their eyes were on labor
market indicators rather than commodity
supplies, exchange rates, and the like.
After some initial delays, the model build-
ers scrambled to disaggregate, to build
microelements into their macromodels.
For example, DRI now has good stage-of-
processing models that absorb the impacts
of food and energy explosions. Price elas-
ticities are being built into the macro-
models to reflect the impact of massive
relative price changes on the macrodimen-
sions of the economy.
The whole experience reminds us of the
role and limits of econometric forecasting
models. First, the combination of com-
puters, mathematics, and econometrics
cannot produce the miracles that the un-
initiated may expect of them-there is no
way of replicating reality with its 3 million
equations, all of them non-linear. Second,
their indispensable function is to bring us
closer to reality and help the mind manage
the previously unmanageable-they per-
mit us to release vastly more animals from
the ceteris paribus pound than we could
manage without these tools. Third, they
have to be constantly adjusted to plug in
common sense, adjust the length of the
lags, and bring in new dimensions of the
problem. Else, they will lock out things
that a more judgmental approach would
include, and will fail to respond quickly to
changes in order of importance.
So the inflation-shock experience has
brought home the need not just to watch
supply but to watch all the pieces lest the
model prevail over the mind, rather than
having the model help the mind prevail
over matter. The macro-stalactites have
to reach toward the micro-stalagmites, and
vice versa. I hope that metaphor is not a
portent of the pace at which the advance
toward macro-micro fusion will proceed.
Economists who use judgmental models
have shown us how to be the master
rather than the slave of the computer. A
case in point was the early analysis (es-
pecially by George Perry) of the macro-
impact of the oil price increases. A year
ago, his work had already brought out the
oil paradox-the inflation of costs and
hence prices, leading to a deflation of ag-
gregate demand-and had provided some
estimates of both. The insight that some
$15 to $20 billion of consumer purchasing
power would be siphoned off into the
hands of oil producers and royalty col-
lectors without any early return to the
economy in the form of demand for im-
ports or investment goods had important
implications for demand-management pol-
icy-implications that were ignored until
severe recession was full upon us.7

### ---Economics-1975-0-23.txt---
These important insights into the
macro-economic policy implications of oil
prices fit into the broader efforts of econo-
mists to disentangle the sources of the
current inflation and identify the appro-
priate remedies. They differentiate among
(1) excess demand, which had spent
most of its force by early in 1974, (2) the
price-wage-price spiral, which began to
turn more rapidly in 1974, and (3) ex-
ternal-shock or special-sector inflation, in
particular, the commodity-price surges
that permeate the present inflation and
account for its special character and
ferocity.
The first responds rather readily to
monetary-fiscal pressure, the second re-
sponds more reluctantly, and the third is
highly resistant to the demand-manage-
ment measures of any given country. For
the second and especially the third types,
therefore, high costs in unemployment and
foregone output have to be incurred for
small gains in curbing inflation. So the dis-
tinction is an instructive one for policy-
even when the instructions are ignored.
As we meet here tonight, the economic
lessons that were so long ignored are being
painfully driven home by severe recession
and unemployment coupled with continu-
ing inflation. A much-belated consensus
that fiscal and monetary stimulus can now
be undertaken with minimal inflationary
risk is rapidly forming.
The economists' three-ply classification
of inflation sources is also useful in driving
home another point: In most U.S. infla-
tions, consisting of the first two types, one
person's price is another person's income,
so that in spite of some reshuffling, there
is no net loss in real income. Not so in
1973-75. Commodity inflation has trans-
ferred tens of billions of dollars of real in-
come out of the pockets of urban con-
sumers and wage earners into the hands of
farmers and foreigners where it is beyond
the reach of the collective bargaining
process. From this, several important
inferences can be drawn:
Point for point, this inflation cum
relative price changes is harsher in its
impact than previous postwar inflations.
In this "no-win" inflation, the wage
earner's loss has not generally been the
employer's gain; hence, if the wage
"catch-up" process succeeds in recoup-
ing the full rise in the cost of living,
much of the wage increase will pass
through to prices and thereby give the
wage-price spiral another self-defeating
turn.
It follows, as various economists
urged throughout 1974, that tax cuts to
bolster the real income of labor, if put in
the context of a social contract, might
well relieve some of the pressure for
higher wages.
In this respect, today's situation contrasts
rather sharply with the 1950-51 inflation
when a similarly rapid run-up in world
commodity prices was accompanied by a
rapid rise in profit margins side-by-side
with vigorous federal policies to boost
capacity. The ensuing combination of
ebbing world market prices and wage in-
creases that could be granted without
generating higher product prices resulted
in a remarkable four-year period of price
stability from 1952 to 1956.
A closely allied economic insight goes to
the nature of the inflationary process. It



### ---Economics-1975-0-24.txt---
explains in good part why inflation is so
stubborn even in the face of overly restric-
tive monetary-fiscal policy and rapidly
mounting unemployment and slack in the
economy. It is the sharp run-up in relative
prices of food, fuel, and imported goods-
coupled with the downward rigidities of
wages and prices that is the key to most
of our stagflationary malaise today.
These downward rigidities are a striking
example of the way in which economic
solutions create their own problems and
move the economist relentlessly from one
new frontier to another. Once macroeco-
nomics gave governments the know-how
and tools of modern demand-management
to avoid depression, and once the public
caught on that even recessions are essen-
tially man-made-chiefly by That Man in
the White House, whoever he is, together
with the Congress and the Federal Reserve
Board-it became part of the politics of
survival to hold employment high and
keep recessions in check. Absent the fears
of mass unemployment and prolonged
recession, the risks of not cutting prices
and not accepting lower wages are mini-
mized. Having put the Great Depression
of the 1930's far behind us, will we there-
fore have to live with the Great Inflation
of the 1970's?
Essentially, the economist answers that,
given the ratchet behavior of wages and
prices, the price level can only float up-
ward to accommodate the massive relative
price increases of oil, grains, certain raw
materials, and imported goods. These
sharp changes in the composition of supply
touch off reverberating price increases
throughout the economy as prices in the
scarce-supply sectors become costs in the
less-scarce ones. The reverberations go on
-in substantial part independent of the
state of aggregate demand and hence of
monetary and fiscal policy-until the
prices of the initiating goods have risen
sufficiently farther than prices in general
to accomplish the necessary realignment
of relative prices. This is the process going
on now. It takes time, but not forever. It
has much to do with double-digit inflation,
but it does not condemn us to Weimar
Republic inflation.
Solow (1975) reminds us that the sup-
ply-shift phenomenon bears a close rela-
tionship to the demand-shift analysis of
the creeping inflation of the mid-1950's.
At that time, the parallel process was
touched off by an investment boom that
put excess demand pressures on capital
goods industries even when there was no
excess aggregate demand in the economy.
Given the downward rigidity and cost-
oriented nature of wages and prices in
areas of excess market power, the price
level had to float upward to accommodate
those relative price changes (see Schultze
(1959)).
John Dunlop and other economists have
emphasized that there is a closely related
phenomenon on the wage side known as
"scale wages" or "wage relativities" or
even a "just wage" (see Robert Hall and
Michael Piore). If the relative wage scale
is thrown out of kilter by an outsized
wage settlement in one industry, the others
will writhe, twist, and turn until the old
relationships are reestablished. There is
only one way the wage structure can move
to accommodate this process: Up. Again,
the process burns itself out only when a
new equilibrium has been established on a
higher plateau.
The policy implications of the supply-
shift, demand-shift, and wage-shift in-
sights are reasonably clear. One is the
limited scope of repressive monetary-fiscal
policy in coping with this process. Another
is that the key to a successful wage-
price policy for these circumstances is
to establish and effectuate norms for the
pace-setters and thus thwart the wage-
wage and price-price spirals and the inter-
acting wage-price spiral. Once the process


### ---Economics-1975-0-25.txt---
is launched, the role of a wage-price
watchdog with teeth would be to see to it
that the adjustment process is a limited
and straightforward one, not a leapfrog-
ging sequence that will prolong the agony
of adjustment. Again, understanding the
economics of the process is the sine qua
non for shaping the right policy to fit the
particular type and phase of inflation that
is beleaguering us.
Let me return now, before closing, to
several of the abiding problems of endemic
inflation that are engaging the attention
and efforts of economists.
An important but' elusive question for
the policy maker concerns the costs of
inflation. Can the economist tell him
anything useful and definitive on this
subject? Useful, perhaps. Definitive, no.
First, the economist would remind him
that people continually blame inflation for
crimes it does not commit. They are sure
that every increase in their pay envelope
is a reward for merit, every increase in
prices an inflationary theft. Especially
pertinent to our present shock-spiral is
the observation that people "blame infla-
tion for changes in relative prices and in
real incomes that stem from market forces
that have nothing to do with the course of
the general price level" (Edward Foster).
Second, studies show that in a typical
U.S. inflation, the poor have gained more
in jobs and incomes than they have lost in
higher prices. But in the present inflation,
prices have shifted sharply against the
poor, and any initial gains they may have
made in jobs and income in 1973 have been
more than offset by the losses incurred in
the deepening 1974-75 recession induced
to fight inflation.
Third, at the rates of inflation experi-
enced prior to the 1973-75 explosion, most
economists find it difficult to believe that
the costs of inflation-mostly in redis-
tributional effects, but with some distor-
tion in resource allocation-hold a candle
to the welfare losses of substantial add-ons
to unemployment. Fourth, however, when
inflation reaches double-digit levels, the
costs in terms of the social conflicts and
tensions it generates and the uncertainties
and loss of confidence in the dollar yard-
stick it may breed are important intangi-
bles that economists cannot ignore, yet
have not been able to quantify. We need
to understand far more about what un-
settles and upsets people about inflation,
how this affects their economic behavior,
and what economic costs result. Clearly,
in an economy where inflation is endemic,
the balance between its gains and losses
deserves intensive further study.
Another important question is this:
How much of the present run-up in prices
of foodstuffs, oil, and raw materials is a
transitory phenomenon, how much is a
one-time shift to a new plateau, and how
much represents a new upward trend?
Economists have trained the guns of price
theory and price elasticity estimation on
these questions in the case of oil and sev-
eral other basic materials. They generally
come up with more optimistic answers
for five to ten years hence than for the
near-term. But much of the answer lies
in geo-political, meteorological, and simi-
lar puzzles-for example, the effective-
ness of oil and other raw material cartels,
the pace of world population increases
and income growth, and the possibility of
a dry, cold phase in world weather-that
lie largely or wholly beyond the reach of
economic analysis.
What we do know is this: The 1950's
and the 1960's were a period of gently de-
clining or roughly stable world prices for
raw materials or foodstuffs. Now, rising
population, industrialization, income, and
aspirations may put such pressure on the
world's supply capabilities that while we
are not nearing any Club-of-Rome ulti-
mate limits, we may for some time exceed
the speed limits of stable expansion. If so


### ---Economics-1975-0-26.txt---
we may have passed an inflection point in
the price trends of basic inputs to the econ-
omy (see Walt Rostow). The mild down-
ward trend of the 1951-71 period facilitated
the rise in real incomes of urban workers
side-by-side with rising profits. If this trend
is reversed, rising income claims will gen-
erate greater strains, and the Phillips
curve tradeoff will take place around a
higher inflation constant. Economic anal-
ysis of long-run supply prices of basic
commodities using alternative assump-
tions regarding world political, weather,
and economic trends could be a useful aid
to rational economic planning.
Coming back into the domain of eco-
nomics as such, one should take account of
the important new thinking and efforts
now being devoted to the continuing
mysteries of industrial pricing policies and
the role of fixed-rule (generally, mark-up)
pricing as a shield against uncertainty.
Answering the question of how, and how
fast, supply-shifts in the auction markets
or market-oriented sector are transmitted
through the rule-determined sector-
where certain relativities seem to be main-
tained in the structure of prices (and
wages)-is essential to an understanding
of structural inflation (see Piore).
In turn, this analysis will strongly in-
fluence thinking on government interven-
tion in private wage-price and perhaps
also supply-demand decisions. If the wage-
price structure is indeed fairly rigid and if
supply- and demand-shifts set off an in-
flationary spiral, the "natural market
forces" will not readily make the necessary
supply-demand adjustment in any case.
Wage-price restraint or controls would not
be supplanting some supple and efficient
resource allocation mechanism, yet would
insert a circuit breaker into the inflation-
ary spiral. This view of the world would
also suggest that government action to
stimulate supply and suppress demand at
certain pressure points in the economy
might well pass the test of economic effi-
ciency. In pursuing these questions and
hypotheses, the economist will be laying a
firmer conceptual and empirical founda-
tion for specifying the areas and circum-
stances in which intervention may be the
lesser evil.
One should not leave the subject of
economists' contributions to analysis and
prescription on the inflation problem
without mention of the intriguing attempt
of the Brookings Panel on Economic
Activity to bring the best analytical and
empirical efforts of economists to bear di-
rectly on the problems and puzzles that
confront the policymaker. In relation to
inflation, the Panel has focussed much of
its attention on such questions as the
structure of labor markets, the Phillips
curve relationship and wage equations,
the costs of unemployment, price behavior
in specific sectors like foodstuffs and oil,
and the role of fiscal and monetary
policies. Apart from the significant con-
tributions that have been made to under-
standing these problems, and to bringing
academic work into closer contact with
current policy problems, the Brookings
Panel is an interesting and perhaps unique
exercise in "continuing confrontational
econometrics." Responding to the kinds of
criticisms quoted earlier in my remarks,
the Brookings Panel combines rigorous
quantitative testing with continuing sur-
veillance by one's peers to assure that the
investigator (a) looks beyond mathemat-
ics and makes his assumptions and- rela-
tions conform to common sense, (b) spells
out the implications of his econometrics
and, if they are implausible, tries again,
and (c) constantly keeps asking questions
of the model. With the Panel now going
into its sixth year of thrice-yearly meet-
ings, previous analyses become not un-
disturbed museum pieces, but grist for the
mill of constant retesting under the harsh
light of reality and peer-group criticism.


### ---Economics-1975-0-27.txt---
I have dealt at some length with the
substance of economists' work and find-
ings on inflation because mere assertions of
progress would hardly suffice to demon-
strate what's right with economics in this
most vulnerable area. The fact that there
are no final or comprehensive answers
has not kept economists from making
significant distinctions, analyses, and mea-
surements that equip policy makers with
better means of judging the policy trade-
offs and determining how to improve the
fit of policy-to-problem for the different
types and stages of inflation. When policy
makers fail to heed these lessons, as in
1974, both the economy and the economist
feel the backlash.
Throughout this discourse, I have time
and again been tempted to kick over the
traces I fastened on myself and give voice
to my own criticisms, dissatisfactions, and
admonitions. But since an unholy (and un-
witting) alliance of my colleagues and out-
side critics has amply and ably taken care
of this, I felt it best to stay within my con-
straints in the interest of doing what I
could do to redress the balance. As eco-
nomists, we have many sins, none deadly,
to confess. But these are far outweighed
by the virtues, all quite lively, that we can
legitimately profess.
## Economics-1976-0


### ---Economics-1976-0-03.txt---
The title of this paper summarizes the
two-fold theme to which I want to address
myself this evening. First, the mainstream
of economic theory sacrifices far too much
relevance in its insistent pursuit of ever
increasing rigor. And, second, we econo-
mists pay too little attention to the chang-
ing institutional environment that condi-
tions economic behavior. We do not often
enough reexamine our basic postulates in
light of changes in this environment, and,
perhaps more important, we shy away
from the big questions about how and why
the institutional structure is changing-
and where it is taking us.'
I
Economists pride themselves on belong-
ing to the most "scientific" of the social
sciences. The justification for this conten-
tion lies in the growing resemblance be-
tween the nature of the analytical tools
used in economics and in the natural
sciences-above all, the increasing use of
mathematical tools in theoretical analysis
and the development of sophisticated
mathematical and statistical techniques in
empirical work. Today, mathematically
formulated economic theory, the develop-
ment of econometric techniques, and the
sophisticated application of econometric
methods to the "testing of hypotheses" in
a variety of applied fields constitute the
core of the science of economics.2
What is science? One brief definition
runs: "A systematic knowledge of the
physical or material world." Most defini-
tions emphasize the two elements in this
definition: (1) "systematic knowledge"
about (2) the real world. Without pushing
this definitional question to its metaphysi-
cal limits, I merely want to suggest that if
economics is to be a science, it must not
only develop analytical tools but must also
apply them to a world that is now observ-
able or that can be made observable
through improved methods of observation
and measurement. Or in the words of the
Hungarian mathematical economist J'anos
Kornai, "In the real sciences, the criterion
is not whether the proposition is logically
true and tautologically deducible from
earlier assumptions. The criterion of 'truth'
is, whether or not the proposition corre-
sponds to reality" (p. 9, his italics). (Com-
pare Wassily Leontief 1966, p. 23.)
One of our most distinguished historians
of economic thought, George Stigler, has
stated that: "The dominant influence upon
the working range of economic theorists is
the set of internal values and pressures of


### ---Economics-1976-0-04.txt---
the discipline. The subjects of study are
posed by the unfolding course of scientific
developments" (p. 22). He goes on to add:
"This is not to say that the environment is
without influence...... "But, he continues,
"whether a fact or development is signifi-
cant depends primarily on its relevance to
current economic theory" (p. 23). (Com-
pare Tjalling Koopmans, p. 170.) What a
curious relating of rigor to relevance!
Whether the real world matters depends
presumably on "its relevance to current
economic theory." Many if not most of to-
day's economic theorists seem to agree
with this ordering of priorities.3
To what aspects of the observable world
does economics apply its analytical tools?
According to the familiar definition in the
International Encyclopedia of the Social
Sciences, which we owe originally to Lionel
Robbins, economics "is the study of the
allocation of scarce resources among un-
limited and competing uses." To this defi-
nition of microeconomics the Encyclo-
pedia then rather weakly adds macroeco-
nomics, which is defined as the study of
money, the general price level, and the
level of output and employment.
Let us consider the microeconomic part
of this definition. Presumably the reference
is to real resources, used to produce ob-
servable goods and services, that are ex-
changed and consumed by real people liv-
ing in the kind of world we see around us.
Of course, some degree of abstraction is
necessary if useful generalizations are to be
reached. Here the economic theorist quickly
runs up against a dilemma. Shall he seek to
make his analysis ever more rigorous, re-
gardless of the possibly diminishing rele-
vance of his conclusions to the observed
world? Or shall he sacrifice elegant refine-
ment for somewhat cruder analysis that
may lead to testable results? I suppose the
reply can be given that we need to do both
and that we need specialists in each of
these approaches. But certainly those who
construct the analytical apparatus should
pay more attention than many of them
now do to the substantive problems with
which economists are presumably con-
cerned.4
In speaking of how well current micro-
economic theory combines rigor and rele-
vance, I should distinguish among the
different but interrelated problem areas
with which this part of economic theory
concerns itself. Micro theory addresses it-
self primarily to three related topics: (1)
the conditions necessary for, and the means
of actually achieving, an optimum alloca-
tion of resources within decision-making
units, both firms and households, under
given assumptions as to the criteria of op-
timization; (2) again under given assump-
tions, the conditions necessary for the
existence of a general (or partial) equilib-
rium among all (or some) of these decision-
making units, including the determination
of the uniqueness and stability of such an
equilibrium; and (3) the conditions re-
quired for the achievement of an economic
optimum from a broad, social point of
view.
Some success has been achieved in blend-
ing rigor and relevance in the theory of the
single decision-making unit. Certainly, as
this year's Nobel prize in economics attests,
considerable progress has been achieved in
dealing with production planning in the
individual firm or establishment (or gov-
ernment department) for which mathe-
matical tools, including programming and
the whole range of activity analysis, have
proved to be useful. To some extent, how-



### ---Economics-1976-0-05.txt---
ever, the success achieved here makes this
part of economics resemble more a branch
of engineering than a social science. And at
the level of the individual firm some prog-
ress continues to be made in empirical
studies of production and cost functions,
the determinants of the demand for inputs,
the transmission of technical change, and
related topics. I do not wish to minimize
the value of this work. But we should not
ignore the extent to which rigorous formu-
lations of the theory of the firm have had
to be relaxed in order to obtain useful re-
sults in empirical work. Nor, I might add,
should we forget the extent to which con-
ventional theory ignores how and why
work is organized within the firm and
establishment in the way that it is, what
may be called the "social relations" of the
production process.
Some success in blending rigor and rele-
vance has also been achieved in the field of
household behavior-ranging from studies
of the determinants of consumers' demand
to recent work on human capital, the be-
havior of labor markets, the economics of
crime, and the like. I must confess to some
skepticism, however, about the relevance
of the economic models of household be-
havior recently developed by Gary Becker
and his followers-what has been referred
to as "the new home economics." Granted
that much useful work has been done in
this area. Nonetheless there is a lamentable
tendency among scholars in this field to
rely upon a caricature of human beings
who continuously and consciously balance
costs and benefits at the margin, whether
in deciding on another year of schooling,
whether and when to marry or be divorced,
how many children to have and when, or
whether and when to commit a crime. And
after a substantial amount of intensive re-
search, the human capital approach still
leaves unexplained a significant part of the
differences in personal incomes.
In the second area mentioned, particu-
larly general equilibrium theory, it seems
to me that relevance has been largely ab-
sent in the recent literature. To find much
relevance at the theoretical level, and I
refer here only to the theoretical literature,
we must go back to the partial-equilibrium
analysis of Alfred Marshall and his fol-
lowers. Walras, Pareto, and their succes-
sors-with their assumptions of atomistic
competition, perfectly flexible prices, cost-
less information, and limitless futures mar-
kets-have contributed little to relevance
in their steadfast pursuit of rigor. Although
a step in the right direction, recent at-
tempts to develop a pure theory of dis-
equilibrium are subject to much the same
criticism.
Rigor and relevance have been success-
fully blended in input-output analysis,
although largely at the expense of ignoring
the price sensitivity of input-output co-
efficients. Here again, the emphasis is on
engineering-type relationships, but in this
case the entire economy is the object of
study.
Micro-economic analysis, as I have noted,
concerns itself with "the allocation of
scarce resources among unlimited and com-
peting uses." As economists we are con-
cerned with how resources may be allo-
cated efficiently, and we are prepared to
provide the layman and the policymaker
with a rigorous definition of efficiency. But
"efficient allocation" for whose benefit? To
me it has always been startling that the
accepted province of micro-economic the-
ory has little room for the personal dis-
tribution of income-and virtually none
for the personal distribution of wealth. Of
course, we speak of "distribution," but by
this we mean either factor prices or total
factor shares.
Why wealth and labor services, the lat-
ter carrying widely different market-deter-
mined prices, are distributed among differ-
ent human beings in the way they actually
are is a question that the non-Marxian


### ---Economics-1976-0-06.txt---
economic theorist seldom asks. An excep-
tion should be made for the relevant litera-
ture in the field of labor economics. Simi-
larly, some exception should be made for
the recent literature on human capital, but
at best it is only a partial exception.5 The
mathematically inclined general theorist
continues to show little interest in the de-
terminants of the personal distribution of
income and wealth.6 It has been said by
George Stigler that: "The problem of per-
sonal income distribution will eventually
receive much theoretical attention, since
it is a problem of all economies and all
times" (p. 22). (Compare Becker, p. 135.)
But if the problem is so important, why
only "eventually"? It is not surprising
that many younger economists are seeking
a radical alternative for the neoclassical
framework, more or less along Marxian
lines. And it is also this concern with the
unequal personal distribution of oppor-
tunity and income which has led to the
development of models of a dual labor mar-
ket. These models, with their emphasis on
institutional barriers to labor mobility,
offer some valuable insights into the opera-
tion of contemporary labor markets, and
they also raise important questions about
some of the assumptions implicit in neo-
classical theory.7
From the point of view of human wel-
fare-a concept that will not go away no
matter how uncomfortable it makes the
economic theorist-can we ignore the per-
sonal distribution of income? Which is
more relevant: a rigorous demonstration as
to how resources can be most efficiently
allocated under ideal conditions that have
never existed, or a much cruder exploration
of how wealth and income came to be dis-
tributed as they in fact are and what might
be done to affect the distribution of income
in one way or another? As Alice Rivlin put
it in her Ely lecture last year (p. 2), econo-
mists "worth their pay" ought to be able
to explain the shape of the income distribu-
tion and why it is changing or not chang-
ing. By this criterion very few of us are
worth our pay.8 To go further, why do
we have so little to say about the inter-
generational movement among occupa-
tional and income classes, about the deter-
minants of the distribution of income
relative to those affecting the distribution
of wealth, and about the ethnic, social, po-
litical, and regional factors affecting the
distribution of both wealth and income?
Am I suggesting that economic theory
become much more normative than it now
is? Of course I am not. "Relevant" and
"normative" are not synonyms, and what
I am alleging here is that neoclassical eco-
nomics has failed to be relevant in its
refusal to deal with the personal distribu-
tion of income and wealth. This refusal
stems, I presume, fron the fact that, with
the analytical tools at hand, the problem
has seemed too difficult.
I should add in this connection that neo-
classical economics has always had a nor-
mative slant. As others have suggested,

### ---Economics-1976-0-07.txt---
conventional micro-economic theory as it
has developed, particularly in the last
seventy-five years or so, takes a normative
stance by default.9 Indeed, it takes a
normative stance by more than default. It
says outright that the primary question to
which economists should address them-
selves is the "optimum" allocation of re-
sources, and it insists on providing a pre-
cise definition of optimum. (Compare
Ward, pp. 52-54, 90.) Since, as Koopmans
points out, competitive equilibrium theory
ignores the welfare implications of the per-
sonal distribution of income that results,
"the term 'optimum' [is] a misnomer"
(p. 49). (See also Ward, pp. 197-98.)
My remarks thus far have been directed
toward microeconomics. But macro-eco-
nomic analysis also must face the problem
of how optimally to combine rigor and
relevance. What we today call macro-
economics grew out of the catastrophe of
the Great Depression,'0 and in the early
development of macro-economic analysis
relevance took precedence over rigor. To-
day, rigor competes with relevance in
macro-economic and monetary theory, and
in some lines of development macro and
monetary theorists, like many of their col-
leagues in micro theory, seem to consider
relevance to be more or less irrelevant. A
good example has been the elaboration of
so-called growth theory Ahich now seems
to be losing some of its earlier popularity.
Apparently, there has come to be a growing
recognition that the considerable efforts
spent on growth models have not signifi-
cantly advanced knowledge beyond the
contributions of the original Harrod-Domar
and the Solow-Swan neoclassical models.
And other intriguing topics have arisen to
stimulate the pursuit of rigor at the ex-
pense of relevance.
In both micro- and macroeconomics, ef-
forts are sometimes made to extract a drop
or two of relevance from exercises in ana-
lytical rigor; and conclusions are drawn
about the functioning of some aspect of
the real world, or policy recommendations
are made, on the basis of theoretical exer-
cises which rest on assumptions that fly in
the face of the facts. One example is the
frequent fitting of the neoclassical invest-
ment function, with its built-in assump-
tions of constant returns and perfect com-
petition, to industries in which these as-
sumptions obviously do not hold. Another
example is a good deal of the recent litera-
ture seeking to reformulate the micro-
economic foundations of macro-economic
theory and policy-what Edmund Phelps
(1969, 1972) has termed "The New Micro-
economics in Inflation and Employment
Theory." The theoretical analysis in much
of this literature rests on assumptions that
also fly in the face of the facts. To cite a
few examples: all unemployment is a vol-
untary activity as part of a search proce-
dure in which workers are continuously
equating costs and prospective benefits at
the margin; the labor supply is typically
taken to be homogeneous with perfect mo-
bility among labor submarkets; so-called
structural unemployment is ignored as are
the striking differences in unemployment
rates among different age, sex, ethnic, and
occupational groups; and downward wage
flexibility is generally assumed, although
some recent attempts have been made to
relax this assumption. Another related re-
cent development in which theory pro-
ceeds with impeccable logic from unrealis-
tic assumptions to conclusions that contra-
dict the historical record, is the recent
work on rational expectations. (Compare
Robert J. Gordon.) And, as a final illustra-
tion I might cite much of the recent litera-
ture on capital theory.
II
I turn now from the first part of my title
to the second from rigor and relevance to

### ---Economics-1976-0-08.txt---
the fact that we live in a world that is con-
tinually changing. And here I want to pose
two questions: First, to what extent does
the changing institutional environment af-
fect the relevance of the analytical tools
that we use and the assumptions that we
make about the determinants of individual
and group behavior? (Here, of course, I am
still raising the question of relevance.) And,
second, why do we ask so few questions
about why and how the institutional en-
vironment has changed in the way that it
has, and what are its internal dynamics
that will lead it to change in particular
ways in the future-not only in the United
States but in other countries? A few econo-
mists have addressed themselves to this
range of questions, notably Karl Marx and
Joseph Schumpeter. Among living econo-
mists, three who at least raise this range
of issues are John Kenneth Galbraith,
Gunnar Myrdal, and, in the Marxist
tradition, Paul Sweezy."1
Certainly the outstanding example of
the failure of economic theory to adapt its
analytical tools to the changing institu-
tional environment must be the stubborn
adherence to the assumption of perfect
competition, a concept which has been de-
scribed as being "as pervasive and funda-
mental as any in the whole structure of
classical and neoclassical economic theory"
(Stigler, p. 234).12 Indeed for a century or
so, economists have toiled to make more
precise the notion of a perfectly competi-
tive market. Over this same period, of
course, the character of actual markets has
been changing in many ways. While im-
provements in transportation and com-
munication have tended to promote com-
petition in expanding markets, the growth
of large firms and the spread of industrial
concentration have made oligopoly a much
more relevant model for industrial markets
than the perfectly competitive model
which today's theorists insist on using. It
is true that sporadic efforts have been
made to develop a theory of oligopoly, and
for a while high hopes were held for what
might be learned from game theory; but
no generally accepted theory of oligopoly
has yet emerged. At the same time, the
emphasis on general equilibrium theory
has tended to turn attention away from
this egregious departure from perfect com-
petition.13
It is true, of course, that in the 1930's,
under the stimulus of the pioneering works
by Edward Chamberlin and Joan Robin-
son, we developed a theory of monopolistic
or imperfect competition, centering on the
notion of product differentiation. And at
the same time increased attention began
to be paid to the determinants of oligopo-
listic behavior. At the applied level, the
field of industrial organization was born.
But while this applied field has continued
to thrive, general micro-economic theory
and the applied work in this area have
largely parted company. General equilib-
rium theory (and not only this branch of
theory) has returned to the assumption of
perfect competition. The notion of a slop-
ing demand curve for the individual firm
seemingly did not add much to the general
theorist's tool box, and the new mathe-
matical economics found it more exciting
to pick up the challenge of Walras and
Pareto and to turn to general equilibrium
analysis and to setting forth the conditions
of Pareto optimality. And for this the as-
sumption of perfect competition was con-
venient if not essential. As William Baumol


### ---Economics-1976-0-09.txt---
has noted, "The case of product differen-
tiation has proved particularly resistant to
general equilibrium analysis" (p. 45).14
And so, as power blocs multiplied in a
pluralistic world, as firms grew larger and
as conglomerates were added to vertical
and horizontal combinations, as advertis-
ing expenditures mounted to influence
spending out of rising discretionary in-
come, as the problem of externalities be-
came ever more important, and as the role
of government in the functioning of mar-
kets steadily increased, micro-economic
theory largely averted its eyes and became
ever more enamored of hypothetical sys-
tems of general equilibrium under condi-
tions of perfect competition.'5
In the meantime, instructors in under-
graduate micro theory have resolutely con-
tinued to teach their students the essen-
tials of the Chamberlinian partial equilib-
rium analysis, with downward sloping de-
mand curves facing the individual firm,
and laying down the conditions for short-
run and long-run equilibrium on an in-
dustry basis. That much, at least, under-
graduates seem able to absorb, and some
factual counterparts can be found for the
theoretical analysis. But at the graduate
level in many universities, and the more so
the more advanced the level of instruction,
Walras and Pareto and their successors
take over, and the analysis proceeds on the
basis of the conditions associated with ato-
mistic competition.
A further example, reflecting another di-
mension of the growth of large-scale busi-
ness, involves the conditions under which
decisions are made in the large firm.'6 In-
volved here are a number of issues which
have been the subject of some theoretical
analysis and a good deal of empirical work
in the postwar years, but very little of the
results of this work has yet found its way
into main corpus of micro-economic theory.
I have in mind such questions as the rela-
tive roles of profit maximizing and of other
criteria in the decision rules used in the
large firm, the effects of the separation of
ownership and management on these op-
timization criteria, the ways in which the
bureaucratization of decision making af-
fects the manner in which business firms
respond to market stimuli, and the effect
of the improvements in the gathering and
processing of information that have come
not only from the revolution in data
processing but also from the development
of a more scientific approach to decision
making.'7 What has been the effect of all
this on the pricing decisions of large firms,
the manner in which they participate in
wage negotiations, or how their investment
planning responds to current and prospec-
tive developments in product and finan-
cial markets? And there are other examples
of the same sort. Early work not only in



### ---Economics-1976-0-10.txt---
economics but also in the other social
sciences led to the development of what is
now called "organization theory," and this
is now a field in the better business schools;
but not much of this has seeped into the
mainstream of economic theory.
Some economic theorists today are be-
ginning to pay serious attention to the be-
ginnings of a theory of information, and
increasing attention is being paid to prob-
lems of decision making under uncertainty.
But here again too little attention tends
to be paid to the changing conditions under
which information is collected and pro-
cessed, and the manner in which institu-
tional arrangements affect the way in
which the future is viewed and attitudes
toward uncertainty change.
There is another and indeed startling
respect in which pure micro-economic the-
ory tends to ignore the changing institu-
tional environment. This has to do with
the steadily increasing role of government
in the functioning of markets. In neo-
classical general equilibrium theory, there
is no place for any kind of public authority.
Of course, we have the field of public
finance, which on the theoretical side and
at the micro level does borrow from neo-
classical theory; and, as Walter Heller re-
minded us last year, cost-benefit analysis
and tax-incidence theory have helped
economists to develop a rationale for many
types of government decision making.
There is also a growing literature on the
economics of government decision making
in a range of problem areas-from pollu-
tion to military spending to housing and
education. But the pure micro theorist
finds no role for a public authority in his
analysis of the determinants of general
equilibrium. (See Bent Hansen, p. 92.)
Here we encounter an important differ-
ence between micro and macro theory.
Much of macro theory (but by no means
all) tends to be policy oriented and to have
a strong normative orientation. It is con-
cerned both with policy variables and with
variables that can be, directly or indirectly,
influenced by policy. While there is a good
deal of macro theory in which the possible
role of government is ignored, much of
theoretical macroeconomics does, either
explicitly or by implication, leave an im-
portant role for government.
Although macro-economic theory does
not ignore the role of government, we can
still find plenty of examples of the failure
of macro theory to reflect the changing in-
stitutional environment. One of the most
striking examples undoubtedly involves
what little we have in the way of a theory
of inflation. The problem is most acute
with respect to accounting for inflationary
trends since World War II.
A number of explanations are currently
circulating regarding the tendency toward
accelerating inflation in the last decade or
more. The purely monetarist one is the
simplest and makes no reference to a
changing institutional structure. It tends
to ignore the sources and nature of the
pressures, operating through government,
which lead to changes in the supply of
money. An increasing number of econo-
mists, monetarists and Keynesians, em-
phasize the existence of a natural rate of
unemployment, with the implication that
government policies to expand aggregate
demand, by pushing unemployment to or
below the natural rate, lead to accelerating
inflation. But advocates of the natural rate
hypothesis have little to say about why the
natural rate, if it exists, is what it is today,
and how and why it has changed over the
years. Much of the work in this area tends
to be done in an institutional vacuum, in-
cluding the recent work on the formation
of price expectations.
I think it is fair to say that we still lack
a general theory with a significant time
dimension of the nature of the inflationary
process and how this process is affected by
the changing institutional setting. Gunnar


### ---Economics-1976-0-11.txt---
Myrdal is one of those to emphasize that
"in modern society the tendency of infla-
tion to become cumulative and to ac-
celerate is rooted in a wide and complex
institutional reality" (p. 24), and to urge
a broader, institutionally oriented analysis
of underlying causes and possible remedies.
Another is Peter Wiles in a provocative
recent essay in the Economic Journal.
Among these institutional changes making
for more rapid and apparently accelerating
inflation are the postwar commitment in
all advanced countries to a high level of
employment (stronger in Europe than in
the United States), the reluctance fully to
cover increasing public expenditures by
taxation, the growing tendency to link
wage and other payments to the consumer
price index, the increasing aggressiveness
of trade unions (emphasized by Wiles)
and other organized groups of income re-
ceivers, an apparent weakening of the
willingness of employers to resist wage de-
mands (which is closely related to the gov-
ernment's commitment to high employ-
ment), and the intensification of infla-
tionary expectations engendered by past
inflation. (See Myrdal, pp. 23 ff.) To all of
which we can add an international mone-
tary system that permitted huge dollar
outflows which became expanded mone-
tary reserves for other countries. This is a
familiar list. But how do these different
but related inflationary pressures interact?
Why have they become stronger? How do
we account for the particular rate of ac-
celeration that has occurred? Why does
the rate of acceleration seem to be differ-
ent, and because of what differences in the
institutional environment, in different
countries? And how have the significant
changes in the international system of
trade and finance affected these inflation-
ary trends? (See R. J. Gordon.)
I shall merely mention one other example
of the failure of economists today to take
adequate account in setting up their
models of the changing institutional en-
vironment. This has to do with the de-
terminants of household behavior, with
respect to both the demand for goods and
services and the supply of labor services.
What has been the effect on household be-
havior, for example, of advancing levels of
education, changes in the ways that news
is disseminated, recent trends toward ur-
banization and suburbanization, or the
massive change in the impact of advertis-
ing made possible by television?'8 To what
extent have these and other developments
made households behave more or less in
the way that economic theory assumes?
What bearing do these and other institu-
tional developments have on the behavior
of personal saving in recent years, in this
and other countries, and on the way that
households respond to recent and prospec-
tive inflationary trends?
III
I turn now to my second question about
the changing institutional environment.
Why does the central body of economic
analysis show so little interest in why and
how the institutional setting for economic
behavior has changed in the past and is
likely to change in the future? The past, of
course, is the domain of the historian, but
I am not aware that the vast amount of
historical research in the past century or
more has yet given us an acceptable model
of socioeconomic development in today's
advanced economies. As I put it more than
a decade ago, "Contemporary economics
does not yet have the tools required for a
comprehensive and evolutionary theory of
economic behavior that would take ap-
propriate account of the main lines of in-
stitutional change" (p. 146).19 Schumpeter
(1947) came closer in this century to pro-



### ---Economics-1976-0-12.txt---
viding such a theory than has any other
economist in the more-or-less orthodox
tradition. Outside that tradition, we can
turn to the Marxian literature.
Here, of course, I am harking back to a
major plea of the early institutionalists.
Veblen asked long ago, in the title of one
of his papers, "Why Is Economics Not
an Evolutionary Science?," and Wesley
Mitchell urged the need for a comprehen-
sive theory of economic behavior that
takes the cumulative change of institu-
tions as its chief concern. The institutional-
ists themselves did not develop such a com-
prehensive and evolutionary theory. While
the classical writers did have the elements
of a dynamic system-what Baumol
once referred to as the "magnificent
dynamics" of the classical school-they
theorized on the assumption of a fixed
set of social and economic institutions. As
Schumpeter put it, "the classics reasoned
in terms of a particular historical situation
which they uncritically idealized and from
which they uncritically generalized" (1947,
p. 75).
As for contemporary economists in the
neoclassical tradition, they, like their pre-
decessors, seem to be afraid to ask the
really big questions about the economic
aspects of society questions which, be-
cause they are big, must be concerned with
the changing institutional fabric. Some ex-
ception to this generalization should be
made for the considerable effort that has
gone into the study of the underdeveloped
parts of the world. Here economists have
not been able to ignore the interaction of
the institutional environment and eco-
nomic behavior, and increasing attention
has come to be paid to the conditions nec-
essary for one or another kind of change
in that environment. I might add here that
I continue to be impressed by the fact that
in general economists in the advanced
countries seem to be prepared to be more
institutional in dealing with other parts of
the world than they are in studying the
particular societies in which they live and
do most of their work.20
Might the following conceptual frame-
work provide a basis for a more systematic
study of the dynamic interaction of eco-
nomic behavior and the institutional
framework? At the most basic level, a so-
ciety is composed of individual human
beings. These individuals are members of
households. The larger number of them
sell the factor services they control to pro-
ducing units ("firms" for short); and those
who sell labor services must physically
participate in the production process. A
flow of newly produced goods and services
results. The distribution of these goods and
services among potential claimants de-
pends on much more than the operation
of "impersonal market forces." It reflects a
complex of institutional arrangements,
which include, among other things, the dis-
tribution of power among different groups
to influence particular commodity and fac-
tor markets, both directly and through
government, how the ownership of wealth
is distributed and for whose benefit it is
used, the tax structure and network of
government regulations that emerge from
the political process, and the total and dis-
tribution of net claims by the rest of the
world against domestic output.
Individuals not only are members of
households and suppliers of input services
to producing units (which may be govern-
mental as well as private), but they are also
part of a political process which, while



### ---Economics-1976-0-13.txt---
partly local and regional, culminates in the
powers of a national government.
Thus we begin with the households and
producing units of conventional economic
theory but immediately add government
as a third basic unit. Households, firms,
and government interact within a set of
evolving economic institutions. These eco-
nomic institutions include a hierarchy of
markets for current output and for the
services of labor, capital, and natural re-
sources, and an array of supporting insti-
tutions-from commercial banks to labor
mediators to government agencies-that
also make a contribution to total output.
Households and firms interact not only in
response to the standard market stimuli
but also by organizing pressure groups to
influence both government and particular
markets.
These pressure groups-not only labor
unions and trade associations but a wide
variety of other formal and informal
groups-operate within and are condi-
tioned by an evolving set of political and
legal institutions that lay down the ground
rules as to the way households, firms, and
government interact with each other. A
major aim of the pressure groups is to in-
fluence government and markets not only
directly but also by altering legal and po-
litical institutional arrangements. And as a
result of these pressures, the conditions
under which households and firms carry
out their economic functions change with
the passage of time-as do the ways in
which households and firms, through a
variety of forms of organization, seek to
change these conditions still further in
favor of their particular interests.21
We may speak of households, firms, and
government as the primary economic
agents which carry on their activities with-
in the framework of a set of evolving eco-
nomic institutions. But these agents and
economic institutions also interact with an
external environment which can be classi-
fied in a variety of ways. One simple clas-
sification might be: (1) the framework of
legal and political institutions, to which I
have already referred; (2) the complex of
social institutions that make up what may
loosely be referred to as the social environ-
ment; (3) the evolving body of scientific
and technical knowledge (and the institu-
tions through which such knowledge is de-
veloped and transmitted); (4) the physical
environment; and (5) the complex of po-
litical and economic arrangements that tie
a nation to the rest of the world.
Against this background, let us now
come back to my final question about the
evolving institutional environment, which
bluntly put was: How did we get to where
we are, and where are we going? Or, if you
will, what is the future of capitalism and
of the kind of market economy to which we
are accustomed and which is changing be-
fore our eyes? Lacking a dynamic, politico-
economic, and institutionally oriented
miodel, the neoclassical economist averts
his eyes-or possibly, and reluctantly, re-
fers the questioner to the still growing
Marxist literature. Has not the time come
for "orthodox" economists-both defenders
and critics of neoclassical theory-to re-
pair this glaring deficiency? Let us borrow
what seems appropriate from Marx and
his followers as well as from others, al-
though what Marx had to say fitted nine-
teenth century England much better than
it does late twentieth century Western
Europe or the United States. But at least
let us try to construct a model of the sort
I suggest that will have something to say
about the evolution and future of the kind
of economy and society in which we live. 

### ---Economics-1976-0-14.txt---
Sketchy as it is, and it is certainly
sketchy, I think my suggested conceptual
framework or something similar offers a
possible starting point. And there are
many intermediate questions to be raised
along the way. We have been witnessing a
significant extension of government control
of the market mechanism in all of the ad-
vanced economies, more so in some than in
others. This intervention ranges from con-
ventional forms of regulation of particular
industries, to sporadic attempts to impose
one or another kind of incomes policy, to
large-scale programs to redistribute in-
comes, to widening experiments in worker
participation, to outright nationalization
of particular firms or industries. What
combinations of pressures have caused this
extension of government intervention;
what forces will extend it further; what
forms will such intervention take; and
what are likely to be the effects on the
allocation of resources, the distribution of
income and wealth, and the rates of infla-
tion and of growth in total output-not to
mention the possible effects on the various
dimensions of the institutional environ-
ment, including the institution of private
property?
There are many other elements, besides
the few mentioned here, that would have
to be incorporated into a full-fledged, in-
stitutionally oriented theory of economic
development for the advanced economies
of the nonsocialist world. And we need
also to fit in the underdeveloped countries.
Here clearly we have to be political econo-
mists, and not just economists in the neo-
classical sense. We are currently witnessing
powerful political forces at work aimed at
improving the terms of trade of the third
world with the advanced countries. What
will determine the eventual outcome? Men-
tion of the third world raises a host of other
issues, political as well as economic. These
include the seemingly inexorable advance
of socialism in many of these countries ;22
the effect of autocratic forms of govern-
ment on the pace of economic growth, the
allocation of resources, and the distribu-
tion of income; and the ability of these
countries to deal with the population
growth resulting from high birth rates and
declining death rates.
And finally, to repeat, there is for econo-
mists the basic question to which not only
Marx and his followers but also Schumpeter
addressed themselves: What is the future
of capitalism in the advanced economies,
given the growing size and bureaucratiza-
tion of business firms, the increasing
strength of organized pressure groups, and
the momentum from the increasing govern-
ment intervention that has already oc-
curred? It seems to me that capitalism as
we know it in this coulntry or even in
Western Europe has little future in the
third world. What is its future in the ad-
vanced economies?
IV
And so, on this somber note, I end. I
have scolded economists for what I think
are the sins that too many of them commit,
and I have tried to point the way to at
least partial redemption. This road to
salvation will not be an easy one for those
who have been seduced by the siren of
mathematical elegance or those who all too
often seek to test unrealistic models with-
out much regard for the quality or rele-
vance of the data they feed into their equa-
tions. But let us all continue to worship at
the altar of science. I ask only that our
credo be: "relevance with as much rigor as
possible," and not "rigor regardless of
relevance." And let us not be afraid to ask
-and to try to answer the really big
questions.


### ---Economics-1976-0-15.txt---

## Economics-1977-0


### ---Economics-1977-0-03.txt---
In recent years and especially since the onset
of the current depression, the economics profes-
sion and the lay public have heard a great deal
about the sharp conflict between "monetarists
and Keynesians" or between "monetarists and
fiscalists.". The difference between the two
"schools" is generally held to center on whether
the money supply or fiscal variables are the
major determinants of aggregate economic ac-
tivity, and hence the most appropriate tool of
stabilization policies.
My central theme is that this view is quite far
from the truth, and that the issues involved are of
far greater practical import. There are in reality
no serious analytical disagreements between
leading monetarists and leading nonmonetarists.
Milton Friedman was once quoted as saying,
"We are all Keynesians, now," and I am quite
prepared to reciprocate that "we are all mone-
tarists' '-if by morietarism is meant assigning to
the stock of money a major role in determining
output and prices. Indeed, the list of those who
have long been monetarists in this sense is quite
extensive, including among other John May-
nard Keynes as well as myself, as is attested by
my 1944 and 1963 articles.
In reality the distinguishing feature of the
monetarist school and the real issues of disagree-
ment with nonmonetarists is not monetarism, but
rather the role that should probably be assigned
to stabilization policies. Nonmonetarists accept
what I regard to be the fundamental practical
message of The General Theory: that a private
enterprise economy using an intangible money
needs to be stabilized, can be stabilized, and
therefore should be stabilized by appropriate
monetary and fiscal policies. Monetarists by
contrast take the view that there is no serious
need to stabilize the economy; that even if there
were a need, it could not be done, for stabiliza-
tion policies would be more likely to increase
than to decrease instability; and, at least some
monetarists would, I believe, go so far as to hold
that, even in the unlikely event that stabilization
policies could on balance prove beneficial, the
government should not be trusted with the neces-
sary power.
What has led me to address this controversy
is the recent spread of monetarism, both in a
simplistic, superficial form and in the form of
growing influence on the practical conduct of
economic policy, which influence, I shall argue
presently, has played at least some role in the
economic upheavals of the last three years.
In what follows then, I propose first to review
the main arguments bearing on the need for
stabilization policies, that is, on the likely extent
of instability in the absence of such policies, and
then to examine the issue of the supposed desta-
bilizing effect of pursuing stabilization policies.
My main concern will be with instability gener-
ated by the traditional type of disturbances-de-
mand shocks. But before I am through, I will
give some consideration to the difficult problems
raised by the newer type of disturbance-supply
shocks.
I. The Keynesian Case for Stabilization Policies
A. The General Theory
Keynes' novel conclusion about the need for


### ---Economics-1977-0-04.txt---
stabilization policies, as was brought out by the
early interpreters of The General Theory (for
example, John Hicks, the author, 1944), re-
sulted from the interaction of a basic contribu-
tion to traditional monetary theory-liquidity
preference-and an unorthodox hypothesis
about the working of the labor market-com-
plete downward rigidity of wages.
Because of liquidity preference, a change in
aggregate demand, which may be broadly de-
fined as any event that results in a change in the
market clearing or equilibrium rate of interest,
will produce a corresponding change in the real
demand for money or velocity of circulation, and
hence in the real stock of money needed at full
employment. As long as wages are perfectly
flexible, even with a constant nominal supply,
full employment could and would be maintained
by a change of wages and prices as needed to
produce the required change in the real money
supply-though even in this case, stability of the
price level would require a countercyclical mon-
etary policy. But, under the Keynesian wage
assumption the classical adjustment through
prices can occur only in the case of an increased
demand. In the case of a decline, instead, wage
rigidity prevents the necessary increase in the
real money supply and the concomitant required
fall in interest rates. Hence, if the nominal
money supply is constant, the initial equilibrium
must give way to a new stable one, characterized
by lower output and by an involuntary reduction
in employment, so labeled because it does not
result from a shift in notional demand and supply
schedules in terms of real wages, but only from
an insufficient real money supply. The nature of
this equilibrium is elegantly captured by the
Hicksian IS-LM paradigm, which to our gener-
ation of economists has become almost as fa-
miliar as the demand-supply paradigm was to
earlier ones.
This analysis implied that a fixed money sup-
ply far from insuring approximate stability of
prices and output, as held by the traditional
view, would result in a rather unstable economy,
alternating between periods of protracted unem-
ployment and stagnation, and bursts of inflation.
The extent of downward instability would de-
pend in part on the size of the exogenous shocks
to demand and in part on the strength of what
may be called the Hicksian mechanism. By this
I mean the extent to which a shift in IS, through
its interaction with LM, results in some decline
in interest rates and thus in a change in income
which is smaller than the original shift. The sta-
bilizing power of this mechanism is controlled
by various parameters of the system. In par-
ticular, the economy will be more unstable
the greater the interest elasticity of demand for
money, and the smaller the interest responsive-
ness of aggregate demand. Finally, a large
multiplier is also destabilizing in that it implies
a larger shift in IS for a given shock.
However, the instability could be readily
counteracted by appropriate stabilization poli-
cies. Monetary policy could change the nominal
supply of money so as to accommodate the
change in real demand resulting from shocks in
aggregate demand. Fiscal policy, through ex-
penditure and taxes, could offset these shocks,
making full employment consistent with the
initial nominal money stock. In general, both
monetary and fiscal policies could be used in
combination. But because of a perceived uncer-
tainty in the response of demand to changes in
interest rates, and because changes in interest
rates through monetary policy could meet diffi-
culties and substantial delays related to expec-
tations (so-called liquidity traps), fiscal policy
was regarded as having some advantages.
B. The Early Keynesians
The early disciples of the new Keynesian
gospel, still haunted by memories of the Great
Depression, frequently tended to outdo Keynes'
pessimism about potential instability. Concern
with liquidity traps fostered the view that the de-
mand for money was highly interest elastic;
failure to distinguish between the short- and
long-run marginal propensity to save led to over-
estimating the long-run saving rate, thereby
fostering concern with stagnation, and to under-
estimating the short-run propensity, thereby
exaggerating the short-run multiplier. Interest


### ---Economics-1977-0-05.txt---
rates were supposed to affect, at best, the de-
mand for long-lived fixed investments, and the
interest elasticity was deemed to be low. Thus,
shocks were believed to produce a large re-
sponse. Finally, investment demand was seen as
capriciously controlled by "animal spirits,"
thus providing an important source of shocks.
All this justified calling for very active stabiliza-
tion policies. Furthermore, since the very
circumstances which produce a large response to
demand shocks also produce a large response to
fiscal and a small response to monetary actions,
there was a tendency to focus on fiscal policy as
the main tool to keep the economy at near full
employment.
C. The Phillips Curve
In the two decades following The General
Theory, there were a number of developments of
the Keynesian system including dynamization of
the model, the stress on taxes versus expendi-
tures and the balanced budget multiplier, and the
first attempts at estimating the critical param-
eters through econometric techniques and mod-
els. But for present purposes, the most important
one was the uncovering of a "stable" statistical
relation between the rate of change of wages and
the rate of unemployment, which has since come
to be known as the Phillips curve. This relation,
and its generalization by Richard Lipsey to allow
for the effect of recent inflation, won wide ac-
ceptance even before an analytical underpinning
could be provided for it, in part because it could
account for the "puzzling" experience of 1954
and 1958, when wages kept rising despite the
substantial rise in unemployment. It also served
to dispose of the rather sterile "cost push"-
"demand pull" controversy.
In the following years, a good deal of attention
went into developing theoretical foundations for
the Phillips curve, in particular along the lines of
search models (for example, Edmund Phelps et
al.). This approach served to shed a new light on
the nature of unemployment by tracing it in the
first place to labor turnover and search time
rather than to lack of jobs as such: in a sense
unemployment is all frictional-at least in de-
veloped countries. At the same time it clarified
how the availability of more jobs tends to reduce
unemployment by increasing vacancies and thus
reducing search time.
Acceptance of the Phillips curve relation
implied some significant changes in the Keynes-
ian framework which partly escaped notice until
the subsequent monetarists' attacks. Since the
rate of change of wages decreased smoothly with
the rate of unemployment, there was no longer a
unique Full Employment but rather a whole
family of possible equilibrium rates, each asso-
ciated with a different rate of inflation (and re-
quiring, presumably, a different long-run
growth of money). It also impaired the notion of
a stable underemployment equilibrium. A fall in
demand could still cause an initial rise in unem-
ployment but this rise, by reducing the growth of
wages, would eventually raise the real money
supply, tending to return unemployment to the
equilibrium rate consistent with the given long-
run growth of money.
But at the practical level it did not lessen the
case for counteracting lasting demand distur-
bances through stabilization policies rather than
by relying on the slow process of wage adjust-
ment to do the job, at the cost of protracted un-
employment and instability of prices. Indeed,
the realm of stabilization policies appeared to ex-
pand in the sense that the stabilization authority
had the power of choosing the unemployment
rate around which employment was to be sta-
bilized, though it then had to accept the asso-
ciated inflation. Finally, the dependence of wage
changes also on past inflation forced recognition
of a distinction between the short- and the long-
run Phillips curve, the latter exhibiting the long-
run equilibrium rate of inflation implied by a
maintained unemployment rate. The fact that the
long-run tradeoff between unemployment and
inflation was necessarily less favorable than the
short-run one, opened up new vistas of "enjoy-
it-now, pay-later" policies, and even resulted in
an entertaining literature on the political busi-
ness cycle and how to stay in the saddle by riding
the Phillips curve (see for example, Ray Fair,
William Nordhaus).


### ---Economics-1977-0-06.txt---
II. The Monetarists' Attack
A. The Stabilizing Power of the
Hicksian Mechanism
The monetarists' attack on Keynesianism was
directed from the very beginning not at the
Keynesian framework as such, but at whether it
really implied a need for stabilization. It rested
on a radically different empirical assessment of
the value of the parameters controlling the sta-
bilizing power of the Hicksian mechanism and of
the magnitude and duration of response to
shocks, given a stable money supply. And this
different assessment in turn was felt to justify a
radical downgrading of the practical relevance
of the Keynesian framework as distinguished
from its analytical validity.
Liquidity preference was a fine contribution
to monetary theory but in practice the respon-
siveness of the demand for money, and hence of
velocity, to interest rates, far from being unman-
ageably large, was so small that according to a
well-known paper by Milton Friedman (1969),
it could not even be detected empirically. On the
other hand, the effect of interest rates on aggre-
gate demand was large and by no means limited
to the traditional fixed investments but quite
pervasive. The difficulty of detecting it empir-
ically resulted from focusing on a narrow range
of measured market rates and from the fact that
while the aggregate could be counted on to re-
spond, the response of individual components
might not be stable. Finally, Friedman's cele-
brated contribution to the theory of the consump-
tion function (1957) (and my own work on the
life cycle hypothesis with Richard Brumberg and
others, reviewed by the author, 1975) implied a
very high short-run marginal propensity to save
in response to transient disturbances to income
and hence a small short-run multiplier.
All this justified the conclusion that (i) though
demand shocks might qualitatively work along
the lines described by Keynes, quantitatively the
Hicks mechanism is so strong that their impact
would be small and transient, provided the
stock of money was kept on a steady growth
path; (ii) fiscal policy actions, like other demand
shocks, would have minor and transitory effects
on demand, while changes in money would
produce large and permanent effects on money
income; and, therefore, (iii) the observed in-
stability of the economy, which was anyway
proving moderate as the postwar period un-
folded, was most likely the result of the unstable
growth of money, be it due to misguided en-
deavors to stabilize income or to the pursuit of
other targets, which were either irrelevant or, in
the case of balance of payments goals, should
have been made irrelevant by abandoning fixed
exchanges.
B. The Demise of Wage Rigidity and the
Vertical Phillips Curve
But the most serious challenge came in
Friedman's 1968 Presidential Address, building
on ideas independently put forth also by Phelps
(1968). Its basic message was that, despite ap-
pearances, wages were in reality perfectly flex-
ible and there was accordingly no involuntary
unemployment. The evidence to the contrary,
including the Phillips curve, was but a statistical
illusion resulting from failure to differentiate be-
tween price changes and unexpected price
changes.
Friedman starts out by reviving the Keynesian
notion that, at any point of time, there exists a
unique full-employment rate which he labels the
"'natural rate." An unanticipated fall in demand
in Friedman's competitive world leads firms to
reduce prices and also output and employment
along the short-run marginal cost curve unless
the nominal wage declines together with prices.
But workers, failing to judge correctly the cur-
rent and prospective fall in prices, misinterpret
the reduction of nominal wages as a cut in real
wages. Hence, assuming a positively sloped
supply function, they reduce the supply of labor.
As a result, the effective real wage rises to the
point where the resulting decline in the demand
for labor matches the reduced supply. Thus, out-
put falls not because of the decline in demand,
but because of the entirely voluntary reduction in
the supply of labor, in response to erroneous
perceptions. Furthermore, the fall in employ-


### ---Economics-1977-0-07.txt---
ment can only be temporary, as expectations
must soon catch up with the facts, at least in the
absence of new shocks. The very same mech-
anism works in the case of an increase in de-
mand, so that the responsiveness of wages and
prices is the same on either side of the natural
rate.
The upshot is that Friedman's model also
implies a Phillips-type relation between infla-
tion, employment or unemployment, and past
inflation,-provided the latter variable is inter-
preted as a reasonable proxy for expected infla-
tion. But it turns the standard explanation on its
head: instead of (excess) employment causing
inflation, it is (the unexpected component of)
the rate of inflation that causes excess
employment.
One very basic implication of Friedman's
model is that the coefficient of price expectations
should be precisely unity. This specification
implies that whatever the shape of the short-run
Phillips curve a shape determined by the rela-
tion between expected and actual price changes,
and by the elasticity of labor supply with respect
to the perceived real wage the long-run curve
must be vertical.
Friedman's novel twist provided a fresh prop
for the claim that stabilization policies are not
really needed, for, with wages flexible, except
possibly for transient distortions, the Hicksian
mechanism receives powerful reinforcement
from changes in the real money supply. Simi-
larly, the fact that full employment was a razor
edge provided new support for the claim that
stabilization policies were bound to prove de-
stabilizing.
C. The Macro Rational Expectations Revolution
But the death blow to the already badly bat-
tered Keynesian position was to come only
shortly thereafter by incorporating into Fried-
man's model the so-called rational expectation
hypothesis, or REH. Put very roughly, this hy-
pothesis, originally due to John Muth, states that
rational economic agents will endeavor to form
expectations of relevant future variables by
making the most efficient use of all information
provided by past history. It is a fundamental and
fruitful contribution that has already found many
important applications, for example, in connec-
tion with speculative markets, and as a basis for
some thoughtful criticism by Robert Lucas
( 1976) of certain features of econometric mod-
els. What I am concerned with here is only its
application to macro-economics, or MREH,
associated with such authors as Lucas (1972),
Thomas Sargent (1976), and Sargent and Neil
Wallace (1976).
The basic ingredient of MREH is the postulate
that the workers of Friedman's model hold ratio-
nal expectations, which turns out to have a num-
ber of remarkable implications: (i) errors of
price expectations, which are the only source of
departure from the natural state, cannot be
avoided but they can only be short-lived and
random. In particular, there cannot be persistent
unemployment above the natural rate for this
would imply high serial correlation between the
successive errors of expectation, which is incon-
sistent with rational expectations; (ii) any at-
tempts to stabilize the economy by means of
stated monetary or fiscal rules are bound to be
totally ineffective because their effect will be
fully discounted in rational expectations; (iii)
nor can the government successfully pursue ad
hoc measures to offset shocks. The private sec-
tor is already taking care of any anticipated
shock; therefore government policy could con-
ceivably help only if the government informa-
tion was better than that of the public, which is
impossible, by the very definition of rational
expectations. Under these conditions, ad hoc
stabilization policies are most likely to produce
instead further destabilizing shocks.
These are clearly remarkable conclusions, and
a major rediscovery for it had all been said 40
years ago by Keynes in a well-known passage of
The General Theory:
If, indeed, labour were always in a posi-
tion to take action (and were to do so),
whenever there was less than full employ-
ment, to reduce its money demands by
concerted action to whatever point was
required to make money so abundant rela-


### ---Economics-1977-0-08.txt---
tively to the wage-unit that the rate of
interest would fall to a level compatible
with full employment, we should, in ef-
fect, have monetary management by the
Trade Unions, aimed at full employment,
instead of by the banking systems.
[p. 2671
The only novelty is that MREH replaces Keynes'
opening "if" with a "since."
If one accepts this little amendment, the case
against stabilization policies is complete. The
economy is inherently pretty stable-except
possibly for the effect of government messing
around. And to the extent that there is a small
residual instability, it is beyond the power of
human beings, let alone the government, to
alleviate it.
III. How Valid Is the Monetarist Case?
A. The Monetarist Model of Wage
Price Behavior
In setting out the counterattack it is convenient
to start with the monetarists' model of price and
wage behavior. Here one must distinguish be-
tween the model as such and a specific implica-
tion of that model, namely that the long-run
Phillips curve is vertical, or, in substance, that,
in the long run, money is neutral. That conclu-
sion, by now, does not meet serious objection
from nonmonetarists, at least as a first
approximation.
But the proposition that other things equal,
and given time enough, the economy will even-
tually adjust to any indefinitely maintained stock
of money, or nth derivative thereof, can be de-
rived from a variety of models and, in any event,
is of very little practical relevance, as I will argue
below. What is unacceptable, because incon-
sistent with both micro and macro evidence, is
the specific monetarist model set out above and
its implication that all unemployment is a volun-
tary, fleeting response to transitory mis-
perceptions.
One may usefully begin with a criticism of the
Macro Rational Expectations model and why
Keynes' "if" should not be replaced by
"since." At the logical level, Benjamin Fried-
man has called attention to the omission from
MREH of an explicit learning model, and has
suggested that, as a result, it can only be inter-
preted as a description not of short-run but of
long-run equilibrium in which no agent would
wish to recontract. But then the implications of
MREH are clearly far from startling, and their
policy relevance is almost nil. At the institu-
tional level, Stanley Fischer has shown that the
mere recognition of long-term contracts is suf-
ficient to generate wage rigidity and a substantial
scope for stabilization policies. But the most
glaring flaw of MREH is its inconsistency with
the evidence: if it were valid, deviations of un-
employment from the natural rate would be
small and transitory in which case The Gen-
eral Theory would not have been written and
neither would this paper. Sargent (1976) has
attempted to remedy this fatal flaw by hypothe-
sizing that the persistent and large fluctuations
in unemployment reflect merely corresponding
swings in the natural rate itself. In other words,
what happened to the United States in the 1930's
was a severe attack of contagious laziness! I can
only say that, despite Sargent's ingenuity,
neither I nor, I expect, most others at least of
the nonmonetarists' persuasion are quite ready
yet to turn over the field of economic fluctua-
tions to the social psychologist!
Equally serious objections apply to Fried-
man's modeling of the commodity market as a
perfectly competitive one-so that the real wage
rate is continuously equated to the short-run
marginal product of labor-and to his treatment
of labor as a homogenous commodity traded in
an auction market, so that, at the going wage,
there never is any excess demand by firms or
excess supply by workers. The inadequacies of
this model as a useful formalization of present
day Western economies are so numerous that
only a few of the major ones can be mentioned
here.
Friedman's view of unemployment as a vol-
untary reduction in labor supply could at best
provide an explanation of variations in labor
force-and then only under the questionable
assumption that the supply function has a sig-


### ---Economics-1977-0-09.txt---
nificantly positive slope-but cannot readily
account for changes in unemployment. Further-
more, it cannot be reconciled with the well-
known fact that rising unemployment is
accompanied by a fall, not by a rise in quits, nor
with the role played by temporary layoffs to
which Martin Feldstein has recently called
attention. Again, his competitive model of
the commodity market, accepted also in The
General Theorv, implies that changes in real
wages. adjusted for long-run productivity trend,
should be significantly negatively correlated
with cyclical changes in employment and output
and with changes in money wages. But as early
as 1938, John Dunlop showed that this conclu-
sion was rejected by some eighty years of British
experience and his results have received some
support in more recent tests of Ronald Bodkin
for the United States and Canada. Similar tests
of my own, using quarterly data, provide strik-
ing confirmation that for the last two decades
from the end of the Korean War until 1973, the
association of trend adjusted real compensa-
tions of the private nonfarm sector with either
employment or the change in nominal compen-
sation is prevailingly positive and very signifi-
cantly so.'
This evidence can, instead, be accounted for
by the oligopolistic pricing model-according
to which price is determined by long-run mini-
mum average cost up to a mark-up reflecting
entry-preventing considerations (see the author,
1958) coupled with some lags in the adjust-
ment of prices to costs. This model implies that
firms respond to a change in demand by endeav-
oring to adjust output and employment, without
significant changes in prices relative to wages;
and the resulting changes in available jobs have
their initial impact not on wages but rather on
unemployment by way of layoffs and recalls and
through changes in the level of vacancies, and
hence on the length of average search time.
If, in the process, vacancies rise above a criti-
cal level, or "natural rate," firms will endeavor
to reduce them by outbidding each other, thereby
raising the rate of change of wages. Thus, as
long as jobs and vacancies remain above, and
unemployment remains below, some critical
level which might be labeled the "noninflation-
ary rate" (see the author and Lucas Papademos,
1975), wages and prices will tend to accelerate.
If, on the other hand, jobs fall below, and unem-
ployment rises above, the noninflationary rate,
firms finding that vacancies are less than optimal
-in the limit the unemployed queuing outside
the gate will fill them instantly will have an
incentive to reduce their relative wage offer. But
in this case, in which too much labor is looking
for too few jobs, the trend toward a sustained
decline in the rate of growth of wages is likely
to be even weaker than the corresponding accel-
eration when too many jobs are bidding for too
few people. The main reason is the nonhomo-
geneity of labor. By far the largest and more
valuable source of labor supply to a firm consists
of those already employed who are not readily
interchangeable with the unemployed and, in
contrast with them, are concerned with protec-
ting their earnings and not with reestablishing
full employment. For these reasons, and because
the first to quit are likely to be the best workers, a
reduction of the labor force can, within limits, be
accomplished more economically, not by re-
ducing wages to generate enough quits, but by
firing or, when possible, by layoffs which insure
access to a trained labor force when demand
recovers. More generally, the inducement to



### ---Economics-1977-0-10.txt---
reduce relative wages to eliminate the excess
supply is moderated by the effect that such a
reduction would have on quits and costly turn-
over, even when the resulting vacancies can be
readily filled from the ranks of the unemployed.
Equally relevant are the consequences in terms
of loss of morale and good will, in part for rea-
sons which have been elaborated by the literature
on implicit contracts (see Robert Gordon).
Thus, while there will be some tendency for the
rate of change of wages to fall, the more so the
larger the unemployment-at least in an eco-
nomy like the United States where there are no
overpowering centralized unions-that ten-
dency is severely damped.
And whether, given an unemployment rate
significantly and persistently above the noninfla-
tionary level, the rate of change of wages would,
eventually, tend to turn negative and decline
without bound or whether it would tend to an
asymptote is a question that I doubt the empirical
evidence will ever answer. The one experiment
we have had the Great Depression suggests
the answer is negative, and while I admit that,
for a variety of reasons, that evidence is mud-
died, I hope that we will never have the oppor-
tunity for a second, clean experiment.
In any event, what is really important for
practical purposes is not the long-run equilib-
rium relation as such, but the speed with which it
is approached. Both the model sketched out and
the empirical evidence suggest that the process
of acceleration or deceleration of wages when
unemployment differs from the noninflationary
rate will have more nearly the character of a
crawl than of a gallop. It will suffice to recall in
this connection that there was excess demand
pressure in the United States at least from 1965
to mid- 1970, and during that period the growth
of inflation was from some 1.5 to only about 5.5
percent per year. And the response to the excess
supply pressure from mid-1970 to early 1973,
and from late 1974 to date was equally sluggish.
B. The Power of Self-Stabilizing Mechanisms:
The Evidence from Econometric Models
There remains to consider the monetarists'
initial criticism of Keynesianism, to wit, that
even without high wage flexibility, the system's
response to demand shocks is small and short-
lived, thanks to the power of the Hicksian mech-
anism. Here it must be acknowledged that every
one of the monetarists' criticisms of early,
simpleminded Keynesianism has proved in
considerable measure correct.
With regard to the interest elasticity of de-
mand for money, post-Keynesian developments
in the theory of money, and in particular, the
theoretical contributions of William Baumol,
James Tobin, Merton Miller, and Daniel Orr,
point to a modest value of around one-half to
one-third, and empirical studies (see for exam-
ple, Stephen Goldfeld) are largely consistent
with this prediction (at least until 1975!). Simi-
larly, the dependence of consumption on long-
run, or life cycle, income and on wealth,
together with the high marginal tax rates of the
postwar period, especially the corporate tax,
and leakages through imports, lead to a rather
low estimate of the multiplier.
Last but not least, both theoretical and empir-
ical work, reflected in part in econometric mod-
els, have largely vindicated the monetarist
contention that interest effects on demand are
pervasive and substantial. Thus, in the construc-
tion and estimation of the MIT-Penn-Social
Science Research Council (MPS) econometric
model of the United States, we found evidence
of effects, at least modest, on nearly every com-
ponent of aggregate demand. One response to
money supply changes that is especially impor-
tant in the MPS, if somewhat controversial, is
via interest rates on the market value of all assets
and thus on consumption.
There is, therefore, substantial agreement that
in the United States the Hicksian mechanism is
fairly effective in limiting the effect of shocks,
and that the response of wages and prices to
excess demand or supply will also work gradu-
ally toward eliminating largely, if not totally,
any effect on employment. But in the view of
nonmonetarists, the evidence overwhelmingly
supports the conclusion that the interim response
is still of significant magnitude and of consider-
able duration, basically because the wheels of
the offsetting mechanism grind slowly. To be
sure, the first link of the mechanism, the rise in
short-term rates, gets promptly into play and


### ---Economics-1977-0-11.txt---
heftily, given the low money demand elasticity;
but most expenditures depend on long-term
rates, which generally respond but gradually,
and the demand response is generally also grad-
ual. Furthermore, while this response is building
up, multiplier and accelerator mechanisms work
toward amplifying the shock. Finally, the clas-
sical mechanism the change in real money
supply through prices has an even longer lag
because of the sluggish response of wages to
excess demand.
These interferences are supported by simula-
tions with econometric models like the MPS.
Isolating, first, the working of the Hicksian
mechanism by holding prices constant, we find
that a 1 percent demand shock, say a rise in real
exports, produces an impact effect on aggregate
output which is barely more than 1 percent, rises
to a peak of only about 2 percent a year later, and
then declines slowly toward a level somewhat
over 1.5 percent.
Taking into account the wage price mech-
anism hardly changes the picture for the first
year because of its inertia. Thereafter, however,
it becomes increasingly effective so that a year
later the real response is back at the impact level,
and by the end of the third year the shock has
been fully offset (thereafter output oscillates
around zero in a damped fashion). Money in-
come, on the other hand, reaches a peak of over
2.5, and then only by the middle of the second
year. It declines thereafter, and tends eventually
to oscillate around a positive value because nor-
mally, a demand shock requires eventually a
change in interest rates and hence in velocity
and money income.
These results, which are broadly confirmed by
other econometric models, certainly do not sup-
port the view of a highly unstable economy in
which fiscal policy has powerful and everlasting
effects. But neither do they support the mone-
tarist view of a highly stable economy in which
shocks hardly make a ripple and the effects of
fiscal policy are puny and fast vanishing.
C. The Monetarist Evidence and the
St. Louis Quandary
Monetarists, however, have generally been
inclined to question this evidence. They coun-
tered at first with tests bearing on the stability of
velocity and the insignificance of the multiplier,
which, however, as indicated in my criticism
with Albert Ando (1965), must be regarded as
close to worthless. More recently, several au-
thors at the Federal Reserve Bank of St. Louis
(Leonall Andersen, Keith Carlson, Jerry Lee
Jordan) have suggested that instead of deriving
multipliers from the analytical or numerical
solution of an econometric model involving a
large number of equations, any one of which
may be questioned, they should be estimated
directly through "reduced form" equations by
relating the change in income to current and
lagged changes in some appropriate measure of
the money supply and of fiscal impulses.
The results of the original test, using the
current and but four lagged values of M1 and of
high Employment Federal Expenditure as mea-
sures of monetary and fiscal impulses, turned out
to be such as to fill a monetarist's heart with joy.
The contribution of money, not only current but
also lagged, was large and the coefficients im-
plied a not unreasonable effect of the order of
magnitude of the velocity of circulation, though
somewhat higher. On the other hand, the esti-
mated coefficients of the fiscal variables seemed
to support fully the monetarists' claim that their
impact was both small and fleeting: the effect
peaked in but two quarters and was only around
one, and disappeared totally by the fourth quar-
ter following the change.
These results were immediately attacked on
the ground that the authors had used the wrong
measure of monetary and fiscal actions, and it
was shown that the outcome was somewhat
sensitive to alternative measures; however, the
basic nature of the results did not change, at least
qualitatively. In particular, the outcome does not
differ materially, at least for the original period
up to 1969, if one replaces high employment out-
lays with a variable that might be deemed more
suitable, like government expenditure on goods
and services, plus exports.
These results must be acknowledged as dis-
turbing for nonmonetarists, for there is little
question that movements in government pur-
chases and exports are a major source of demand
disturbances; if econometric model estimates of


### ---Economics-1977-0-12.txt---
the response to demand disturbances are roughly
valid, how can they be so grossly inconsistent
with the reduced form estimates?
Attempts at reconciling the two have taken
several directions, which are reviewed in an
article coauthored with Ando (1976). Our main
conclusion, based on simulation techniques, is
that when income is subject to substantial shocks
from many sources other than monetary and
fiscal, so that these variables account for only a
moderate portion of the variations in income (in
the United States, it has been of the order of one-
half to two-thirds), then the St. Louis reduced
form method yields highly unstable and unreli-
able estimates of the true structure of the system
generating the data.
The crucial role of unreliability and instability
has since been confirmed in more recent work of
Daniel O'Neill in his forthcoming thesis. He
shows in the first place that different methods
of estimation yield widely different estimates,
including many which clearly overstate the
expenditure and understate the money multi-
pliers. He further points out that, given the
unreliability of the estimates resulting from
multicollinearity and large residual variance,
the relevant question to ask is not whether
these estimates differ from those obtained by
structural estimation, but whether the difference
is statistically significant; that is, larger than
could be reasonably accounted for by sampling
fluctuations.
I have carried out this standard statistical test
using as true response coefficients those gener-
ated by the MPS model quoted earlier.2 I find
that, at least when the test is based on the largest
possible sample-the entire post-Korean period
up to the last two very disturbed years-the
difference is totally insignificant when estima-
tion is in level form (F is less than one) and is
still not significant at the 5 percent level, when in
first differences.
This test resolves the puzzle by showing that
there really is no puzzle: the two alternative esti-
mates of the expenditure multipliers are not
inconsistent, given the margin of error of the
estimates. It implies that one should accept
whichever of the two estimates is produced by a
more reliable and stable method, and is generally
more sensible. To me, those criteria call, with-
out question, for adopting the econometric
model estimates. But should there be still some
lingering doubt about this choice, I am happy to
be able to report the results of one final test
which I believe should dispose of the reduced
form estimates-at least for a while. Suppose
the St. Louis estimates of the expenditure multi-
plier are closer to God's truth than the estimates
derived through econometric models. Then it
should be the case that if one uses their coeffi-
cients to forecast income beyond the period of
fit, these forecasts should be appreciably better
than those obtained from a forecasting equation
in which the coefficients of the expenditure vari-
able are set equal to those obtained from eco-
nometric models.
I have carried out this test, comparing a re-
duced form equation fitted to the period origi-
nally used at St. Louis, terminating in 1969 (but
reestimated with the lastest revised data) with an
equation in which the coefficients of government
expenditure plus exports were constrained to be
those estimated from the MPS, used in the above
F-test. The results are clear cut: the errors using
the reduced form coefficient are not smaller but
on the average substantially larger than those
using MPS multipliers. For the first four years,
terminating at the end of 1973, the St. Louis
equation produces errors which are distinctly
larger in eight quarters, and smaller in but three,
and its squared error is one-third larger. For the
last two years of turmoil, both equations perform
miserably, though even here the MPS coeffi-
cients perform just a bit better. I have repeated
this test with equations estimated through the
first half of the postwar period, and the results
are, if anything, even more one-sided.
The moral of the story is pretty clear. First,



### ---Economics-1977-0-13.txt---
reduced form equations relying on just two exog-
enous variables are very unreliable for the pur-
pose of estimating structure, nor are they
particularly accurate for forecasting, though per
dollar of research expenditure they are surpris-
ingly good. Second, if the St. Louis people want
to go on using this method and wish to secure the
best possible forecast, then they should ask the
MPS or any other large econometric model what
coefficients they should use for government
expenditure, rather than trying to estimate them
by their unreliable method.
From the theory and evidence reviewed, we
must then conclude that opting for a constant rate
of growth of the nominal money supply can
result in a stable economy only in the absence of
significant exogenous shocks. But obviously the
economy has been and will continue to be ex-
posed to many significant shocks, coming from
such things as war and peace, and other large
changes in government expenditure, foreign
trade, agriculture, technological progress, popu-
lation shifts, and what not. The clearest evidence
on the importance of such shocks is provided by
our postwar record with its six recessions.
IV. The Record of Stabilization Policies:
Stabilizing or Destabilizing
A. Was Postwar Instability Due to Unstable
Money Growth?
At this point, of course, monetarists will ob-
ject that, over the postwar period, we have not
had a constant money growth policy and will hint
that the observed instability can largely be traced
to the instability of money. The only way of
meeting this objection squarely would be, of
course, to rerun history with a good computer
capable of calculating 3 percent at the helm of
the Fed.
A more feasible, if less conclusive approach
might be to look for some extended periods in
which the money supply grew fairly smoothly
and see how the economy fared. Combing
through our post-Korean War history, I have
been able to find just two stretches of several
years in which the growth of the money stock
was relatively stable, whether one chooses to
measure stability in terms of percentage devia-
tions from a constant growth or of dispersion of
four-quarter changes. It may surprise some that
one such stretch occurred quite recently and
consists of the period of nearly four years begin-
ning in the first quarter of 1971 (see the author
and Papademos, 1976). During this period, the
average growth was quite large, some 7 percent,
but it was relatively smooth, generally well
within the 6 to 8 percent band. The average
deviation from the mean is about .75 percent.
The other such period lasted from the beginning
of 1953 to the first half of 1957, again a stretch
of roughly four years. In sharp contrast to the
most recent period, the average growth here is
quite modest, only about 2 percent; but again,
most four-quarter changes fell well within a
band of two percentage points, and the average
deviation is again .7. By contrast, during the
remaining 13-year stretch from mid-1957 to the
end of 1970, the variability of money growth
was roughly twice as large if measured by the
average deviation of four quarter changes, and
some five times larger if measured by the per-
centage deviation of the money stock from a
constant growth trend.
How did the economy fare in the two periods
of relatively stable money growth? It is common
knowledge that the period from 1971 to 1974, or
from 1972 to 1975 if we want to allow a one-year
lag for money to do its trick, was distinctly the
most unstable in our recent history, marked by
sharp fluctuations in output and wild gyrations
of the rate of change of prices. As a result, the
average deviation of the four-quarter changes in
output was 3.3 percent, more than twice as large
as in the period of less stable money growth. But
the first stretch was also marked by well above
average instability, with the contraction of 1954,
the sharp recovery of 1955, and the new contrac-
tion in 1958, the sharpest in postwar history
except for the present one. The variability of out-
put is again 50 percent larger than in the middle
period.
To be sure, in the recent episode serious exog-
enous shocks played a major role in the develop-
ment of prices and possibly output, although the


### ---Economics-1977-0-14.txt---
same is not so readily apparent for the period
1953 to 1958. But, in any event, such extenu-
ating circumstances are quite irrelevant to my
point; for I am not suggesting that the stability of
money was the major cause of economic insta-
bility-or at any rate, not yet! All I am arguing is
that (i) there is no basis for the monetarists' sug-
gestion that our postwar instability can be traced
to monetary instability-our most unstable
periods have coincided with periods of relative
monetary stability; and (ii) stability of the
money supply is not enough to give us a stable
economy, precisely because there are exogenous
disturbances.
Finally, let me mention that I have actually
made an attempt at rerunning history to see
whether a stable money supply would stabilize
the economy, though in a way that I readily
acknowledge is much inferior to the real thing,
namely through a simulation with the MPS. The
experiment, carried out in cooperation with
Papademos, covered the relatively quiet period
from the beginning of 1959 to the introduction of
price-wage controls in the middle of 1971. If
one eliminates all major sources of shocks, for
example, by smoothing federal government
expenditures, we found, as did Otto Eckstein in
an earlier experiment, that a stable money
growth of 3 percent per year does stabilize the
economy, as expected. But when we allowed for
all the historical shocks, the result was that with
a constant money growth the economy was far
from stable-in fact, it was distinctly less stable
than actual experience, by a factor of 50 percent.
B. The Overall Effectiveness of Postwar
Stabilization Policies
But even granted that a smooth money supply
will not produce a very stable world and that
there is therefore room for stabilization policies,
monetarists will still argue that we should none-
theless eschew such policies. They claim, first,
that allowing for unpredictably variable lags and
unforseeable future shocks, we do not know
enough to successfully design stabilization
policies, and second, that the government would
surely be incapable of choosing the appropriate
policies or be politically willing to provide
timely enforcement. Thus, in practice, stabili-
zation policies will result in destabilizing the
economy much of the time.
This view is supported by two arguments, one
logical and one empirical. The logical argument
is the one developed in Friedman's Presidential
Address (1968). An attempt at stabilizing the
economy at full employment is bound to be de-
stabilizing because the full employment or
natural rate is not known with certainty and is
subject to shifts in time; and if we aim for the
incorrect rate, the result must perforce be explo-
sive inflation or deflation. By contrast, with a
constant money supply policy, the economy will
automatically hunt for, and eventually discover,
that shifty natural rate, wherever it may be
hiding.
This argument, I submit, is nothing but a
debating ploy. It rests on the preposterous as-
sumption that the only alternative to a constant
money growth is the pursuit of a very precise
unemployment target which will be adhered to
indefinitely no matter what, and that if the target
is off in the second decimal place, galloping
inflation is around the corner. In reality, all that
is necessary to pursue stabilization policies is a
rough target range that includes the warranted
rate, itself a range and not a razor edge; and, of
course, responsible supporters of stabilization
policies have long been aware of the fact that the
target range needs to be adjusted in time on the
basis of forseeable shifts in the warranted range,
as well as in the light of emerging evidence that
the current target is not consistent with price
stability. It is precisely for this reason that I, as
well as many other nonmonetarists, would side
with monetarists in strenuous opposition to
recent proposals for a target unemployment rate
rigidly fixed by statute (although there is nothing
wrong with Congress committing itself and the
country to work toward the eventual achieve-
ment of some target unemployment rate through
structural changes rather than aggregate demand
policies).
Clearly, even the continuous updating of
targets cannot guarantee that errors can be


### ---Economics-1977-0-15.txt---
avoided altogether or even that they will be
promptly recognized; and while errors persist,
they will result in some inflationary (or defla-
tionary) pressures. But the growing inflation to
which Friedman refers is, to repeat, a crawl not a
gallop. One may usefully recall in this connec-
tion the experience of 1965-70 referred to ear-
lier, with the further remark that the existence of
excess employment was quite generally recog-
nized at the time, and failure to eliminate it
resulted overwhelmingly from political consid-
erations and not from a wrong diagnosis.3
There remains then only the empirical issue:
have stabilization policies worked in the past and
will they work in the future? Monetarists think
the answer is negative and suggest, as we have
seen, that misguided attempts at stabilization,
especially through monetary policies, are re-
sponsible for much of the observed instability.
The main piece of evidence in support of this
contention is the Great Depression, an episode
well documented through the painstaking work
of Friedman and Anna Schwartz, although still
the object of dispute (see, for example, Peter
Temin). But in any event, that episode while it
may attest to the power of money, is irrelevant
for present purposes since the contraction of the
money supply was certainly not part of a com-
prehensive stabilization program in the post-
Keynesian sense.
When we come to the relevant postwar period,
the problem of establishing the success or failure
of stabilization policies is an extremely taxing
one. Many attempts have been made at devel-
oping precise objective tests, but in my view,
none of these is of much value, even though I am
guilty of having contributed to them in one of my
worst papers (1964). Even the most ingenious
test, that suggested by Victor Argy, and relying
on a comparison of the variability of income with
that of the velocity of circulation, turns out to
be valid only under highly unrealistic restrictive
assumptions.
Dennis Starleaf and Richard Floyd have pro-
posed testing the effectiveness of stabilization by
comparing the stability of money growth with
that of income growth, much as I have done
above for the United States, except that they
apply their test to a cross section of industrial-
ized countries. They found that for a sample of
13 countries, the association was distinctly
positive. But this test is again of little value. For
while a negative association for a given country,
such as suggested by my U.S. test, does provide
some weak indication that monetary activism
helped rather than hindered, the finding of a
positive association across countries proves
absolutely nothing. It can be readily shown, in
fact, that, to the extent that differential variabil-
ity of income reflects differences in the character
of the shocks-a most likely circumstance for
their sample-successful stabilization also
implies a positive correlation between the vari-
ability of income and that of money.
But though the search for unambiguous quan-
titative tests has so far yielded a meager crop,
there exists a different kind of evidence in favor
of Keynesian stabilization policies which is
impressive, even if hard to quantify. To quote
one of the founding fathers of business cycle
analysis, Arthur Burns, writing in 1959, "Since
1937 we have had five recessions, the longest of
which lasted only 13 months. There is no parallel
for such a sequence of mild-or such a sequence
of brief-contractions, at least during the past
hundred years in our country" (p. 2). By
now we can add to that list the recessions of
1961 and 1970.
There is, furthermore, evidence that very
similar conclusions hold for other industrialized
countries which have made use of stabilization
policies; at any rate that was the prevailing view
among participants to an international confer-
ence held in 1967 on the subject, "Is the busi-


### ---Economics-1977-0-16.txt---
ness cycle obsolete?" (see Martin Bronfen-
brenner, editor). No one seemed to question the
greater postwar stability of all Western econ-
omies-nor is this surprising when one recalls
that around that time business cycle specialists
felt so threatened by the new-found stability that
they were arguing for redefining business cycles
as fluctuations in the rate of growth rather than
in the level of output.
It was recognized that the reduced severity of
fluctuations might in part reflect structural
changes in the economy and the effect of stron-
ger built-in stabilizers, inspired, of course, by
the Keynesian analysis. Furthermore, the greater
stability in the United States, and in other indus-
trialized countries, are obviously not indepen-
dent events. Still, at least as of the time of that
conference, there seemed to be little question
and some evidence that part of the credit for the
greater stability should go to the conscious and
on balance, successful endeavor at stabilizing
the economy.
V. The Case of Supply Shocks and the
1974-76 Episode
A. Was the 1974 Depression Due to Errors of
Commission or Omission?
In pointing out our relative postwar stability
and the qualified success of stabilization poli-
cies, I have carefully defined the postwar period
as ending somewhere in 1973. What has hap-
pened since that has so tarnished the reputation
of economists? In facing this problem, the first
question that needs to be raised is whether the
recent combination of unprecedented rates of
inflation as well as unemployment must be
traced to crimes of commission or omission. Did
our monetary and fiscal stabilization policies
misfire, or did we instead fail to use them?
We may begin by establishing one point that
has been blurred by monetarists' blanket indict-
ments of recent monetary policy: the virulent
explosion that raised the four-quarter rate of
inflation from about 4 percent in 1972 to 6.5
percent by the third quarter of 1973, to 11.5
percent in 1974 with a peak quarterly rate of
13.5, can in no way be traced to an excessive, or
to a disorderly, growth of the money supply. As
already mentioned, the average rate of money
growth from the beginning of 1970 to the second
half of 1974 was close to 7 percent. To be sure,
this was a high rate and could be expected sooner
or later to generate an undesirably high inflation
-but how high? Under any reasonable assump-
tion one cannot arrive at a figure much above 6
percent. This might explain what happened up to
the fall of 1973, but not from the third quarter
of 1973 to the end of 1974, which is the really
troublesome period. Similarly, as was indicated
above, the growth of money was reasonably
smooth over this period, smoother than at any
other time in the postwar period, staying within
a 2 percent band. Hence, the debacle of 1974
can just not be traced to an erratic behavior of
money resulting from a misguided attempt at
stabilization.
Should one then conclude that the catastrophe
resulted from too slavish an adherence to a stable
growth rate, forsaking the opportunity to use
monetary policy to stabilize the economy? In
one sense, the answer to this question must in
my view be in the affirmative. There is ample
ground for holding that the rapid contraction that
set in toward the end of 1974, on the heels of a
slow decline in the previous three quarters, and
which drove unemployment to its 9 percent
peak, was largely the result of the astronomic
rise in interest rates around the middle of the
year. That rise in turn was the unavoidable result
of the Fed's stubborn refusal to accommodate,
to an adequate extent, the exogenous inflation-
ary shock due to oil, by letting the money supply
growth exceed the 6 percent rate announced at
the beginning of the year. And this despite re-
peated warnings about that unavoidable result
(see, for example, the author 1974).
Monetarists have suggested that the sharp
recession was not the result of too slow a mone-
tary growth throughout the year, but instead of
the deceleration that took place in the last half of
1974, and early 1975. But this explanation just
does not stand up to the facts. The fall in the
quarterly growth of money in the third and fourth
quarters was puny, especially on the basis of


### ---Economics-1977-0-17.txt---
revised figures now available: from 5.7 percent
in the second to 4.3 and 4.1-hardly much
larger than the error of estimate for quarterly
rates! To be sure, in the first quarter of 1975 the
growth fell to .6 percent. But, by then, the vio-
lent contraction was well on its way-between
September 1974 and February 1975, industrial
production fell at an annual rate of 25 percent.
Furthermore, by the next quarter, monetary
growth had resumed heftily. There is thus no
way the monetarist proposition can square with
these facts unless their long and variable lags
are so variable that they sometimes turn into
substantial leads. But even then, by anybody's
model, a one-quarter dip in the growth of money
could not have had a perceptible effect.
B. What Macro Stabilization Policies
Can Accomplish, and How
But recognizing that the adherence to a stable
money growth path through much of 1974 bears
a major responsibility for the sharp contraction
does not per se establish that the policy was
mistaken. The reason is that the shock that hit
the system in 1973-74 was not the usual type of
demand shock which we have gradually learned
to cope with, more or less adequately. It was,
instead, a supply or price shock, coming from
a cumulation of causes, largely external. This
poses an altogether different stabilization prob-
lem. In particular, in the case of demand shocks,
there exists in principle an ideal policy which
avoids all social costs, namely to offset com-
pletely the shock thus, at the same time, stabi-
lizing employment and the price level. There
may be disagreement as to whether this target
can be achieved and how, but not about the
target itself.
But in the case of supply shocks, there is no
miracle cure-there is no macro policy which
can both maintain a stable price level and keep
employment at its natural rate. To maintain
stable prices in the face of the exogenous price
shock, say a rise in import prices, would require
a fall in all domestic output prices; but we know
of no macro policy by which domestic prices can
be made to fall except by creating enough slack,
thus putting downward pressure on wages. And
the amount of slack would have to be substantial
in view of the sluggishness of wages in the face
of unemployment. If we do not offset the exoge-
nous shock completely, then the initial burst,
even if activated by an entirely transient rise in
some prices, such as a once and for all deteriora-
tion in the terms of trade, will give rise to further
increases, as nominal wages rise in a vain at-
tempt at preserving real wages; this secondary
reaction too can only be cut short by creating
slack. In short, once a price shock hits, there is
no way of returning to the initial equilibrium
except after a painful period of both above equi-
librium unemployment and inflation.
There are, of course, in principle, policies
other than aggregate demand management to
which we might turn, and which are enticing
in view of the unpleasant alternatives offered by
demand management. But so far such policies,
at least those of the wage-price control variety,
have proved disappointing. The design of better
alternatives is probably the greatest challenge
presently confronting those interested in stabili-
zation. However, these policies fall outside my
present concern. Within the realm of aggregate
demand management, the only choice open to
society is the cruel one between alternative fea-
sible paths of inflation and associated paths of
unemployment, and the best the macroecono-
mist can offer is policies designed to approxi-
mate the chosen path.
In light of the above, we may ask: is it con-
ceivable that a constant rate of growth of the
money supply will provide a satisfactory re-
sponse to price shocks in the sense of giving
rise to an unemployment-inflation path to which
the country would object least?
C. The Monetarist Prescription: Or, Constant
Money Growth Once More
The monetarists are inclined to answer this
question affirmatively, if not in terms of the
country's preferences, at least in terms of the
preferences they think it should have. This is
evidenced by their staunch support of a continu-
ation of the 6 percent or so rate of growth through


### ---Economics-1977-0-18.txt---
1974, 1975, and 1976.
Their reasoning seems to go along the follow-
ing lines. The natural rate hypothesis implies
that the rate of inflation can change only when
employment deviates from the natural rate. Now
suppose we start from the natural rate and some
corresponding steady rate of inflation, which
without loss of generality can be assumed as
zero. Let there be an exogenous shock which
initially lifts the rate of inflation, say, to 10 per-
cent. If the Central Bank, by accommodating
this price rise, keeps employment at the natural
rate, the new rate of 10 percent will also be main-
tained and will in fact continue forever, as long
as the money supply accommodates it. The only
way to eliminate inflation is to increase unem-
ployment enough, above the natural rate and for
a long enough time, so that the cumulated re-
duction of inflation takes us back to zero. There
will of course be many possible unemployment
paths that will accomplish this. So the next
question is: Which is the least undesirable?
The monetarist answer seems to be-and
here I confess that attribution becomes difficult
-that it does not make much difference be-
cause, to a first approximation, the cumulated
amount of unemployment needed to unwind
inflation is independent of the path. If we take
more unemployment early, we need to take less
later, and conversely. But then it follows imme-
diately that the specific path of unemployment
that would be generated by a constant money
growth is, if not better, at least as good as any
other. Corollary: a constant growth of money is
a satisfactory answer to supply shocks just as it
is to demand shocks-as well as, one may sus-
pect, to any other conceivable illness, indisposi-
tion, or disorder.
D. Why Constant Money Growth Cannot
Be the Answer
This reasoning is admirably simple and ele-
gant, but it suffers from several flaws. The first
one is a confusion between the price level and
its rate of change. With an unchanged constant
growth of the nominal money stock, the system
will settle back into equilibrium not when the
rate of inflation is back to zero but only when,
in addition, the price level itself is back to its
initial level. This means that when inflation has
finally returned back to the desired original rate,
unemployment cannot also be back to the origi-
nal level but will instead remain above it as long
as is necessary to generate enough deflation to
offset the earlier cumulated inflation. I doubt that
this solution would find many supporters and for
a good reason; it amounts to requiring that none
of the burden of the price shock should fall on
the holder of long-term money fixed contracts-
such as debts-and that all other sectors of soci-
ety should shoulder entirely whatever cost is
necessary to insure this result. But if, as seems
to be fairly universally agreed, the social target
is instead to return the system to the original rate
of inflation-zero in our example-then the
growth of the money supply cannot be kept con-
stant. Between the time the shock hits and the
time inflation has returned to the long-run level,
there must be an additional increase in money
supply by as much as the price level or by the
cumulant of inflation over the path.
A second problem with the monetarists' argu-
ment is that it implies a rather special preference
function that depends only on cumulated unem-
ployment. And, last but not least, it requires the
heroic assumption that the Phillips curve be not
only vertical in the long run but also linear in the
short run, an assumption that does not seem
consistent with empirically estimated curves.
Dropping this last assumption has the effect that,
for any given social preference, there will be in
general a unique optimal path. Clearly, for this
path to be precisely that generated by a constant
money growth, would require a miracle-or
some sleight of the invisible hand!
Actually, there are grounds for holding that
the unemployment path generated by a constant
money growth, even if temporarily raised to take
care of the first flaw, could not possibly be close
to an optimal. This conclusion is based on an
analysis of optimal paths, relying on the type of
linear welfare function that appears to underlie
the monetarists' argument, and which is also a
straightforward generalization of Okun's fa-


### ---Economics-1977-0-19.txt---
mous "economic discomfort index." That index
(which according to Michael Lovell appears to
have some empirical support) is the sum of un-
employment and inflation. The index used in my
analysis is a weighted average of the cumulated
unemployment and cumulated inflation over the
path. The weights express the relative social
concern for inflation versus unemployment.
Using this index, it has been shown in a forth-
coming thesis of Papademos that, in general, the
optimum policy calls for raising unemployment
at once to a certain critical level and keeping it
there until inflation has substantially abated. The
critical level depends on the nature of the Phillips
curve and the relative weights, but does not
depend significantly on the initial shock-as
long as it is appreciable. To provide an idea of
the order of magnitudes involved, if one relies on
the estimate of the Phillips curve reported in
my joint paper with Papademos (1975), which
is fairly close to vertical and uses Okun's
weights, one finds that (i) at the present time, the
noninflationary rate of unemployment corres-
ponding to a 2 percent rate of inflation can be
estimated at 5.6 percent, and (ii) the optimal re-
sponse to a large exogenous price shock consists
in increasing unemployment from 5.6 to only
about 7 percent. That level is to be maintained
until inflation falls somewhat below 4 percent;
it should then be reduced slowly until inflation
gets to 2.5 (which is estimated to take a couple of
years), and rapidly thereafter. If, on the other
hand, society were to rate inflation twice as
costly as unemployment, the initial unemploy-
ment rate becomes just over 8 percent, though
the path to final equilibrium is then shorter.
These results seem intuitively sensible and quan-
titatively reasonable, providing further justifica-
tion for the assumed welfare function, with its
appealing property of summarizing preferences
into a single readily understandable number.
One important implication of the nature of the
optimum path described above is that a constant
money growth could not possibly be optimal
while inflation is being squeezed out of the sys-
tem, regardless of the relative weights attached
to unemployment and inflation. It would tend
to be prevailingly too small for some initial
period and too large thereafter.
One must thus conclude that the case for a
constant money growth is no more tenable in the
case of supply shocks than it is in the case of
demand shocks.
VI. Conclusion
To summarize, the monetarists have made a
valid and most valuable contribution in estab-
lishing that our economy is far less unstable than
the early Keynesians pictured it and in rehabil-
itating the role of money as a determinant of
aggregate demand. They are wrong, however,
in going as far as asserting that the economy is
sufficiently shockproof that stabilization poli-
cies are not needed. They have also made an
important contribution in pointing out that such
policies might in fact prove destabilizing. This
criticism has had a salutary effect on reassessing
what stabilization policies can and should do,
and on trimming down fine-tuning ambitions.
But their contention that postwar fluctuations
resulted from an unstable money growth or that
stabilization policies decreased rather than in-
creased stability just does not stand up to an
impartial examination of the postwar record of
the United States and other industrialized coun-
tries. Up to 1974, these policies have helped to
keep the economy reasonable stable by historical
standards, even though one can certainly point
to some occasional failures.
The serious deterioration in economic stabil-
ity since 1973 must be attributed in the first place
to the novel nature of the shocks that hit us,
namely, supply shocks. Even the best possible
aggregate demand management cannot offset
such shocks without a lot of unemployment
together with a lot of inflation. But, in addition,
demand management was far from the best. This
failure must be attributed in good measure to the
fact that we had little experience or even an
adequate conceptual framework to deal with
such shocks; but at least from my reading of
the record, it was also the result of failure to
use stabilization policies, including too slavish
adherence to the monetarists' constant money


### ---Economics-1977-0-20.txt---
growth presciption.
We must, therefore, categorically reject the
monetarist appeal to turn back the clock forty
years by discarding the basic message of The
General Theorxv. We should instead concentrate
our efforts in an endeavor to make stabilization
policies even more effective in the future than
they have been in the past.
## Economics-1978-0


### ---Economics-1978-0-01.txt---
I. The Meaning of Supply and Demand
in a Macroeconomic Context
It is worth considering whether a new
basic model should guide our thinking
about performance of the economy as a
whole. It is not that the macro models of
the past twenty-five years or so have failed
to serve us well. When we consider the state
of our knowledge about the analytics of the
economy at the end of World War II and
the apprehensiveness with which we ap-
proached the modern era of expansion, it
should be evident that we have come a long
way professionally. Yet the economic prob-
lems of today seem to be intractable when
studied through the medium of simplified
macro models. The new system should
combine the Keynesian model of final de-
mand and income determination with the
Leontief model of interindustrial flows.
This is the motivation for my focusing at-
tention on the supply side of the economy.
It is frequently said, in almost an offhand
manner, that the theories of aggregate em-
ployment and output determination are de-
mand models, that economic policy for
overall direction of the economy is a policy
of demand management. I would generally
agree with these remarks, but not in every
last detail, once the meaning of demand in
these contexts is carefully pulled apart and
analyzed. The demand aspects are possibly
overstated.
It is, of course, true that demand for the
GNP built up as the sum of demands by
consumers, businesses, government, and
foreigners (consumption, investment, public
spending, and net exports) covers total de-
mand in the economy and is composed of
demands by the constituent parts. But de-
mand by firms, and, in many cases by gov-
ernment, are not ends in themselves. Busi-
ness demand is largely for goods to produce
goods. The capital formation that results
from business demand goes into the incre-
ment of capital stock, after allowance for
capital consumption, and the capital stock
becomes a factor input in the production
function. The accumulation of capital con-
tributes to the supply of goods and services.
Indeed, investment demand now for new
capital facilitates the implementation of the
production process with the supply of fac-
tors of ever-increasing powers of productiv-
ity, thus making it possible to supply in-
creasing amounts of goods and services
with inputs that are increasing at a some-
what slower rate.
By focusing attention excessively on the
"short run," in which the capital stock is
timelessly held fixed by assumption only
and not in reality, we have ignored the sup-
ply-side characteristics of investment de-
mand. Students of today's business cycle
commonly cite investment demand as the
promising potential route to higher produc-
tivity in the relatively near future, thereby
lessening inflationary pressure. In this re-
spect, economic theoreticians have been
myopic relative to the applied economic
analysts in the world of affairs. Neverthe-
less, as we shall see, there is much more
to the supply side than the transformation
of investment into productive capital, and
the basic characterization of contemporary
macroeconomics as demand analysis has a
point. A strong indication of the demand
side orientation is given by the elaboration
of the standard macro model. In place of
aggregate consumption, the more elaborate
model gives separate treatment to consumer
expenditures on durables, nondurables, and
services. This is the first stage. At a higher
stage, there is further disaggregation into
types of durables, nondurables, and services
such as food, cars, medical services, etc.
The detail that is introduced for consump-


### ---Economics-1978-0-02.txt---
tion is repeated in business investment de-
mand, housing demand, public expendi-
tures, exports, and imports. Elaboration
essentially means taking a closer look at de-
mand side components by types of demand.
The mainstream model of macro eco-
nomic thought has thus become a detailed
system of demand analysis, but if it is to be
a closed system, it will also have to include
corresponding detail on the national income
side of the social accounts. If this is done
fully, there will have to be analyses of factor
rewards, factor use, and pricing. The devel-
opment of factor demand goes beyond capi-
tal formation, which appears as a demand
for final goods in the GNP, and takes up
an explanation of wage income. An ade-
quate explanation of wage income cannot
avoid the explicit treatment of physical
production involving labor input as well as
capital input. The demand for labor, like
the demand for capital, is supply side analy-
sis. While the demand for capital enters di-
rectly as a component of total demand, the
demand for labor, together with wage for-
mation, enters national income, and only
after expenditure does it enter final demand
for GNP. To the extent that labor produc-
tivity affects wage determination and also
price formation, we find supply-side factors
influencing inflation and consequently the
overall performance of the economy. Labor
demand can also be associated with train-
ing. The training component is, in fact,
investment in human rather than fixed
capital. Looked at in this way, factor de-
mand for labor and factor demand for fixed
capital are simply different, but related,
aspects of total investment.
Behind the IS-LM diagram or other sim-
plified renditions of the aggregate demand
model lie many supply-side relationships.
Not only is the supply side in the back-
ground, but it also plays a more essential
role once it is recognized that the simplified
model is actually incomplete. If we were to
assume the existence of money illusion, it
would be possible to consider the IS-LM
system as a closed system of relationships
depending on nominal income and nominal
interest rates. I find this approach theoreti-
cally unsatisfactory. That simple system
exists only as an aggregative approxima-
tion for a given price level. If we assume no
money illusion and, more properly, I be-
lieve, the need to determine the aggregate
price level, then the IS-LM diagram does
not provide a closed system analysis, and
we must extend the system to include the
whole supply-side apparatus of production
relationships, factor demand, and factor
supply.
It is well known that Keynes included
the aggregate supply function in the Gen-
eral Theory, but it was introduced in his
chapter on "The Principle of Effective De-
mand." That part of his analysis dealing
with supply has been largely played down
by the profession at large-not by all stu-
dents of macroeconomics.' Also, by way of
side comment, Keynes probably confused
the issues by making labor supply depen-
dent on the nominal wage rate, assuming
the existence of money illusion, and by not
treating the stock of capital as an explicit
variable.
If the demand relationships explaining
the components of the GNP are disaggre-
gated into a highly detailed set, it does not
necessarily mean that the supply side must
be equally disaggregated to a similar extent,
as long as the total flow of income and
purchasing power to be directed towards
the expenditure flow can be generated. The
detailed expenditure flow will, however, in-
volve price relatives. That is a consequence
of disaggregation. An aggregate supply-side
explanation that generates only an average
price level for output as a whole can be
adequate, provided separate prices, needed
for the price-relatives, can be explained in
terms of a relationship to the overall price
or wage level. This is much like the use of a
term structure relationship in credit market
analysis to explain the spectrum of interest
rates, given one strategic rate.
It is, however, more satisfactory, and
more revealing, to explain the whole set of
prices, one by one, on the basis of costs
in individual sectors. These sector prices, on
the side of production, are then combined
with input weights into the several final de-
ISee Sidney Weintraub (1956, 1957).


### ---Economics-1978-0-03.txt---
mand prices needed to account for variation
in components of final expenditure. This
brings us to a fundamental set of new con-
siderations on the supply side.
II. The Task of Modeling Supply
If sector prices by line of production are
to be explained in a fundamental way by
sector costs, there will have to be an accom-
panying explanation of sector outputs and
inputs. This brings us directly to the supply
side of things. While the supply side is
represented in the macro production func-
tion from an aggregative point of view, once
we disaggregate the supply side by sector of
production, we encounter a new dimension.
The aggregate production function, in the
spirit of Paul Douglas and Charles Cobb,
expresses value-added as a function of pri-
mary factor inputs, namely, labor and capi-
tal. They were able to compress the tech-
nology as they did, because at a full macro
level, one sector's output is someone else's
input, and for the economy as a whole, only
value-added is left in the output aggrega-
tion. Intermediate inputs or outputs may be
neglected in the interests of avoiding double
counting. This way of looking at things is
strictly correct only for a closed economy.
In an open system, intermediate imports
must be treated like primary factor inputs.
At the sector level, however, there is no
question about the need to consider inter-
mediate inputs. Sector output (gross) is
properly a function of intermediate inputs,
labor input, and capital input-all sector
designated. The presently fashionable way
of summarizing this idea is to use the
KLEM production function, whose inputs
consist of capital, labor, energy, and mate-
rials.
The KLEM production function concept
is useful in partial studies of separate indus-
tries or sectors, and has long been antici-
pated in aggregative production function
studies. It has been routine in production
function studies in agriculture to use feed,
seed, fertilizer, and other intermediate in-
puts as explanatory variables. The depen-
dent variable is generally a measure of gross
output gallons of milk, bushels of grain,
or bales of cotton. In manufacturing, one
of the earliest studies was by Ragnar Frisch.
He expressed isoquants for the output of
the Freia chocolate factory as a function of
fat content and molding-cooling input. One
of these is a pure material input and the
other stands for some capital, labor, and
general running cost input. In my own in-
vestigations of U.S. railroad production
functions, I included fuel consumption (in
coal equivalents) as one of the factor inputs
together with labor and capital. The gross
output concept consisted of a log-linear
combination of ton miles and passenger
miles.2
These individual industry production
functions with a small number of intermedi-
ate inputs are hardly substitutes for a de-
tailed input-output analysis on a general
system level. The role of input-output
analysis is to explain intermediate flows in
the economic system. The full system is
needed in order to provide an adequate sup-
ply analysis because
(i) There is much more to economic ac-
tivity than can be summarized by the
system of final goods production.
(ii) The explanation of types of final
prices depends on highly specific
types of intermediate, as well as final,
goods/services prices.
The occurrence of bottlenecks potential
or realized as in the oil embargo of
1973--74 or the diversion of large amounts
of agricultural output to export markets as
in 1973 and 1975 are striking examples of
cases where there was a great deal of eco-
nomic activity going on outside final GNP
sectors. An economic understanding of
those activities and an estimate of their
macro impacts on the GNP could not be
readily derived from demand analysis with-
out consulting the table of intermediate
flows in I-0 analysis. These are only strik-
ing examples. Many more have arisen in
the past, and more are bound to occur in
the future; therefore, the concern of this
presentation is not with singular events.
An adequate explanation of the price sys-
tem, especially on the cost side, cannot stop
2See the author.


### ---Economics-1978-0-04.txt---
at the KLEM level with separate considera-
tion of energy, materials, wage, and capital
costs. It must take account of prices of
grains, ferrous metals, nonferrous metals,
coal, crude oil, machinery, textiles, and the
other component prices in an input-output
system. The appropriate amount of detail
is not a fixed matter. It depends on human
capabilities of analysis, machine facilities,
data bases, and other practical considera-
tions, but it is, in any case, an order of
magnitude greater than contemplated by
mainstream macro model analysis.
From an analytical point of view, what is
being suggested is a full combination of two
systems of thought. the Leontief model and
the Keynesian model. That these two svs-
tems can be put back-to-back into a single
consistent model, with full feedback be-
tween each part, is now well known, having
been implemented first with the Brookings
Model and later with various generations of
Wharton Models, and more recently by
Dale Jorgenson in a translog mode. A prin-
cipal feature of such combined systems is
that they are not based on restrictive as-
sumptions of the fixed coefficient input-
output model, but are generalized to allow
the coefVlcients of production to vary, ac-
cording to the variation of relative prices.
The above expression, "full feedback,"
means that the macro model of final de-
mand and national income generation can-
not be solved, by itself, without also solving
the input-output system for generatin- sec-
tor production flows. Moreover sector
prices cannot be solved without also solving
the macro model simultaneously.
Price formation in individual sectors is
specified in terms of mark-up relations over
unit labor costs. Thus, sector outputs and
labor inputs are needed in order to explain
sector prices. These prices are needed, in
turn, in order to explain final demand
prices. Similarly, sector investment depends
on sector output as well as sector price.
It is for these and similar reasons that final
demand cannot be generated without mak-
ing use of the input-output system in order
to generate sector outputs.
At the same time, the input-output sys-
tem is driven by final demand; therefore,
the conventional macro demand model
must be used in order to solve the input-
output system. These are the specific senses
in which full feedback is used in order to
obtain simultaneous and consistent integra-
tion of the entire supply and demand sides
of the economy.
In terms of the history of economic
thought, the above approach means think-
ing in terms of the empirical implementa-
tion of the Walrasian system. Essentially,
Tinbergen implemented the Keynesian sys-
tem and Leontief implemented a part of the
Walrasian system. By putting the two to-
gether, with due allowance to Kuznets for
making the data bases of final demand and
national income available, a complete syn-
thesis of supply and demand in the econ-
omy as a whole can be put together. This
gives the antecedents of what is meant by
modeling supply, taking into account what
is needed from demand models at the same
time.
III. Why Model Supply?
At the time of the Keynesian Revolution,
there was a pervasive deficiency of demand
throughout most of the world. The Key-
nesian policy development, building on
that model, did, in my opinion, much good
for the economy of the Western world, en-
abling us to come through an expansive era
of more than twenty-five years without a re-
currence of a Great Depression. That does
not mean that this system of thought and
policy formation did its work for all time
in putting the world economy on a stable
footing. It carried the situation only so far,
and undoubtedly underestimated inflation
potentials, leaving us now at the point
where new systems of thought, drawing
more on the supply side, are needed in
order to develop policies that will be able
to deal with the world's contemporary eco-
nomic problems; hopefully, policies that
will have as much longevity as the demand
management policies of the last two to three
decades. That should bring us nicely into
the twenty-first century, which is about as
far ahead as we might attempt to look at the
present time.


### ---Economics-1978-0-05.txt---
The limits of demand management pol-
icies have become clearly visible in recent
years. Let us look at the issues through the
medium of specific problems, say the joint
problems of too much unemployment and
too much inflation. Policies of demand
management alone have appeared to be
adequate to deal with one or the other, but
not both together. If demand is stimulated
enough to bring down the unemployment
rate to a full-employment minimum, there
is danger of generating undue inflationary
pressure as a side effect. Conversely, anti-
inflationary policies of demand restriction
run the danger of generating excessive un-
employment while holding down the infla-
tion rate.
How might supply-side policies be intro-
duced to lower both the inflation and un-
employment rates at the same time'? It is
conventionally thought that policies of ag-
gregative demand stimulus through tradi-
tional fiscal and monetary policies might be
able to bring down the U.S. unemployment
rate to about 5.5 percent. This is not a firm
point estimate, and is subject to error of at
least one-half point above or below that
figure, but it is not, in any case, a full-em-
ployment target figure.
One way, but not the only way, of getting
to full employnment without generating fresh
inflationary pressure is to design a jobs pro-
gram for about 1.0 million long-term, hard
core unemployed. This jobs program can-
not be described in full detail in the context
of this presentation, but it is not to be
viewed as an ordinary public jobs program.
It is viewed as a job training program
aimed at people who show signs of recep-
tivity to training and enlisting the participa-
tion of employers who provide really pro-
ductive jobs with potential for upward
mobility. The 1.0 million target, spread over
three years, is not purely indicative. It is
meant to be plausible and necessary if full
employment is to be reached by 1980-82 in
the United States.
Apart from the fact that some public
funds are to be spent on this program, it is
not a typical demand management policy.
It is aimed at increasing the supply of
goods, at raising labor productivity, at sec-
tors of the economy where job training can
be accomodated or needed, and at sectors
of the labor force. It is basically a supply-
side policy and needs for its implementa-
tion/assessment a full scale analysis through
the medium of a Leontief-Keynes system.
In first approximations, such assessments
have been made with the appropriate ver-
sion of the Wharton Model.
In anticipation of criticism of this policy
approach from the side of those who are
strongly wedded to emphasis on demand
management, I want to stress that a jobs
program aimed at increasing productivity
and reducing hard core unemployment is
not a futile exercise in pushing some sub-
sidized workers into the ranks of the em-
ployed while pushing others out. The pro-
gram is intended to have balance; i.e., to be
part of a larger program with correspond-
ing support from the demand side. Such
support could not be justified from the
point of view of inflation potential unless
steps are being taken to complement the
effect with a jobs program and eventual
lifting of productivity. Undue preoccupa-
tion with demand policies is not going to be
adequate to meet the problems of the day,
nor is pure emphasis on supply. Both sides
of the economy must be coordinated in
policy formation.
It should also be emphasized that de-
mand policies of federal expenditures for
public service employment appear to be in-
ferior to private sector jobs programs of
the type being mentioned here. In the
former case, there is no long-term oppor-
tunity for those taken into the program and
there is no contribution to national produc-
tivity. As long as job expenditures are going
to be made, they ought, preferably, to be di-
rected to an effort that promises to have
some lasting benefit.
This example of the jobs program is one
that fits the contemporary American eco-
nomic scene and has been investigated with
a U.S. model and data. The underlying
idea, however, is meant to be much more
general. It is that the whole industrial world
is faced with a series of new supply-side
economic problems. The problems of cy-
clical stabilization and reaching full em-


### ---Economics-1978-0-06.txt---
ployment without inflation will have to be
dealt with as before, and the latter will re-
quire some degree of supply-side analysis in
other economies as in the U.S. case, but a
whole new range of economic issues looms
on the horizon. These are development of
new, greater energy supplies, protection of
the environment, controlling the exhaustion
of resources, enhancing agricultural sup-
plies, balancing population development,
and others of like nature. The juggling of
public budgets, the setting of tax rates, and
the giving of a tone to money market condi-
tions are not going to deal effectively with
this new class of problems, from the view-
points of influencing them in a favorable
direction. Similarly, the demand oriented
model is not going to provide much under-
standing of them.
The coming problems of the industrial
economy are not going to be wholly dealt
with or analyzed on the basis of the gen-
eral purpose Leontief-Keynes system that is
being advocated here. In many cases, the
unforeseen problems that are bound to arise
are going to be more specialized than can
be conveniently anticipated. In such cases,
the analysis must extend into partial system
analysis giving more detailed and explicit
treatment on the supply side. In terms of
model building that means construction of
many "satellite" systems on the supply side,
as the need arises. At the present time,
many energy satellite systems are being de-
veloped to deal with new fuel processes,
large energy using sectors, and large energy
delivery sectors. These satellite systems are
then all linked, in a technical and consistent
way, with the input-output cum macro
model system. In any event, the intent is to
move the discussion of macroeconomics
and policy formation to a new plane of dis-
course.
The discussion, thus far, has focused on
the modeling and related policy problems
for the modern industrial economy. The
analysis of the supply side, however, is not a
new issue for the developing economy. A
deficiency of demand analyzed within the
framework of the Keynesian Model has not
generally been thought to be the issue or
approach for dealing with the problems of
economic development. That is not to say
that demand relations are nonexistent or
unimportant for the developing economy. It
is primarily a matter of emphasis. Avail-
ability of fixed capital treated as a limiting
factor in production is central to under-
standing the problems facing many develop-
ing economies.
Energy problems of production and use
are already apparent, as are population
control and agricultural production. Where
problems of environmental protection and
resource exhaustion have not yet arisen,
they are bound to occur in significant in-
stances; therefore, it is wise for the develop-
ment economist to be forearmed with a full
model for analysis of both supply and de-
mand sides.
The centrally planned economies are for
the most part industrial economies and
have the same needs for supply-side analy-
sis. In their cases, the supply side has per-
haps been excessively developed with in-
adequate attention paid to the demand side,
not from the viewpoint of deficient demand
but from the viewpoint of chronic excess
demand, with latent inflationary pressure.
The present analysis attempts to look at a
particular facet of the modern economy,
namely the supply side. That does not im-
ply, by any means, that monetary analysis
and policy are unimportant. Most of the
supply-side problems have monetary impli-
cations or aspects; therefore, monetary
policy must be appropriate to insure the
smooth working of the supply side of the
economy.
In terms of the analytical apparatus
needed to combine monetary analysis with
the kind of supply-demand model that I
have outlined above, it is a matter of inte-
grating the flow-of-funds system together
with the input-output and final demand na-
tional income system. It would also be in a
full feedback mode. To complement the
supply-side detail underlying the IS curve,
we would turn to the complete flow-of-
funds model to provide background for the
LM curve.
It is my feeling that overall monetary and
fiscal policies have been overworked, with
expectations of results that are not j ustified.


### ---Economics-1978-0-07.txt---
Without downgrading their very important
role, the present message simply says that
a full supply-side analysis must be devel-
oped into which an elaborated IS-LM sys-
tem of thought can be fully integrated.
## Economics-1979-0


### ---Economics-1979-0-03.txt---
The title of my address implicitly assumes
that economics is itself one of the sciences.
I believe that to be so, and intend as I go on
to indicate more fully in what sense I hold
that view. However, my principal aim in
choosing my topic is not that of claiming
any particular status for economic analysis.
Rather, I want to share with you some ob-
servations I have made over the last six
years as a result of involvement in various
interdisciplinary studies, through reading
the reports of other such studies, or dis-
cussing them with colleagues in various
fields of science.
With increasing frequency natural and
social scientists are indeed finding them-
selves thrown together in the study of new
problems that are of great practical im-
portance for society, and essentially inter-
disciplinary in character. Prominent among
these are problems of environmental policy,
such as the protection of air and water
quality. Another class of problems concerns
a desirable long-range mix of technologies
of energy supply, conversion and use. These
two classes of problems overlap, for in-
stance, with respect to the disposal of nu-
clear wastes, heat rejection to the environ-
ment, and in the case of fossil fuels the
as yet poorly understood global and re-
gional effects of sustained large releases of
carbon dioxide into the atmosphere.
Assembled in pursuit of such studies, our
interdisciplinary group soon finds that its
diverse participants ask different questions;
use different concepts; use different terms
for the same concept and the same term
with different meanings; explicitly or im-
plicitly make different assumptions; and
perceive different opportunities for em-
pirical verification which may lead them
to apply different methods to that end. The
result can be politely concealed bewilder-
ment, possibly a suppressed surge of "we-
and-they" feeling, in the worst case a grow-
ing mistrust that only time and sustained
interaction can overcome.
I shall try to illustrate the difficulties of
such interaction by a few examples from re-
cent studies involving, besides economics,
mostly the natural sciences and engineering.
Limitations of experience, background, and
time have compelled me to omit examples
involving a strong participation from the
other social sciences. Had my guide, men-
tor, and dear friend Jacob Marschak lived
to give this address, and had he chosen a
similar topic, the social sciences would have
received an emphasis reflecting their impor-
tance to the problems of contemporary so-
ciety. The writings Marschak left us, and
the program and the Proceedings of last
year's meeting of the American Economic
Association, stand together as a monu-
ment to his awareness and vision of the
actual and potential contributions of the
social and behavioral sciences.
To prepare for the task I have set myself,
I have requested and obtained interviews
with a somewhat casually selected sample
of natural scientists and engineers, and with
a few colleagues in economics. Their re-
sponses have been drawn on in the prepara-
tion of this address, without attribution by
name. I here express my, and indeed our,
indebtedness for the help we have been
given. Later on, I will cite some statements
verbatim.
Table 1 can serve as a two-dimensional
table of contents for my discussion. Three
topics of study are listed on the left. On
each of the three topics a recent study has


### ---Economics-1979-0-04.txt---

been made by or for the National Research
Council. I will draw mostly on the first two
studies and briefly mention the third.
My principal intent is not that of criticiz-
ing these studies or of evaluating their find-
ings. I want merely to identify some of the
issues that arise in their formulation, con-
trast responses to these issues in different
professions, and comment on the methods
that have been or might have been pro-
posed or applied by the respective col-
laborating professions. Those issues and
methods that I shall have time to refer to
are set out along the top of the table.
Each check mark in a cell of the table in-
dicates that a reference is made to that issue
or method in my discussion of that topic of
study.
1. The Case for Helium Conservation
This study is described in the preface to
the report of the Helium Study Committee
as "a task that had to be undertaken
quickly and completed with great speed."'
Likewise, on the concluding page (40), it is
called a "preliminary analysis.'
The principal current source of helium is
as an optional by-product of the production
of natural gas, in which it may occur in con-
centrations ranging (by volume) from 10
percent on down with increasing costs of
separation. Present demand for various in-
dustrial and space uses falls below present
supply, and a program of storage in the par-
tially depleted Cliffside gas field near
Amarillo, Texas, is in operation. The study
is motivated by the anticipation of a sub-
stantially higher future demand.
The report of the Helium Study Com-
mittee lists, on pages 35-36, five steps that
can be taken for the purpose of increasing
the rate of storage. I paraphrase:
Step i: Stop the current venting of
helium which has been separated from
natural gas allocated as a feedstock to
petro-chemical industries. Store the
helium instead.
Step ii: Designate helium currently
stored in Cliffside a "national strategic
reserve" for possible major technical
changes that may greatly expand future
demand.
Step iii: Reactivate presently idle
separation plants to reduce the release of


### ---Economics-1979-0-05.txt---
helium resulting from productive com-
bustion of the host gas, and store the
helium instead.
Step iv: Build new helium separation
plants on helium-rich gas streams. Store
the helium.
Step v: Delay the use of helium-rich
gas fields, undeveloped, and already pro-
ducing.
Ultimate Step: Extract helium from the
atmosphere.
The ultimate step is not included in the
report of the Committee, but is mentioned
in the transcript, page 135, of the Public
Forum held as part of the study. It involves
a process that by present technology costs a
large multiple of the cost of extraction from
natural gas containing .3 to .5 percent
helium.
Steps i, iii, iv, and the "ultimate step"
consist of successive technical process
choices. Taken in that order, they cor-
respond to the economist's notion of a
long-run supply curve, indicating how the
cost of each additional unit of supply is a
rising step function of the cumulative sup-
ply up to that point assuming a constant
state of the technology of extraction. These
steps need to be carried out only according
as the expectation of demand growth be-
comes larger and firmer. Steps ii and v are
steps whose timing should depend on ad-
ditional factors besides the separation cost
sequence already mentioned.
The expectation of a much larger demand
well into the twenty-first century is docu-
mented, in the report and in the Forum, by
a fascinating enumeration of anticipated
future technologies. Many of these are based
on or may utilize superconductivity, so far
attained best by cryogenic techniques for
which helium is the working fluid. The
superconductivity is in turn expected to be
applicable to a number of uses, such as
power transmission with low energy loss,
energy storage, and a number of applica-
tions of strong magnetic fields. Among the
latter are several "technologies that either
do not now exist or are in early stages of
development" (pp. 13-18), such as magnetic
containment for nuclear fusion reactors.
Another possible application is magneto-
hydrodynamic (MHD) power generation
that converts some of the energy contained
in a high temperature gas stream from either
a coal-fired burner or a nuclear fission reac-
tor directly into electricity, instead of rout-
ing all the energy through a conventional
steam cycle. The MHD development is
further along in the Soviet Union. There
also is a development furthest along in
West Germany and Japan-of magnetically
levitated low-noise high-speed trains.
It should be added that research is in
progress on the use of aluminum and pos-
sibly other materials reaching low resistivity
at temperatures of 20-30?K, a range reach-
able using liquid hydrogen as a coolant.
(See L. A. Hall, National Bureau of Stan-
dards Report, and E. B. Forsyth et al.)
From the economic point of view, the
case for the helium storage program is not
convincingly made either in the report or
in the Forum. I have not found either cost
or benefit estimates for the program. Ac-
tually, because of the importance of energy
supply processes among the increased uses
of helium listed above, the benefits cannot
be estimated without comparable cost and
fuel availability estimates for alternative
energy supply and use technologies which
have low or zero helium requirements. In
other words, to assess the helium storage
program, one also needs a long-run model
of the energy sector of the economy that
addresses the second decision problem of
Table 1. One will, of course, also need to
consider other important helium uses that
are not directly energy related.
Before turning to problem (2), I draw at-
tention to a few passages in the Helium Re-
port that will provide background for Sec-
tions III and IV below, where I shall discuss
the choice of measures of value in which to
express benefits and costs. The report
(p. 23) contains an important piece of in-
formation bearing on cost comparisons, to
the effect that the energy requirements for


### ---Economics-1979-0-06.txt---
extracting helium from the atmosphere are
about 1,000 times those for extracting it
from natural gas containing .3 to .5 percent
of helium. Large as that figure is, I shall de-
scribe later the economist's case (Section
III) for including in the calculation inputs
other than energy, such as that for plant
and equipment, and (Section IV) for taking
into account that the costs of all kinds in
any required future extraction from the at-
mosphere will not be incurred until much
later.
In fact, one statement in the report reads
as a rejection of the idea that the time at
which capital cost is incurred is at all per-
tinent. In a description of the possible role
of the government in implementing the five
steps, the report says: "The burden of the
discount rate as a criterion of performance
could be eliminated and the present debt to
the U.S. Treasury written off' (p. 38). I
shall explain in Section IV why I think not
many economists will support the proposal
to eliminate the criterion of the discount
rate. Meanwhile, the statement leads one to
infer that the capital cost component is not
negligible as a factor in the decision.
II. Technology Mixes of Future
Energy Supply and Use
My second illustration is a study that was
carried out as an input to the deliberations
of the Committee on Nuclear and Alterna-
tive Energy Systems (CONAES, in short),
and of its Synthesis Panel. It is entitled
"Energy Modeling for an Uncertain Fu-
ture." As explained in the preface, it is a
"supporting paper" published without hav-
ing gone through the customary report re-
view procedure of the Academy. While for
the other illustrations I have not named
authors or committee chairpersons, I
should not conceal that I was the chairman
of the group, called the Modeling Resource
Group (MRG), which collectively did the
work described in its Report. The group
consisted mostly of economists and opera-
tions researchers, two somewhat like-minded
professions. My comments on interdisci-
plinary interactions about the ideas and
findings of the group will therefore draw
on discussions with members of other pro-
fessions within and outside CONA ES.
For that purpose it may suffice to give
only the briefest description of the ques-
tions addressed, the assumptions made, and
the methods used. One important question
arises from the fact that several competing
objectives enter into the choice of a long-
run energy technology mix. The net eco-
nomic effect (economic benefit minus cost)
of the development of a given technology
mix can be estimated in a crude way, as sug-
gested in Table 1, column (a), by its effect
on the Gross National Product (GNP). In
addition, one will also want to register risks
of adverse effects such as mining accidents,
air pollution, acid rain, oil spills, possible
leakage from nuclear waste disposal, or di-
version or proliferation of weapons-grade
nuclear materials. For brevity, all such ef-
fects will be called "environmental" effects.
The place in Table 1 for these impacts is
column (b), tersely dubbed "health and
life."
The Risk/Impact Panel of CONAES de-
cided not to try to estimate money equiva-
lents for such adverse impacts of various
magnitudes. Were such estimates possible
and available, then one could also define
and find a balance between desired benefits
and adverse "environmental" impacts that
remain after scrubbers, inspectors, Civex
and the like have done their jobs. Not hav-
ing such estimates, the MRG turned the
question around: Assume that tentatively
chosen upper bounds are imposed on the
use of technologies that have such impacts.
Estimate the loss in GNP associated with
these bounds. Then that number also places
a price tag on the reduction in "environ-
mental" impacts achieved by those bounds.
Thus, even if an a priori valuation of the
reduction in impacts is not available, then
such a valuation is still implicit in any
decision actually taken. It may help the
decision makers to know these implicit
price tags.
I will list only the principal assumptions
made for this purpose. Numerical values
were assigned to three sets of variables. As


### ---Economics-1979-0-07.txt---
principal exogenous, also called "realiza-
tion," variables we chose:
R1. The growth rate of real GNP, out to
2010, in the absence of new environ-
mental bounds on energy technolo-
gies.
R2. Capital cost levels of present and po-
tential future energy technologies.
R3. Availabilities of oil, gas, uranium, at
various costs of extraction.
R4. Long-run price and income elastici-
ties of demand for end-use energy
forms.
The "policy" variables represent the hypo-
thetical bounds already described,
P1. Moratoria on new nuclear construc-
tion.
P2. Limits placed on output of coal and
shale oil.
Forming a third category, the "blend" vari-
ables have traits of both realization and
policy variables,
Bi. Discount rates applied to future
benefits and costs.
B2. Oil import price or quantity ceilings.
The method applied was to compare the
already specified projection of a rising future
GNP in which no bounds have been im-
posed on the use of energy technologies (the
base case), with other projections in which
such a bound or bounds were imposed. This
procedure was carried out for each of three
long-run models of the U.S. energy sector.
The numerical inputs into the three models
were the same for almost all realization and
blend variables, except for the price and in-
come elasticities of demand, which were
specific to each model. Two ideas central to
current economic analysis entered into this
procedure. One is the use of an optimiza-
tion algorithm to simulate the behavior of a
competitive market economy, in any one
year, and through time. The other is the use
of long-run elasticities of demand. For de-
mand by end-use consumers, these are to be
based on econometric analysis of time-
series and/or cross sections of income,
prices, and quantities consumed. For in-
dustrial demand, a process analysis of al-
ternative industrial energy-using processes
may add valuable information.
The principal finding was the propor-
tionally small effect on GNP of sizable cuts
in energy use below its base case growth
path. In interpreting this finding, note that
the optimization procedure implies an as-
sumption whereby the economy responds to
anticipated changes by minimizing the cost
of adaptation. The principal means of adap-
tation are changes in the type and composi-
tion of the capital equipment for the ex-
traction, conversion, transport, and use of
energy-at the regular time for replace-
ment or earlier.
Table 2 shows the numerical results. For
two models, with price elasticities of -.25
and -.4, respectively, policies entailing per-
centage cuts in energy use out of the base
case that gradually increase to between 10
and 20 percent in the year 2010, were found
to cut not more than 2 percent out of the
discounted sum of annual real GNP, 1975-
2010, and a comparably small percentage
out of GNP for the single year 2010. The
instruments of the curtailment of growth in
energy use were, in row (1) of the table, the
placement of bounds on specific energy sup-
ply technologies described above. In row
(2), a zero-energy-growth path is simulated
by the imposition of a hypothetical "con-
servation tax" on primary energy flows. The
rate of this fictitious tax must increase as
the GNP continues to grow in spite of the
downward pull from the zero-energy-growth
path.
Another finding, reported in row (2), was
that for the effects of the larger cuts in
energy use, the value of the long-run price
elasticity of demand for energy becomes
crucial. In a sensitivity analysis made with
one model, a zero-energy-growth policy
from 1975 on, leading to a 60 percent cut in
energy use out of the base case in 2010,
was found to induce only a 2 percent cut in
cumulative discounted GNP if that price
elasticity is -.5, but a 30 percent cut if it is


### ---Economics-1979-0-08.txt---
-.25. I shall come back.later to the estima-
tion of the elasticity parameters found to
have been very important.
111. Interdisciplinary Differences in Outlook
We have now assembled enough reference
material for us to make a start with our
main topic-the way in which differences in
outlook between the disciplines affect the
conduct and evaluation of joint studies.
The most significant difference between
economics and the natural sciences lies in
the opportunities for testing and verification
of hypotheses. Jacob Marschak used to say
that economists carry the combined bur-
dens of meteorologists and engineers. Like
the meteorologists, they are expected to pre-
dict the future course of important vari-
ables in their field of study. Just as engi-
neers design more and more efficient
machines, economists are also expected to
improve the design of society where it af-
fects good use of resources. But, like the
meteorologist, the economist has tradi-
tionally been confined to drawing inferences
from passive observations, records of data
generated by the turbulence of the at-
mosphere or the fluctuations and trends of
economic life. Finally-a very important
difference-meteorologists and engineers
have all the laws and measurements es-
tablished by physics and chemistry avail-
able to them, fully documented by experi-
mental tests and results.
Traditionally, economists have not
searched for similar inputs from experi-
mental or observational research of a
psychological or sociological nature. In the
1950's and early 1960's they have engaged
in some experimentation of their own on be-
havior under uncertainty and in bargaining
and gaming situations. However, the find-
ings of this work have not been put to use
as premises for modeling an entire economy.
For that purpose, over a few articulate pro-
tests, many economists have been satisfied
to postulate simple rules of behavior by
consumers and business firms. The terms
"introspection" and "casual empiricism"
have been used to describe the cognitive
sources of these premises. In the version of
the currently dominant "neoclassical"
school of thought, these premises express
optimizing responses of demand and supply
to a uniform price system: satisfaction
maximizing by consumers, profit maximiz-
ing by firms.
These premises have a certain intuitive
plausibility about them. Undoubtedly, their
widespread adoption has also been aided by
the richness of the body of inferences one
can draw from them. In fact, the premises
form the logical foundation for the paradigm
of neoclassical economics: the concept of an
equilibrium of prices and quantities that in
some way ties together the economic de-
cisions taken by all seemingly independent
agents. Conceptually the prices and the
quantity responses may describe a sta-
tionary state over an extended period of
time. More realistically, they may be dated
variables and thus also link decisions that
vary over successive periods, to sustain a
moving intertemporal equilibrium.
Parenthetically, use of the term equi-
librium does not imply an assumption that


### ---Economics-1979-0-09.txt---
the real economy actually is at any time "in
equilibrium." Rather, the notion of equi-
librium is a first approximation, a reference
point or path, like the cycles of Ptolemy
without the epicycles and the eccentricity.
If the market were to extend to all per-
tinent economic decisions over the entire
period considered, the result of an inter-
temporal equilibrium would be an "ef-
ficient" path of the economy in the limited
sense that no one can be made better off at
any time without someone being made
worse off at some time. Where market
power interferes with competition, or where
important economic decisions are made at
government levels, the instinct of the neo-
classical economist is to recommend that
legislation, regulation, the use of suitable
incentives, or direct government decision
either restore or mimic the operation of the
competitive market.
In the present context, an important trait
of the neoclassical model is that it does not
postulate one sole primary resource, be it
labor, energy or any other, whose scarcity
controls that of all other goods, and which
thereby becomes a natural unit of value for
all other goods. The model of production is
such that-not by logical necessity, but as
an empirical fact--any primary input to
production can be substituted to some ex-
tent for any other. If such substitution does
not take place within one-and-the-same
production process, then it can still come
about through suitable changes in the levels
of several processes and in the inputs to
these. In this view "the energy problem" is
not one of just "saving energy," regardless
of the cost in other resources. It is rather
one of seeing to it that the increasing real
cost of domestic energy extraction and sup-
ply, and the increased market power of
OPEC, are-over time-reflected in the
real prices of primary energy forms relative
to other primary inputs, and thereby in dif-
ferent degrees in the prices of all other
goods and services. In the projections de-
scribed above, the energy prices are cal-
culated so as to be in balance with an ef-
ficient path of the technology mix into the
future, and thereby to induce the right
amount of energy saving. In particular if, as
projected by MRG, real prices of primary
energy rise in this path, then energy use is
projected to grow less than proportionally
to GNP.
The contrary doctrine-that regardless of
prices there is a persistent relationship be-
tween energy use and GNP-has frequently
been expressed in the engineering literature.
In line with this observation, the MRG find-
ing of a possible small impact on GNP of
incisive bounds on specific energy tech-
nologies led to lively correspondence and
discussions with members of CONA ES, and
of its Supply/Delivery Panel, an engineer-
ing-oriented group. I should add that the
MRG study was not the first modeling study
to cast doubt on the doctrine referred to.
By my knowledge the first was a study by
Edward Hudson and Dale Jorgenson.
IV. Discounting Future Benefits and Costs
We are now ready for a closer look at the
discounting of future benefits and costs.
This practice reflects a simple technological
fact combined with the paradigm of equi-
librium over time. The simple fact is that-
short of capital saturation-society can
temporarily curtail the production of cur-
rent consumption goods by transferring
some factors of production to the forma-
tion of additional suitable capital goods,
in such a way as to return a multiple (> 1) of
the same unit bundle of consumption goods
in the future. Efficient intertemporal equi-
librium then demands that the present
value of the goods returned to consump-
tion be equal to that of the goods not now
consumed. The quantity of the future
bundle being larger, its per-unit present
value must be correspondingly lower. In a
projection that gives to one unit of the fu-
ture bundle a future real market price nu-
merically equal to its current price, a dis-
count factor d < 1 must be applied to the
future market price to obtain the present
value, per unit of the future bundle. Given
competitive markets for capital, present
goods and future goods, and ignoring dif-
ferences in risk, different investments bear-


### ---Economics-1979-0-10.txt---
ing fruit in the same future year t will tend
to give rise to the same discount factor
I t
dt + )
where rt is the annual discount rate ap-
plicable to the period from year zero to year
t. The usual practice in cost-benefit analyses
is to assume also that rt is independent of
t, rt = r, say.
This reasoning simply registers the eco-
nomic accounting implications of assumed
intertemporal efficiency with capital non-
saturation. To many highly educated
people, there is something ethically offen-
sive about it.
A difficult practical problem on which
economists still differ among themselves is
how to read a good estimate for r from
capital market and other data. Different tax
rates on corporate and individual incomes
complicate the problem. Considering this
and various market imperfections, the pre-
cluded alternative use of funds drawn upon
for a public project also enters into the
choice of r. I will not venture into these
questions here.
Coming back to helium storage, the dis-
counting criterion would lead most econo-
mists to recommend that those steps of the
storage program be implemented for which
the rate of return on the total investment
(not that on energy alone) exceeds or equals
the discount rate appropriate to the prob-
lem. Step i, storing helium currently vented,
is likely to meet the test. The problem is to
estimate which of the four or six steps
would.
Two final remarks, the first added as an
afterthought since August 30.
The two issues we have discussed-
whether to count only energy costs or all
costs, and whether or not to discount future
benefits and costs-are logically distinct
implications of the notion of intertemporal
equilibrium. However, psychologically they
are related. If one counts only energy costs,
everything is expressible in equivalent
Btu's, and to the physicist, steeped in the
law of conservation of energy, Btu's are the
same everywhere and at all times. To dis-
count future Btu's therefore seems not just
strange but outright wrong. So it is. But the
economist does not discount quantities of
any kind. He discounts only real values,
that is, quantities (including energy) multi-
plied by real prices that reflect the expected
balance of cost and preference as of a
specified future time and beyond. It is to
these prices that the discount factor is ap-
plied. I am hoping that this simple distinc-
tion may help to reduce misunderstanding
between the professions.
Secondly, our reasoning has proceeded
blandly as if there were no uncertainty about
the outcome of the development of processes
expected to be substantial users of helium.
If there is considerable uncertainty, econo-
mists may want to add an allowance for risk
to the discount rate. They may also wish to
experiment with models in which judg-
mental probabilities are attached to these
uncertain outcomes. This device may pro-
duce insights even if the conclusions de-
pend on admittedly uncertain premises. A
study of this kind is included as chapter IV
in the MRG report.
V. Attaching Values to Health and Life
The question of estimating the value of
health and the value of life arises mostly in
contexts where either public decisions, or
public monitoring of private decisions, can
be shaped so as to improve health and pro-
long life. One example is the investment of
public funds to diminish physical risks to
traffic by the design of roads, bridges, turn-
outs, and crossings. Another is regular ex-
penditures for traffic police, building in-
spectors, and other law enforcers who
restrain some people from killing or hurt-
ing themselves or others by recklessness or
neglect.
A common trait of these decisions is that
from good experience records one may be
able to estimate the years of lives saved,
perhaps also of health and limbs preserved,
per dollar spent on efficiently run projects
or activities of this kind. Such calculations
make it possible to spot discrepancies be-
tween different projects in regard to "health


### ---Economics-1979-0-11.txt---
and life benefits" bought per dollar spent.
The ideal of equilibrium then suggests re-
distributing expenditures, if needed, in or-
der to maximize total benefits from the
given expenditure for protection. Valua-
tions of health or life that have a modicum
of public approval could result from such
redistribution. Note that these valuations,
also called shadowv prices, are in efTect set by
the budgetary decision makers, whether
they are aware of it or not.
After such redistribution if called for, the
calculation of money values of health and
life registers what in good practice we con-
sistently spend to save a life. The process
recognizes that, disturbing as it is to our
sensibilities, society is being compelled by
the facts of technology and behavior to set
up equivalences between lives of unidenti-
fied people and bundles of goods and ser-
vices implicitly of the same market or
shadow value - --thus bracketing contem-
porary lives together with current goods
and services in the same category of ex-
changeables.
The examples given so far concern small
to moderate risks affecting small to moder-
ate numbers of people, less than 100 at a
time, say. Moreover, the time intervals be-
tween the decision to commit funds for the
reduction of risks, the actual expenditure of
these funds, and the reaping of benefits
therefrom are moderate, less than twenty
years, say. Finally, the problems are mostly
local or national, not international in scope.
The long-run choices between energy
technology mixes are different in these re-
spects. By a gradual shift from oil and gas
to coal, fossil fuels can remain a principal
source of energy for countries with abun-
dant resources of coal, especially the United
States, the USSR, and China, for a long
time to come. Intensive current discussion
with regard to this option concerns the pos-
sible climatic effects of the increase in the
atmospheric concentration of carbon dioxide
caused by continued large-scale combus-
tion of fossil fuels or their derivatives,
alongside with world-wide deforestation.
Among the large-scale effects held pos-
sible are an increase in average global
temperature, entailing dislocation of agri-
culture depending on how each region is
affected, and an increase in the level of the
oceans due to the melting of polar ice not
previously floating. The present state of
knowledge is not such as to be ready for an
assessment of these risks. New hypotheses
and observations appear regularly in the
pages of Science and other journals. So I
would describe this problem as involving an
unknown risk to a large number of people.
If current estimates of the capital cost of
central station solar power are realistic, the
principal alternative to fossil fuels for bulk
power generation is nuclear power. I am
not qualified to even comment on the reac-
tor safety and waste disposal problems. I
assume, however, that the developers of
these technologies would classify these
problems in terms of very small risks to
substantial numbers of people. Perhaps this
leaves as the principal concern the difficulty
of keeping industrial and weapons use of
nuclear materials apart. Since on this one
we are all groping in the dark, I feel I should
describe this aspect of nuclear technology
as an unknown risk to a very large number
of people.
I cannot see my way through to a calcu-
lus of the value of human lives in large
numbers, that would help clarify issues of
the scope of those just discussed although
estimates of numbers of lives at risk are
and will remain important. These are
basically problems for judgment, even
though the need for making these judg-
ments will weigh hard on the people called
upon to make them. But supposing I should
be wrong, let me point to one apparent
paradox to be faced in any attempt to
bring a calculus of the shadow price of
human life to bear on problems with a long
time span.
Suppose one accepts as an ethical prin-
ciple that, in balancing risks to human life
in the present and in the future, equal num-
bers of lives should receive equal weight.
This would make the present value of the
future human life independent of the time
at which it is lived. However, we have seen
that as long as capital saturation is not at-


### ---Economics-1979-0-12.txt---
tained, the present value of a standard bun-
dle of goods in the future decreases as that
future time recedes. Hence the present value
of future life relative to that of future goods
will be much higher than the value of present
life in relation to present goods. It should
not be inferred from this that future de-
cision makers are assumed or advised to de-
vote greater resources to safety and health
than the present decision makers, although
the future ones may well want to do this for
reasons of their own. The inference is rather,
I submit, that the present values I have de-
scribed reflect a curious mixture of three
ingredients: one intertemporal ethical rule,
present preferences between consumption
and protection, and an assumption about
savings behavior of all generations within
the next fifty years, say. Under these as-
sumptions, sets of "present values" formed
at successive points in time need not, and
generally will not, be consistent with each
other.
VI. The Empirical Basis of
Quantitative Economics
I now go on to a discussion of the em-
pirical basis for some of the quantitative
statements that economics contributes to
interdisciplinary studies. I will again il-
lustrate this question with reference to the
few studies I have chosen as examples. At
the same time I will emphasize the role that
the premises underlying the concept of
equilibrium play in this process.
The premise of profit maximization im-
plies a subpremise of cost minimization.
I regard that subpremise as fitting reality
more closely than the entire premise. It
underlies the supply side of the MRG study
of future energy technology mixes I have
described.
The premise of maximization of satis-
faction by the consumer can be made more
plausible and more applicable by a further
specification. Applied to energy, it says that
successive equal additions to a consumer's
annual energy end-use budget are worth
less and less to him. Operationally, how
much each successive addition is worth to
him can be measured, for instance, by that
increase in the expenditure for the rest of
his consumption that he would have re-
garded as equivalent to each next addition
to his energy consumption.
This specification implies the existence of
a household demand function for energy, in
which per capita demand for energy de-
creases as its price increases, and increases
as per capita real income increases. The
MRG extended this concept to the sum of
direct and indirect demand for energy, the
latter being the energy used as input to the
production of all nonenergy goods, includ-
ing capital goods as well. Another exten-
sion distinguishes demand for individual
fuels, where the demand for one fuel in-
creases if the price of another competing
fuel goes up.
These functions are then estimated from
empirical data. In the procedure followed
in the model with the estimated long-run
price elasticity of -.4 mentioned above, a
parametric form of these functions was
fitted to cross-section and time-series data
for seven OECD countries, including the
United States, for the period 1955-72. In
the model with price elasticity -.25 the
estimation procedure was not stated with
comparable explicitness. In both models the
estimated long-run demand functions,
written with price as a function of quantity,
were then integrated to estimate the benefit
from the consumption of energy in all
forms.
By comparison, the empirical basis for
the production side is more direct. Each of
the various competing energy producing,
converting, and using processes is repre-
sented by constant ratios of inputs to out-
puts, reflecting operating experience where
available, or based on estimates of such
ratios and of future availability dates for
processes not yet developed. For instance,
process estimates for the years 1985 and
2000 were drawn upon in estimating the
elasticity of substitution between electric
and nonelectric energy in the second of the
two models just discussed. This did con-
strain but not by itself imply numerical
estimates of the elasticities of demand for


### ---Economics-1979-0-13.txt---
energy, whether in toto (given as -.25), or
for the two components.
This completes my description of the em-
pirical basis for the MRG procedures and
the premises on which they rest. I want,
in passing, to draw attention at this point
to the econometric aspects of another
study, designed to estimate perceived bene-
fits of air quality improvements from resi-
dential property values in areas with dif-
ferent air quality. The study is entitled "The
Costs and Benefits of Automobile Emis-
sion Controls." It draws on a body of
econometric work in which property values
are related to various characteristics of the
site and the neighborhood, including air
quality and other environmental amenities,
and the income of the household.
The foregoing examples lead me to some
broader remarks on the empirical basis of
quantitative economic knowledge in gen-
eral, not limited to the type of studies we
are here mostly concerned with.
In all formal procedures involving sta-
tistical testing or estimation, there are ex-
plicitly stated but untested hypotheses,
often called "maintained" hypotheses by
statisticians. In the econometric studies we
have here considered, the "premises" al-
ready discussed play that role. More in
general, any statement resulting from such
studies retains the form of an "if ... then . . ."
statement. The set of "ifs," sometimes called
"the model," is crucial to the meaning of
the "thens," usually but somewhat inac-
curately called the "findings." For instance,
in fitting demand relations, the principal
maintained hypotheses specify the variables
entering into these relations, and possibly
other variables with which these variables
are in turn linked in other pertinent rela-
tions.
The "if ... then ..." statements are simi-
lar to those in the formal sciences. They
read like logical or mathematical reasoning
in the case of economic theory, and like ap-
plications of statistical methods in the case
of econometric estimation or testing. The
heart of substantive economics is what can
be learned about the validity of the "ifs"
themselves, including the "premises" dis-
cussed above. "Thens" contradicted by ob-
servation call, as time goes on, for modifica-
tion of the list of "ifs" used. Absence of
such contradiction gradually conveys sur-
vivor status to the "ifs" in question. So I do
think a certain record of noncontradiction
gradually becomes one of tentative con-
firmation. But the process of confirmation
is slow and diffuse.
For some purposes, and at considerable
expense, short cuts can be made to di-
minish the dependence on untested "ifs." I
am speaking of systematic experiments such
as the so-called negative income tax ex-
periment conducted in New Jersey over the
period 1968-72, and followed by similar in-
come maintenance experiments in other
areas of the United States. If one wants to
know whether income maintenance pay-
ments to families near the poverty line have
a disincentive effect, or no effect, or even a
positive incentive effect on labor supply,
one does not need to have a pretested theory
as to what, if anything, the family is maxi-
mizing. Instead, one can make such pay-
ments to a sample of families and com-
pare its behavior with that of an unaided
control group. This is what the New Jersey
experiment did. In one category of families
where the numbers spoke rather clearly-
white husband-and-wife whole families-
the effect on labor supply was found to be
negative, moderate but statistically sig-
nificant, and with the effect on the husband's
labor supply smaller than that on the wife's.
In addition, much was learned about the de-
sign, conduct, and evaluation of such ex-
periments for use in later studies.
There have not been many such experi-
ments on a scale needed to obtain sta-
tistically significant outcomes. Moreover,
they have been limited to questions of
great and urgent policy importance. Mean-
while, we do need to find ways in which
verification of the premises of economics,
through cumulative econometric analyses
and through experiments that find a spon-
sor, can be pursued.
I have not found in the literature a per-
suasive account of how such confirmation
of premises can be perceived and docu-


### ---Economics-1979-0-14.txt---
mented. How do we keep track of the con-
tradictions and confirmations? How do we
keep the score of surviving hypotheses?
And what are we doing in those directions?
The same questions have been raised be-
fore, among others by my predecessors,
Wassily Leontief and Robert Aaron Gor-
don, and good and bad examples of con-
cern and unconcern were referred to by
both of them. Meanwhile, unresolved issues,
sometimes important ones from the policy
point of view, and mostly quantitative ones,
drag on and remain unresolved. Do they
have to?
With one exception I am aware of, even
our best college-level introductory texts of
economics do not press these questions.
They teach good reasoning, and describe
the views of leading minds and schools of
thought, present and past, in the field.
Texts in econometrics teach with great care
how to test assumptions and to estimate
parameters, duly emphasizing the crucial
role of the models. What is also needed is
to teach the tested and confirmed state-
ments.
VII. Aphorisms on Interactions
After all I have said about the need for
empirical validation, I owe you a brief re-
port on my own casual-empirical sample
study of the difficulties of interaction be-
tween scientists, engineers, and economists,
as seen by participants in joint studies.
Rather than classifying and tabulating the
views expressed, I shall let the respondents
speak for themselves. The following is a
selection (by me) of statements, drawn from
my notes, that carried the most punch.
A physical scientist: "Economists are
technological radicals. They assume every-
thing can be done."
A geologist: "Economists have been
too enthusiastic about deep sea mining.
They think there is more than there is, that
it is easier to get up than it is, and easier to
process than it is."
A development economist: "Scientists
think big. Economists are marginalists.
Scientists don't think in terms of oppor-
tunity cost."
An engineer: "Economics is not dismal
but incomplete. The things missed are very
important."'
A life scientist: "Market imperfection
is more widespread than economists care to
admit."
An economist: "Where economists see
the invisible hand guiding the market place
to produce pretty good outcomes, scientists
see only chaos."
An engineer: "The economic motive is
overrated."
A psychologist: "All the conclusions
that are drawn from the assumption of ra-
tionality can also be drawn from assump-
tions of adaptive behavior."
A life scientist: "Economists have great
skill in handling data. However, they tend
to ask only for data, not for concepts and
ideas. Drawing up a model is an inter-
disciplinary task."
An engineer: "Economists often use
smooth production functions even when
engineers might be reluctant to do so."
A life scientist: "Many scientists do not
understand discounting."
An engineer: "Economics is the Ther-
modynarnics of the Social Sciences. Every-
thing is deduced from a few simple postu-
lates without the necessity for knowing
detailed mechanisms."
VIII. Final Remarks
After this instructive intermezzo, allow
me a few final words. I will not be able to
match the brevity and incisiveness we just
savored. However, I do look on the col-
laboration of the diverse professions in-
volved in the newly discovered joint prob-
lems as an important development. To
economists it is a new challenge and a new
frontier. Among the problems themselves
are some of great importance, nationally
and internationally. They deserve the best
effort and talent that can be brought to
bear, within and across the disciplines.
An important talent requiring cultivation
is skill in communication between dis-
lThe reference is to the need to fit environmental
protection into economic analysis.


### ---Economics-1979-0-15.txt---
ciplines. We should begin with the defusing
of jargon. Perhaps some terms should be
explained at first use. To the physicist who
has used calculus on problems going back
to Isaac Newton, it is unexpected to learn
that everything called "marginal" is a first
derivative of something. It appears natural
to him, however, to learn that an "elas-
ticity" is the dimensionless slope of a curve
plotted on double-log paper. There is more
trouble lying in wait with "externalities,"
an institutional concept presupposing pri-
vate property, or at least an accountability
for private or public production or house-
hold decisions that is dispersed over in-
dividuals and organizations. If we will be
more forthcoming with explanations of our
cherished terms, our science colleagues may
be more inclined to help us out with "en-
tropy," which to me is a more difficult con-
cept than anything economics has to offer.
A more serious problem is that, while our
universities are the principal training ground
for future scientists of all kinds, they do not
seem to be the best place for gaining ex-
perience in interdisciplinary interaction. I
believe that the root of the difficulty lies in
the procedures for academic appointment
and promotion. The initiative, the decisive
first step, is usually taken in the depart-
ment of one's own discipline. Young faculty
members must prove their worth first to
their senior colleagues in the field they are
identified with. A joint appointment holds
somewhat less promise as a stepping stone
to tenure. Even our graduate students are
already aware of these factors.
The increasing demand for the contribu-
tions of interdisciplinarians may gradually
break the barriers down. Progress will be
slow unless university faculties and adminis-
trations perceive the problem. Once they
do, the irrepressible curiosity and venture-
someness of our undergraduates will pro-
vide a point at which to start and from
which to build up.
## Economics-1980-0


### ---Economics-1980-0-01.txt---
There is a long-standing tension in eco-
nomics between belief in the advantages of
the market mechanism and awareness of its
imperfections. 'Ever since Adam Smith,
economists have been distinguished from
lesser mortals by their understanding of and
-I think one has to say-their admiration
for the efficiency, anonymity, and subtlety
of decentralized competitive markets as an
instrument for the allocation of resources
and the imputation of incomes. I think we
all know this; for confirmation one can look
at the results of a paper (James Kearl et al.)
presented at the last annual meeting, report-
ing the responses of professional economists
to a sort of survey of technical opinion. The
propositions which generated the greatest
degree of consensus were those asserting the
advantages of free trade and flexible ex-
change rates, favoring cash transfers over
those in kind, and noting the disadvantages
of rent controls, interest rate ceilings, and
minimum wage laws.
Views on these policy issues did not seem
to represent mere conservative ideology:
half of the respondents agreed and another
30 percent agreed "with provisions" that
redistribution of income (presumably to-
ward the poorest) is a legitimate function
of government policy. The profession's res-
ervations about rent control, interest rate
ceilings, and minimum wage laws do not
appear to reflect a rejection of the goals of
those measures, but rather a feeling that
nonprofessionals simply do not understand
fully the consequences, often unexpected
and undesired, of messing around with the
market mechanism. Most of us are con-
scious of a conflict that arises in our minds
and consciences because, while we think it is
usually a mistake to fiddle the price system
to achieve distributional goals, we realize
that the public and the political process are
perversely more willing to do that than to
make the direct transfers we would prefer. If
we oppose all distorting transfers, we end up
opposing transfers altogether. Some of us
seem to welcome the excuse, but most of us
feel uncomfortable. I don't think there is
any very good way to resolve that conflict in
practice.
Simultaneously, however, there is an im-
portant current in economics that focuses
on the flaws in the price system, the ways
that real markets fail because they lack
some of the characteristics that make ide-
alized markets so attractive. I think that
outsiders, who tend to see economists as
simple-minded marketeers, would be
astonished to learn how much of the history
of modern economic analysis can be written
in terms of the study of the sources of
market failure. The catalog runs from nat-
ural and artificial monopoly, to monopolis-
tic competition, to the importance of public
goods and externalities of many other kinds,
to-most recently-a variety of problems
connected with the inadequate, imperfect,
or asymmetric transmission of information
and with the likelihood that there will sim-
ply be no markets for some of the relevant
goods and services.
Even the vocabulary can be revealing.
Market "imperfection" suggests- a minor
blemish of the sort that can make the
purchase of "irregular" socks a bargain.
Market "failure" sounds like something
more serious. To take a more subtle exam-
ple, I mentioned that one kind of flaw in the
system can be the absence of certain
markets. The common generic term for the
reason why markets are missing is "transac-
tion costs." That sounds rather minor,
the sort of thing that might go away in
due course as accounting and information


### ---Economics-1980-0-02.txt---
processing get cheaper. But some of the
cases of missing markets really go much
deeper. The fact that distant future genera-
tions can not participate directly in the
markets for nonrenewable resources will not
be remedied by improvements in com-
munication. Nor are the residents of densely
populated areas ever likely to be able to
dicker effectively with the dozens or hun-
dreds of sources of barely traceable pollut-
ants whose health effects, if any, cumulate
over many years.
There is a large element of Rohrschach
test in the way each of us responds to this
tension. Some of us see the Smithian virtues
as a needle in a haystack, as an island of
measure zero in a sea of imperfections.
Others see all the potential sources of
market failure as so many fleas on the thick
hide of an ox, requiring only an occasional
flick of the tail to be brushed away. A
hopeless eclectic without any strength of
character, like me, has a terrible time of it.
If I may invoke the names of two of my
most awesome predecessors as President of
this Association, I need only listen to Milton
Friedman talk for a minute and my mind
floods with thoughts of increasing returns to
scale, oligopolistic interdependence, con-
sumer ignorance, environmental pollution,
intergenerational inequity, and on and on.
There is almost no cure for it, except to
listen for a minute to John Kenneth
Galbraith, in which case all I can think of
are the discipline of competition, the large
number of substitutes for any commodity,
the stupidities of regulation, the Pareto opti-
mality of Walrasian equilibrium, the impor-
tance of decentralizing decision making to
where the knowledge is, and on and on.
Sometimes I think it is only my weakness of
character that keeps me from making obvi-
ous errors.
The critics of the mainstream tradition
are mistaken when they attribute to it a
built-in Panglossian attitude toward the
capitalist economy. The tradition has pro-
vided both the foundations for a belief in
the efficiency of market allocations and the
tools for a powerful critique. Economic
analysis by itself has no way of choosing
between them; and the immediate prospects
for an empirically based model of a whole
economy, capable of measuring our actual
"distance" from the contract curve, are
mighty slim. The missing link has to be a
matter of judgment-the Rohrschach test
I spoke of a minute ago. For every Dr.
Pangloss who makes the ink blot out to be
of surpassing beauty, give or take a few
minor deviations-the second-best of all
possible worlds, you might say-there is a
Candide to whom it looks a lot like an ink
blot. Maybe there are more Panglosses than
Candides. But that was true in Voltaire's
time too-just before the French Revolu-
tion, by the way-and has more to do with
the state of society than with the nature of
economics.
The tension between market efficiency
and market failure is especially pointed in
discussions of the working of the labor
market, for obvious reasons. The labor
market connects quickly with everything
else in the economy and its performance
matters more directly for most people than
that of any other market. Moreover, the
labor market's own special pathology, un-
employment, is particularly visible, particu-
larly unsettling, and particularly frustrating.
The fuse leading from theory to policy in
this field is short, and has been known to
produce both heat and light throughout
much of the history of economics.
Contemporary macro-economic theory,
though apparently full of technical novel-
ties, has revived many of the old questions
in only slightly different form. One of the
points I want to make is that underneath the
theoretical innovations-some of which are
interesting and important the basic con-
troversial issues that come to the surface are
the same ones that occupied earlier litera-
ture. The most important among them is
really the old tension between market
efficiency and market failure. Should one
think of the labor market as mostly clearing,
or at worst in the process of quick return to
market-clearing equilibrium? Or should one
think of it as mostly in disequilibrium, with
transactions habitually taking place at non-
market-clearing wages? In that case pre-
sumably the wage structure is either not
receiving any strong signals to make it


### ---Economics-1980-0-03.txt---
change in the right direction or is not re-
sponding to the signals it receives. My own
belief in this case lies with the market-
failure side. That is to say, I believe that
what looks like involuntary unemployment
is involuntary unemployment.
Of course that conclusion only leads to
another question. If the labor market often
fails to clear, we had better figure out why.
There is no shortage of candidate hypothe-
ses. Here I think it is worthwhile to insist on
a commonplace: although it is natural for
academic people to seek a single weighty
Answer to a weighty Question, if only be-
cause it is so satisfying to find one, it is
quite likely that many of the candidate hy-
potheses are true, each contributing a little
to the explanation of labor-market failure.
Now the second general point I want to
make is one that I am surprised to hear
myself making. While I find several of the
candidate hypotheses entirely believable, I
am inclined to emphasize some that might
be described as noneconomic. More pre-
cisely, I suspect that the labor market is a
little different from other markets, in the
sense that the objectives of the participants
are not always the ones we normally impute
to economic agents, and some of the con-
straints by which they feel themselves
bound are not always the conventional con-
straints. In other words, I think that among
the reasons why market-clearing wage rates
do not establish themselves easily and adjust
quickly to changing conditions are some
that could be described as social conven-
tions, or principles of appropriate behavior,
whose source is not entirely individualistic.
I said that I am a little surprised at my-
self. That is because I am generally stodgy
about assumptions, and like to stay as close
to the mainstream framework as the prob-
lem at hand will allow. In any case, I think
that the unconventional elements in what I
have to say are only part of the story. And I
assure you that I am not about to peddle
amateur sociology to a captive audience. All
I do mean to suggest is that we may predis-
pose ourselves to misunderstand important
aspects of unemployment if we insist on
modelling the buying and selling of labor
within a set of background assumptions
whose main merit is that they are very well
adapted to models of the buying and selling
of cloth. Far from advocating that we all
practice sociology, I am pleasantly im-
pressed at how much mileage you can get
from the methods of conventional economic
analysis if only you are willing to broaden
the assumptions a little.
I
It might be interesting to have a history of
the evolution of economic ideas about un-
employment, and their relation both to the
internal logic of the subject and to the
parallel evolution of the institutions of the
labor market. I am not sufficiently well read
to provide that kind of survey. To make my
point about the persistence of the market-
efficiency market-failure tension, I took a
short cut. I went back to reread Pigou's
Lapses from Full Employment, a little book I
remember having been assigned to read as a
student just after the war. And that in turn
sent me back to its parent book, Pigou's
Theory of Unemployment. The Preface to
The Theory of Unemployment is dated April
1933, after a decade of poor performance
and relatively high unemployment in Great
Britain, well into the Great Depression, and
before the publication of the General The-
ory. The Preface to Lapses from Full Em-
ployment (another example of a revealing
vocabulary) is dated November 1944, after
five years of the war that put an end to the
depression, and well after the appearance of
the General Theory. That seemed like an
interesting approach to the historical ques-
tion, because current controversies in
macro-economic theory are often described
as a debate between "Keynesians" and
others- "monetarists," "Classicals," or
" equilibrium theorists" - and because
Pigou, besides being a great economist, was
in particular the embodiment of the
Marshallian tradition, the leading figure in
the "classical economics" that the Keynes-
ian revolution was explicitly intended to
overthrow.
Lapses makes interesting rereading. It em-
phasizes the money wage, whereas its prede-


### ---Economics-1980-0-04.txt---
cessor was written almost entirely in terms
of the real wage. The general macro-theo-
retic framework, in which the discussion of
the labor market is embedded, clearly has
an eye on Keynes. The underlying model
could be IS-LM without doing much vio-
lence to the argument. There are little
anachronisms: Pigou tends to think of the
interest rate as being determined in the
goods market (by Savings = Investment) and
nominal income as being determined by
the demand for money. Today we take
simultaneity seriously, but the General The-
ory more or less speaks as if real output is
determined in the goods market and the
interest rate by liquidity preference. After
what is to me a confusing description
of a Keynesian low-level liquidity-trap
equilibrium, Pigou invokes the Pigou effect
to explain why the low level might not be as
low as all that and then, characteristically,
remarks that none of it is very important in
practice anyway. All this is relevant here
only as background for the treatment of the
labor market.
Pigou says the obvious thing first, and I
agree that it is the first thing to say: if there
is "thorough-going competition" among
workers, then the only possible equilibrium
position is at full employment. That is little
more than a definition of equilibrium. He is
aware that he is taking a lot of dynamics for
granted. Expectations of falling wages could
perversely reduce the demand for labor; and
he discusses the possibility that under some
conditions, with the interest rate at its prac-
tical floor, nominal wage rates and prices
may chase each other down and thus pre-
vent the real-wage adjustment needed for an
increase in employment. (This is where the
Pigou effect makes its appearance, of
course.)
It is what comes next that interests me. It
is obvious to Pigou, writing in 1944, that the
labor market does not behave as if workers
were engaged in thorough-going competi-
tion for jobs. With the common sense that
seems somehow to have escaped his modem
day successors, he wonders why it does not.
And he discusses three or four of the institu-
tional factors that a reasonable person
would mention even now as obstacles to the
classical functioning of the labor market.
First of all, he realizes that the labor
market is segmented. Not everyone in it is
in competition with everyone else. I am not
referring here to the obvious fact that abili-
ties, experience, and skills differ, so that
unemployed laborers can not compete for
the jobs held by craftsmen. That fact of life
merely reminds us that "labor" is not a
well-defined homogeneous factor of produc-
tion. Even within skill categories or occupa-
tional groups, however, workers have ties to
localities, to industries, to special job classi-
fications, even to individual employers.
These ties can be broken, but not easily. It
is interesting to me that even the Theory of
Unemployment of 1933 devotes a lot of space
to the analysis of a labor market in
which there are many "centers of em-
ployment"-to use the neutral term chosen
by Pigou to describe segmentation of the
labor market-between which mobility is
absent or slow. Of course he observes that
even in a completely segmented labor
market, if there is thorough-going competi-
tion within segments, full employment will
be the rule, although there may be wage
differentials between centers of employment
for otherwise identical workers. I think that
the fact of segmentation is very important,
not only because it limits the scope of com-
petition but because its pervasiveness sug-
gests-though it can not prove-that habit
and custom play a large role in labor market
behavior. From the prominence that he
gives it, I gather that Pigou might have
agreed.
A second factor, which has been more
often discussed, is trade unionism. Pigou
does not have very much to say about col-
lective bargaining, but what he says makes
sense.
Of course, these agencies in their deci-
sions have regard to the general state
of the demand for labour; they will
have no wish to set wage rates so high
that half the people of the country are
thrown out of work. Nevertheless,
there is reason to believe that they do
not have regard to demand conditions
in such degree as would be necessary
to secure, as thorough-going competi-
tion would do, the establishment of
full employment. [ 1945, p. 26]


### ---Economics-1980-0-05.txt---
Later on in the book, Pigou makes an ob-
servation that is not explicitly connected
with collective bargaining. He does connect
it with "actual life" however, and it fits
organized workers very well, and perhaps
others besides:
In periods of expansion employers
might be willing to agree to substantial
advances in wage rates if they
were confident that, when prosperity
ended, they would be able to cancel
them. They know, however, that in
fact this will not be easy, that elab-
orate processes will have to be gone
through, and that their work-people
will put up a strong rear-guard ac-
tion... . In periods of depression
wage-earners, for precisely similar rea-
sons, hold out against wage reduc-
tions, which they might be ready to
concede if it were not for the difficulty
that they foresee in getting them
cancelled when times improve.... A
widespread desire for 'safety first'
helps to make wage rates sticky.
[1945, p. 48]
These casual remarks raise more questions
than they answer about the determination
of nominal wages by collective bargaining.
The first excerpt can be taken as a redefini-
tion of full employment when the labor
market is not competitive; the second, how-
ever, advances an account of wage sticki-
ness and is therefore on a different footing.
It would help to explain the failure of the
labor market to clear on any reasonable
definition, and thus provide a connection
between nominal demand and real output.
The third institutional factor mentioned
by Pigou has also been the subject of much
analysis, past and present: the provision of
unemployment insurance. There are several
channels by which the availability of unem-
ployment compensation can add to the re-
corded amount of unemployment. The
prolongation of search is only the most
obvious. My own impression is that this is
currently a significant factor. As an indica-
tion of the complexity of the issues, let me
just mention here that some recent research
by my colleagues Peter Diamond and Eric
Maskin suggests the possibility that in some
environments search activity conveys a posi-
tive externality. So the optimal search
strategy for the individual might provide
less than the socially optimal amount of
search, and unemployment compensation
could be regarded as a corrective subsidy.
This is a neat twist on the theme of the
counterpoint between market efficiency and
market failure. In any case, it can hardly be
doubted that the unemployment compensa-
tion system is an important determinant of
behavior on both sides of the labor market,
and complicates even the definition of full
employment.
The last comment of Pigou's that I want
to cite is especially intriguing because it is so
unlike the sort of thing that his present day
successors keep saying. Already in the 1933
Theory of Unemployment he wrote: "... . pub-
lic opinion in a modem civilized State
builds up for itself a rough estimate of what
constitutes a reasonable living wage. This is
derived half-consciously from a knowledge
of the actual standards enjoyed by more
or less 'average' workers.... Public opin-
ion then enforces its view, failing success
through social pressure, by the machinery
of... legislation" (p. 255). A similar remark
appears in Lapses. Such feelings about eq-
uity and fairness are obviously relevant to
the setting of statutory minimum wages, and
Pigou uses them that way. I think they also
come into play as a deterrent to wage cut-
ting in a slack labor market. Unemployed
workers rarely try to displace their em-
ployed counterparts by offering to work for
less; and it is even more surprising, as I
have had occasion to point out in the past,
that employers so rarely try to elicit wage
cutting on the part of their laid-off em-
ployees, even in a buyer's market for labor.
Several forces can be at work, but I think
Occam's razor and common observation
both suggest that a code of good behavior
enforced by social pressure is one of them.
Wouldn't you be surprised if you learned
that someone of roughly your status in the
profession, but teaching in a less desirable
department, had written to your department
chairman offering to teach your courses for
less money? The fact that nominal wage
rates did fall sharply during the early stages
of the depression of the 1930's, and the fact
that the Chrysler Corporation has been able


### ---Economics-1980-0-06.txt---
to negotiate concessions from the UAW cer-
tainly show that wage rates are not com-
pletely rigid. But those very instances seem
to me only to confirm the importance of
social convention in less extreme circum-
stances. After all, people have been known
to try to claw their way into a lifeboat who
would never dream of cheating on a lift-line.
I think I have made the case that the most
eminent representative of orthodox econom-
ics in the 1940's was fully aware of the many
obstacles to "thorough-going competition"
among workers, that is, of the many ways in
which the labor market may "fail." In par-
ticular, one cannot under those circum-
stances expect the labor market always to
clear. Pigou certainly drew that conclusion.
He says, in the Preface to Lapses: "Pro-
fessor Dennis Robertson... has warned me
that the form of the book may suggest that
I am in favour of attacking the problem
of unemployment by manipulating wages
rather than by manipulating demand. I
wish, therefore, to say clearly that this is not
so" (P. v).
Pigou clearly felt the tension between
market efficiency and market failure. Never-
theless, he did not come down on the side of
market failure, even after the 1930's. The
very title of Lapses from Full Employment
tells us that much. Evidently he concluded
that the tendency of the capitalist economy
to seek (and find) its full-employment
equilibrium was strong enough so that de-
partures from full employment could be re-
garded as mere episodes. Is that surprising?
Well, to begin with, there is no accounting
for Rohrschach tests. One person's ink blot
is another person's work of art. But I think
there is also something more systematic to
be said.
In the Theory of Unemployment, Pigou
gives an elaborate analysis of the short-run
elasticity of demand for labor. He is very
careful: he allows for the elasticity of supply
of complementary raw materials; he allows
for the (presumably very high) price elastic-
ity of demand for exports; he discusses the
effects of discounting future returns to
labor. It is a masterly attempt to get a grip
on orders of magnitude. It is all based on
the presumption that the only possible start-
ing point is the elasticity of the marginal-
product-of-labor curve. Let me remind you
that in the old standby, two-factor Cobb-
Douglas case, the elasticity of demand for
labor with respect to the real wage is the
reciprocal of the share of capital. Every-
body's back-of-the-envelope puts the capital
share at 1/4 and the elasticity of demand
for labor at 4. This is not exactly the way
Pigou proceeds, but he reaches the same
conclusion: the initial estimate of the elas-
ticity is "certain to be (numerically) much
larger than - 1 and may well amount to - 5
or more." There follow some modifications,
but the conclusion remains that in times of
depression, the aggregate elasticity of de-
mand for labor with respect to the real wage
"cannot, on the least favourable assumption
here suggested, be numerically less than - 3
and may well be larger than -4" except
perhaps in the very shortest run.
For practical purposes, one would want
to know the elasticity of demand with re-
spect to the nominal wage, taking account
of the likelihood that prices will follow
wages down, at least partially. (Obviously if
product prices fall equiproportionally with
wage rates, as Keynes thought might
happen in unlucky circumstances, the real
wage doesn't move at all and employment
will not improve.)' The details of Pigou's
calculations do not concern us, but his con-
clusion does: "... we may... not unreason-
ably put the elasticity of the money demand
for labour in times of deep depression at not
less numerically than - 1.5."
If I could believe that, I too could believe
that the labor market generally clears. To
reduce the unemployment rate by 6 per-
centage points is to increase employment by
about 6 percent, if we ignore for this pur-
pose the side effects that go to make up
Okun's Law. If that could be accomplished
by a real-wage reduction of 2 percent, or
even less, that is, by foregoing one year's
normal productivity increase, than I could
imagine that the labor market might easily
'Neither Pigou nor Keynes invoked Kaldor's notion  that prices can be expected to fall faster than wages in  a recession with the resulting rise in real wages provid-
ing the force for recovery from the demand side,
through a distributional shift toward wage incomes
which generate more spending per dollar than other
incomes do.


### ---Economics-1980-0-07.txt---
learn to adjust smoothly to fluctuations in
aggregate demand. I could even imagine
that workers might accept the necessary 4
percent reduction in nominal wages, in the
expectation that half of it would be offset by
lower prices. The trouble is that Pigou's
demand elasticities are way too high. A re-
cent econometric study by Kim Clark and
Richard Freeman, based on quarterly data
for U.S. manufacturing. 1950-76, puts the
real-wage elasticity of demand for labor at
about one-half, a whole order of magnitude
smaller than Pigou's guess.2 And the Clark-
Freeman work is presented as revisionist, a
counterweight to other estimates that are
typically lower, averaging out at about 0.15
according to a survey by Daniel Hamer-
mesh. To my mind, smooth wage adjust-
ment seems intrinsically unlikely in a world
with such a small demand elasticity and
institutions like those sketched earlier.
Nothing I read in the newspapers suggests
to me that 6 percent of nonfrictional unem-
ployment produces a threat adequate to set
off a quick 12-15 percent fall in the real
wage, or a drop in nominal wage rates twice
as large. Sellers facing inelastic demands
usually try to discourage price cutting; why
should workers be different?
The modern classical school seems curi-
ously remote from all this. When they try to
explain how the equilibrium volume of em-
ployment can fluctuate as widely as actual
employment does in business cycles, their
only substitute for Pigou's high elasticity of
demand is a high elasticity of supply (of
labor) in the face of a perceived temporary
opportunity for unusual gains, which in this
case reflects wages that differ from average
expected (discounted) future wages. In other
words, People who give the vague impres-
sion of being unemployed are actually en-
gaged in voluntary leisure. They are taking
it now, planning to substitute extra work
later, because they think, rightly or wrongly,
that current real wages are unusually low
compared with the present value of what the
labor market will offer in the future. They
may be responding to changes in real wages
or to changes in the real interest rate.
It is astonishing that believers have made
essentially no effort to verify this central
hypothesis. I know of no convincing evi-
dence in its favor,3 and I am not sure why it
has any claim to be taken seriously. It is
hardly plausible on its face. Even if the
workers in question have misread the future,
they are merely mistaken, not confused or
mystified about their own motives. It is thus
legitimate to wonder why the unemployed
do not feel themselves to be engaged in
voluntary intertemporal substitution, and
why they queue up in such numbers when
legitimate jobs of their usual kind are
offered during a recession.4
When they face the market-clearing issue
at all, Pigou's successors take a rather ab-
stract line. They regard it as inherently in-
credible that unexploited opportunities for
beneficial trade should be anything but
ephemeral-which means merely that they
ignore all those human and institutional
facts of which Pigou was aware. Or else they
argue that one cannot believe in the failure
of markets to clear without having an
acceptable theory to explain why that
happens. That is a remarkable precept when
you think about it. I remember reading once
that it is still not understood how the giraffe
manages to pump an adequate blood supply
all the way up to its head; but it is hard to
imagine that anyone would therefore con-
clude that giraffes do not have long necks.
At least not anyone who had ever been to a
zoo. Besides, I think perfectly acceptable



### ---Economics-1980-0-08.txt---
theories can indeed by constructed, as soon
as one gets away from foolishly restrictive
and inappropriate assumptions.
II
That brings me to the second and last
general point I had hoped to make. Suppose
one chooses to accept the apparent evidence
of one's senses and takes it for granted that
the wage does not move flexibly to clear the
labor market. By the way, my own inclina-
tion is to go further and claim that commod-
ity prices are sticky too, at least downward.
But it is the persistence of disequilibrium in
the labor market that I want to emphasize.
How can we account for it?
There is, as I mentioned at the beginning,
a whole catalog of possible models of the
labor market that will produce the right
qualitative properties. Since I have surveyed
this literature elsewhere, I will just list a
half-dozen possibilities now, with the re-
minder that they are not mutually exclusive
alternatives.
(1) There is Keynes's idea that case-
by-case resistance to wage reductions is the
only way that workers can defend tradi-
tional wage differentials in a decentralized
labor market. The net result is to preserve
the general wage level or its trend, but that
is an unintended artifact.
(2) There is a complementary hypothe-
sis about the behavior of employers that I
have proposed myself: if employers know
that aggressive wage cutting in a buyer's
market may antagonize the remaining work
force, hurt current productivity, and make it
harder to recruit high-quality workers when
the labor market tightens, they will be less
inclined to push their short-run advantage.
(3) Pigou realized that widely held no-
tions of fairness, enforced by social pressure
or by legislation, might have to be part of
any serious account of wage determination.
George Akerlof has pursued this trail fur-
ther, documented the prescription of codes
of good behavior in manuals of personnel
practice, and showed formally that such
codes of behavior can be self-enforcing if
people value their reputations in the com-
munity. Obviously there are no Emily Post
manuals to consult as regards the behavior  of laid-off workers, but you would certainly
not be astonished to learn that self-esteem
and the folkways discourage laid-off work-
ers from undercutting the wages of their
still-employed colleagues in an effort to dis-
place them from jobs. Reservation wages
presumably fall as the duration of unem-
ployment lengthens; but my casual reading
suggests that this pattern shows up more in
a willingness to accept lower-paid sorts of
jobs than in "thorough-going competition"
for the standard job. The cost to the worker
of this sort of behavior is diminished by the
availability of unemployment insurance. It
is worth remembering that the acceptance of
lower-grade jobs is itself a form of unem-
ployment.
(4) I need only touch on the Azariadis-
Baily-Gordon implicit-contract theory, be-
cause it has been much discussed in the
literature. Here wage stability is a vehicle by
which less-risk-averse firms provide income
insurance for more-risk-averse workers, pre-
sumably in exchange for a lower average
wage.5 It is now understood that the theory
works well only when workers have some
source of income other than wages, unem-
ployment compensation for instance. This is
not really a disadvantage in a world with
well-developed unemployment insurance
systems. In any case such implicit contracts
do not themselves account for unemploy-
ment. Their effect is to reduce the average
amount of unemployment below the level
that would occur in a simple spot market.
The theory belongs in my list because I
suspect it does help to account for the habit
of wage inertia and therefore the vulnerabil-
ity of employment to unexpected fluctua-
tions in aggregate demand.
(5) Wherever there is collective bargain-
ing in our economy, the standard pattern,


### ---Economics-1980-0-09.txt---
with few exceptions, is that wage rates are
specified in the contract, and the employer
chooses the amount of employment. This is
not exactly simple monopoly, because the
union cannot set the wage schedule unilater-
ally. To the extent that it can, another
source of wage stickiness can be identified.
Under a reasonable assumption about what
the union maximizes, it turns out that the
only aspect of the demand for labor that has
any effect on the monopoly wage is its elas-
ticity. So if the demand curve for labor
shifts down nearly isoelastically in a reces-
sion, the contractual wage will change little
or not at all, and the full effect of the fall in
demand will bear on employment. The
amount of unemployment compensation
available plays a role here too. (There is
much more to be said along these lines,
and Ian McDonald of the University of
Melbourne and I hope to say it on another
occasion.)
(6) As a last example, I recall Pigou's
observation that wage changes may be
seen by the parties as hard to reverse with-
out a struggle whose duration and outcome
cannot be foreseen. The resulting uncer-
tainty causes employers to drag their feet
when demand increases temporarily and
workers to reciprocate when demand falls.
The result is wage stickiness in the face of
fluctuating employment.
Only what Veblen called trained incapac-
ity could prevent anyone from seeing that
some or all of these mechanisms do indeed
capture real aspects of the modern capitalist
economy. Assessing their combined signifi-
cance quantitatively would be a very dif-
ficult task, and I do not pretend to be able
to do that. We are all interpreting this ink
blot together. Obviously I would not be
giving this particular talk if I did not think
that wage stickiness is a first-order factor in
a reasonable theory of unemployment.
To make my position plausible, I want to
try to summarize the sort of general char-
acteristics that the labor market should have
if the particular mechanisms that I have
enumerated are to be important. By the
way, I have no reason to believe that my list
is anything like exhaustive; you may think
of others. Simply to narrow the field, I have
deliberately left out of account factors relat-
ing specifically to age, sex, race, and other
characteristics that normally form the basis
for discussions of structural unemployment
as distinct from cyclical unemployment.
The sort of labor market I have in mind is
segmented. It often makes sense to think of
an employer or definable group of em-
ployers as facing its own labor pool. Some
members of the labor pool may be unem-
ployed, but still belong to it. Although
transportation, information, and transaction
costs are possible sources of segmentation,
they need not be among the most important.
The buildup of firm-specific or industry-
specific human capital may be more funda-
mental, and equally a kind of mutual know-
ing-what-to-expect that gives both parties in
the labor market a stake, a rent, in the
durability of the relationship. This point is
close to the distinction between auction
markets and customer markets made by
Arthur Okun in a different context. The
labor market, at least the "primary" labor
market, is a customer market; this may be
one of the important facts that differentiates
the primary from the secondary labor
market.
A second general characteristic is the
availability of some nontrivial source of
nonemployment income. The obvious one is
unemployment compensation, but I imagine
that fringe activity ranging from hustling to
home maintenance can function in much
the same way. I suppose in some societies
the possibility of returning temporarily to
farming is now as important as it once was
here. The presence of a second earner in the
family can make an obvious difference. One
consequence is that it becomes easier to
maintain a labor pool in the presence of
fluctuating employment. In addition, as I
mentioned a few moments ago, several of
the specific sticky-wage mechanisms in my
catalog depend for their operation on this
characteristic.
Third, the stability of the labor pool
makes it possible for social conventions to
assume some importance. There is a dif-
ference between a long-term relationship
and a one-night stand, and acceptable be-
havior in one context may be unacceptable
in the other. Presumably most conventions
are adaptive, not arbitrary, but adaptiveness


### ---Economics-1980-0-10.txt---
may have to be interpreted broadly, so as to
include pecuniary advantage but not be
limited by it. Critics who deride the notion
of "economic man" have a point, but usu-
ally the wrong point. Economic man is a
social, not a psychological, category. There
are activities in our culture in which it is
socially acceptable and expected that indi-
vidual pecuniary self-interest will be the
overriding decision criterion: choosing a
portfolio of securities, for example.6 There
are others in which it is not: choosing a
mate, for example.7 The labor market is
more complicated than either, of course,
and contains elements of both. Perhaps in
nineteenth-century Manchester labor was
bought and sold by "thorough-going compe-
tition" but I think that is unlikely to be a
good approximation to contemporary wage
setting. In particular, as I have emphasized,
there is nothing in the data or in common
observation to make you believe that mod-
erate excess supply will evoke aggressive
wage cutting on either side of the labor
market.
In
I draw two conclusions from this whole
train of thought, one about economics and
the other about the economy.
About economics: it -need not follow
that we old dogs have to learn a lot of new
tricks. It still seems reasonable to presume
that agents do the best they can, subject to
whatever constraints they perceive. But in
some contexts the traditional formulations
of the objective function and constraints
may be inappropriate. In the labor market,
the participants are firms and groups of
firms on one side, and individual workers,
organized trade unions, and informally
organized labor pools on the other. Grant
me that all feel constrained, to some nontriv-
ial degree, by social customs that have to
do with the wage and wage-setting proce-
dures. The result is that factor prices turn
up in our equations in unfamiliar ways. Let
me just mention a few examples from my
earlier list of hypotheses. If Keynes was
right about the conventional significance of
relative wages, then ratios of wage rates
appear in the objective functions on the
labor side. If the current or future perfor-
mance of workers depends on their feelings
that wage levels are fair, then wage rates
appear in the production functions con-
straining firms. If the individual worker's
utility function depends quite convention-
ally on current income, then the collective
objective function of a labor pool of identi-
cal workers might reasonably be a weighted
average of the utility of the wage and the
utility achievable when unemployed, with
weights equal to the employment and unem-
ployment fractions. This objective function
contains both wage and volume of employ-
ment as arguments; and it has the inter-
esting property that the marginal rate of
substitution between wage rate and employ-
ment can depend very sensitively on the size
of the unemployment insurance benefit.
Constrained maximization and partial or
complete reconciliation in the market can
still be the bread and butter of the macro
theorist. Spread with more palatable be-
havior assumptions, they may make a tastier
sandwich, and stick to the ribs.
About the economy: if the labor mar-
ket is often not in equilibrium, if wages are
often sticky, if they respond to nontradi-
tional signals, then there is a role for macro
policy and a good chance that it will be
effective. Equilibrium theories that conclude
the opposite may conceivably turn out to
have the right answer, but they simply
assume what they purport to prove. It is not
my argument that standard textbook policy
prescriptions are bound to be right. That
has to be worked out case by case. All I do
claim is that a reasonable theory of eco-
nomic policy ought to be based on a reason-
able theory of economic life.

## Economics-1981-0


### ---Economics-1981-0-01.txt---
The early debates over the role of govern-
ment in economic life, at least during the
era of industrialization, took the form of a
contest between laissez-faire and thorough-
going socialism. In Western Europe and
North America, however, the movement
away from individualism followed a much
less radical course, which John Maynard
Keynes was one of the first to define. His
famous lectures in the mid-1920's on The
End of Laissez-Faire carried the following
passage:
... a time may be coming when we
shall get clearer than we are at pres-
ent as to when we are talking about
Capitalism as an efficient or inefficient
technique, and when we are talking
about it as desirable or objection-
able in itself. For my part, I think that
Capitalism, wisely managed, can prob-
ably be made more efficient for at-
taining economic ends than any alter-
native yet in sight, but that in itself it
is in many ways extremely objection-
able. Our problem is to work out a
social organization which shall be as
efficient as possible without offending
our notions of a satisfactory way of
life. [p. 53, emphasis added]
Keynes, as we can now see, was among
the first writers to form a definite vision of
the kind of system under which we have
come to live during the last half century, the
system we now call the Mixed Economy or
Welfare Capitalism or the Middle Way. Like
the much more individualistic, much less
guided, system that preceded it, the Mixed
Economy developed with the support of a
broad consensus of opinion. That con-
sensus, however, has now weakened. The
economic role of government is again the
subject of debate, attack, and resistance far
more intense than we have known for de-
cades. The attack ranges over a wide spec-
trum. It questions the scope of government,
the particular measures and policies through
which government exercises its functions,
and the political institutions which shape
the measures and policies employed. A few
voices call on us to move on to a more en-
compassing socialism, including the owner-
ship of industry. Many more call for a dras-
tic revival of market rule.
We all, I think, sense that we have come
to a very difficult juncture in the develop-
ment of our Mixed Economy. How we shall
emerge is still in dim prospect. As in other
illnesses, social crises often are surmounted
and are followed by periods of renewed
stable development. But sometimes not. We,
therefore, ought to think where we are and
what the nature of our troubles is.
I
There is no single, simple way to gather
together all the threads of our present dis-
content, and I shall not try. One useful
opening, however, is to consider the pro-
nounced and worrisome retardation of pro-
ductivity growth from which we now suffer.
Productivity growth, I need hardly say, is
the main source of measured per capita
output growth. And per capita output, in
turn, is a central component of economic
welfare as we economists conceive it, many
would say the central component. It is ele-
mentary, however, that per capita output
growth and welfare growth are not the same
thing. National product is not even an ade-
quate long-term measure of net output rele-
vant to welfare. It makes inadequate al-


### ---Economics-1981-0-04.txt---
lowance for the quality and variety of goods.
It excludes the household and treats all
government expenditure as final product. It
neglects the externalities of production and
consumption and the costs of growth proper,
for example, the dislocation of people. It
makes dubious assumptions about people's
ability to appraise and guard against the
dangers carried by jobs and products. And
there is much more to economic welfare
than can be captured in any long-term mea-
sure of output: job stability; income secur-
ity, a fair distribution of opportunities and
rewards.
The economic role of government ex-
panded during the last half century and
more in large part in order to pursue the
social objectives that are not comprehended
in measured net national product. The result
is the mixed economy or welfare state in
which we now live and which is now the
object of attack.
Productivity growth is a useful focus of
discussion in relation to the current discon-
tents and the accompanying reappraisal of
our mixed economy for a combination of
two reasons.
To begin with, productivity, viewed as a
source of private earnings, exists in a state
of uneasy tension with the other welfare
objectives, which we pursue largely through
the government. The causes of the tension
need to be underscored.
First-an obvious point-the more in-
come that is diverted to social uses, the less
of any given aggregate remains under the
private control of income earners for their
own personal use.
Next, the size of the diversion and the
way it is made and used affects the level of
output and productivity, present and future.
That is partly because a host of government
activities are supportive of current output
and productivity, and many activities, in-
cluding some, like education, that are un-
dertaken for generalized social objectives,
are in the nature of capital formation.' In a
still more basic sense, moreover, and one
much neglected in current debates, the pace
of growth in a country depends not only on
its access to new technology, but on its
ability to make and absorb the social adjust-
ments required to exploit new products and
processes. Simply to recall the familiar, the
process includes the displacement and redis-
tribution of populations among regions and
from farm to city. It demands the abandon-
ment of old industries and occupations, and
the qualification of workers for new, more
skilled occupations. The extension of educa-
tion, with all its implications for shifts in
social status, in aspiration, and in political
power, is a requisite. Along the technologi-
cal path which we have followed, growth
also demands very large-scale enterprise
which establishes new types of market power
and alters the relations of workers and em-
ployers. Viewed from another angle, the de-
pendent employment status of workers and
the mobility of industry and people imply a
great change in the structure of families and
in their roles in caring for children, the sick,
and the old. Because the required adapta-
tions can and do alter the positions, pros-
pects, and power of established groups,
conflict and resistance are intrinsic to the
growth process. To resolve such conflict and
resistance in a way which preserves a large
consensus for growth, yet does not impose a
cost which retards growth unduly, a mecha-
nism of conflict resolution is needed. The
national sovereign state necessarily becomes
the arbiter of group conflict and the mitiga-
tor of those negative effects of economic
change which would otherwise induce resis-
tance to growth.2
The enlargement of the government's eco-
nomic role, including its support of income
minima, health care, social insurance, and
the other elements of the welfare state, was,
therefore-at least up to a point-not just a
question of compassionate regard for the
unfortunate, and not just a question of re-
ducing inequalities of outcome and oppor-
tunity, though that is how people usually
think of it. It was, and is-up to a point-a



### ---Economics-1981-0-05.txt---
part of the productivity growth process it-
self.
And yet, manifestly, there is another side
to the story, the side that is so much to the
fore today. The government's roles as referee
and as mitigator of the costs of growth- as
well as instrument for pursuing welfare goals
supplementary to measured productivity-
must be paid for. But it is essentially impos-
sible to design a tax system that places no
marginal burden on the rewards for produc-
tive effort, or a regulatory system that has
no cost in measured output. Similarly, we
can hardly design a transfer system which-
up to a point-necessarily divorces income
from work, but which yet does not qualify
economic incentives. There is a presump-
tion, therefore, that the tax-transfer-regula-
tory system, whatever its essential, long-
term, indirect, supportive role, operates more
immediately and directly to constrict work,
saving, investment, and mobility-just how
much is, of course, a question.
There is, therefore, an uneasy many-
faceted tension between measured produc-
tivity growth and the private earnings it
generates on the one side, and the pursuit of
other welfare goals through government on
the other side. The tension implies a dif-
ficult and delicate problem of choice and
balance. A balance-certainly a wide ac-
ceptance of the pace and nature of our joint
pursuit of different welfare goals- seemed
to exist during the first two postwar decades
when productivity growth was relatively
rapid. That balance, if it was a balance,
has, however, now been upset by the pro-
tracted retardation of productivity growth
during the last dozen or more years. That is
the second reason why productivity growth
is a useful focuis for examining the current
dissatisfaction with our mixed economy.
I shall deal briefly with three matters:
1) What were the developments which
were antecedent to (which stand in the
background of) our present troubles and its
accompanying discontent?
2) What can we now say about the
causes of the current productivity retarda-
tion? In particular, to what extent is the
retardation connected with the enlarged role
of government and its pursuit of alternative
social goals?
3) What is the outlook for productivity
growth, and what are the implications of
that outlook for the further development of
our mixed economic system?
II
In the early part of the postwar period,
economic growth, in the aggregate and per
capita, established itself as a premier goal of
economic policy-co-equal with "full" em-
ployment, perhaps of even higher priority.
Besides the standard reason, that per capita
growth raises average levels of consumption,
there were special reasons. Growth was seen
as the best way to overcome poverty without
the social conflicts accompanying redistri-
bution. It would create a favorable environ-
ment in which to open opportunities for
blacks and other minorities. It would pro-
vide the resources for meeting still other
social goals, for example, extended educa-
tion and health care. Growth was also sought
to maintain defense, to compete politically
with a fast-growing Soviet Union and to
assert continued leadership in our rapidly
progressing alliance. Growth would enable
us to help not only the poor in our own
country, it would permit us to help the still
more impoverished people of the less-
developed world. Productivity growth was a
goal distinguishable from full employment,
but it was also seen-not necessarily cor-
rectly- as a condition of full employment.
Unless we could hold our own in interna-
tional trade, our foreign accounts would im-
pose demand restraints on policy and make
for chronic underemployment.
This growth, so ardently desired, was in
fact achieved. For two decades, income per
capita grew faster than ever before and out-
put per hour much faster. At the same time,
there was a rapid development of govern-
ment in pursuit of other welfare objectives,
and this was also eagerly sought. The Social
Security system established in the 1930's
was enlarged; education was rapidly ex-
tended; science was fostered; there were
large programs for hospital building and
housing. The proportion of the population
living below defined poverty levels was


### ---Economics-1981-0-06.txt---
reduced- the joint result of rising average
incomes, and extended insurance and wel-
fare provision. Partly because government
was bigger, partly because the scope of pro-
gressive taxation was wider, partly because
of old age and unemployment insurance and
other forms of income maintenance, we
enjoyed the benefits of a system of "built-in
stabilizers." Recessions were milder and
growth more steady than they had ever been
before in American experience as an
industrialized country.
The main point, however, is that in this
period, productivity growth paid easily for
the pursuit of other welfare goals. Although
government grew faster than GNP, fast
growth of productivity supported fast growth
of per capita disposable income, of real
spendable earnings of workers, and of aver-
age family incomes.3 Productivity growth
was, therefore, the substantial basis on which
the consensus of opinion supporting the
development of the mixed economy rested.
III
Frank Knight liked to say that progress is
not a question of happiness; it is a question
of what people are unhappy about. Not
surprisingly, therefore, the progress of the
first two postwar decades was followed by a
certain recoil from growth-a reordering, if
not reversal, of priorities. This took several
forms:
1) Whereas in the 1950's, measured growth
was regarded as the main instrument for
overcoming poverty, as the 1960's wore on
the view took hold, with much justification,
that future growth alone could not deal ade-
quately with the poverty which past growth
had left behind. Although technical prog-
ress, capital accumulation, and general edu-
cation would continue to be important in
the future, an increasing proportion of the
"residual poor" had special handicaps. They
had to be helped directly, principally by a
fight against discrimination, by special edu-
cation and training programs, and by new
and expanded schemes for social insurance,
income support, health care programs, and
other transfers in kind. The impulse to fight
poverty directly was fed by new information
about the size and composition of the re-
maining poor population, by the indignation
of social reformers and, most of all, by
rising racial tensions.4 "We cannot," said
the Council of Economic Advisors, "leave
the further wearing away of poverty solely
to the general progress of the economy"
(1964, p. 60).5
2) As individual income levels rose, peo-
ple generally became more sensitive to their
immediate surroundings. They found hos-
pital and educational facilities inadequate
and the urban physical plant shabby. Yet
the demand for improvement had to be met
in difficult circumstances which continue to
plague and torment local government to this
day. The relative price of public, like that of
private, services was rising. Higher incomes
and automobiles were transporting up-
wardly mobile families to the suburbs, car-
rying their tax base with them. The cities,
increasingly abandoned to the poor, unable
to tap the suburban affluence about them,
could barely cope. Congestion on the high-
ways and streets, noise, air and water pollu-
tion, all fed by growth itself, swelled, moved
to the countryside and everywhere became
more objectionable to otherwise more af-
fluent people.
3) People discovered the terrors of tech-
nology-products, working conditions, and
environmental changes that carried risks.
The dangers feared were often invisible, they
operated at a distance and cumulated over
time, carrying both real and imaginary
threats to health and life now and in genera-
tions to come. Technological progress, which
for decades had been seen as the process by
which problems and dangers might be over-
come, was now increasingly feared as a
major source of our troubles.
These shifts in outlook had two important
practical consequences. One was the very


### ---Economics-1981-0-07.txt---
rapid expansion of government social wel-
fare and civil rights programs which began
in the mid-1960's and which developed and
matured in the 1970's. Expenditures for "so-
cial welfare," which were 9 percent of GNP
in 1950 and only 10 percent in 1960, rose to
15 percent in 1970 and to 20 percent in
1977.6 The other was "explosion" of public
regulatory legislation and administration di-
rected to the protection of the environment,
and to the safety of workers and consumers.7
The new legislation became the basis for
strong, privately organized campaigns to
limit growth and the application of new
technology.
IV
The maturing of the Great Society pro-
grams in the spheres of welfare and civil
rights, and the implementation and expan-
sion of the social regulatory laws, brought
our mixed economy to a new stage of devel-
opment. There was a new distribution of
emphasis among the different dimensions of
economic welfare, and correspondingly a
new distribution of economic power be-
tween the private and public spheres. The
new development of the mixed economy,
however, is now confronted by a changed
and less-favorable growth environment.
Looking back, we can now see that a
slower rate of productivity growth accompa-
nied the institution and the maturing of the
Great Society programs. To what extent the
two developments were associated as effect
and cause, however, is still an open ques-
tion. So is a related matter; that is, the
responsibility of transient as distinct from
durable factors for bringing about the
slowdown we observe. It would be wrong to
pretend that there are now definite answers
to these questions. The factual position,
however, deserves description because it
bears on the origins of our present discon-
tents.
Beginning in the late 1960's, private-sector
productivity growth fell back from the high
speed it had reached in the years preceding.
The retardation before 1973 was moderate.
The new pace approximated that during the
somewhat slack later 1950's. After 1973,
however, the slowdown became much more
serious. The upshot is that average produc-
tivity growth for the fourteen years between
1965 and 1979 ran at only one-half the pace
of the years from 1948 to 1965; since 1973,
it has risen at less than one-fifth that earlier
pace.8 The extent of the slowdown between
the two rough halves of the postwar period,
before and after 1965-to say nothing of
the post-1973 period by itself-may be
judged from the fact that the post-1965 pro-
ductivity slowdown has been more severe
than any of the retardations measured across
major depressions going back to the 1890's.
That includes the retardation from the 1920's
to the 1930's.9 Yet, up to 1979 we had had
no major depression.
In my judgment, the productivity retarda-
tion, at least since 1973, has been accompa-
nied by a slower rate of improvement in
material conditions of well-being. In some
respects, and by some measures, there have
even been significant declines. It is true that,
because the labor force was rising rapidly in
relation to population, the growth rate of
real disposable income per capita was well
maintained-at least if we depend on the
deflator for "personal consumption expendi-
tures"; not if we use the CPI. As perceived
by many people, however, the welfare sig-
6See U.S. Social Secuxity Administration. Social
welfare expenditures cover social insurance, public
assistance, health and medical care, veterans' programs,
education, housing and "other." At present, exhaustive
expenditures accdunt for nearly half and transfer
programs for somewhat more than half of total wel-
fare expenditures. (See Sheldon Danziger, Robert
Haveman, and Robert Plotnick, pp. 6-8.) The major
reasons for the accelerated growth since 1965 appear to
lie in the initiation and expansion of new programs,
such as Medicare, and in the generous increase of
benefit schedules in old programs like Social Security
(see Plotnick, pp. 277-78).
7The Federal Register, which records new regula-
tions, contained 10,000 pages in 1953, but 65,000 pages
in 1977. The federal budget to administer regulatory
activities was $5 billion in 1978, having doubled since
1974. Compare Arthur Bums, p. 4.  8I depend for these comparisons on the easily acces-
sible Bureau of Labor Statistics figures for "output per
hour of all persons" in the private business sector. See
Economic Report of the President (1980, Table B-37).


### ---Economics-1981-0-08.txt---
nificance of even the more favorable mea-
sure is qualified. That is partly because the
demographic changes that supported labor-
force growth also made for a faster increase
of households than of population, so to some
degree expenses per head increased with in-
come per head.' It is qualified also to the
extent that women felt forced to take paid
work to offset the slower rise or actual de-
cline of their husbands' real earnings; to the
extent that the proportion of persons living
in pretransfer poverty has been tending to
rise since 1968; to the extent that transfer
incomes became a more important part of
aggregate disposable income- to the disad-
vantage of income earners; and to the ex-
tent that the rise of noncash compensation
reduced worker's discretionary take-home
pay. The upshot is that in recent years, the
average real cash incomes of workers have,
depending on the measure, almost ceased to
rise or begun to fall. The same is true of the
average real total income of families, sup-
ported as that has been by transfer incomes
and by the entry of second workers. The
presumption is that the real earned income
of representative single worker families, still
more their cash income, has definitely
declined."
The slowdowns in the growth rates of
productivity, annual wages, and household
incomes are, moreover, not the only disturb-
ing elements in our economic situation. They
are accompanied by rapid and volatile infla-
tion which redistributes income and wealth
in arbitrary and confusing ways. Taken to-
gether, these developments have disap-
pointed peoples' expectations; they have
robbed many people of the fruits of earlier
work and saving, and made almost everyone
unsure or fearful about their future.
These developments stand in the back-
ground of the current discontent with the
operation of our mixed economy. They have
led to a blacklash against the earlier recoil
from productivity growth. This blacklash-
perhaps justifiably, perhaps not-raises
sharply the issue of maintaining a steady
balance between the productivity growth
that supports the rise of earned incomes and
the pursuit of other vitally important social
goals.
V
Our attitudes towards that issue would be
clearer if we could know to what extent the
current productivity retardation is actually
due to the workings of our mixed economy
or to its past and current attempts to raise
social welfare through government actions.
Many believe that the welfare and regula-
tory programs are heavily implicated both
in direct ways and because of their arguably
plausible connection with the onset and per-
sistence of an erratic and accelerating infla-
tion. There is a concomitant fear that the
welfare and regulatory programs may be a
serious drag on future productivity growth.
Opposition to these programs, is, therefore,
rising. True, if future productivity growth is
slow for whatever reasons, people will be
less willing than they might otherwise be to
bear the cost of pursuing alternative welfare
goals. But if that pursuit were actually a
significant cause of slower growth, the reluc-
tance would be still stronger, as it then
should be.
The causes of the current retardation,
however, remain cloudy. A portion of the
slowdown is, by general agreement, due to a
virtual cessation of the shift of workers from
small-scale inefficient farming and from
self-employment in petty trade to higher
productivity occupations in larger- scale
urban enterprise. A portion too is assignable
to the massive entry of workers-youth and
women-since the mid-1960's. Finally, a
small part of the retardation is attributable
to the diversion of resources to comply with
environmental regulation and safety re-
quirements in ways that do not register in
measured output, though, of course, they


### ---Economics-1981-0-09.txt---
should. Serious students, however, offer
widely different estimates of the contribu-
tions of other factors: the quality of school-
ing, conventional capital services, R&D, and
the influence of cyclical or other forces af-
fecting intensity of resource use. The impact
of higher energy prices on the substitution
of labor for capital in the operation of exist-
ing energy-using equipment and on the
post-1973 slowdown of capital deepening is
equally unclear, though possibly very im-
portant. Most analyses leave a substantial
part of the retardation unconnected with
any identified and measured contributory
source, and they disagree about the time-
whether after 1973 or as early as the latter
1960's-when that unspecified residual re-
tardation made its appearance.'2
In this state of factual uncertainty, it is
not hard to propose estimates of the sources
of retardation which assign substantial re-
sponsibility to factors connected with the
government's welfare and regulatory activi-
ties. We, therefore, find William Fellner ask-
ing: "...whether, directly or indirectly [the
analyses of the retardation] do not suggest
that the weakening of the productivity trend
is attributable in part to changes in the
socio-political environment that are of re-
cent origin or that have cumulated to a
'critical mass"' (p. 4).
The suggested mode of operation of these
factors is, first, through a decline in the rate
of capital deepening; second, through a de-
cline of worker effort symptomized by ab-
senteeism and by a drop in hours worked
relative to hours paid; third, by a disinclina-
tion for risky, innovatory effort, whose
manifestation is the observed slowdown in
the residual measures of total factor produc-
tivity growth; and fourth, through the diver-
sion of resources to regulatory compliance,
the benefits of which do not register in
measured output even when they should.
These sources of retardation whether great
or small-the "suspects," as Fellner calls
them-are arguably associated with char-
acteristic features of our mixed economy,
even if they are not exclusively due to them.
The first of those features is the widening
difference between before- and after-tax
marginal rates of return to work, saving,
investment, and risk taking. The magnitude
of the rise in these rates is indicated by the
overall increase of total government ex-
penditures from 20 percent of GNP in
1947-49 to 28 percent in 1963-65 and again
to over 32 percent in 1977-79.13 The incen-
tive effects of the tax increases are still im-
perfectly understood, but there is little
reason to suppose they are not distinctly
unfavorable.'4 Allied to the effects of rising
tax burdens is the possible effect of the
cumulating "social security wealth" of indi-
viduals on savings and that of other in-
surance and income-support programs on
work.'5 Next, there are the effects of bur-
geoning regulatory activity. These go be-
yond the direct resource costs of compliance
already mentioned. There are also indirect
costs and risks of obtaining administrative
and judicial clearance for new projects, the
diversion of R&D expenditure to meet en-
vironmental and safety standards, and the
hazards of possible future changes in regula-
tory requirements. Finally, there are the
manifold effects of erratic and accelerating
inflation.



### ---Economics-1981-0-10.txt---
Inflation belongs in this litany because
our pursuit of alternative welfare goals has
thus far also involved a tolerance, indeed a
pressure, for chronic budgetary deficits, and
an understandable political incapacity to
employ monetary and fiscal restraint force-
fully and consistently at the risk of elevated
unemployment. Inflation, in conjunction
with tax rules and accounting practices de-
signed for a stable price regime, has meant
very high marginal taxes on returns to
capital. In the judgement of some public
finance experts, it has also meant a differen-
tial burden on business investment com-
pared with that on household borrowing,
spending, and investing.'6 If there are fears
of accelerated inflation in the future, they
carry the prospect of still higher taxes and
lower returns while the erratic nature of
rapid inflation makes the future more dif-
ficult to discern and increases the sense of
risk. And if the same fears give rise to a
vision of price controls, the risks of invest-
ment and innovation are compounded. In
any event, inflation compels- or threatens
to compel-governments to reduce capacity
utilization below its potential. Therefore
inflation acts to diminish one of the induce-
ments to invest, as the 1980 business con-
traction following on financial disorder il-
lustrates. We should remember, moreover,
that there is an element of vicious circularity
in this aspect of our present conjecture. In-
flation has deleterious effects on productiv-
ity growth-and unexpected declines in
productivity growth exacerbate inflation.
This range of considerations leads some
students to the view that the pursuit of
alternative welfare goals accounts for a very
considerable part of the retardation. Fellner,
whom I mentioned before, suggests that "the
causes of at least 1 percentage point annual
slackening of the trend in output per
worker's hour can be found among the 'sus-
pects"' (p. 10). That loss is equal to one-half
the observed difference between the private-
sector productivity growth since 1973 and
that during the quarter century between 1948
and 1973.
Such numbers and the argument that leads
to them should be understood to be no more
than what they are-a prima facie indica-
tion that something very substantial may be
involved in the choices we make between
productivity growth and alternative welfare
goals. I would not mention them if I did not
fear that there is much to the problem, if
not as a cause of the recent abrupt retarda-
tion, then as a longer-term secular con-
straint. Yet, at the present time the argu-
ment is only speculative, and the estimated
loss still more so. The theoretical and
quantitative issues are unsettled and deserve
our most urgent attention.'7  


### ---Economics-1981-0-11.txt---
VI
So much for the past. We must now try to
look ahead. What general view of the future
is it sensible to entertain? And what are its
implications?
Since our understanding of the productiv-
ity retardation of the last dozen years is so
clouded, conjecture about the future must
be still more fuzzy. True, the negative im-
pact of the recent big influx of inexperi-
enced young workers is due to be reversed.
In looking ahead, however, more basic ques-
tions need to be addressed. No one, indeed,
ought to doubt the persistence of some
substantial continuity in what Solomon
Fabricant has identified as
the basic factors underlying economic
growth in the United States: the tastes
and preferences of the American peo-
ple, the economic opportunities and
alternatives open to them, the social
framework within which they live and
work together, and the relations of the
United States with the rest of the
world. Different assumptions would be
contrary to all experience and could
only lead to wild speculation. [So he
concludes] The trend of national out-
put per worker-hour will ... continue to
be upward. [p. 1]
I agree; but, as Fabricant also asks, how
fast will the trend line rise? A "substantial
degree of continuity" is not the same as
ironclad fixity, and much of this talk has
already pointed to some change in
Fabricant's basic factors. Within the coun-
try, preferences and goals have changed in
the degree to which concern for income
security, equality of opportunity, environ-
mental protection, and consumer and worker
safety sways votes and, to some degree, per-
sonal behavior. Corresponding to these shifts
in tastes and concerns, the "social frame-
work within which we live and work to-
gether" has been recast. The government
has come to play a larger role in shaping the
"economic opportunities and alternatives"
open to us-while imposing burdens on our
growth potential whose weight we can now
suspect but cannot yet clearly assess. Partly
because of higher incomes, partly because
of changes in industrial and labor market
organization, and partly because of govern-
ment regulation and income support, there
has been a decline in market flexibility-in
the responsiveness of prices and wages to
the balance of supply and demand, and
of people's own responsiveness to price
changes-the implications of which Tibor
Scitovsky sketched last year.
Our relations with the rest of the world
have also changed in ways which I believe
are dominantly, but not entirely, unfavor-
able to U.S. growth prospects. The eco-
nomic rise of Europe and Japan has, indeed,
brought those countries to the technological


### ---Economics-1981-0-12.txt---
frontier in many fields. On that account, the
effort and experience on which world tech-
nological advance rests now has a wider
base. The United States, therefore, should
now begin to profit more from other coun-
tries' technical effort even as other countries
borrow from us. It remains to be seen, of
course, whether we shall prove as successful
at borrowing and adapting foreign technol-
ogy as some other countries have been.
The advance of other countries, however,
also has a darker side for us. The develop-
ment of many industries in which this coun-
try has long been a leader is now threatened
by the competition of other countries. This
changes the prospects for U.S. productivity
growth to our disadvantage. It is harder for
an industry to push forward, or even to keep
up with, the technological frontier when its
rate of expansion slows down, still harder
when it is contracting. It is an old story that,
in the course of aggregate productivity
growth, the rise of new, more rapidly pro-
gressing industries constricts the growth of
the old. That is Schumpeter's "creative de-
struction," and it helps explain why retarda-
tion in the growth of output and productiv-
ity is the normal fate of individual industries
within a country, while the growth rate of
the aggregate remains constant or even
speeds up. The reverse, however, is not nec-
essarily true, nor even probably true. We
cannot count on new, more progressive sec-
tors stepping into the breach merely because
the development of our old industries is
constricted by foreign competition. Foreign
success, of course, offers us cheap imports.
Yet the experience of Britain from 1870 to
1913 presents this country with a worrisome
historical question mark. As Britain's basic
industries lost their leadership and markets
to the United States, Germany, and other
countries after 1870, Britain's labor produc-
tivity growth rate was halved compared with
previous decades, and her average total fac-
tor productivity growth during the forty
years after 1870 fell to zero.'8 The question
is: Can we mount a more energetic and
successful response to the challenge of newly
rising foreign competitors after 1970 than
Britain did after 1870?19
The relative decline of U. S. economic and
political power carries with it other disad-
vantages, and not for ourselves alone. The
leadership of the United States in the liber-
alization and stabilization of international
economic relations was one of the bases for
rapid world-wide productivity growth in the
postwar years. We were able to assert that
leadership because superabundant economic
strength permitted us to propose arrange-
ments beneficial to ourselves but generous
to other countries, and because dominant
political power persuaded sometimes re-
calcitrant partners to cooperate. Today, with
U.S. influence reduced and U.S. as well as
European industries under pressure, the
world economy is threatened by a resur-
gence of protectionism, in which this coun-
try is itself taking part. The world-wide price
discipline, which a relatively stable U. S
monetary policy imposed through the dol-
lar-exchange standard, has, for the time
being, been lost. And with U.S. influence
diminished, effective international coopera-
tion in the petroleum market and in other
aspects of relations between industrialized
and developing countries has been beyond
our reach.
In these circumstances, it is just as dif-
ficult to maintain a vision of an unbroken 3



### ---Economics-1981-0-13.txt---
percent trend rate of private-sector produc-
tivity growth as it is to discard a vision of a
trend rate which continues to be signifi-
cantly positive. It should, therefore, be no
surprise that official and other responsible
projections foresee productivity growth rates
that lie above zero, but significantly below
the average postwar rate.20
The uncertainty surrounding any such
forecasts can hardly be overstated. The
progress of science and the enlargement of
the knowledge bases of technology go on
apace. Our problem is to overcome or miti-
gate the forces that are checking our ability
to give our growing knowledge practical ap-
plication and to exploit its benefits fully.
There are both physical and monetary sides
to our present condition which make our
prospects particularly perplexing. On the
physical side is the new energy question.
Quite apart from the policies we pursue-
which may themselves be of crucial impor-
tance- we do not now know on what terms
supplies will be available, even so far as they
depend only on physical and technological
considerations. We are uncertain about the
elasticity of substitution between energy and
other resources, and we do not know how
much technological progress will itself be
impeded as we try to move along a less-
energy-intensive path than we have followed
in the past. The spread of industrialization
from Europe and North America to Asia
and Latin America also raises questions
about the supplies of other primary materi-
als. As for money, so long as we prove
incapable of overcoming our present dis-
position to inflation, we shall not be able to
reach and exploit what would otherwise be
the growth potentials of our economy. But if
we ever do regain a substantial degree of
price stability, we may be happily surprised,
even as the Stagnationists of the 1930's were
astonished by our growth performance in
the postwar period.
VII
In spite of these uncertainties and what-
ever pleasant or gloomy surprises they may
hold, we can hardly avoid the present pre-
sumption that our policy choices in the
calculable future will need to be made in a
less favorable growth environment than that
of the generation just past. Our problem of
choice will be all the more aggravated if, as
now seems likely, the burden of defense
expenditures must increase.
That means, first, that our further pursuit
of social welfare goals will have to be paid
for out of smaller increments of output and
income. So, there will be a more difficult
problem of choice even if our growth rate
itself were not affected by what we choose.
It means, second, that the impact of our
choices on the measured growth rate itself
becomes a more pressing concern and may
go far to determine whether the projections
now entertained are, indeed, ratified by his-
tory or belied. The new, more confined
growth environment means, third, that the
role of government as a contributor to mea-
sured productivity will also be more vitally
important, not merely insofar as the govern-
ment may act to minimize its regulatory or
fiscal impact on private performance, but
also in the support it gives to research, edu-
cation, information, labor mobility, and to
human capital formation generally.
As we think about these questions, we
should not be trapped in the grooves of
popular debate. As already said, the alterna-
tive paths to economic progress do not pre-
sent us with clear-cut choices between
welfare through government production
guidance and income redistribution on the
one side, and welfare through private pro-
ductivity growth on the other. Even if we
cared for little except the private use of
private earnings, we could not ignore the
costs and conflicts arising from the eco-
nomic and social displacements which
accompany growth. We could not, for


### ---Economics-1981-0-14.txt---
example, disregard problems which the
changing structure and role of the family
bring in their train. The state of our cities
with all their problems of poverty, crime
and deteriorating education, and all their
exposure to the pressures of racial con-
centration and frustration, should be a suffi-
cient reminder. All are bound up with the
productivity growth process itself. They are
sources of antagonism, conflict, and decline
of personal quality which will work to con-
strain growth unless moderated.
VIII
In the new, less-favorable growth environ-
ment, the tensions between productivity and
other welfare goals are screwed several
notches tighter. The success of our mixed
economy and pluralistic society in the next
generation will depend heavily on how those
tensions are managed. In present circum-
stance, therefore, economic progress turns
very largely on the policies we pursue, on
what we do through government, and how
we do it. As things now stand, however, we
can hardly be said to be adopting policies so
much as floundering among them, recoiling
from growth and backlashing against the
recoil, for lack of knowledge and for lack of
proper political institutions to use such
knowledge as we have.
The gaps in our knowledge define the job
for economics. Virtually every facet of the
way productivity depends on policy involves
matters of fact still to be established. What
is the elasticity of substitution between en-
ergy and other resources, and how much
will it cost us in future output if we forego
the cheapest mode of increasing energy sup-
plies in order to provide a greater degree of
protection for environment and people?
What are the full benefits and what are the
full costs of other environmental or safety
measures as now legislated and applied? And
how much could we save if we sought simi-
lar levels of protection more efficiently by
making larger use of market incentives as
regulatory devices? What are the effects of
different levels and-just as important-
different types of taxes and transfers on the
supplies of saving, investment, and risky
enterprise, and on the supply of labor and
the quality of people? What is the full range
of our government expenditure which has
the character of capital formation-and
what are the returns to investment in educa-
tion and in research and development? What
would our progress in productivity look like
if we tracked it by a system of national
accounts more relevant to long-term change
in economic welfare than our conventional
national product? The questions go on and
on. These are matters to which, for the most
part, economists have only recently turned.
They are now being attacked with vigor,
which is testimony to the fact that the ag-
gravated tension between measured produc-
tivity growth and other welfare goals is
eliciting a constructive response. There are
promising beginnings of useful analytical
and empirical work, and these will benefit
from future experience and experiment. At
the same time, our knowledge about this
entire range of questions continues to be
uncertain.
The weakness of our knowledge, more-
over, is matched, probably exceeded, by the
weakness of the political institutions and
procedures through which that knowledge
must be brought to bear. The structure of
government and politics, which served us
well enough during a more individualistic
era and before the population movements of
the last fifty years, has not been successfully
adapted to the new scale and complexity of
public functions. Let me just allude to three
political problems.
One concerns federal budget procedure.
In principle, the budget is the place where
the conflicting claims of special interests
should confront, not only one another, but
also the general interest in economy and in
maintaining a balance between private and
public uses of income. It is also the place
where our concern for increasing welfare by


### ---Economics-1981-0-15.txt---
raising measured productivity should be
brought into balance with our interest in
other welfare goals. But our budgetary pro-
cess, in spite of improvements in recent
years, remains weak. Tolerance for deficits
is the overt, inflation is the covert, mode by
which competing claims are reconciled. For
lack of a systematic way of facing the future
costs of present acts, three-quarters of the
budget consists of "uncontrollable" items.
Capital investment is not distinguished from
current consumption. We have just begun to
recognize that regulatory acts impose private
costs of compliance, analogous to excise
taxes, which must somehow be brought
within the budgetary ambit of the public
household.
A second matter is what, by pleasant eu-
phemism, is called our system of local
government. Fractionated geographically
and functionally and poorly coordinated,
operating in a confused relation to the
federal government, plagued by financial
crisis reflecting in part the disjunction be-
tween the populations they serve and the tax
bases on which they rest, our towns, cities,
and districts are fertile generators of exter-
nal costs, duplicative and costly regulation,
and chronic neglect. If, as historians gener-
ally agree, Britain could not have carried
through its Industrial Revolution without
the great Victorian reforms of local govern-
ment, we ought to be asking whether we can
meet the emerging problems of growth and
welfare in the second half century of our
mixed economy without also facing up to
the need for systematic local government
reform.
The third matter is both basic and diffuse,
and that is the weakness of our party sys-
tem. It is a commonplace that our national
parties are no more than fluid, transistory,
and undisciplined coalitions of regional
and economic interest groupings. Their lack
of central organization and authority, re-
flecting the size and diversity of the country
and people, and our lack of ideological
commitment, lays us wide open to the dis-
torting influence of special-interest lobbies
and single issue politics. In our political life,
we are all too vulnerable to particularistic
pressures and all too resistant to the needs
of general interest legislation.
Ix
The rationale supporting the development
of our mixed economy sees it as a pragmatic
compromise between the competing virtues
and defects of decentralized market capi-
talism and encompassing socialism. Its goal
is to obtain a measure of distributive justice,
security, and social guidance of economic
life without losing too much of the alloca-
tive efficiency and dynamism of private en-
terprise and market organization. And it is a
pragmatic compromise in another sense. It
seeks to retain for most people that measure
of personal protection from the state which
private property and a private job market
confer, while obtaining for the disad-
vantaged minority of people through the state
that measure of support without which their
lack of property or personal endowment
would amount to a denial of individual free-
dom and capacity to function as full mem-
bers of the community.
The viability, to say nothing of the success,
of this compromise demands a rough, three-
cornered balance between the degree to
which we look for economic progress
through the development of our powers of
production by private action, the degree to
which we try through government to protect
and promote those aspects of production
which markets do not reach, and the degree
to which we use governments to alter and
cushion the market's income verdicts and to
resolve the social conflicts which are inher-
ent in growth and change. Until recently, we
have paid inadequate attention to the re-
quirements of achieving that balance wisely.
We were able to neglect the problem be-
cause we enjoyed the amplitude of a run of
fortunate years, when rapid and steady
growth was the unseen moderator of the
tensions of balance. In the new and less
favorable environment of growth, however,
the tensions between productivity and the
alternative dimensions of welfare are ag-
gravated and the problems of balance-of
how much to do and how to do it- are
more severe.
In the last analysis, values- feelings,
tastes, and sympathies- control choices. But
those feelings and sympathies should not


### ---Economics-1981-0-16.txt---
have to be deployed with the sad deficien-
cies of knowledge which, in so many spheres,
is the case today. Nor should we have
to bring feelings and knowledge to bear
through political institutions and procedures
which are as imperfect as those through
which we -now act.
When Keynes spoke of the potential ef-
ficiency of a "wisely managed" capitalism,
he was assuming that the knowledge neces-
sary for wise management was either in
hand or would be forthcoming. But he did
not seem to be thinking about the limita-
tions of the political process in bringing
knowledge to bear. Now that economists
and other social scientists have begun to
work at it, we can be cautiously hopeful that
our knowledge about both the tradeoffs and
the complementarities between productivity
growth and the other dimensions of eco-
nomic welfare will gradually improve. For
the calculable future, however, our limited
political capabilities may well prove to be
the most binding constraint on our ability to
work out a social organization which, as
Keynes said, "shall be as efficient as possi-
ble without offending our notions of a
satisfactory way of life."
Contemplating these obdurate realities,
what can one say to conclude this talk on an
upbeat note? The best I can do is a some-
what inspirational passage from a lecture by
Jacob Viner, who, as we all know, was no
flaming New Dealer, no Great Society man,
and no Keynesian. I am fond of this pas-
sage, not only because of its sturdy de-
termination, but also because it displays so
well Viner's precise but involuted mind, and
his amiable weakness for the nonstop
sentence. At the close of a long critique of
the American welfare state, which is the
mixed economy I have been talking about,


### ---Economics-1981-0-17.txt---
Viner says:
For all these reasons, ... there is in the
abstract no reason for making an idol
of the welfare state in its American
form or for dedicating ourselves unre-
servedly to its continuance as it is to-
day without qualification or amend-
ment. Given the... imperfection of the
procedures whereby it deals with prob-
lems which it cannot evade or defer or
with problems which special interests
may press upon it for premature reso-
lution, it would be only by the dis-
pensation of a benevolent Providence
that it would ever make precisely the
right decisions or always avoid major
mistakes. It does not have theoretical
superiority over all conceivable alter-
native systems.... If ... I nevertheless
conclude that I believe that the welfare
state, like old Siwash, is really worth
fighting for and even dying for as
compared to any rival system, it is
because, despite its imperfections in
theory and in practice, in the aggre-
gate it provides more promise of pre-
serving and enlarging human free-
doms, temporal prosperity, the extinc-
tion of mass misery, and the dignity of
man and his moral improvement than
any other social system which has pre-
viously prevailed, which prevails
elsewhere today or which, outside
Utopia, the mind of man has been
able to provide a blueprint for.



### ---Economics-1981-0-18.txt---

## Economics-1982-0


### ---Economics-1982-0-03.txt---
The address of the departing president is
no place for modesty. Nevertheless, I must
resist the temptation to describe the analysis
I will report here as anything like a revolu-
tion. Perhaps terms such as "rebellion" or
"uprising" are rather more apt. But, never-
theless, I shall seek to convince you that the
work my colleagues, John Panzar and Robert
Willig, and I have carried out and encapsu-
lated in our new book enables us to look at
industry structure and behavior in a way that
is novel in a number of respects, that it
provides a unifying analytical structure to
the subject area, and that it offers useful
insights for empirical work and for the for-
mulation of policy.
Before getting into the substance of the
analysis I admit that this presidential address
is most unorthodox in at least one significant
respect-that it is not the work of a single
author. Here it is not even sufficient to refer
to Panzar and Willig, the coauthors of both
the substance and the exposition of the book
in which the analysis is described in full. For
others have made crucial contributions to the
formulation of the theory-most notably
Elizabeth Bailey, Dietrich Fischer, Herman
Quirmbach, and Thijs ten Raa.
But there are many more than these. No
uprising by a tiny band of rebels can hope to
change an established order, and when the
time for rebellion is ripe it seems to break
out simultaneously and independently in a
variety of disconnected centers each offering
its own program for the future. Events here
have been no different. I have recently re-
ceived a proposal for a conference on new
developments in the theory of industry struc-
ture formulated by my colleague, Joseph
Stiglitz, which lists some forty participants,
most of them widely known. Among those
working on the subject are persons as well
known as Caves, Dasgupta, Dixit, Fried-
laender, Grossman, Hart, Levin, Ordover,
Rosse, Salop, Schmalensee, Sonnenschein,
Spence, Varian, von Weiszacker, and
Zeckhauser, among many others.' It is, of
course, tempting to me to take the view that
our book is the true gospel of the rebellion
and that the doctrines promulgated by others
must be combatted as heresy. But that could
at best be excused as a manifestation of the
excessive zeal one comes to expect on such
occasions. In truth, the immediate authors of
the work I will report tonight may perhaps
be able to justify a claim to have offered
some systematization and order to the new
doctrines-to have built upon them a more
comprehensive statement of the issues and
the analysis, and to have made a number of
particular contributions. But, in the last
analysis, we must look enthusiastically upon
our fellow rebels as comrades in arms, each
of whom has made a crucial contribution to
the common cause.
Turning now to the substance of the the-
ory, let me begin by contrasting our results
with those of the standard theory. In offering
this contrast, let me emphasize that much of
the analysis rests on work that appeared
considerably earlier in a variety of forms.


### ---Economics-1982-0-04.txt---
We, no less than other writers, owe a heavy
debt to predecessors from Bertrand to Bain,
from Cournot to Demsetz. Nevertheless, it
must surely be acknowledged that the follow-
ing characterization of the general tenor of
the literature as it appeared until fairly re-
cently is essentially accurate.
First, in the received analysis perfect com-
petition serves as the one standard of wel-
fare- maximizing structure and behavior.
There is no similar form corresponding to
industries in which efficiency calls for a very
limited number of firms (though the earlier
writings on workable competition did move
in that direction in a manner less formal
than ours).
Our analysis, in contrast, provides a gener-
alization of the concept of the perfectly com-
petitive market, one which we call a "per-
fectly contestable market." It is, generally,
characterized by optimal behavior and yet
applies to the full range of industry struc-
tures including even monopoly and oligop-
oly. In saying this, it must be made clear that
perfectly contestable markets do not popu-
late the world of reality any more than per-
fectly competitive markets do, though there
are a number of industries which un-
doubtedly approximate contestability even if
they are far from perfectly competitive. In
our analysis, perfect contestability, then,
serves not primarily as a description of real-
ity, but as a benchmark for desirable
industrial organization which is far more
flexible and is applicable far more widely
than the one that was available to us before.
Second, in the standard analysis (including
that of many of our fellow rebels), the prop-
erties of oligopoly models are heavily depen-
dent on the assumed expectations and reac-
tion patterns characterizing the firms that
are involved. When there is a change in the
assumed nature of these expectations or re-
actions, the implied behavior of the oligopo-
listic industry may change drastically.
In our analysis, in the limiting case of
perfect contestability, oligopolistic structure
and behavior are freed entirely from their
previous dependence on the conjectural vari-
ations of incumbents and, instead, these are
generally determined uniquely and, in a
manner that is tractable analytically, by the
pressures of potential competition to which
Bain directed our attention so tellingly.
Third, the standard analysis leaves us with
the impression that there is a rough con-
tinuum, in terms of desirability of industry
performance, ranging from unregulated pure
monopoly as the pessimal arrangement to
perfect competition as the ideal, with relative
efficiency in resource allocation increasing
monotonically as the number of firms ex-
pands.
I will show that, in contrast, in perfect-
ly contestable markets behavior is sharply
discontinuous in its welfare attributes. A
contestable monopoly offers us some pre-
sumption, but no guarantee, of behavior con-
sistent with a second best optimum, subject
to the constraint that the firm be viable
financially despite the presence of scale
economies which render marginal cost pric-
ing financially infeasible. That is, a contest-
able monopoly has some reason to adopt the
Ramsey optimal price-output vector, but it
may have other choices open to it. (For the
analysis of contestable monopoly, see my
article with Elizabeth Bailey and Willig, Pan-
zar and Willig's article, and my book with
Panzar and Willig, chs. 7 and 8.)
But once each product obtains a second
producer, that is, once we enter the domain
of duopoly or oligopoly for each and every
good, such choice disappears. The contest-
able oligopoly which achieves an equilibrium
that immunizes it from the incursions of
entrants has only one pricing option-it must
set its price exactly equal to marginal cost
and do all of the things required for a first
best optimum! In short, once we leave the
world of pure or partial monopoly, any con-
testable market must behave ideally in every
respect. Optimality is not approached gradu-
ally as the number of firms supplying a
commodity grows. As has long been sug-
gested in Chicago, two firms can be enough
to guarantee optimality (see, for example,
Eugene Fama and Arthur Laffer).
Thus, the analysis extends enormously the
domain in which the invisible hand holds
sway. In a perfectly contestable world, it
seems to rule almost everywhere. Lest this


### ---Economics-1982-0-05.txt---
seem to be too Panglossian a view of reality,
let me offer two observations which make it
clear that we emphatically do not believe
that all need be for the best in this best of all
possible worlds.
First, let me recall the observation that
real markets are rarely, if ever, perfectly con-
testable. Contestability is merely a broader
ideal, a benchmark of wider applicability
than is perfect competition. To say that con-
testable oligopolies behave ideally and that
contestable monopolies have some incentives
for doing so is not to imply that this is even
nearly true of all oligopolies or of unregu-
lated monopolies in reality.
Second, while the theory extends the do-
main of the invisible hand in some direc-
tions, it unexpectedly restricts it in others.
This brings me to the penultimate contrast I
wish to offer here between the earlier views
and those that emerge from our analysis.
The older theoretical analysis seems to have
considered the invisible hand to be a rather
weak intratemporal allocator of resources, as
we have seen. The mere presence of unregu-
lated monopoly or oligopoly was taken to be
sufficient per se to imply that resources are
likely to be misallocated within a given time
period. But where the market structure is such
as to yield a satisfactory allocation of resources
within the period, it may have seemed that it
can, at least in theory, do a good job of
intertemporal resource allocation. In the ab-
sence of any externalities, persistent and
asymmetric information gaps, and of inter-
ference with the workings of capital markets,
the amounts that will be invested for the
future may appear to be consistent with
Pareto optimality and efficiency in the supply
of outputs to current and future generations.
However, our analysis shows that where
there are economies of scale in the produc-
tion of durable capital, intertemporal con-
testable monopoly, which may perform rela-
tively well in the single period, cannot be
depended upon to perform ideally as time
passes. In particular, we will see that the
least costly producer is in the long run
vulnerable to entry or replacement by rivals
whose appearance is inefficient because it
wastes valuable social resources.
There is one last contrast between the
newer analyses and the older theory which I
am most anxious to emphasize. In the older
theory, the nature of the industry structure
was not normally explained by the analysis.
It was, in effect, taken to be given exoge-
nously, with the fates determining, ap-
parently capriciously, that one industry will
be organized as an oligopoly, another as a
monopoly and a third as a set of monopolis-
tic competitors. Assuming that this destiny
had somehow been revealed, the older
analyses proceeded to investigate the conse-
quences of the exogenously given industry
structure for pricing, outputs, and other deci-
sions.2
The new analyses are radically different in
this respect. In our analysis, among others,
an industry's structure is determined ex-
plicitly, endogenously, and simultaneously
with the pricing, output, advertising, and
other decisions of the firms of which it is
constituted. This, perhaps, is one of the prime
contributions of the new theoretical analyses.
I. Characteristics of Contestable Markets
Perhaps a misplaced instinct for melo-
drama has led me to say so much about
contestable markets without even hinting
what makes a market contestable. But I can
postpone the definition no longer. A con-
testable market is one into which entry is
absolutely free, and exit is absolutely costless.
We use "freedom of entry" in Stigler's sense,
not to mean that it is costless or easy, but
that the entrant suffers no disadvantage in
terms of production technique or perceived
product quality relative to the incumbent,


### ---Economics-1982-0-06.txt---
and that potential entrants find it ap-
propriate to evaluate the profitability of en-
try in terms of the incumbent firms' pre-entry
prices. In short, it is a requirement of con-
testability that there be no cost discrimina-
tion against entrants. Absolute freedom of
exit, to us, is one way to guarantee freedom
of entry. By this we mean that any firm can
leave without impediment, and in the process
of departure can recoup any costs incurred
in the entry process. If all capital is salable
or reusable without loss other than that cor-
responding to normal user cost and deprecia-
tion, then any risk of entry is eliminated.
Thus, contestable markets may share at
most one attribute with perfect competition.
Their firms need not be small or numerous
or independent in their decision making or
produce homogeneous products. In short, a
perfectly competitive market is necessarily
perfectly contestable, but not vice versa.
The crucial feature of a contestable market
is its vulnerability to hit-and-run entry. Even
a very transient profit opportunity need not
be neglected by a potential entrant, for he
can go in, and, before prices change, collect
his gains and then depart without cost, should
the climate grow hostile.
Shortage of time forces me to deal rather
briefly with two of the most important prop-
erties of contestable markets-their welfare
attributes and the way in which they de-
termine industry structure. I deal with these
briefly because an intuitive view of the logic
of these parts of the analysis is not difficult
to provide. Then I can devote a bit more
time to some details of the oligopoly and the
intertemporal models.
A. Perfect Contestability and Welfare
The welfare properties of contestable
markets follow almost directly from their
definition and their vulnerability to hit-and-
run incursions. Let me list some of these
properties and discuss them succinctly.
First, a contestable market never offers
more than a normal rate of profit-its eco-
nomic profits must be zero or negative, even
if it is oligopolistic or monopolistic. The
reason is simple. Any positive profit means
that a transient entrant can set up business,
replicate a profit-making incumbent's output
at the same cost as his, undercut the in-
cumbent's prices slightly and still earn a
profit. That is, continuity and the opportun-
ity for costless entry and exit guarantee that
an entrant who is content to accept a slightly
lower economic profit can do so by selecting
prices a bit lower than the incumbent's.
In sum, in a perfectly contestable market
any economic profit earned by an incumbent
automatically constitutes an earnings oppor-
tunity for an entrant who will hit and, if
necessary, run (counting his temporary but
supernormal profits on the way to the bank).
Consequently, in contestable markets, zero
profits must characterize any equilibrium,
even under monopoly and oligopoly.
The second welfare characteristic of a con-
testable market follows from the same argu-
ment as the first. This second attribute of
any contestable market is the absence of any
sort of inefficiency in production in industry
equilibrium. This is true alike of inefficiency
of allocation of inputs, X-inefficiency, ineffi-
cient operation of the firm, or inefficient
organization of the industry. For any unnec-
essary cost, like any abnormal profit, con-
stitutes an invitation to entry. Of course, in
the short run, as is true under perfect compe-
tition, both profits and waste may be pres-
ent. But in the long run, these simply cannot
withstand the threat brandished by potential
entrants who have nothing to lose by grab-
bing at any opportunity for profit, however
transient it may be.
A third welfare attribute of any long-run
equilibrium in a contestable market is that
no product can be sold at a price, p, that is
less than its marginal cost. For if some firm
sells y units of output at such a price and
makes a profit in the process, then it is
possible for an entrant to offer to sell a
slightly smaller quantity, y - E, at a price a
shade lower than the incumbent's, and still
make a profit. That is, if the price p is less
than MC, then the sale of y - E units at price
p must yield a total profit X + A7r which is
greater than the profit, va, that can be earned
by selling only y units of output at that price.
Therefore, there must exist a price just
slightly lower than p which enables the en-
trant to undercut the incumbent and yet to


### ---Economics-1982-0-07.txt---
earn at least as much as the incumbent, by
eliminating the unprofitable marginal unit.
This last attribute of contestable equilibria
-the fact that price must always at least
equal marginal cost-is important for the
economics of antitrust and regulation. For it
means that in a perfectly contestable market,
no cross subsidy is possible, that is, no
predatory pricing can be used as a weapon of
unfair competition. But we will see it also
has implications which are more profound
theoretically and which are more germarte to
our purposes. For it constitutes half of the
argument which shows that when there are
two or more suppliers of any product, its
price must, in equilibrium, be exactly equal
to marginal cost, and so resource allocation
must satisfy all the requirements of first best
optimality.
Indeed, the argument here is similar to the
one which has just been described. But there
is a complication which is what introduces
the two-firm requirement into this proposi-
tion. p < MC constitutes an opportunity for
profit to an entrant who drops the unprofit-
able marginal unit of output, as we have just
seen. It would seem, symmetrically, that p >
MC also automatically constitutes an op-
portunity for profitable entry. Instead of sell-
ing the y-unit output of a profitable in-
cumbent, the entrant can now offer to sell
the slightly larger output, y + e, using the
profits generated by the marginal unit at a
price greater than marginal cost to permit a
reduction in price below the incumbent's.
But on this side of the incumbent's output,
there is a catch in the argument. Suppose the
incumbent is a monopolist. Then output and
price are constrained by the elasticity of
demand. An attempt by an entrant to sell
y + e rather than y may conceivably cause a
sharp reduction in price which eliminates the
apparent profits of entry. In the extreme case
where demand is perfectly inelastic, there
will be no positive price at which the market
will absorb the quantity y +? . This means
that the profit opportunity represented by
p > MC can crumble into dust as soon as
anyone seeks to take advantage of it.
But all this changes when the market con-
tains two or more sellers. Now p > MC does
always constitute a real opportunity for prof-
itable entry. The entrant who wishes to sell a
bit more than some one of the profitable
incumbents, call him incumbent A, need not
press against the industry's total demand
curve for the product. Rather, he can under-
cut A, steal away all of his customers, at least
temporarily, and, in addition, steal away e
units of demand from any other incumbent,
B. Thus, if A and B together sell Ya + Yb > Ya'
then an entrant can lure away Ya + -> Ya
customers, for - sufficiently small, and earn
on this the incremental profit e( p - MC)>O.
This means that the entrant who sells Ya + e
can afford to undercut the prevailing prices
somewhat and still make more profit than an
incumbent who sells Ya at price p.
In sum, where a product is sold by two or
more firms, any p > MC constitutes an irre-
sistible entry opportunity for hit-and-run en-
try in a perfectly contestable market, for it
promises the entrant supernormal profits
even if they accrue for a very short period of
time.
Consequently, when a perfectly contest-
able market contains two or more sellers,
neither p < MC nor p > MC is compatible
with equilibrium. Thus we have our third
and perhaps most crucial welfare attribute of
such perfectly contestable markets- their
prices, in equilibrium, must be equal to
marginal costs, as is required for Pareto opti-
mality of the "first best" variety. This, along
with the conclusion that such markets permit
no economic profits and no inefficiency in
long-run equilibrium, constitutes their criti-
cal properties from the viewpoint of eco-
nomic welfare. Certainly, since they do enjoy
those three properties, the optimality of per-
fectly contestable equilibria (with the res-
ervations already expressed about the case of
pure monopoly) fully justifies our conclusion
that perfect contestability constitutes a
proper generalization of the concept of per-
fect competition so far as welfare impli-
cations are concerned.
B. On the Determination of Industry
Structure
I shall be briefer and even less rigorous in
describing how industry structure is de-
termined endogenously by contestability


### ---Economics-1982-0-08.txt---
analysis. Though this area encompasses one
of its most crucial accomplishments, there is
no way I can do justice to the details of the
analysis in an oral presentation and within
my allotted span of time. However, an intui-
tive view of the matter is not difficult.
The key to the analysis lies in the second
welfare property of contestable equilibria-
their incompatibility with inefficiency of any
sort. In particular, they are incompatible with
inefficiency in the organization of an in-
dustry. That is, suppose we consider whether
a particular output quantity of an industry
will be produced by two firms or by a thou-
sand. Suppose it turns out that the two-firm
arrangement can produce the given output at
a cost 20 percent lower than it can be done
by the 1,000 firms. Then one implication of
our analysis is that the industry cannot be in
long-run equilibrium if it encompasses 1,000
producers. Thus we already have some hint
about the equilibrium industry structure of a
contestable market.
We can go further with this example. Sup-
pose that, with the given output vector for
the industry, it turns out that no number of
firms other than two can produce at as low a
total cost as is possible under a two-firm
arrangement. That is, suppose two firms can
produce the output vector at a total cost
lower than it can be done by one firm or
three firms or sixty or six thousand. Then we
say that for the given output vector the in-
dustry is a natural duopoly.
This now tells us how the industry's struc-
ture can be determined. We proceed, concep-
tually, in two steps. First we determine what
structure happens to be most efficient for the
production of a given output vector by a
given industry. Next, we investigate when
market pressures will lead the industry to-
ward such an efficient structure in equi-
librium.
Now, the first step, though it has many
intriguing analytic attributes, is essentially a
pure matter of computation. Given the cost
function for a typical firm, it is ultimately a
matter of calculation to determine how many
firms will produce a given output most effi-
ciently. For example, if economies of scale
hold throughout the relevant range and there
are sufficient complementarities in the pro-
duction of the different commodities sup-
plied by the firm, then it is an old and
well-known conclusion that single firm pro-
duction will be most economical-that we
are dealing with a natural monopoly.
Similarly, in the single product case sup-
pose the average cost curve is U shaped and
attains its minimum point at an output of
10,000 units per year. Then it is obvious that
if the industry happens to sell 50,000 units
per year, this output can be produced most
cheaply if it is composed of exactly five
firms, each producing 10,000 units at its
point of minimum average cost.
Things become far more complex and more
interesting when the firm and the industry
produce a multiplicity of commodities, as
they always do in reality. But the logic is
always the same. When the industry output
vector is small compared to the output vec-
tors the firm can produce at relatively low
cost, then the efficient industry structure will
be characterized by very few firms. The op-
posite will be true when the industry's output
vector is relatively far from the origin. In the
multiproduct case, since average cost cannot
be defined, two complications beset the char-
acterization of the output vectors which the
firm can produce relatively efficiently. First,
since here average cost cannot be defined, we
cannot simply look for the point of mini-
mum average costs. But we overcome this
problem by dealing with output bundles hav-
ing fixed proportions among commodity
quantities-by moving along a ray in output
space. Along any such ray the behavior of
average cost is definable, and the point of
minimum ray average cost (RA C) is our
criterion of relatively efficient scale for the
firm. Thus, in Figure 1 we have a ray average
cost curve for the production of boots and
shoes when they are produced in the propor-
tion given by ray OR. We see that for such
bundles ytm is the point of minimum RA C. A
second problem affecting the determination
of the output vectors the firm can produce
efficiently is the choice of output proportions
-the location of the ray along which the
firm will operate. This depends on the degree
of complementarity in production of the
goods, and it also lends itself to formal anal-
ysis.
We note also that the most efficient num-
ber of firms will vary with the location of the


### ---Economics-1982-0-09.txt---
industry's output vector. The industry may
be a natural monopoly with one output vec-
tor, a natural duopoly with another, and
efficiency may require seventy-three firms
when some third output vector is provided
by the industry.
This, then, completes the first of the two
basic steps in the endogenous determination
of industry structure. Here we have ex-
amined what industry structure is least costly
for each given output vector of a given in-
dustry, and have found how the result de-
pends on the magnitudes of the elements of
that output vector and the shape of the cost
function of the typical firm. So far the dis-
cussion may perhaps be considered norma-
tive rather than behavioral. It tells us what
structure is most efficient under the circum-
stances, not which industry structure will
emerge under the pressures of the market
mechanism.
The transition toward the second, behav-
ioral, stage of the analysis is provided by the
observation that the optimal structure of an
industry depends on its output vector, while
that output vector in turn depends on the
prices charged by its firms. But, since pricing
depends on industry structure, we are
brought full circle to the conclusion that
pricing behavior and industry structure must,
ultimately, be determined simultaneously and
endogenously.
We are in no position to go much further
than this for a market whose properties are
unspecified. But, for a perfectly contestable
market, we can go much further. Indeed, the
properties of perfect contestability cut
through every difficulty and tell us the equi-
librium prices, outputs, and industry struc-
ture, all at once.
Where more than one firm supplies a
product, we have already characterized these
prices precisely. For we have concluded that
each equilibrium price will equal the associ-
ated marginal cost. Then, given the industry's
cost and demand relationships, this yields
the industry's output quantities simulta-
neously with its prices, in the usual manner.
Here there is absolutely nothing new in the
analysis.
But what is new is the format of the
analysis of the determination of industry
structure. As I have already pointed out,
structure is determined by the efficiency re-
quirement of equilibrium in any contestable
market. Since no such equilibrium is compat-
ible with failure to minimize industry costs,
it follows that the market forces under per-
fect contestability will bring us results con-
sistent with those of our normative analysis.
Whatever industry structures minimize total
costs for the equilibrium output vector must
turn out to be the only structures consistent
with industry equilibrium in the long run.
Thus, for contestable markets, but for con-
testable markets only, the second stage of the
analysis of industry structure turns out to be
a sham. Whatever industry structure was
shown by the first, normative, portion of the
analysis to be least costly must also emerge
as the industry structure selected by market
behavior. No additional calculations are re-
quired by the behavioral analysis. It will all
have been done in the normative cost-
minimization analysis and the behavioral
analysis is pure bonus.
Thus, as I promised, I have indicated how
contestability theory departs from the older
theory which implicitly took industry struc-
ture to be determined exogenously in a
manner totally unspecified and, instead,
along with other recent writings, embraces
the determination of industry structure as an
integral part of the theory to be dealt with
simultaneously with the determination of
prices and outputs.
At this point I can only conjecture about
the determination of industry structure once
we leave the limiting case of perfect contest-
ability. But my guess is that there are no


### ---Economics-1982-0-10.txt---
sharp discontinuities here, and that while the
industry structures which emerge in reality
are not always those which minimize costs,
they will constitute reasonable approxima-
tions to the efficient structures. If this is not
so it is difficult to account for the similarities
in the patterns of industry structure that one
observes in different countries. Why else do
we not see agriculture organized as an
oligopoly in any free market economy, or
automobiles produced by 10,000 firms?
Market pressures must surely make any very
inefficient market structure vulnerable to en-
try, to displacement of incumbents by for-
eign competition, or to undermining in other
ways. If that is so, the market structure that
is called for by contestability theory may not
prove to be too bad an approximation to
what we encounter in reality.
II. On Oligopoly Equilibrium
I should like now to examine oligopoly
equilibrium somewhat more extensively. We
have seen that, except where a multiproduct
oligopoly firm happens to sell some of its
products in markets in which it has no com-
petitors, an important partial monopoly case
which I will ignore in what follows, all prices
must equal the corresponding marginal costs
in long-run equilibrium. But in an oligopoly
market, this is a troublesome concept. Unless
the industry output vector happens to fall at
a point where the cost function is char-
acterized by locally constant returns to scale,
we know that zero profits are incompatible
with marginal cost pricing. Particularly if
there are scale economies at that point, so
that marginal cost pricing precludes financial
viability, we can hardly expect such a solu-
tion to constitute an equilibrium. Besides, we
have seen that long-run equilibrium requires
profit to be precisely zero. We would thus
appear to have run into a major snag by
concluding that perfect contestability always
leads to marginal cost pricing under oligop-
oly.
This is particularly so if the (ray) average
curve is U shaped, with its minimum occur-
ring at a single point, y n. For in this case
that minimum point is the only output of the
firm consistent with constant returns to scale
and with zero profits under marginal cost
pricing. Thus, dealing with the single product
case to make the point, it would appear, say,
that if the A C-minimizing output is 1,000, in
a contestable market, equilibrium is possible
if quantity demanded from the industry hap-
pens to be exactly 2,000 units (so two firms
can produce 1,000 units each) or exactly
3,000 units or exactly 4,000 units, etc. But
suppose the demand curve happens to inter-
sect the industry AC curve, say, at 4,030
units. That is, then, the only industry output
satisfying the equilibrium requirement that
price equals zero profit. But then, at least
one of the four or five firms in the industry
must produce either more or less than 1,000
units of output, and so the slope of its AC
curve will not be zero at that point, preclud-
ing either MC pricing or zero profits and,
consequently, violating one or the other of
the requirements of equilibrium in a per-
fectly contestable market.
It would appear that equilibrium will be
impossible in this perfectly contestable
market unless by a great piece of luck the
industry demand curve happens to intersect
its AC curve at 2,000 or 3,000 units or some
other integer multiple of 1,000 units of out-
put.
There are a variety of ways in which one
can grapple with this difficulty. In his disser-
tation at New York University, Thijs ten
Raa has explored the issue with some care
and has shown that the presence of entry
costs of sufficient magnitude, that is, irre-
versible costs which must be borne by an
entrant but not by an incumbent, can
eliminate the existence problem. The mini-
mum size of the entry cost required to permit
an equilibrium will depend on the size of the
deviation from zero profits under marginal
cost pricing and ten Raa has given us rules
for its determination. He has shown also that
the existence problem, as measured by the
required minimum size of entry cost,
decreases rapidly as the equilibrium number
of firms of the industry increases, typically
attaining negligible proportions as that num-
ber reaches, say, ten enterprises. For, as is
well known, when the firm's average cost
curve is U shaped the industry's average cost
curve will approach a horizontal line as the


### ---Economics-1982-0-11.txt---

size of industry output increases. This is
shown in Figure 2 which is a standard dia-
gram giving the firm's and the industry's AC
curves when the former is U shaped. As a
result, the deviations between average cost
and marginal cost will decline as industry
output increases and so the minimum size of
the entry cost required to preserve equi-
librium declines correspondingly.
However, here I want to describe another
approach offered in our book to the problem
of existence which I have just described- the
difficulty of satisfying simultaneously the
zero-profit requirement and the requirement
of marginal cost pricing. This second avenue
relies on the apparently unanimous conclu-
sion of empirical investigators of the cost
function of the firm, that AC curves are not,
in fact, characterized by a unique minimum
point as they would be if they had a smooth
U shape. Rather, these investigators tell us,
the A C curve of reality has a flat bottom -an
interval along which it is horizontal. That is,
average costs do tend to fall at first with size
of output, then they reach a minimum and
continue at that level for some range of
outputs, after which they may begin to rise
once more. An A C curve of this variety is
shown in Figure 3. Obviously, such a flat
segment of the A C curves does help matters
because there is now a range of outputs over
which MC pricing yields zero profits. More-
over, the longer the flat-bottomed segment
the better matters are for existence of equi-
librium. Indeed, it is easy to show that if the
left-hand end of the flat segment occurs at
output y' and the right-hand end occurs at
kym, then if k is greater than or equal to 2 the
existence problem disappears altogether, be-
cause the industry's AC curves will be hori-
zontal for any output greater than Ym, That
is, in any contestable market in which two or
more firms operate the industry AC curve
will be horizontal and MC pricing will al-
ways yield zero profits. To confirm that this
is so, note that if, for example, the flat
segment for the firm extends from y = 1,000
to y 2,000, then any industry output of,
say, 9,000 + Ay where 0< A y < 9,000 can be
produced by nine firms, each of them turn-
ing out more than 1,000 but less than 2,000
units. Hence, each of them will operate along
the horizontal portion of its AC curve, as
equilibrium requires.
Thus, if the horizontal interval (yi, kym)
happens to satisfy k , 2, there is no longer
any problem for existence of equilibrium in a
contestable market with two or more firms.
But fate may not always be so kind. What if
that horizontal interval is quite short, that is,
k is quite close to unity? Such a case is
shown in our diagram where for illustration I
have taken k =4/3.
I should like to take advantage of your
patience by dealing here not with the sim-
plest case-that of the single product in-
dustry-but with the multiproduct problem.
I do this partly to offer you some feeling of
the way in which the multiproduct analysis,
which is one of the hallmarks of our study,
works out in practice.
Because, as we have seen, there is no way
one can measure average cost for all output
combinations in the multiproduct case, I will
deal exclusively with the total cost function.
Figure 4 shows such a total cost function for
the single firm, which is taken to manufac-
ture two products, boots and shoes.
Let us pause briefly to examine its shape.
Along any ray such as OR, which keeps


### ---Economics-1982-0-12.txt---
output proportions constant, we have an
ordinary total cost curve, OST. With one
exception, which I will note soon, I have
drawn it to have the usual sort of shape, with
marginal costs falling near the origin and
rising at points much further from the origin.
On the other hand, the trans ray cut above
AB yields a cross section C'TC which is more
or less U shaped. This means that it is rela-
tively cheaper to produce boots and shoes
together (point U) than to produce them in
isolation (point A or point B). That is, this
convex trans ray shape is enough to offer us
the complementarity which leads firms and
industries to turn out a multiplicity of prod-
ucts rather than specializing in the produc-
tion of a single good.
Now what, in such a case, corresponds to
the flat bottom of an AC curve in a single
product case? The answer is that the cost
function in the neighborhood of the corre-
sponding output must be linearly homoge-
neous. In Figure 5 such a region, a/3yS, is
depicted. It is linearly homogeneous because
it is generated by a set of rays such as L, M,
and N. For simplicity in the discussion that
follows, I have given this region a very regu-
lar shape-it is, approximately, a rectangle
which has been moved into three-dimensional
space and given a U-shaped cross section.
Now Figure 6 combines the two preceding
diagrams and we see that they have been
drawn to mesh together, so that the linearly
homogeneous region constitutes a portion of
the firm's total cost surface. We see then that
the firm's total cost does have a region in
which constant returns to scale occur, and
which corresponds to the flat-bottomed seg-
ment of the A C curve.
Moreover, as before, I have deliberately
kept this segment quite narrow. Indeed, I
have repeated the previous proportions, let-
ting the segment extend from a distance ym
from the origin to the distance I 4ym along
any ray on the floor of the diagram.
Let us now see what happens in these
circumstances when we turn to the total cost
surface for the industry. This is depicted in
Figure 7 which shows a relationship that
may at first seem surprising. In Figure 7 I
depict only the linearly homogeneous por-
tions of the industry's cost surface. There we
see that while for the firm linear homogene-
ity prevailed only in the interval from y' to
13 Imy in the case of industry output linear
homogeneity also holds in that same interval
but, in addition, it holds for the interval 2ym
to 22 , and in the region extending from
3ym to infinity. That is, everywhere beyonc
3y' the industry's total cost function is lin-
early homogeneous. In this case, then, we
have three regions of local linear homogene-


### ---Economics-1982-0-13.txt---
ity in the industry's cost function, a,/yS,
which is identical with that of the individual
firm, the larger region abcd, and the infinite
region aleph beth....
Before showing why this is so we must
pause to note the implications of the ex-
ercise. For it means that even a relatively
small region of flatness in the A C curve of
the individual firm, that is, of linear homo-
geneity in its total cost function, eliminates
the bulk of the existence problem for oligop-
oly equilibrium in a contestable market. The
problem does not arise for outputs nearer to
the origin than Ym because such outputs are
supplied most efficiently by a monopoly
which is not required to price at marginal
cost in a contestable market equilibrium. The
problem also does not arise for any industry
output greater than 3ym in this case, because
everywhere beyond that marginal cost pric-
ing yields zero profits. There are two rela-
tively narrow regions in which no equi-
librium is, indeed, possible, but here we may
conjecture that the vicissitudes of disequi-
librium will cause shifts in the demand rela-
tionships as changing prices and changing
consumption patterns affect tastes, and so
the industry will ultimately happen upon an
equilibrium position and remain there until
exogenous disturbances move it away. Thus
we end up with an oligopoly equilibrium
whose prices, profits, and other attributes are
determined without benefit of the conjec-
tural variation, reaction functions, and the
other paraphernalia of standard oligopoly
analysis.
To complete this discussion of oligopoly
equilibrium in a contestable market, it only
remains for me to explain why the regions of
linear homogeneity in the industry's cost
function are as depicted in Figure 7. The
answer is straightforward. Let C(y) be the
firm's total cost function for which we have
assumed for expository simplicity that in the
interval from ym to I lym along each and
every ray, total cost grows exactly pro-
portionately with output. Then two firms can
produce 2ym at the same unit cost, and three
firms can produce 3ym at that same unit cost
for the given output bundle, etc. But by
exactly the same argument, the two firms
together, each producing no more than 1 ' '


### ---Economics-1982-0-14.txt---
can turn out anything up to 2'ym without
affecting unit costs, and three firms can pro-
duce as much as 3 ym, that is, as much as
4ym. In sum, the intervals of linear homo-
geneity for the industry are the following:

Interval 1: from ym to I ym

Interval 2: from 2ym to 22ym

Interval 3: from 3ym to 4ym

Interval 4: from 4ym to 54ym

Interval 5: from Sytm to 62y'
That is, each interval begins at an integer
multiple of ym and extends 1/3 ym further
than its predecessor. Thus, beyond 3ym
successive intervals begin to touch or overlap
and that is why linear homogeneity extends
everywhere beyond 3ym as I claimed.3
There is one complication in the multi-
product case which I have deliberately slid
over, feeling the discussion was already com-
plicated enough. The preceding argument as-
sumes implicitly that the firms producing the
industry output all employ the same output
proportions as those in the industry output
vector. For otherwise, it is not legitimate to
move outward along a single ray as the num-
ber of firms is increased. But suppose in-
creased industry output were to permit sav-
ings through increased specialization. Might
there not be constant returns with fixed out-
put proportions and yet economies of scale
for the industry overall? This problem is
avoided by our complementarity assumption
used to account for the industry's multiprod-
uct operation-our U-shaped trans-ray cross
section. This, in effect, rules out such savings
from specialization in the regions where lin-
ear homogeneity also rules out savings from
increased scale.
This, then, completes my discussion of
oligopoly equilibrium in perfectly contest-
able markets, which we have seen, yields a
determinate set of prices and outputs that is
not dependent upon assumptions about the
nature of incumbent firm's expectations re-
lating to entrants' behavior and offers us a
concrete and favorable conclusion on the
welfare implications of contestable oligopoly.
III. Intertemporal Vulnerability to
Inefficient Entry
Having so far directed attention to areas
in which the invisible hand manifests unex-
pected strength, I should like to end my
story by dealing with an issue in relation to
which it is weaker than some of us might
have expected. As I indicated before, this is
the issue of intertemporal production involv-
ing durable capital goods.
The analysis is far more general than the
following story suggests, but even the case I
describe is sufficiently general to make the
point. We deal with an industry in which a
product is offered by a single firm that pro-
vides it period after period. The equilibrium
quantity of the commodity that is demanded
grows steadily with the passage of time in a
manner that is foreseen without uncertainty.
Because of economies of scale in the produc-
tion of capacity the firm deliberately builds
some excess capacity to take care of antic-
ipated growth in sales volume. But there is
some point, let us say, z =45 years in the
future, such that it would be uneconomic to
take further growth in sales volume into
account in the initial choice of capacity. This
is so because the opportunity (interest) cost
of the capacity that remains idle for 45 or
more years exceeds the savings made possi-
ble by the economies of scale of construc-
tion. Thus, after 45 years it will pay the firm
to undertake a second construction project
to build the added capacity needed to pro-
duce the goods demanded of it.
Suppose that in every particular period
our producer is a natural monopolist, that is,
he produces the industry's supply of its one
commodity at a cost lower than it can be
done by any two or more enterprises. Then
considering that same product in different
periods to be formally equivalent to different
goods we may take our supplier to be an
intertemporal natural monopolist in a multi-
product industry. That is, no combination of


### ---Economics-1982-0-15.txt---
two or more firms can produce the industry's
intertemporal output vector as cheaply as he.
I will prove now under a set of remarkably
unrestrictive assumptions that despite its cost
advantages, there exists no intertemporal
price vector consistent with equilibrium for
this firm. That is, whatever his price vector,
his market will at some time be vulnerable to
partial or complete takeover by an entrant
who has neither superior skills nor techno-
logical superiority and whose entrance
increases the quantities of resources used up
in production. In other words, here the
invisible hand proves incapable of protecting
the most efficient producing arrangement and
leaves the incumbent producer vulnerable to
displacement by an aggressive entrant. I leave
to your imaginations what, if anything, this
says about the successive displacements
on the world market of the Dutch by the
English, the English by the Germans and the
Americans, and the Americans, perhaps, by
the Japanese.
The proof of our proposition on the inter-
temporal vulnerability of incumbents to en-
try that is premature from the viewpoint of
cost minimization does require just a little
bit of algebra. To keep our analysis simple, I
will divide time into two periods, each last-
ing z =45 years so that capacity in the first
period is, optimally, just sufficient to satisfy
all demand, but in the second, it requires the
construction of added capacity to meet de-
mand growth because, by assumption, antic-
ipatory construction to meet growth more
than z years in the future simply is too
costly. Also for simplicity, I will assume that
there are no costs other than cost of con-
struction. Of course, neither this nor the use
of only two periods really affects the argu-
ment in any way. My only three substantive
assumptions are that demand is growing with
time, that there are economies of scale, that
is, declining average costs in construction,
and that there exists some length of time, z,
so great that it does not pay in the initial
construction to build capacity sufficient for
the growth in quantity demanded that will
occur beyond that date.
The argument, like the notation, is now
straightforward. Let y, be output in period t,  P, be price in period t, and K(y) be the cost
of construction of capacity sufficient to pro-
duce (a maximum of) y units per period.
Here, both p, and K(y) are expressed in
discounted present value.4
Then, by assumption, our firm will con-
struct at the beginning of the first period
capacity just sufficient to produce output y,
at cost K(y,) and at the beginning of the
second period it will produce the rest of the
capacity it needs, Y2- yI >0, at the cost
K(y2 - y ).
The first requirement for the prices in
question to be consistent with equilibrium is
that they permit the incumbent to cover his
costs, that is, that
(1) PIYI+P2Y2 2 K(y1)+K(y2-y1).
Second, for these prices to constitute an
equilibrium they must protect the incumbent
against any and all possible incursions by
entrants. That is, suppose an entrant were to
consider the possibility of constructing
capacity y, and not expanding in the future,
and, by undercutting the incumbent, selling
the same output, y,, in each period. Entry on
these terms will in fact be profitable unless
the prices are such that the sale of y, in each
period does not bring in revenues sufficient
to cover the cost, K(y,), of the entrant's
once-and-for-all construction. That is, entry
will be profitable unless
(2) plyl + P2Y1 - K(y1).
Thus, the prices in question cannot con-
stitute an equilibrium unless (2) as well as (1)
are satisfied.
Now, subtracting (2) from (1) we obtain
immediately
P2(Y2-y) K(y2- yi)
or
(3) p2 > K(Y2-Y1Y)/(AY2-Yj),

### ---Economics-1982-0-16.txt---
but, by the assumption that average con-
struction cost is declining, since Yi >0,
(4) K(y2-y1)/(y2-y1)> K(y2)/y2.
Substituting this into (3) we have at once
P2> K(Y2)/Y2
or
(5) P2Y2 > K(y2).
Inequality (5) is our result. For it proves
that any prices which satisfy equilibrium
requirements (1) and (2) must permit a sec-
ond-period entrant using the same tech-
niques to build capacity Y2 from the ground
up, at cost K(y2), to price slightly below
anything the incumbent can charge and yet
recover his costs; and that in doing so, the
entrant can earn a profit.
Thus, our intertemporal natural monopo-
list cannot quote, at time zero, any prices
capable of preventing the takeover of some
or all of his market. Moreover, this is so
despite the waste, in the form of replication
of the incumbent's plant, that this entails.
That, then, is the end of the formal argu-
ment, the proof that here the invisible hand
manifests weakness that is, perhaps, unex-
pected.
You will all undoubtedly recognize that
the story as told here in its barest outlines
omits all sorts of nuances, such as entrants'
fear of responsive pricing, the role of bank-
ruptcy, depreciation of capital, and the like.
This is not the place to go into these matters
for it is neither possible nor appropriate here
for me to go beyond illustration of the logic
of the new analysis.
IV. Concluding Comments
Before closing let me add a word on policy
implications, whose details must also be left
to another place. In spirit, the policy conclu-
sions are consistent with many of those
economists have long been espousing. At
least in the intratemporal analysis, the heroes
are the (unidentified) potential entrants who
exercise discipline over the incumbent, and
who do so most effectively when entry is
free. In the limit, when entry and exit are
completely free, efficient incumbent monop-
olists and oligopolists may in fact be able to
prevent entry. But they can do so only by
behaving virtuously, that is, by offering to
consumers the benefits which competition
would otherwise bring. For every deviation
from good behavior instantly makes them
vulnerable to hit-and-run entry.
This immediately offers what may be a
new insight on antitrust policy. It tells us
that a history of absence of entry in an
industry and a high concentration index may
be signs of virtue, not of vice. This will be
true when entry costs in our sense are negli-
gible. And, then, efforts to change market
structure must be regarded as mischievous
and antisocial in their effects.
A second and more obvious conclusion is
the questionable desirability of artificial
impediments to entry, such as regulators were
long inclined to impose. The new analysis
merely reinforces the view that any proposed
regulatory barrier to entry must start off
with a heavy presumption against its adop-
tion. Perhaps a bit newer is the emphasis on
the importance of freedom of exit which is as
crucial a requirement of contestability as is
freedom of entry. Thus we must reject as
perverse the propensity of regulators to resist
the closing down of unprofitable lines of
activity. This has even gone so far as a
Congressional proposal (apparently sup-
ported by Ralph Nader) to require any plant
with yearly sales exceeding $250,000 to pro-
vide fifty-two weeks of severance pay and to
pay three years of taxes, before it will be
permitted to close, and that only after giving
two years notice!
There is much more to the policy implica-
tions of the new theory, but I will stop here,
also leaving its results relating to empirical
research for discussion elsewhere.
Let me only say in closing that I hope I
have adequately justified my characterization
of the new theory as a rebellion or an upris-
ing. I believe it offers a host of new analy-
tical methods, new tasks for empirical
research, and new results. It permits reex-
amination of the domain of the invisible
hand, yields contributions to the theory of


### ---Economics-1982-0-17.txt---
oligopoly, provides a standard for policy that
is far broader and more widely applicable
than that of perfect competition, and leads
to a theory that analyzes the determination
of industry structure endogenously and
simultaneously with the analysis of the other
variables more traditionally treated in the
theory of the firm and the industry. It aspires
to provide no less than a unifying theory as a
foundation for the analysis of industrial
organization. I will perhaps be excused for
feeling that this was an ambitious under-
taking.
## Economics-1983-0


### ---Economics-1983-0-01.txt---
rx ;a_
.vic
_ f _
.... ..
_W+z; s_
BW '. i
F !
: ^
si F:
_.-: m a r>_E_
F' gi ... _
1
L ^ ^. L X ti:-;g9^
*_ . ..::St. ... _F ' . . PiF S o ' 3_,
+ . . 11 ?> fl Dis$: . o <_
OD
_
Sx s_
.. '' ze.
b:. _i. '.;
_I o < ..
B X.
o w.w.
s
a i *
_ _ 3 . ws.
_ a. | /
z
_E l,
!_ s c
p. '\ .
_ t \.
- e nL ? ;.Ki.
Su,_ i : X@.
':op9;
_ _ ,c>. .
_ _ - * -'''' '
_ X, :_-
_ _ .c-'. w
_w^j^ ,.
_ - - , ' t
_ zY Z a ! 2
_ w{s h .0:
-e:} | | .>.
_ .- __ 11 w o^
_ .?, _ | ..
s__ E _ - I n ... ,,:
{.f . _ N " ,,s, U:
<.\ .................. _ ' _ ?
_ ' _ K g :@,


### ---Economics-1983-0-03.txt---
When I began to study economics, in the
1930's, macroeconomics certainly existed, in
the works of such luminaries as Wicksell,
Fisher, Robertson, and the early Keynes. But
it was surely not recognized as a branch of
economics in which one might specialize; nor
was it regarded as necessary for the educa-
tion of an economist. Thus, like almost ev-
eryone else, I began professional life as a
price-theorist. The principal alternative was
to become an institutionalist; and that didn't
particularly attract me. Only later, and some-
what by accident, did I become a macro-
economist.
Ever since the emergence of macroeco-
nomics as a distinct and (almost) respectable
branch of analysis, there has been a con-
scious tension between macroeconomics and
microeconomics; much of this tension relates
to the roles and the behavior of prices and of
the price level. Surely, it cannot be said that
macroeconomics ignores prices and price
changes, as is sometimes suggested. Milton
Friedman and his monetarist associates and
followers-who are macroeconomists of the
first water-surely do not ignore prices. And
the patron saint of my kind of macroeconom-
ics, John Maynard Keynes, also certainly
paid a great deal of attention to both relative
prices and the price level. My concern with
prices here, however, is not with inflation,
but rather with the price-theoretical founda-
tions of macroeconomics. Essentially, I will
be discussing some of the roles that micro-
economists and macroeconomists see for
prices, and particularly for price changes.
Price theory has moved a long way since I
deserted it, and I no longer claim any exper-
tise in this area. But I have the impression
that many current problems both in micro-
and macroeconomics tend to be the same
problems-looked at from opposite sides of
the borderline between them. Thus I propose
to lead us on a stroll along some sectors of
that border, moving back and forth across it
from time to time, for there is no fence. And
I intend only a meander, not a mapping. The
spirit in which the journey is undertaken is
that this is really all one country, and strollers
should be welcome.
But it is not an imaginary country that I
propose we visit. We will see no Walrasian
auctioneers, although we will see many
markets that seem to work pretty well without
them. On the other hand, we will see very
few wage rates being frequently revised; and
many prices will look as though they were
being revised only to maintain fairly stable
markups over unit costs. In general, we will
observe that the population of this country is
neither very much brighter-nor much more
stupid-than you and I are, in our own
economic decisions.
Some aspects of the problems that I will
discuss are particularly important in an age
of inflation, and to the theory of inflation.
But I prefer to conduct most of my discus-
sion without explicit reference to changes in
the general price level. For almost all of the
matters that I will discuss primarily involve
relative prices; and it is simpler to deal with
them on the assumption of a constant price
level. That way, I do not need to keep repeat-
ing "real price."
I start with the prices and inventories of
standardized commodities.
I. Commodity Prices and Inventories
Economists often find it useful to think of
the quantities of a commodity supplied to a
competitive market as consisting of a supply
from current production plus a possible
supply from inventory; and the market de-


### ---Economics-1983-0-04.txt---
mand, similarly, as consisting of a demand
for current use or consumption plus a possi-
ble demand for additions to inventory. Any
market-participant's demand for additions to
inventory clearly should be based upon an
expectation that the price will increase suffi-
ciently over some future period, at least to
cover costs of storage plus interest for that
period. Any market-participant's willingness
to supply goods from inventory should be
based on an expectation that the price will
rise insufficiently over any future period to
cover costs of storage and interest for that
period. Since expectations of future prices
are never certain, the expected prices de-
scribed should include discounts to reflect
risk aversion, or premiums to reflect the
pleasures of risk assumption.
Given the conditions that permit or re-
quire the holding of inventories, inventories
may have either a stabilizing or a destabi-
lizing effect on the commodity's price, pro-
duction, and consumption. Traditionally,
however, economists have assumed that the
effect of inventories is to stabilize each of
these. We think of the wheat market, for
instance, where an entire year's new supply
(at least in either Hemisphere) becomes
available in a relatively short period of time.
Were the holding of inventories of wheat (or
wheat products) impossible, the market price
would have to fall low enough during the
harvest period to assure immediate consump-
tion of the entire crop. The price would then
rise high enough during the remainder of the
year to cut off all consumption-or else high
enough to make profitable the production
of wheat in greenhouses, and to reduce its
off-season consumption to the quantity so
produced. However, given the possibility of
storage of wheat or wheat products-by pro-
ducers, dealers, or intermediate or final con-
sumers-the price would normally fall only
enough during the harvest period to induce
the appropriate amount of inventory accu-
mulation. The price would then rise, during
the remainder of the year, as inventories
were drawn down, sufficiently to cover at all
times the costs of storage, interest, and the
assumption of risk from holding inventories.
Such seasonal price and inventory move-
ments often are approximately observable.
The recognition that not only seasonal but
also year-to-year variations may occur in the
harvest as a result of weather conditions or
civil disturbance, and that year-to-year varia-
tions may also occur in the demand for
wheat, reflecting, say, the "business cycle,"
will induce some or many market par-
ticipants to carry over inventories of wheat
(or of its products) from one crop year to the
next (or to reduce stocks previously carried
over). Stocks held will increase or decrease as
the current market price varies relative to
what is believed to be the current "normal"
or "long-run equilibrium" price: the price
that would exactly balance normal annual
new supply and normal annual consumption.
Through this process, not only seasonal
fluctuations but also year-to-year fluctua-
tions of market price and of consumption are
reduced, even in the presence of substantial
year-to-year changes in production or in fi-
nal demand. Through changes in inventories,
supply or demand in any particular year, in
effect, may thus borrow from past and/or
from future years' supply or demand.
As, and to the extent, that market par-
ticipants learn of new "events" affecting or
likely to affect either future normal produc-
tion or future normal demand, the rate of
inventory accumulation or decumulation will
be varied so as to produce a new time path
of price and current consumption, associated
with an expected new equilibrium of prices
and quantities. Needless to add, this behav-
ior is stabilizing with respect both to prices
and quantities: at least as compared to what
would have happened if inventories could
not exist, or if storage costs-or the interest
rate-were higher. And this activity clearly
increases economic welfare.
These activities of course reflect the behav-
ior now described as based upon "rational
expectations." Market participants have in
their heads a "model" of how supply and
demand affect market price over time; on
the basis of that model, and of all avail-
able information-including all new infor-
mation-about present and future produc-
tion and demand and the size of existing
inventories, agents buy for or sell from in-
ventories in ways that cause the market price
to move continuously toward its current nor-


### ---Economics-1983-0-05.txt---
mal, long-term, market-clearing level, taking
account of storage costs and interest, and
appropriately discounted for uncertainty. In-
deed, it was precisely in the context of rea-
soning about markets for storable individual
commodities (and agricultural commodities
in particular) that John Muth first presented
the concept that he called "rational expecta-
tions". ' In this particular microeconomic
context there can surely be no valid objec-
tion to rational expectations. But we must
not forget that the primary way in which
expectations- rational or otherwise-affect
current prices is precisely through affecting
behavior with respect to inventories, along
with sales or purchases for future delivery
(i.e., negative inventories) or through affect-
ing some other form of intertemporal sub-
stitution between, for example, labor and
leisure, now and in the future.2
Markets for commodities, of course, vary
widely in the extent to which inventories are
able to stabilize price or consumption. At the
one extreme is the traditional market for
fresh flowers. Holding inventories is, by defi-
nition, impossible. Random fluctuations in
the production of or the demand for fresh
flowers are thus fully reflected in daily prices.
And because the immediate response of
amounts supplied to price changes is zero, by
definition, and the response of amounts de-
manded to price is relatively small, price
fluctuations in fresh flowers may be sub-
stantial. Inventories cannot supplement
below-normal current production; nor can
inventories be accumulated to profit from a
below-normal current price or from an
expected above-normal future price.
At the opposite extreme are the markets
for the durable products of agriculture and
mining-for example, for wheat or tin. Here
storage costs are relatively low, and invento-
ries may easily reach the equivalent of one or
even several years' production. Under such
circumstances, it is not implausible to argue
that rational expectations and inventory
adjustments tend to stabilize prices and con-
sumption in the presence of random fluctua-
tions in supply or demand.3 On the other
hand, durable or " permanent" changes in
supply or demand alter the equilibrium price,
and, almost at once, the actual market price
begins to reflect that change.
II. Price Speculation
However, the existence of large inventories
also introduces the possibility of price insta-
bility arising from "speculation." Consider,
for example, the extreme case of gold, when
it is only a commodity, and not used as
money. Gold is obviously very durable. And
its consumption and its production in any
year, or even in any decade, are both very
small relative to the size of the total existing
stock. The costs of storage are relatively low.
It is also nearly indestructible: its services as
ornament or store of value are consumed
with little or no disappearance or dissipation.
Most of the gold that was ever mined pre-
sumably still exists, and is potentially avail-
able as an addition to the market supply
from new production-at prices deemed suf-
ficiently above equilibrium. Gold is currently
produced; and its rate of production does


### ---Economics-1983-0-06.txt---
respond to its relative price (and to the ex-
pected price that so strongly influences its
current price). But a year's production, even
at an historically enormous real price, adds
very little to the current market supply, com-
pared to that which is available from inven-
tories. Changes in the market price may af-
fect, at least modestly, the quantities of gold
demanded: by dentists, by manufacturers of
jewelry and objets d'art, or in industry (as a
conductor or chemical). But such changes in
quantities demanded are likewise small rela-
tive to the size of the stock; and even the
manufacture of gold objects does not really
remove them from the inventory of gold.
Indeed, unmined gold (and the shares of
gold mining companies) are in effect part of
the inventory, too.
Although the price of gold has some effect
on its rates of discovery and production, as
well as on its consumption (in the sense of
its complete and permanent removal from
potential market supply), these responses of
quantities produced and consumed are truly
minimal in comparison with the size of out-
standing inventories. Thus, the market price
of gold depends mainly on peoples' (or, in
the past, on governments') willingness at that
price to hold the immense existing inventory
of gold. And this means that the current
price of gold depends mainly on expectations
of its future price. As noted earlier, the cur-
rent price of a standardized commodity can
diverge from any expected future price only
by the relatively small costs of storage plus
interest (and the cost of assuming the risk of
an incorrect expectation). But, in the case of
gold, a changed expectation of future price is
not soon erased by a changed rate of gold
production, nor by an altered level of any
consumption that subtracts permanently
from the stock. There may always be some
normal, long-run equilibrium price of gold
that would exactly equate current production
and current consumption (in the sense of
permanent disappearance). But that normal
price does not discipline the actual market
price of gold in the way that the normal,
long-run equilibrium price of wheat disci-
plines its current market price. Rather-in
the absence of a fixed monetary price of
gold-its current price depends overwhelm-
ingly on the current expectation of what its
future price will be. And that future price
will depend on the expectation then of its
subsequent price.
Such a market is best characterized by
borrowing Keynes' parable (pp. 154-160) of
the beauty contest, which he used to explain
share prices. The price level of shares, he
suggested, depends on each market par-
ticipant's calculation of what the other par-
ticipants are likely to expect it to be. It is
analogous to the contest to choose a beauty
queen, he said, in which the prizes go to
those who select the candidate for queen
thought most beautiful by the largest num-
ber of other contestants. Instead of selecting
the candidate who is the most beautiful, each
contestant tries to calculate which candidate
is most likely to be chosen by other con-
testants. But once each realizes that others
will be choosing on the same basis, he is
forced to speculate about what the average
opinion will be of what the average opinion
is. And that speculation can be carried to
progressively higher degrees, Keynes sug-
gested. Given no more solid a basis than this
for valuing shares, said Keynes, the price of
shares can be almost anything-and is likely
at times to be highly unstable.
Why does anyone buy gold at $52 an
ounce-or at $520 an ounce? Why does any-
one sell it at that price? Because the buyer
expects that the price tomorrow will exceed
$52 by more than the cost of carrying an
ounce of gold; and the seller expects that it
may be less than $52 plus carrying costs
tomorrow. Each such expectation in turn
reflects buyers' and sellers' judgments about
what buyers and sellers will be expecting
tomorrow for the day after tomorrow. The
only other rational reason for buying or sell-
ing gold is the pure pleasure of risk assump-
tion-better known as gambling. And there
is surely much of that in the gold market.
Presumably, pure gambling has little net ef-
fect on the price, although it does raise the
incomes or employment of brokers.4


### ---Economics-1983-0-07.txt---
Now, what precisely is the basic difference
between the wheat and the tin markets, on
the one hand, and the gold and the share
markets, on the other, that lets us assume in
the wheat or tin case that rational expecta-
tions will normally stabilize prices and con-
sumption in the face either of random or of
predictable fluctuations in amounts supplied
or demanded, while in the gold case, there is
often destabilizing speculation?
The difference obviously has nothing to do
with price flexibility and continuous market
clearing; for these are trademarks not only of
the markets for wheat, tin, and pork bellies,
but also for gold (and for General Motors
shares). Rather, the difference is that in the
wheat and similar cases, the response of
quantities produced and/or quantities con-
sumed to price changes arising from shifts in
supply or demand can be large enough and
prompt enough to begin to move the price
toward its new equilibrium level within a
relevant time period; and that this response
therefore comes to be anticipated by market
participants. This prompt and substantial
stabilizing response of quantities produced
and consumed does not occur-and there-
fore it is not expected to occur-in the case
of gold. As a consequence, in the presence of
large inventories, price expectations dominate
price-level determination not only in the short
term, but even in the moderately long term.
The prices so determined are unlikely to
contribute either to the stability of produc-
tion or consumption, or to the equality of
production and consumption. They may thus
produce movements in actual inventories, the
price effects of which, however, have only
modest and long-delayed effects in reversing
such movements.
Clearly, wheat and gold are more-or-less
extreme examples of a spectrum of durable
commodities, capable of storage. At the
wheat end of that spectrum, the responses of
amounts produced and consumed to price
changes are strong and prompt. Market par-
ticipants come to expect them to occur, and
take actions with respect to inventories that
tend to stabilize prices around their equi-
librium level, including any expected new
equilibrium level. At the gold end of the
spectrum, the responses of amounts pro-
duced and consumed to price changes are
weak and slow, while inventories are very
large.5 Participants in such markets thus can-
not depend on price movements to be quickly
self-limiting. It is therefore not irrational for
some or many of them to speculate on the
direction of intermediate price movements.
Their speculation may often extend and ex-
aggerate price movements that had some
origin in changed supply or demand condi-
tions. Or it may extend and exaggerate price
movements caused by some random exog-
enous disturbance, or even by the actions of
a few large traders (for example, the Hunts
in silver).
Most commodity markets lie between these
extremes. In such intermediate markets, price
movements may sometimes be-perhaps or-
dinarily are-in the direction of a price that
tends fairly quickly to equate production and
consumption. At other times, price move-
ments may develop a cumulative momentum
in one direction, which can easily overshoot
the current long-run equilibrium price. Occa-
sionally, moreover, speculation can affect
even the most stable markets; and specula-
tive fevers can be transmitted from one
market to another.
The years 1971 through 1973 provide a
clear example of such speculation and of
such transmission.6 Coincidental crop failures
in wheat and coarse grains in several of the
main producing countries of the world-at a
time when world stocks were severely de-
pleted-caused grain prices to soar; this
helped to attract public attention to the then
popular "Club-of-Rome" fantasies of gen-
eral resource scarcity, which in turn helped
to transmit the speculative fever to still other
commodities. In a political environment in
which-partly for accidental reasons-mac-
roeconomic policies in a number of major
countries were unusually permissive, the
speculative rise in commodity prices soon
came to be reflected in wage rates and in-

### ---Economics-1983-0-08.txt---
dustrial costs. Given the inertia of inflation,
once it becomes embodied in wage rates and
industrial costs; given the fortuitous re-
sponse of the oil-producing countries when
awakened by the international inflation; and
given the perhaps appropriate, but surely
delayed, responses to inflation by monetary
and fiscal policymakers in many of the in-
dustrial countries, it is possible to under-
stand why the 1970's turned out to be such a
disappointing- even a disastrous- decade.
And commodity price speculation played
more than a small part in that disaster.
III. Rational "Price Bubbles"
The fact that rational expectations may
not preclude the existence for considerable
periods of speculative, self-maintaining price
movements toward zero or infinity has re-
cently been recognized in a rapidly expand-
ing theoretical literature of working papers
and a few published articles.7 Indeed, we are
seeing a "bubble" of papers on "rational
price bubbles." Whether rational expecta-
tions are or are not consistent with price
bubbles, however, seems to depend entirely
on what definition one gives to the "rational-
ity" of rational expectations. One may define
as rational any expectation that, if generally
acted upon, will turn out to be essentially
self-confirming. In that case, price bubbles
generated by the simplest of extrapolative
price expectations may be consistent with
rational behavior. On the other hand, one
may alternatively define as rational only
those expectations that fully incorporate an
understanding of " long-run" "market funda-
mentals": namely, the assumption by each
agent of rationally maximizing behavior by
each other agent, each responding to ob-
served changes in prices and quantities as
would occur in a market model of "long-run
equilibrium," although observed through a
screen of random, nonserially correlated,
short-run disturbances. Actions based on
such expectations thus tend to confirm the
expectations; and each confirmation rein-
forces further reliance up on the long-term
equilibrium model. There seems little room
for price bubbles in that version of rational
expectations.
But whether, and to what extent, market
fundamentals will, in fact, prevail, surely de-
pends, as I have argued above, on the dura-
bility of the commodity, its storage costs,
and particularly on the degree to which, and
the speed with which, its production and
consumption are affected by expected price.
Given the world as it is, I suggest that the
"fundamentals" do not always and every-
where prevail. Bubbles do occur, and are
important.
However, most or all of the new literature
on price bubbles appears to deal only with
price movements away from, or back to-
wards, the equilibrium price that reflects
long-run market fundamentals. It thus im-
plies that, when prices are, for any period,
approximately stable, they must therefore
be at or close to an equilibrium dictated
by market fundamentals-reflecting, at that
price, an approximate balance between the
expected supply from new production and
the expected demand for final consumption.
Price bubbles, in contrast, involve an extrap-
olation of expected price movements (how-
ever originating), causing further movement
in the same direction.
In my view, however, where the impacts of
price on amounts produced and consumed
are small, slow, and uncertain, a speculative
price-(i.e., a nonequilibrium price) is not
always or necessarily a moving price. The
price may rest for a considerable period of
time at-or fluctuate narrowly around-a
level far above (or below) any equilibrium
determined by market fundamentals. This
situation might represent either the extrapo-
lation of an originally accidental stability, or
a standoff between expectations of further
rise by some participants and the expectation
of fall by others.8



### ---Economics-1983-0-09.txt---
Under circumstances in which uncertainty
is overpowering, as Keynes suggested was
often the case for stock prices, a price may
remain approximately stable for a consid-
erable time on the basis of a tacit "conven-
tion," which market participants come to
accept. The convention amounts to the as-
sumption that
... the existing state of affairs will con-
tinue indefinitely, except in so far as
we have specific reasons to expect a
change... For, if there exist organized
investment markets,... an investor can
legitimately encourage himself with the
idea that the only risk he runs is that of
a genuine change in the news over the
near future, as to the likelihood of which
he can attempt to form his own judg-
ment, and which is unlikely to be very
large. For, assuming that the conven-
tion holds good, it is only these changes
which can affect the value of his invest-
ment, and he need not lose his sleep
merely because he has not any notion
of what his investment will be worth
ten years hence.
[General Theory, pp. 152-53]
Thus, the price of gold might well, for a
considerable period of time, fluctuate nar-
rowly around a level far from the equi-
librium price at which amounts produced
and consumed would in the long run be
equal. And so, although to a considerably
lesser extent, could the price of wheat or tin.
Yet such a period of approximate stability
might at any time be upset by a major,
self-maintaining movement in either direc-
tion.
IV. Macroeconomic Inventory Theory
Let us now turn to some of the macroeco-
nomic implications of this microeconomic
theory of commodity prices and inventories.
First, and most important, is to recognize
that there is nothing in standard price the-
ory-even when we expand it to take account
of speculative demands for inventories, price
bubbles, or of the possible transmission of
speculative fever from one market to an-
other-that implies that the aggregate stock
of inventories, and the rate of aggregate
inventory accumulation for an entire econ-
omy should exhibit any systematic variation
over time. Random disturbances to supply
and/or demand for particular commodities
or products might lead to periods of net
accumulation or net decumulation of inven-
tories of those products. But the aggregation
of many time-series, each subject to random,
non-serially-correlated variation, produces
only a time-series with proportionally smaller
variation. Thus, several years of systematic
general accumulation of inventories, fol-
lowed by substantial periods of general
decumulation of inventories, finds no basis
in conventional price theory.
Yet one of the most obvious macroeco-
nomic facts of life is the existence of pro-
nounced cycles, both in the size of aggregate
inventories and in their rate of accumulation.
Indeed, of all of the conventional subaggre-
gates of real national product, the one that
shows the greatest decrease (not merely in
percentage but in aggregate dollar amount)
between periods of business expansion and
of business contraction is, almost invariably,
that of the net addition to business invento-
ries. This total typically goes from a large
positive amount at business cycle peaks to
a large negative amount at business cycle
troughs. This difference exceeds the typical
cyclical decline in business investment in
plant and equipment, in residential construc-
tion, in purchases by consumers or govern-
ments, or in net exports. The existence of
these pronounced cycles in aggregate inven-
tory accumulation has long challenged mac-
roeconomists to develop theories that might
explain this phenomenon. The response to
this challenge has produced a second and
macroeconomic literature about inventories,
that is almost completely nonintersecting
with microeconomic price theory.
In this macroeconomic inventory litera-
ture, prices and price expectations are rare-



### ---Economics-1983-0-10.txt---
ly mentioned. This second literature deals
primarily with work-in-process and manufac-
tured product inventories, including inven-
tories held by wholesalers and retailers-
although it may also embrace commodity
inventories held by manufacturers or proces-
sors (but not by producers and dealers). The
earliest versions of this literature described
inventories as being held, increased, or re-
duced as the result of production or ordering
decisions that were based upon expectations
of future changes in quantities produced or
demanded-expectations generated mainly
by recently experienced levels of production
or sales. It purported to describe the determi-
nants, for example, of the desired and actual
stocks of coal and iron ore held by steel
mills; of the desired and actual inventories of
finished steel held by mills, steel warehouses,
or steel-using manufacturers; of the desired
and actual inventories of automobiles held
by producers and dealers; and of the desired
stocks and actual stocks of steel bedsprings
held by department stores. In early versions
of this macroeconomic literature, inventory
decisions were shown to be capable of hav-
ing highly destabilizing macroeconomic ef-
fects-particularly when expectations of fu-
ture sales were modelled as responsive in
particular ways to experienced levels and
changes of sales, while production responded
to orders and expected sales.9
This literature, of course, belongs to a
universe of discourse in which prices (includ-
ing wage rates) do not clear markets continu-
ously, but rather adjust slowly to evidence of
gaps between amounts supplied and de-
manded. Or they may be "administered" on
the basis of working rules of thumb based
mainly on costs or on other prices. In this
universe of discourse, such pricing rules are
not necessarily irrational, given the limited
extent of knowledge, and the experience of
past instability. And, since prices so estab-
lished do not typically cause production and
consumption to move quickly into approxi-
mate equality, market participants do not
expect that prices will so move, and therefore
they do not so move. Rather, production and
sales are brought toward equality primarily
by changes-delayed changes-in planned
rates of production or purchase, that reflect
observed or expected changes in quantities
consumed or used in production, and that
are designed to restore or to maintain effi-
cient levels of inventories. Indeed, microeco-
nomic theories of rational quantity adjust-
ments to unplanned differences between
production and sales began to be developed
in the early 1950's, and have increasingly
supplied a formal basis for macroeconomic
inventory theory.'0 These fluctuations in
quantities produced or purchased may lead,
in the face of relatively inflexible prices and
wages, to further self-reinforcing changes in
production, purchases, and employment-
self-reinforcing through income effects on
consumption and "accelerator" effects on in-
vestment: perhaps dampened by interest rate
effects on investment, to the extent that the
supply of money does not accommodate
changes in the demand for it.
Indeed, if such patterns of quantity re-
sponses at the level of the firm to unplanned
changes in inventories become standard-
ized-because such patterns do, in time, re-
verse imbalances between production and
sales-it may become entirely rational to
expect such patterns of quantity movements
to occur at a macroeconomic level. Rational
expectations based on such "theories" could
then lead to inventory, production, and
purchase decisions that help to perpetuate the
macroeconomic instability of production, con-
sumption, and inventories.
Persistent and massive macroeconomic in-
ventory cycles deny either the existence of
rational expectations, or, more plausibly, the
ability of such expectations to stabilize out-
put and employment. As the persistence of
such cycles comes to be expected, and their
amplitude to be accepted, it is not surprising
that full flexibility of prices comes to be seen
by many firms as a useless and unprofitable
course of conduct.


### ---Economics-1983-0-11.txt---
by many firms as a useless and unprofitable
course of conduct.
V. The Demand for Commodities and
the Demand for Labor
I referred earlier to the case (exemplified
by fresh flowers) in which the holding of
inventories is by definition impossible, and
in which the entire response to unexpected
shifts in supply or demand must be a price
change-at least, given perfectly competitive
markets. This case may be only a trivial
curiosity when we deal with commodities.
But it is a matter of considerable importance
when we recognize that an inability to store
output is, by definition, the case for ser-
vices-whether they are final products, or
are services used in production. The largest
class of services, of course, is the labor
services used for the production of goods. If
the price of labor services was a flexible,
continually market-determined price, the
price of labor services should respond rather
sharply to random shocks to the demand for
goods produced using labor. Indeed, prices
of labor should, in general, be more variable
than prices of commodities, on the reason-
able assumption that the supply of labor is
less price elastic than the supply of cooperat-
ing factors of production."
In fact, of course, the evidence is undeni-
able that wage rates normally fluctuate far
less than do prices. This anomaly seems to
require an "institutional" explanation, or,
more fundamentally, a theory that explains
the institutions that produce these results.
Such explanations often run in terms of
" set-up," "transactions," and "information"
costs, that make implicit or explicit contracts
mutually beneficial both to workers and to
employers, despite the fact that such con-
tracts necessarily imply substantial intermit-
tent unemployment, as well as occasional
labor shortages.12 An extensive literature has
developed along these lines, greatly advanced
in Arthur Okun's posthumous Prices and
Quantities: A Macroeconomic Analysis. The
conclusion of Okun's analysis, of course, is
that models of the labor market that assume
continuous market clearing- and therefore
continuous full employment-are erroneous.
And, as a result, critiques of government
stabilization policy-as powerless to improve
economic welfare even when properly used
(or unable to damage the national interest
when badly used)-necessarily fail.
VI. A Price-Theoretic Version of
the Business Cycle
One well-known critique of stabilization
policy is that associated with Robert Lucas
and Robert Barro. However, Lucas and Barro
accept the reality of a business cycle, involv-
ing serially-correlated changes in real output,
although they still deny the ability of mone-
tary or fiscal policy to affect the economy.
The price-theoretic approach of Lucas and
Barro stands, however, at an opposite pole
from that of Okun. For instead of trying to
model the imperfect flexibility of wage rates
in a real world, wages are sometimes as-
sumed not to exist. In one version (1977) of
Lucas' theory of the business cycle, we have
a world reminiscent of J. B. Say, in which
there are no firms, no hired labor, but only
"yeoman farmers."'3 Thus, there are only
prices and profits-no wage rates. Actually,
this model could also accommodate simple
manufacturers- craftsmen without hired
workers-as did the model world of Say.
Needless to say, competition is perfect, and
information free and nearly complete.



### ---Economics-1983-0-12.txt---
However, this very simple world has a
central bank, or its ruler has a printing press.
When bank loans or printing press money
are used to finance a public purpose (such as
an increment in the Prince's consumption)
goods prices are bid up. However, each yeo-
man farmer or craftsman is likely to confuse
the rise in his own selling price as a rise in
his price relative to prices for the products
and services of other yeomen. Such relative
price changes occur for various reasons, and
are familiar to each of them. Each therefore
works harder in the presence of inflation,
and produces more, so as to permit him to
consume more of the output of his fellow
farmers or craftsmen, whose prices he pre-
sumes not to have risen. Of course, the Prince
has already consumed more of their output,
too; and their prices, too, have risen, But
until each yeoman discovers that the rise in
his price is general rather than relative, real
GNP increases. Soon, however, each learns
that there has been no increase in his real
price, and finds only the sour taste of infla-
tion. The boom ends. It can be repeated as
soon as the short memories of all citizens are
erased. 14
What can this have to do with the business
cycle in a world in which yeoman farmers
and craftsmen are replaced by firms with
hired employees? Very little, I think. For, in
even the simplest possible version of this
more familiar world, there have to be two
kinds of prices, not one: prices for goods,
and prices for labor. Increased production
now requires increased inputs not only from
proprietors, but also from their workers. Un-
der standard price theory, in order for
employers to wish to hire more labor services,
they must believe that product prices have
risen relative to wages; but in order for exist-
ing workers to respond to inflation by
working longer hours, and other potential
workers to enter the labor force, requires
that they interpret what happens as a rise in
the ratio of wages to prices. It was a nice
enough trick to be able to fool each yeoman
about his own real price; but it is an even
nicer trick for an inflation to fool both em-
ployers and workers- in opposite direc-
tions -about the movement of the real wage
paid by one and received by the other!'5
I suggest that more may be learned about
cycles from Knut Wicksell's discussion of
business fluctuations, seventy-five years ear-
lier. Wicksell understood that, even in a simi-
larly simple world, there needed to be not
merely one kind of price level-nor merely
two kinds-but actually three: price levels
for goods, for labor, and for loans. And
whether or not there was a Prince with a
printing press, there were competitive banks,
aggressively lending at a flexible price to
businesses. Given a plausible (although in-
completely specified) lag structure, Wicksell
showed that banks' competition in money
creation might initially reduce the price for
loans; and their continuing money creation
might keep it depressed for a time. Through
this means, investment, financed by bank
credit, could exceed ex ante saving, crowding
out consumption. The result, of course, was
also inflation, unanticipated by all. Once the
limits of money creation were reached, the
boom collapsed.
At roughly the same time, in another part
of Europe, J. A. Schumpeter was describing
a rather different source of instability. His
bourgeois prince- the innovating entrepre-
neur-driven by new technological, mana-
gerial, or marketing ideas that promised
abnormal profits, repeatedly upset the gen-
eral equilibrium: accommodated, of course,
by an elastic banking system. To be sure, his
entrepreneurial activities-his "creative de-
struction"-would soon generate an infla-
tion that had to subside before the next
wave of innovation might again disturb the
economy.
'41n another version (Lucas, 1975), there are genuine
firms selling products and purchasing labor and capital
inputs; but production is scattered among noncom-
municating islands, using capital that is immobile and
labor that is randomly mobile (between periods), while
increments of money are distributed stochastically
among the separated markets from period to period.  This schema permits changes in money to create fluctua-
tions of real output (of capital goods); but it is not at all
clear (to me) why or how the postulated source of such
"cycles" bears any relationship to the cycles of the "real
world."


### ---Economics-1983-0-13.txt---
Of course, the disturbances of macroeco-
nomic equilibrium that were visualized by
Wicksell and Schumpeter, and by Fredrich
von Hayek, R. G. Hawtrey, D. H. Robert-
son, the early Keynes (and so many others)
were, in the end, mainly disturbances of the
price level, although they normally left a
permanent legacy of a larger capital stock,
newer technology, and increased human
capital.'6 However, most of these pioneers
recognized that the price level did not auto-
matically, instantaneously, and proportion-
ately reflect every change in the stock of
money or the output of goods; for instance,
many recognized that prices did not fall suf-
ficiently promptly in recessions to avoid non-
frictional unemployment of labor and/or
machines. And such unemployed resources
then permitted a subsequent expansion of
real output, once the next boom began.
VII. Price-Theoretic Models of
Aggregate Investment
Most business cycle theories-or, more
broadly, most macroeconomic theories of the
"medium run"-from the time of Wicksell
or even earlier, have thus been built on
more-or-less elaborate price-theoretical con-
siderations, related essentially to investment;
and mainly to fixed investment. For, clearly,
it is investment-not consumption or pro-
prietors' labor-that is the primary source of
medium-run macroeconomic disturbance and
instability. Although (as noted earlier) sharp
fluctuations in the rate of investment in in-
ventories contribute more to U.S. business
cycle recessions and to the early stages of
business recoveries than do fluctuations in
plant-and-equipment investment, the latter
typically contribute significantly more to ex-
pansions of GNP from cyclical troughs to
peaks than does inventory accumulation.
Moreover, in the medium and longer run,
fluctuations in inventories are governed by
most of the same factors that govern plant
and equipment expenditures.
There are many price levels-relative price
levels-important for investment in plant,
equipment, and normal inventories. They in-
clude:
1) The price level for loans: some partic-
ular rate of interest, or some average of rates,
at which investment can be financed;
2) The demand-price level of new capital
goods, reflecting their physical productivity,
the prices of the goods produced by their
use, and the supply-prices of cooperating
factors of production;
3) The supply-price level for new capital
goods, sometimes taken as a function of their
rate of production;
4) The supply-price and the demand-price
levels of entrepreneurship and innovation;
5) The supply-price levels of risk and/or
uncertainty bearing, by investors and lenders;
6) The level and nature of the prices
imposed by government; taxes and their struc-
ture; and
7) The price level of ownership of exist-
ing enterprises; that is, the level of share
prices.
The question is not which among these
price levels are relevant for investment: all of
them (and others) are doubtless relevant to
some degree. Rather, the question is: which
are "strategically" important? Which are the
price levels, the changes in one or more of
which relative to another or others are pri-
marily responsible-in the real world-for
macroeconomic stability or instability, real
and nominal?
I can illustrate the wide variety of price
theoretic explanations of investment by ref-
erence to three familiar but quite different
examples. 7


### ---Economics-1983-0-14.txt---
I remind you of Martin Feldstein's com-
plex analyses of the interaction of tax laws
and inflation as affecting the profitability
of investment. Alternatively, there is Dale
Jorgenson's "neoclassical" investment the-
ory, which carefully models the relationship
among all of the prices and quantities that
enter into dynamic profit-maximizing invest-
ment decisions.'8
As a third example, there is James Tobin's
theory, suggested by Keynes, that focuses on
the relationship between the aggregate market
value of the marketable debt and equity
claims against existing enterprises, and the
aggregate cost of reproducing, at today's
prices, the assets of those enterprises. The
ratio of these two global magnitudes has
come to be designated as "q."
I propose to conclude these comments on
price-theoretical explanations of investment
with a few remarks on the q theory. The
Keynes-Tobin approach makes the volume
of aggregate investment dependent upon
-indeed, ordinarily taken as proportional
to-the excess of q over 1: where q is the
ratio of the market value of enterprises to the
replacement cost of their assets. The market
value of enterprises includes the value both
of equities and debts, as currently priced in
security markets; the replacement cost of
their assets is the reproduction cost of exist-
ing plant, equipment, and inventories at cur-
rent price levels."9
However formulated in detail, the q theory
of course employs much of the same infor-
mation that is used in other macroeconomic
theories of investment. For example, most
investment theories incorporate a bond-
market interest yield, presumably to repre-
sent the cost of borrowed long-term funds,
or the alternate return on owned funds. Some
investment theories may use short-term in-
terest rates, as well, to represent the cost of
(or the alternative return on) funds borrowed
to finance inventories or other working
capital, or to finance the purchase of capital
goods while awaiting more favorable rates in
the long-term market. The q theory incorpo-
rates interest rates as they affect the value of
marketable debt claims against enterprises.
This use of interest rates in the q theory is
thus conventional in investment theory.
What is essentially unique about the q
formulation is its inclusion of the market
value of stocks: the price level of ownership
of corporations. This can be thought of as an
indirect measure of the cost (or opportunity
cost) of equity funds.20 Given the typical
volatility of share prices, medium-run move-
ments of q are often or perhaps ordinarily
dominated by changes in the prices and thus
the market value of outstanding shares.
With that in mind, let me recall to you my
earlier discussion of the speculative demand
for and supply of storable commodi-
ties-gold was the specific example. You
recall my borrowing Keynes' parable of the
beauty contest to describe such markets. You
also recall that this parable was, in fact,
Keynes' analogy for the price determination
of equities.
In recent years, economists have been pay-
ing greatly increased attention to stock
prices-a subject largely avoided by econo-
mists after the debacle, in and after 1929,
both of share prices and of economists' fore-
casts of share prices. The revival of
economists' interest in stocks has involved
the development and application of the
"capital asset pricing model" and associated
"portfolio theories," and, most recently, the
attempted application of rational expec-
tations theory to stock prices.

### ---Economics-1983-0-15.txt---
However, Robert Shiller's recent paper
"Do Stock Prices Move Much Too Much to
be Justified by Subsequent Changes in Di-
vidends?" appears to demolish the possibility
that movements of U.S. stock prices can be
explained by the rational expectations of
share holders.2' For over a century, real stock
prices appear to have fluctuated far more
than any plausible change in the rational
expectation of real dividends or earnings.
Shiller does not attempt to characterize the
source of the greatly excessive volatility of
stock prices. But, surely, it is possible that
speculative price bubbles, upward or down-
ward, based upon the extrapolation of nomi-
nal share-price levels and movements, and
on the effort to profit (or to avoid loss) from
such movements, supply some part of the
explanation. Another piece of the explana-
tion for recent stock prices may well be
Franco Modigliani's and Richard Cohn's
"inflation-illusion" theory-itself clearly in-
consistent with rational expectations.
The rational expectations theory, at least
as applied to individual commodities, as-
sumes that there exists, at all times, some
long-run equilibrium price-that price which
would equate amounts produced and con-
sumed. Market participants can and do have
at least a rough idea of what this price is;
moreover, their individual estimates of this
price are basically similar, for all have essen-
tially the same information, and use essen-
tially the same model of how that price is
determined.
Those who attempt to apply the concept
of rational expectations to the stock market
rarely state their understanding of what is
the equilibrium price level for shares-or of a
particular share-that it would be rational
for participants to expect. Is it the level of
share prices at which net new issues of shares
would be zero? Or would it be the level of
share prices at which net private investment
would be zero? The level at which net private
investment would equal net saving at full
employment? The level at which investment
might maintain the economy on a Golden
Rule growth path? Or is there some concept
of a less-fundamental, less-long-run equi-
librium level of share prices which market
participants can be expected to understand
and quantitatively approximate? If there is
no such concept of equilibrium share-price
level, how can there be a unique rational
expectation of share prices?
A simpler course is to admit that we have
no very precise concept of an equilibrium
level of share prices, but to argue that we can
nevertheless predict the direction and rate of
movement over time of that equilibrium,
whatever it may be. The rate of movement
might, for example, be expected to ap-
proximate the rate of growth of profits or of
dividends per share. (This was Shiller's de-
vice.) This may suffice for rough tests of the
ex post rationality of historical share price
movements. But it offers essentially zero
guidance to the purchaser or seller of a
particular stock at a particular time. He must
guess whether the prices of particular stocks
will rise or fall, over some less than infinite
horizon, from where they stand today. Is it
strange that he is more concerned with the
correctness of his guess about what other
buyers and sellers are expecting will happen
to prices of those particular shares, and to
the market averages? Is there a better de-
scription than the "beauty contest" parable?
Actually, Keynes' description of the de-
termination of stock prices is far more de-
tailed and substantive than I have here de-
scribed it, and I recommend its occasional
rereading. However, there is no reason to
suppose that Keynes in 1935 had the last
word on stock prices. Henry Wallich, an
acute observer, who began his distinguished
career on Wall Street, has recently written
about the "Radical Revisions of the Distant
Future" that occur from time to time in the
stock market, and for which one cannot find
rational explanation, in any narrow sense of
that term. His explanation for at least a part
of the most recent "radical revision" -since
about 1973-runs in terms that I can per-
haps best describe as "sociological":
One might guess that [the reasons for
this massive change in investment at-
titudes] have something to do with

### ---Economics-1983-0-16.txt---
the professionalization of the securities
business. Very likely this tends to ho-
mogenize views, increasing the herd in-
stinct among bulls and bears, respec-
tively. The rewards/penalties system
for professionals works in that direc-
tion. It is dangerous to be wrong in
support of an unpopular cause....
Professionals have made the market
efficient, in the narrow sense that there
is nothing of predictive value to be
learned from the past data of the
market. It is far from clear that they
have made it rational. There may be
something to be learned from the his-
tory of mass delusions in the market
after all. [p. 38]
Modigliani and Cohn's suggestion may be
one such systematic mass delusion.
As one close to retirement, and one of
quite a number of us (I suspect) who have
left most of our retirement resources tied up
in CREF, I would of course, be pleased if
stock prices should return closer to their
average past relationship to earnings or divi-
dends. But I would not, I confess, find it a
confirmation of the rationality of my own
expectations. Personally, I long ago decided
that being an economist was not merely no
advantage, but probably a disadvantage in
the security markets; and I have never per-
sonally participated in them. I have been
fearful, I suppose, of succumbing, myself, to
the herd instincts that I seem to observe
there. The broker who tells his customers
that Joe Granville is stupid, but that they
must pay attention to him because others
will, both assumes and encourages behavior
only one level removed from that of lem-
mings.
Because stock prices are not fully rational,
either in the large or even in the small,
sharp-eyed members of several generations
of my graduate students learned (not from
me) to support themselves in reasonable
comfort by playing on trivial systematic
anomalies that they had found in share price
movements. They succeeded, presumably, by
acting exactly as others do, but a trifle sooner.
Indeed, the lemming instinct affects par-
ticipants in other markets. One current ex-
ample is that of the international bankers,
whose loans to particular LDCs were safe
because-but only so long as-other inter-
national bankers recognized exactly the same
source of safety.
Whether one describes investment deci-
sions in terms of the q formulation or in
some other way, prices in security markets
necessarily affect the volume of aggregate
investment. And, because such prices are
clearly not fully rational, investment is a
potential and actual source of exogenous dis-
turbance of macroeconomic equilibrium; and
successful government stabilization policies
are not, by definition, precluded.
Our stroll along the border between micro-
and macroeconomics comes to an end. What
can we conclude? I conclude that the rational
expectations model of economic behavior
adequately describes an important range
of economic activities, where prices adjust
smoothly and efficiently to clear markets and
to stabilize production and consumption over
time. But rational expectations do not ade-
quately explain other kinds of markets, where
speculative prices may systematically tend to
overshoot changing equilibrium levels: nor
yet another kind-including most labor
markets and many "customers markets"
-where price changes tend systematically to
undershoot changing equilibrium levels,
whether because of an inability to develop
efficient long-term contracts, the existence of
bilateral monopoly, or merely because of the
rapid pace of unpredictable technological,
institutional, or other exogenous change. All
of the resulting aberrant forms of microeco-
nomic behavior may in some sense be indi-
vidually "rational"; yet their macroeconomic
effects are often perverse.
Nevertheless, we economists do our best
to understand our world, and to discover
those dependable regularities of behavior
-whether or not fully rational-that pro-
vide the basis for economics theories, which
we can then use to prescribe policies, whether
these policies are of laissez-faire or of selec-
tive intervention. All forms of dependably
regular behavior that we seek to discover and
to describe-and not merely those that are
fully rational-are equally important parts
of the social science of Economics, that
Marshall once defined simply as "a study of


### ---Economics-1983-0-17.txt---
mankind in the ordinary business of life;
... that part of individual and social action
which is most closely connected with the
attainment and use of the material requisites
of wellbeing" (p. 1, emphasis added).
## Economics-1985-0


### ---Economics-1985-0-03.txt---
. .. [T]he world may have its reasons for
being non-Walrasian.
Robert Solow
The vast majority of our profession share
a common view on most microeconomic
policy issues. But we are widely split over
macroeconomic theory and policy. Our con-
census on micro issues arises from a shared
model of how markets work in the long run.
Our division on macro issues stems from a
number of reasons, the emphasis on which
has shifted over the years. In recent times the
main disagreement has centered on how
markets perform in the short run. In particu-
lar, we cannot agree on why nominal wages
are sticky on the face of aggregate demand
shocks. The traditional view argues that
wages are structurally sticky. The new classi-
cal macroeconomists argue that wages are
fundamentally flexible. But the rational ex-
pectations of economic agents, grounded on
past experience with attempts at employ-
ment-supporting monetary policy, have pro-
duced the observed wage stickiness. Intro-
duction of a changed policy regime, based on
a stable growth path for the money supply or
some similar rule, would-so the argument
goes-eventually change the pattern of ex-
pectations and eliminate the stickiness.
A large and rapidly expanding body of
recent research on implicit contracts, prin-
cipal-agent relationships, and related sub-
jects has begun to flesh out our knowledge of
why wages are sticky. Almost universally the
implicit contract and related literature con-
cludes that optimal behavior implies a good
deal less wage flexibility in the face of changes
in the marginal revenue product of labor
than would occur in the spot auction markets
of the Walrasian model. But this literature
deals with the stickiness of real and relative
wages in response to shocks of various kinds.
It seems to have little to say about the mac-
roeconomic stickiness of nominal wages. A
micro theory of real wage stickiness may
help explain the difficulty of adjusting to
sudden large changes in aggregate supply
conditions like the two oil shocks of the
1970's. But the more familiar problems fac-
ing macroeconomic theory and policy have
to do with the ability of the economy to
adjust to aggregate demand shocks where
nominal wage stickiness is a major barrier to
successful adjustment. And here the im-
portant question is what, if anything, does
the new research imply for the behavior of
nominal wages? It is to this subject I want to
give my attention.
A road map will be helpful. After sum-
marizing the existing literature, the first
section concentrates on relative wage ad-
justments, and argues that under optimal
arrangements for the determination of wages,
relative wages while not rigid will be sticky.
They will adjust only gradually to relative
changes in the conditions facing individual
firms. The paper then argues that contrary to
general opinion, relative wage stickiness nec-
essarily produces aggregate nominal wage
stickiness; if wages move sluggishly in re-
sponse to the relative conditions facing indi-
vidual firms, they will move sluggishly in
response to aggregate nominal shocks. Sever-
al mechanisms that might produce a flexible
wage response to nominal shocks, given sticky
relative wages, are considered and rejected
-various forms of indexing and rational
expectations. Finally the "external" nature
of the gains from nominal wage flexibility
is invoked against the criticism that attribut-
ing cyclical unemployment to nominal wage
stickiness implies nonrational behavior on


### ---Economics-1985-0-04.txt---
the part of employers and workers. Macro-
economic shocks will gradually overcome the
relative wage stickiness and move the aggre-
gate nominal wage level in the desired direc-
tion, but the transitional costs are large.
I. Some Relevant Features of the Implicit
Contract Literature
By now the literature on implicit contracts
is so large and so diverse that I cannot do it
justice in a brief summary. But it is necessary
to sketch out a few elements of that research,
paying particular attention to several key
features that bear on the relationship be-
tween wage behavior and aggregate demand
shocks.
The flexible-price, market-clearing model,
in which economic agents are price takers
and prompt quantity adjusters, would be a
useful paradigm in a very particular kind of
world. In this world labor and product
markets would be characterized by a great
deal of homogeneity, and so individual trans-
actions would be carried on in very "thick"
markets. There would be no reason for pre-
serving a continuity of relationships between
workers and firms, customers and suppliers,
lenders and borrowers. Workers would be
interchangeable; the marginal revenue prod-
uct of a particular class of workers would be
the same regardless of the firm to which the
worker was attached. Either labor effort could
be easily monitored or it would be com-
pletely proportional to labor hours paid for.
And, wherever commitments had to be made
for the future, expectations about the im-
portant variables entering into the decision
could be drawn from fixed stochastic distri-
butions, knowledge of which, in turn, could
be derived from the recurrent nature of past
events. As well as being unbiased, forecasts
could significantly improve on coin-flips.
The world that we are trying to model,
however, is in fact different in several fun-
damental ways. Most importantly, in a
substantial part of the economy there are
large returns to maintaining the continuity of
association between workers and firms.
Workers acquire nontransferable, firm-
specific skills; and some of the cost of the
acquisition may be paid by the firm. They
acquire knowledge about the nonwage attri-
butes of a job through experience on thal
job. Continuity of association also provides
firms with hard-to-come-by knowledge about
the reliability and productivity of specific
workers. Additional transition, search, and
moving costs are incurred by workers and
firms when the association is broken. Sub-
stantial bilateral monopoly rents to continu-
ity are thus generated among firms and their
experienced work force.
Risk aversion introduces another reason
for continuity of association. For at least
some range of possible variations in the eco-
nomic environment facing a firm, it is likely
to be less risk averse than its workers. But
the relevant insurance contracts cannot be
traded separately from employment con-
tracts, and so continuity of association be-
comes a joint product with insurance. Fi-
nally, in the real world, labor time is not
synonymous with performance. Monitoring
worker performance or effort is costly, but
the payment of higher than the "going wage"
will bind workers to the firms with an incen-
tive to avoid shirking. And the particular
workers who "survive" the monitoring are
those who have found the premium sufficient
to avoid monitorable shirking, a piece of
valuable information to the firm flowing from
continuity of association.
Realizing the benefits from long-term
worker-firm relationships requires, of course,
some sort of explicit or implicit agreement
between employers and workers on the terms
of the relationship, especially with respect to
wages and employment opportunities. Several
problems in modeling these long-term work-
er-firm agreements have dominated the re-
cent literature. First, when the marginal rev-
enue product of labor changes, how are wages
and employment to be adjusted while still
preserving contractual relationships? Second,
since firms are much better able than workers
to observe the marginal product of labor and
since contingent contracts directly tied to the
various states of nature cannot practically be
designed, how can contract terms allow for
some flexibility in meeting changing condi-
tions without giving employers incentives
to provide false information about labor's
marginal product? This is the problem of


### ---Economics-1985-0-05.txt---
asymmetric information and has given rise to
the modeling of incentive-compatible con-
tracts. Third, since explicit written contracts
between unions and employers cover only a
small part of the workers involved in long-
term relationships, what keeps either workers
or firms from violating the implicit agree-
ment or exploiting their half of bilateral mo-
nopoly situations when conditions are fa-
vorable to do so? Analysis of this issue has
given rise to the concept of a firm's labor
market "reputation," or brand-name capital,
fear of losing which provides an enforcement
constraint. This is the problem of en-
forcement.
Three major strands of the literature on
implicit contracts can be discerned, each of
which emphasizes one of the rationales for
the continuity of association (without neces-
sarily denying the existence of other aspects),
and each of which deals somewhat differ-
ently with the problems cited in the prior
paragraph.' The earliest version of implicit
contracts emphasized the role of risk aver-
sion, firms being either risk neutral or less
risk averse than workers to fluctuations in
their income.2 Firms thus offer risk-sharing
contracts that improve social welfare relative
to spot auction markets. Another body of
research stresses transactions costs and asset
specificity -that is, the acquisition of firm-
specific skills by workers, and specific and
valuable knowledge about each other by both
firms and workers.3 This approach also em-
phasizes the asymmetry of knowledge be-
tween firms and workers about the marginal
revenue product of labor, and its influence
on the nature of the contract. Still a different
emphasis is given in the efficiency wage4
literature to an assumed positive correlation
between the level (or the career profile) of
wages on the one hand and the "effort" or
productivity of workers on the other.5
While there are substantial differences
among these various approaches, they all
conclude that, under optimal contracts, real
wages will be smoothed in the face of changes
in the marginal revenue product of labor
relative to what would be predicted by an
auction market. And all of them provide a
rationale for the existence of ex post Pareto
inefficiency and involuntary unemployment.
II. Some Extensions to Implicit Contract Theory
We can distinguish several categories and
subcategories of changes in economic cir-
cumstances, the wage response to which must
be accommodated by social conventions and
informal understandings that we call implicit
contracts. Let us consider first some of the
implications of contract theory as it deals
with the response of wages to changes in the
relative conditions facing individual firms or
labor markets. For that purpose I define
relative changes to be those which occur on
the assumption that the perceived general
level of opportunities facing workers-call
it W-remains unchanged in real and nomi-
nal terms. (The relevant W is, of course, in
real terms. But since we are here abstracting
from any aggregate disturbances, real and
nominal W are the same.) In turn there are
two kinds of relative changes in economic
conditions that implicit contracts must allow
for; changes which are realizations of a prob-
ability distribution known at the time the
contract is entered, and those stemming from
developments to which no basis could be
found for assigning probabilities.



### ---Economics-1985-0-06.txt---
To deal with implicit labor contracts
covering the long tenures that are typical in
U.S. industry, it is necessary to make the
currently out-of-fashion distinction between
risk and uncertainty. Most of the mathemati-
cal modeling of implicit contracts has as-
sumed that workers and firms base their
agreements on a known probability distribu-
tion (presumably commonly held) of the rel-
evant variables, most importantly the mar-
ginal revenue product of labor or some
related variable. The distribution of the mean
expected bilateral monopoly rents from con-
tinuity is decided at the beginning of the
contract on the basis of the known distribu-
tion of possible economic environments that
will be faced over the life of the contract,
and the contract then specifies the behavior
of wages (and in some cases employment) as
the realization of that distribution occurs.
The wage is either rigid or changes sluggishly
in the face of these changing realizations.
But recent research on the surprisingly long
lengths of job tenure in the United States
casts doubt on the usefulness and sufficiency
of this assumption. Robert Hall (1980) has
estimated that, in 1973, half of all work in
America was done on jobs whose completed
tenures were fifteen years or more. And for
men alone the relevant completed job tenure
was twenty-five years! Douglas Wolf and
Frank Levy (1984) reached very similar con-
clusions on the basis of a 1979 survey. The
contracts, rules-of-behavior, and social con-
ventions that make possible such long associ-
ations must be such as to allow wages to
adjust appropriately in response to changes
in circumstances whose probability of occur-
rence could not be determined in advance. In
other words, the informal agreements which
make possible long-term association between
workers and employers must take into
account Knightian uncertainty about future
possible outcomes. With respect to many of
possible states of the world, over such a long
period of time, there is no basis in past
statistical regularities for knowing the distri-
bution. As William Nordhaus (1976) points
out, contracts must take account of changes
in the economic climate (i.e., when the
parameters of the distribution shift) as well
as changes in the economic weather (i.e., as
realizations of the known distribution).
Most of the possible long-term changes to
be faced by firms and workers do not result
from the cyclical variance of aggregates, like
national income and output, but from
changes in relative variables potentially re-
sponding to a bewildering permutation of
possibilities. Seen in 1973, what were the
rationally expected probabilities of the 1974
and 1979 oil price increases, the introduction
and growth of personal computers, or the
Chrysler brush with bankruptcy? Compared
to workers, firms may indeed be relatively
risk neutral to temporary changes in income
following some known distribution. But no
firm is so risk neutral and has such unlimited
access to capital as to enter upon or honor
contacts specifying rigid wages or some fixed
function of wages on employment over very
long periods,6 when no rational basis exists
for specifying the distribution of outcomes.
Some of the modern wage literature (for
example, Hall and David Lilien, 1979; San-
ford Grossman and Oliver Hart, 1981) mod-
els a contract with a "lump-sum" distribu-
tion of the rents-that is, an amount to be
paid the workers regardless of unemploy-
ment status-and a marginal compensation,
paid when the worker is employed and itself
an agreed upon increasing function of the
level of labor input. Employers then de-
termine employment by maximizing profits
in the light of the marginal compensation
schedule. In these approaches, the climatic
changes to which I refer would be an occa-
sion for changing the basic lump sum distri-
bution of the rents.
A workable distinction can thus be made
between those contract provisions which deal
with wages in the face of moderate and
temporary changes in the marginal product
of labor that are perceived as the realization
of a known probability distribution and those
provisions which deal with climatic and per-
manent changes, the probability of whose


### ---Economics-1985-0-07.txt---
occurrence cannot be estimated before the
fact. With respect to changes in labor de-
mand that are perceived to be consistent
with a previously known distribution, im-
plicit contract theory predicts either rigid
wages or-in the models like those of Hall
and Lilien and Grossman and Hart-wages
which move less than spot auction markets
would predict but are positively correlated
with the level of employment. But the infor-
mal agreements or generally accepted con-
ventions that we call implicit contracts must
also provide for changes in circumstances
whose probability cannot rationally be es-
timated at the time workers enter into the
contract. These climatic changes in economic
circumstances can be of several broad kinds.
They might involve a relatively long-term
change, because of shifts in demand or costs,
in the rents available to be shared by a firm
and its workers. Long-term changes in the
relative demand and supply of particular
occupations or in particular local labor
markets will also call for changes in relative
wages around a given W.
If the present value of the stream of bene-
fits to workers (wages and employment prob-
abilities) flowing from continuing with the
firm begins to decline relative to the alterna-
tive combination of initial investment costs
and future rents that can be generated at
other firms, it is appropriate that contract
terms signal the information to workers, so
that they can make the relevant comparisons,
and decide whether to quit the firm. Simi-
larly, if a substantial and permanent decline
occurs in the relative demand for labor by
occupation or locality, wages ought to signal
the change. Conversely, economic circum-
stances might increase the rents to be divided
making it optimal for the firm to enlarge its
share of the relevant labor market pool of
experienced workers. In that case, the signal
of higher relative wages ought to be trans-
mitted to attract from other firms or occupa-
tions workers for whom the lost rents are less
than the improved opportunities.
An efficient determination of wages must
thus cope with two hard-to-reconcile sets of
facts. Because long continuity of association
between firms and specific workers confers
substantial benefits on both parties, rent-
sharing arrangements that offer protection
against exploitation and promote such con-
tinuity are profitable. But the period of as-
sociation is so long that the probability dis-
tribution of circumstances requiring changes
in wages is largely unknowable. And so the
rules and conventions governing wage de-
termination must be flexible enough to allow
response. Seen in this light, the terms "im-
plicit contract" may be misleading. It is, I
think, useful to think of wages as being
set and periodically revised by firms with-
in limits imposed by a set of social conven-
tions, concepts of equity and fairness, and
informal understandings. These conventions,
concepts, and understandings provide sub-
stantial, if imperfect, protection against ex-
ploitation but allow flexibility to deal with
Knightian uncertainty.
While very lengthy association requires
relative wage adjustments in response to
" unforeseeable" changes in circumstances,
other characteristics of the labor market sug-
gest that those adjustments will tend to be
gradual and delayed. It would be hard to
account for the long job tenures that we
observe unless the combination of positive
returns to association and the cost of transi-
tion were quite sizeable. The quantitative
evidence on the magnitude of explicit turn-
over costs suggests that they are large. Daniel
Mitchell and Larry Kimbell (1982), for ex-
ample, report a recent estimate, based on a
survey of Los Angeles firms, that firms' own
costs of turnover (exit costs plus replacement
costs) averaged $3,600, $2,300, and $10,400
for production, clerical, and salary-exempt
workers, respectively.
Under these circumstances, erroneous sig-
nals can have asymmetrical results. Changes
in wages undertaken on the mistaken iden-
tification of a temporary change in cir-
cumstances as a permanent change can cause
a substantial loss to workers and firms from
the unnecessary scrapping of "investment"
and the incurring of other turnover costs.
Entire rent streams are wiped out to the
extent that workers having transferred to
other firms cannot return when the mistake
is discovered. Moreover, once experienced
workers do change jobs, it is likely to take
several tries before they find another long-
tenure job. Hall (1982), for example, shows
that in 1978 a worker aged 45-49 who was in


### ---Economics-1985-0-08.txt---
a new job had only a 20 percent probability
of holding that job as long as five years.
While the large magnitude of rents for
experienced workers tends to provide some
room for errors, workers are presumably
arranged along a spectrum with respect to
their own evaluation of potential opportuni-
ties elsewhere. As a consequence, the losses
from the errors will be a continuous positive
function of the size of the errors. Errors of
the opposite type-failing to introduce a
contract change to meet a permanent alter-
ation in the climate-can be reversed at a
much smaller cost. Some workers will have
remained too long with a particular firm,
while a smaller group will have lost income
from the higher layoffs associated with this
type of error. But these losses are likely to be
much smaller than the loss of the rent stream
itself, unless the error persists for a long
time.
Thus, given Knightian uncertainty about
economic conditions over the long length of
job tenures, implicit contracts must allow for
the possibility of relative wage changes in the
face of climatic changes in external condi-
tions. But the interest of both firms and
workers dictates that those changes occur
only after enough information has been
accumulated to warrant a high probability
forecast that the change is permanent. To
justify a substantial wage adjustment, it is
not sufficient that the firm act on unbiased
forecasts-they must also acquire some con-
fidence in the accuracy of the forecasts.
One might object to this line of reasoning
on grounds that failure to adjust wages
quickly enough while the evidence is accu-
mulating that the change in circumstances is
permanent, is itself likely to send out wrong
signals. If, for example, wages are slow to
adjust downward when the demand for labor
falls, employment will decline. Why will
workers not take this as a signal that the
future stream of benefits from staying in the
current job have declined relative to earlier
anticipation? There are a number of reasons
why this objection is not valid. First, a change
in wages is known immediately, while it takes
some time to begin to realize that an actual
change in employment reflects a shift in the
long-term distribution of employment prob-
abilities. Second, the common practice of
layoffs subject to recall is a way for a firm to
signal that the lower employment is expected
to be temporary. Third, significant down-
ward changes in relative wages are not lightly
made. Given the inability of workers easily to
assess the magnitude of the available rents,
firms are deterred from exploiting the bi-
lateral monopoly relationship through the
damage they might do to their "reputations"
and the future increases in employment costs
thereby imposed. Since reputation is a fragile
asset, and since workers are naturally less
likely than firms to interpret current facts as
warranting a relative wage cut, firms must
wait until a substantial body of evidence
points in the required direction. The efficiency
wage literature emphasizes the unfavorable
productivity consequences of relative wage
reductions that turn out to be unwarranted.
And, since firms know that it is difficult to
reduce wages once they have been raised,
they do not want to make a mistake in the
upward direction. As a consequence, wage
changes that survive these barriers are much
more clearly interpreted as a signal that the
stream of future rents has changed than are
variations in employment.
Efficient implicit wage contracts, in the
presence of uncertainty, must also have the
characteristic that they minimize "haggling
costs." They should not lead to a constantly
renewed battle over the division of the rents.
Frequent struggles would waste resources,
possibly reduce productivity, and erode
scarce reputation capital, thereby reducing
the probability of long-tenure associations.
These considerations argue that significant
relative wage adjustments to meet perceived
permanent changes in condition be an infre-
quent occurrence and not lightly changed
once made.
In sum, modern contract theory concludes
that relative wages will tend to be quite
sticky in comparison to predictions from the
auction market model, in the face of changes
in conditions that are the realizations of
known probability distributions-what I
have loosely called temporary changes. But
the existence of very lengthy job tenures and
the large gains from continuity suggest that
the social conventions and informal agree-


### ---Economics-1985-0-09.txt---
ments which we call implicit contracts must
provide for adjustments in wages that move
towards market clearing in response to un-
foreseeable permanent changes in relative
economic conditions. Finally, however, the
substantial penalties which can be suffered if
firms and workers respond to erroneous sig-
nals by prematurely severing association call
for informal arrangements and agreements
that produce a very slow and cautious ad-
justment of wages even to what ultimately
turn out to be permanent changes in relative
conditions.7
It is not surprising, given the large social
returns to continuity of association and the
very great difficulty of distinguishing tem-
porary from permanent changes in economic
circumstances, that society should have de-
veloped social conventions and informal
agreements that minimize the sending of pre-
mature signals for a reallocation of re-
sources.
III. Response to Aggregate Demand Shocks
So far we have considered a world in
which only relative or local changes are per-
mitted, a world in which the nominal and
real value of the general wage level, or the
wage "norm," was fixed. Now impose ag-
gregate demand shocks on such a world,
optimal adjustment to which requires a
change in the path of average prices and
wages. (For simplicity of exposition we will
be considering only aggregate demand
shocks, and exclude aggregate shocks to the
supply curve, like those arising from OPEC-
imposed oil price increases or from crop
shortages. We can thus assume that the equi-
librium solution will not call for changes in
aggregate real wages.) An efficient system of
implicit contracts must obviously provide for
adjustments in the nominal wages of individ-
ual firms when changes occur in the average
level of nominal wages, W. Under the social
conventions and understandings which gov-
ern wage determination, there is a rebuttable
presumption that-barring the existence of
circumstances which call for changes in real
and relative wages-nominal wages in each
firm will be adjusted in line with observed
changes in prices and wages generally. But
this process of wage determination does not
generate prompt and flexible adjustment of
aggregate nominal wages to nominal shocks.
A change in the average level of wages is the
product of changes in wages by individual
firms. To the extent that individual wage
adjustments must wait on changes in the
average, aggregate nominal wage flexibility
will not be a characteristic of the system.
And, as discussed below, this is also true, but
to a somewhat lesser degree, of the wage
response to price changes. Given the sub-
stantial costs of sticky nominal wages to
society as a whole and to individual firms
and their workers, is there not some other
adjustment mechanism which would gener-
ate a prompt and flexible nominal wage re-
sponse, preserving relative wages but produc-
ing the desired nominal flexibility?
Several lines of inquiry suggest themselves.
First, why are not nominal wages explicitly
indexed to some aggregate nominal indica-
tor, producing the appropriate change in W
in response to aggregate demand shocks?
Second, even with relative wage stickiness,
would not rational firms and their workers
forecast the ultimate equilibrium change in
W and promptly set individual wages ac-
cordingly? And, finally, if that is not feasi-
ble, why do implicit contracts not permit
swifter and larger nominal wage adjustments
by individual firms under the force of ag-
gregate nominal shocks?


### ---Economics-1985-0-10.txt---
Let us start with the issue of indexing
wages in individual firms to the general price
level. In the United States, wages are not
widely protected against changes in price by
explicit indexing formulae. In 1983, only 58
percent of union workers were covered by
COLAs. On the average, the ones that were,
received protection against only 53 percent
of the changes in the CPI. Jo Anna Gray
(1978) and Stanley Fischer (1977) examined
the conditions under which indexing would
or would not be optimal for individual firms
given the assumption that wages once set are
not renegotiated for some period. The main
conclusion from this research is that, in the
face of real (as opposed to nominal) shocks,
indexing, by freezing real wages, produces
real wage results that are not optimal for the
firm. Given the probability that nominal and
real shocks are both likely to occur, Gray
shows that partial indexing will be an opti-
mal choice. Moreover, even nominal shocks
are likely, during the transition to a new
equilibrium, to have nonneutral effects; the
firm's product price and the Consumer Price
Index may not move in parallel. As a conse-
quence, indexing would have unwanted real
effects even in the face of monetary shocks.
While we have seen that some degree of real
wage stickiness is optimal, the absence of full
indexing even in multiyear union contracts
indicates that the opposite extreme- auto-
matic guarantees of a fixed real wage over
several years-is not a workable approach.
Within-year indexing is virtually nonex-
istent in annual union contracts and in the
annual wage adjustment cycle followed by
the vast bulk of nonunion firms. Under im-
plicit contracts, changes in the path of aver-
age wages and prices in the economy as a
whole or in relevant submarkets are com-
monly agreed to constitute a major element
in determining the size of those annual wage
adjustments. But, in the United States, it is
almost universally the practice not to make
the relationship to the price level or to aver-
age wages an explicit and automatic one,
either within the year or over longer periods.
And, as noted earlier, in those multiyear
union contracts where indexing is found, that
indexing is almost always less than complete.
Haggling costs are apparently minimized by
making periodic wage adjustments that si-
multaneously take into account nominal, real,
and relative factors, rather than by fixing the
nominal relationship in a formula and sep-
arately adjusting for changes in real and
relative conditions.
In any event, even if wages were fully
indexed to prices, they would not produce
highly flexible nominal wages in response to
aggregate demand shocks. The cumulative
costs of wage indexing, in the face of real
shocks and the transitional nonneutrality of
nominal shocks, would be severely ex-
acerbated if the indexing were instantaneous.
As a consequence, the indexing we do ob-
serve-except in countries which have devel-
oped extremely rapid and sustained inflation
-typically involves a substantial lag be-
tween observed price changes and wage ad-
justments. Such indexing only guarantees a
gradual response of wages to aggregate de-
mand shocks in proportion as prices them-
selves are flexible in the face of constant
wages. Even if prices were competitively de-
termined, the economy would still have to
work its way through a series of price-wage-
price reactions in each one of which prices
fell, relative to wages, by an amount depend-
ing on the slope of the marginal cost curves.
And prices do not move with such frequency
or flexibility. Arthur Okun (1981) has care-
fully elaborated the reasons why, in the
customer markets which predominate in
modern economies, prices are not likely to
move quickly and easily up and down a
marginal cost curve. Robert Gordon (1981)
has elaborated how the highly articulated
input-output relationships of modern econo-
mies tend to slow the price reaction to ag-
gregate demand shocks. And George Akerlof
and Janet Yellen (1984) have recently shown
that in less than perfectly competitive markets
inertial price-setting behavior in response to
a shock may impose only second-order losses
on the firms who follow such behavior, even
though the macro result may be first-order
losses for the economy.8 Everything else

### ---Economics-1985-0-11.txt---
being equal, indexing wages to prices would
provide some nominal wage flexibility in the
face of nominal shocks. But if wages are
otherwise sticky, indexing them to prices
would still yield a very gradual iterative pro-
cess of demand inflation or disinflation.
Granted the obstacles to indexing wages to
prices in implicit contracts, and the in-
sufficiency of that arrangement-even if
feasible-to produce prompt nominal wage
adjustments, why are not implicit contracts
indexed to some aggregate like nominal GNP
or the money supply? Such an arrangement
might seem to be a way to approximate the
role of the Walrasian auctioneer, automati-
cally generating W at a level to clear the
aggregate supply-demand balance, while rel-
ative wages continued to be set under im-
plicit contracts along lines suggested earlier.
In fact, of course, we observe no such
arrangement anywhere in the world, and a
little thought supplies a number of reasons.
For purposes of indexing wage contracts to
nominal GNP, some agreed-upon process
would have to be found for separating "dis-
turbances" in nominal GNP from the trend
increases consistent with full employment at
a stable inflation rate. Anything that altered
the parallel growth of average and marginal
labor productivity, or the growth of full em-
ployment labor inputs, would change the
trend and require the contracts to be renego-
tiated. Robert Gordon (1981, 1983) has
identified a number of reasons, why, even if
the appropriate split could be made between
trend and disturbances, indexing wages to
nominal GNP would not be feasible in im-
plicit contracts. If prices themselves are not
completely flexible relative to wages, declines
in nominal GNP under an indexed system
would produce long periods with unwar-
ranted real wage decreases. And, since the
costs and hence the prices of the typical large
firm depend on the costs and prices of a long
and heterogeneous chain of suppliers, index-
ing wages on nominal GNP would only in-
dex part of an individual firm's costs.
Workers would rightly be skeptical that such
an indexing system would quickly move
prices down proportionally with wages.
The problems of automatic indexing to
some other nominal aggregate, like the mon-
ey supply, are even worse since the relation-
ship between any other aggregate variable
and the equilibrium full employment wage
level is still more complex and unstable than
it is in the case of nominal GNP. And unless
all firms could somehow agree on a common
translation formula for indexing purposes,
nominal demand shocks would produce a
wide dispersion of unwarranted changes in
relative wages. (This point is elaborated fur-
ther in the paragraphs that follow.) More
complex explicit indexing formulas can be
imagined, but are no more feasible than sim-
ple ones. The two parties to a contract would
be subjecting themselves to very great uncer-
tainty in agreeing to a given information set
and forecasting model as the basis for the
indexing. It takes a very large run of data
to sort systematic error from noise in eco-
nomic time-series. And so agents would have
huge space for disagreement about the ap-
propriate information set and the relevant
model for translating information into fore-
casts. Alternative choices could lead to biased
outcomes, whose bias could not be de-
termined for a very long time. (The ap-
propriate order in which to enter variables in
a vector autoregression model is hardly the
subject for fruitful labor negotiations.) In
short, feasible state-contingent contracts can-
not be designed to replace the Walrasian
auctioneer as a means of coordinating the
system's response to nominal shocks.9
In the absence of explicit state-contingent
contracts, can nominal wage flexibility be
rescued by a rational expectations model of
wage determination? Why do not individual
firms and their workers rationally forecast
the change in the equilibrium path of aver-
age wages (W) expected to result from a
nominal shock, and promptly change wages
accordingly, recognizing that their actions
involve no decision to change relative wages?



### ---Economics-1985-0-12.txt---
Stochastic errors in forecasting could gener-
ate temporary wage "errors" and departures
of employment from its natural rate. But
nominal wages would fundamentally be
flexible.
A rational expectations approach to the
determination of the aggregate nominal wage
and price level, however, cannot simply be
carried over into a world of sticky relative
wages. There are several reasons why this is
so. In the first place, in the new classical
model it is not the expectational element
that generates aggregate nominal wage flexi-
bility. Rather, a prompt response of aggre-
gate nominal wages to nominal shocks is
guaranteed by the perfect ex ante flexibility
of relative wages in auction markets. In these
models a downward nominal demand shock
generates a prompt and "neutral" change in
the path of nominal wages precisely because
of individual workers' presumed willingness
to underbid wages, shading their bids and
offers in the face of excess supplies, to the
point where markets are cleared. In the auc-
tion-market model, workers or groups of
workers are willing to accept lower wages in
the face of excess supply even when errors in
expectations lead them to misperceive the
entire wage cut as a relative one. In the event
of such misperceptions, some labor supply is
withdrawn but nominal wages still fall. And
as soon as the misperception is corrected,
wages quickly fall by the remaining amount
necessary to eliminate excess labor supply
and clear labor markets. In the world of
implicit contracts I have described earlier,
however, the absence of substantial relative
wage flexibility eliminates this basis for
prompt nominal wage flexibility.
In the absence of auction markets with
their relative wage flexibility, the achieve-
ment of aggregate nominal wage flexibility
becomes a prisoner's dilemma problem. But,
since wages are not completely rigid under
implicit contracts, it is not possible that indi-
vidual firms and their workers forecast the
ultimate equilibrium response of average
wages to nominal shocks, promptly adjust
their own wages to it and thereby solve the
prisoner's dilemma in favor of nominal wage
flexibility? I think not. Two key features of
implicit contracts interact with one central
feature of rational forecasts to reduce sharply
the feasibility of commonly shared expecta-
tions about the equilibrium W as a surrogate
for Arrow-Debreu contingent claims con-
tracts. First, firms are wage setters, not wage
takers; second, frequent haggling over wage
changes is very costly to the development of
mutually beneficial long-term relationships
between workers and firms; and third, fore-
casts of equilibrium wage and price levels are
subject to substantial stochastic error and
forecast outcomes are likely to be widely
distributed over the population of wage-set-
ting firms.
In a world of auction markets, the fact
that forecasts of individual agents are widely
distributed around the "true" mean is for
most purposes irrelevant. In his seminal
article (1961), John Muth pointed out that
cross-sectional differences in expectations
posed no problem for the theory because
their aggregate effect would be negligible so
long as deviations from the rational forecast
by individual firms were not strongly corre-
lated with each other. In auction markets,
specific prices or wages are not determined
by individual forecasts. But, in a world of
implicit contracts with firms as wage setters,
they would be. The dispersion of individual
forecasts concerning the equilibrium nominal
wage W, and therefore the dispersion of indi-
vidual wage decisions, would often be a wide
one. Robert Lucas' words about the role of
rational expectations in shaping the actions
of economic agents are relevant in this re-
gard:
Neither will [rational expectations] be
applicable in situations in which one
cannot guess which, if any, observable
frequencies are relevant: situations
which Knight called 'uncertainty'. It
will most likely be useful in situations
in which the probabilities of interest
concern a fairly well defined recurrent
event, situations of 'risk' in Knight's
terminology. [1977, p. 15]
Changes in the path of nominal wages, how-
ever, have not simply, or even primarily,
been driven by recurrent patterns of endoge-


### ---Economics-1985-0-13.txt---
nous events, at least in recent years. The
Vietnam War, two massive oil shocks, the
introduction of floating exchange rates, and
the institution of a new monetary regime in
the United States in 1979 have dominated
events. Even if the vast majority of firms
held a broadly similar view of the way the
economic world works, the very great macro-
economic uncertainty and the stochastic
variance of prior forecasts around the actual
outcomes would guarantee a wide dispersion
of individual forecasts whenever large shocks
occurred.
A wide dispersion of the forecasts of indi-
vidual economic agents and the experience of
errors in prior forecasts would have a
number of consequences. In the first place,
given the large room for disagreements about
the forecast, we have to rule out on moral
hazard grounds implicit contracts under
which workers, prior to actually observing
a deterioration in employment conditions,
would accept employer forecasts of a declin-
ing equilibrium nominal wage as the basis
for a downward wage adjustment. But even
waiving this difficulty, the large dispersion of
individual forecasts would result in wide-
spread unintended relative wage changes,
even if all firms and their workers accepted a
wage adjustment based on the firm's equi-
librium forecasts. Because of both risk aver-
sion and the consequences to firms and
workers that follow from erroneous signals,
these changes could impose significant losses
on the parties. Yet, a high frequency of wage
changes is also costly, so that errors would
tend to persist for some time. Indeed, giv-
en the incompleteness and imperfections of
current information, and the murkiness of
the variable being forecast-the equilibrium
nominal wage level-there would be sub-
stantial room for disagreement among the
parties as to whether or not a prior forecast
had or had not been in error. Finally, to the
extent that "bad" experience with forecasts
caused some firms and workers to reduce the
forward-looking element in wage setting, the
unreliability of forecasts for those who used
them would become greater. It would be-
come increasingly less rational to base indi-
vidual wage decisions on the assumption that
others were forecasting the equilibrium
adjustment and promptly adjusting wages
accordingly. Thus, without the "policing"
mechanism of relative wage flexibility, a sys-
tem that relied on rational expectations fore-
casts of the equilibrium wage outcome would
be unstable.
In sum, under implicit contracts, wide-
spread tying of individual wage decisions to
expectations about equilibrium aggregate
wage outcomes is not a feasible way of antic-
ipating the optimal adjustment to nominal
shocks. The policing mechanism of ex ante
relative wage flexibility is absent, so that
nominal wage flexibility becomes a prisoner's
dilemma problem. And prompt rational
expectations "indexing" to the equilibrium
outcome is no solution to that problem, since
it would increase haggling costs, produce
unwanted relative wage changes, and become
increasingly an irrational action on the part
of individual firms.
In the absence of widespread indexing
to some nominal aggregate, or to the ratio-
nal expectation of the equilibrium wage norm
W, wages must find their way to a lower level
as the product of specific decisions among
individual firms and their workers, in a pro-
cess constrained by the same social conven-
tions and informal agreements that dictate
the change in relative wages under implicit
contracts. In a world of price and wage
setters, firms and workers observe demand
shocks principally in the form of changes in
their own physical quantities- sales first and
then output and employment-and in the
context, initially, of an unchanged perceived
level of W. The dynamics of the process by
which firms adjust from one level of the
work force to another can, as described by
Okun and by George Perry (1980), generate
modest wage changes in response to the ag-
gregate shocks. Beyond this, the change in
external pressures for wage adjustment must
be large enough and last long enough to
satisfy the constraints imposed by long-term
implicit contracts on "permanent" wage
changes. Finally, to the extent that these
changes become substantial and widespread,
enough to yield a long-term change in the
perceived level of W, the whole nominal


### ---Economics-1985-0-14.txt---
wage structure around which individual
adjustments occur will be changed.
There are several points to note about this
process. The major gains, in terms of higher
employment, that came from lowering wages
in the face of downward aggregate demand
shocks do not accrue to particular workers in
particular firms as the result of their own
actions. Rather, the gains accrue through the
effect of generalized lower wages in reducing
prices, raising real money balances and
thereby increasing aggregate demand. Once
the assumption of flexible auction markets
and a competitive bidding down of wages by
individual workers is abandoned, it is no
longer valid to level against sticky-wage the-
ories the charge that they imply an irrational
failure on the part of economic agents to
pursue unexploited gains from trade. Without
the Walrasian auctioneer, the individual firms
in an economy are, as noted earlier, in a
prisoner's dilemma. The large comparative
statics gain from an aggregate nominal wage
cut does not translate into such a gain seen
from the point of view of individual firms.'0
The potential gain they see is the one that
would accrue from making a relative change.
They will indeed make such changes, but
slowly and cautiously, acting under the con-
straints on relative changes spelled out
earlier.11 Only as the perceived long-term
level of W falls will the situation be differ-
ent.
Since what is important for nominal wage
adjustment is the perceived level of W, ex-
pectations about its future value will, of
course, be relevant. Within the constraints
imposed by implicit contracts, wages in indi-
vidual firms have to be adjusted to deal with
changing conditions. Since wage changes are
difficult and impose strains on long-term re-
lationships, the wage once set has to last for
a while, typically at least a year (and under
union contracts often longer). The expecta-
tions that workers and employers have about
the future course of average wages and prices
will therefore exert an important influence
over the current wage decision. I do not want
here to join the controversy over the extent
to which wage setting is backward or for-
ward looking. But what is central to my
message is that the relevant forecast does not
assume prompt adjustment to a new equi-
librium wage but rather the more hesitant
and gradual process described above.
The appropriate framework for analyzing
the aggregate behavior of wages, therefore, is
not one in which certain macroeconomic im-
perfections-information gaps or mispercep-
tions about the general wage and price level
-prevent the market-clearing adjustment of
wages, which themselves are perfectly flexi-
ble in the face of relative disturbances. The
essence of the behavior of wages in response
to aggregate demand shocks is just the op-
posite. Macroeconomic shocks break through
the short-run stickiness of wages and prices
in the face of relative disturbances to pro-
duce the aggregate adjustments, albeit slow
and gradual ones, that we do in fact observe.
There is a nice paradox in all of this. A
prompt adjustment of nominal wages to ag-
gregate demand shocks, leaving relative
wages unchanged, can be produced only by a
system of highly flexible relative wages. Con-
versely, the existence of sticky relative wages
yields long transitional periods in which firms
are adjusting individually to nominal shocks,
and produces, as a side effect, changes in
relative wage and prices.
IV. Final Reflections
The large costs which accompany disinfla-
tion arise from the fact that society has to


### ---Economics-1985-0-15.txt---
send out the same kind of initial signals-
changes in the volume of sales-when it
wants a reallocation of resources as it does
when it wants a change in the general level of
wages and prices. In the first situation, given
the substantial efficiencies which flow from
long-term associations of suppliers with
customers and firms with workers, very cau-
tious and sluggish changes in wages and
prices are the optimal response to signals. A
large part of the adjustment is optimally
taken up as temporary variations in slack
adjustments in hours, layoffs and rehires,
inventory building and depletion, and ration-
ing of various kinds. Indeed, a large part of
economic life is dominated by the social
conventions, institutions, and patterns of be-
havior that have evolved to avoid the chaos
and inefficiencies that would result from con-
tinuous market clearing.
The signals which firms initially receive
when aggregate demand shocks occur are the
same as those for a resource transfer, but an
exactly opposite response is wanted-large
changes in wages and prices and small
changes in quantities or slack. Since the bulk
of the disturbances to which individual firms
and workers must adjust are relative or local
in nature, and since over long periods of
time micro efficiency tends to outweigh ag-
gregate resource utilization as a source of
economic welfare, wage- and price-setting
institutions have developed with a bias to-
ward the sluggish response called for by con-
siderations of micro efficiency. The cyclical
behavior of the aggregate wage and price
levels unfolds from the gradual overcoming
of that bias.
In the long run, those features of economic
relationships which make short-run price and
wage stickiness optimal and which rationally
prevent continuous market clearing disap-
pear. Specific assets are converted to capital.
Attrition and learning change the mix of
skills. Random changes get smaller com-
pared to systematic changes. The private re-
turns from specific customer-supplier and
worker-firm attachment shrink relative to the
returns from making appropriate adjust-
ments to changes in tastes, technology, and
other external developments. The rationally
based barriers to market clearing crumble.
We economists are indeed correct to insist on
the long-run efficacy of markets and the util-
ity of the market clearing paradigm as a way
of explaining long-term market allocations.
But we need not abandon the premise of the
rational maximizing calculus in order to ex-
plain the structural stickiness of wages and
prices and the failure of markets to clear in
the short run. Both phenomena-long-run
market clearing and short-run stickiness-
ultimately derive from the same rational
aspects of human behavior.
Some of the consequences of this recog-
nition are nevertheless very troubling for
economic theory and theoretically informed
empirical research. In the new classical eco-
nomics, there is no need for empirical re-
search to determine how wages and prices
respond to demand shocks, given expecta-
tions about the general price level. Pure
theory-the auction-market model-dictates
how prices and wages behave. Empirical re-
search is needed principally to tell us some-
thing about the formation of expectations on
the general price level.
While contract theory and related research
has been developing rationally based founda-
tions for structural wage and price stickiness,
the work to date is essentially in the form of
existence theorems. That is, it tells us why
sticky wages are consistent with the rational
calculus. But it does not give us a theoretical
basis for specifying the two basic compo-
nents of macro wage adjustment: What
"laws" do firms follow, under implicit con-
tracts, in adjusting their wages, assuming the
stability of W, the wage norm? And what
does it take to produce a perceived "perma-
nent" change in that norm?
A full and complete microeconomic foun-
dation to wage adjustment with the power of
the auction-market model may never be
forthcoming. If that is so, we may have to
look to regularities derived from macroeco-
nomic empirical research to infer microeco-
nomic behavior. But this raises another set of
problems. While forward-looking expecta-
tions play much less of a role in the macro
wage adjustment process I have outlined,
they are not completely absent in forming
perceptions about the wage norm. Hence the
force of the Lucas critique, though weakened,


### ---Economics-1985-0-16.txt---
does not disappear. The new classical eco-
nomics simply assumes that structural behav-
ior is market clearing, and hence claims to be
able to identify the expectational effects of a
particular policy regime. In the absence of
such an a priori assumption, however, how
does one go about separately identifying the
expectational from the structural elements in
wage formation? I do not have the answer.
Conceivably, economics, like physics, is sub-
ject to a fundamental indeterminacy theo-
rem.
## Economics-1986-0


### ---Economics-1986-0-03.txt---
When the word of my prospective eleva-
tion to this exalted position first circulated at
MIT at the end of March 1983, I happened
to encounter Peter Temin in the library. He
offered congratulations, and added: "In your
presidential address, skip the methodology.
Tell them a story." This is the technique that
he and Paul David used to great effect in
the session on economic history at Dallas a
year ago. I choose, however, to follow the
lead of another economic historian, Donald
McCloskey, who maintains that economics
should be a conversation (1983).
In a recent paper, unpublished I believe,
George Stigler discussed " the imperialism of
economics," which, he claims, is invading
and colonizing political science-through
public choice theory and the economic the-
ory of democracy-law, and perhaps espe-
cially sociology, where our soon-to-be presi-
dent-elect, Gary Becker (1981), has extended
the reach of economics into questions of the
family, marriage, procreation, crime, and
other subjects usually dealt with by the soci-
ologist. "Imperialism" suggests super- and
subordination, with economics on top, and
raises the question whether as a profession
we are not flirting with vainglory.
My interest has long been in trade, and I
observe that economics imports from, as well
as exports to, its sister social sciences. In
public choice, we can perhaps explain after
the event whose interest was served by a
particular decision, but we need political sci-
ence to be able to forecast which interest is
likely to be served, whether that of the execu-
tive, the legislature, the bureaucracy, some
pressure group-and which pressure group
or, in the odd instance, the voters. Indi-
viduals act in their own interest, let us grant,
but a more general motive of emulation may
be drawn from sociology as Adam Smith was
aware in the Wealth of Nations (1776, p.
717), as well as in The Theory of Moral
Sentiments (1759 (1808), I, p. 113). I want
today to borrow one or two ideas from polit-
ical philosophy, and to conduct a conversa-
tion with a new, impressive, and growing
breed of political scientists working on inter-
national economic questions. The discussion
falls into two loosely connected halves- the
first dealing with what economists can, per-
haps should, and to some extent do, import
from political philosophy and sociology; the
second dealing more especially with interna-
tional public goods.
That sharp and sometimes angry theorist,
Frank Graham (1948), thought it a mistake
to think of trade between nations. Trade
took place between firms, he insisted. The
fact that they were in different states was
irrelevant so long as economic policy was
appropriately minimal, consisting perhaps of
free trade, annually balanced budgets, and
the gold standard. But states may differenti-
ate between firms, through such measures as
tariffs, embargos, monetary, fiscal, and ex-
change rate policy which affect all firms
within a given space, and this adds a political
dimension (see my 1978 study). The essence
may go deeper. In an early graduate quiz,
I asked for the difference between domes-
tic and international trade, expecting a Ri-
cardian answer on factor mobility. One pa-
per, however, held that domestic trade was
among " us," whereas international trade was
between "us" and "them." The student who


### ---Economics-1986-0-04.txt---
wrote this (now escaped from economics and
teaching international law at a leading uni-
versity) had come from Cambridge Univer-
sity and a course with Harry Johnson. We
go beyond this simple statement today in
saying that nations are groups of people with
common tastes in public goods (Richard
Cooper, 1977). Geography discriminates be-
tween countries, as a hypothetical customs
union between Iceland and New Zealand
would demonstrate, and so do governments.
Behind and alongside of governments, peo-
ple discriminate.
Public goods, let me remind you, are that
class of goods like public works where exclu-
sion of consumers may be impossible, but in
any event consumption of the good by one
consuming unit-short of some level ap-
proaching congestion-does not exhaust its
availability for others. They are typically
underproduced-not, I believe, for the Gal-
braithian reason that private goods are ad-
vertized and public goods are not-but be-
cause the consumer who has access to the
good anyhow has little reason to vote the
taxes, or pay his or her appropriate share.
Unless the consumer is a highly moral per-
son, following the Kantian Categorical Im-
perative of acting in ways which can be
generalized, he or she is apt to be a "free
rider." The tendency for public goods to be
underproduced is serious enough within a
nation bound by some sort of social con-
tract, and directed in public matters by a
government with the power to impose and
collect taxes. It is, I propose to argue in due
course, a more serious problem in interna-
tional political and economic relations in the
absence of international government.
Adam Smith's list of public goods was
limited to national defense, law and order,
and public works that it would not pay indi-
viduals to produce for themselves. Most
economists are prepared now to extend the
list to include stabilization, regulation, and
income redistribution (Cooper, 1977), even
nationalism (Albert Breton, 1964), and stan-
dards that reduce transaction costs, includ-
ing weights and measures, language, and
money. Public goods were popular a decade
ago. There is something of a tendency today,
at least in political science, to draw back and
claim that such institutions as open world
markets are not public goods because coun-
tries can be excluded from them by dis-
crimination. One monetarist goes so far as to
maintain that money is not a public good,
arguing, I believe, from the store-of-value
function where possession by one individual
denies possession by others, rather than from
the unit-of-account function in which exclu-
sion is impossible and exhaustion does not
hold (Roland Vaubel, 1984).
II
Before addressing international public
goods, I want to digress to suggest that there
are other limits to the imperialist claims of
economics. Social goods are not traded in
markets, for example-honor, respect, dig-
nity, love. In his address to the Columbia
University Bicentennial Assembly, Sir Den-
nis Robertson asserted that what economists
economize is love (1955, pp. 5-6). Michael
Walzer (1983, pp. 101-02) has compiled a
list of " things" that contemporary moral
philosophy will not tolerate being bought
and sold: human beings, political power,
criminal justice, freedom of expression, mar-
riage and procreation rights (pace Becker),
the right to leave the political community,
exemptions from military service and jury
duty, political office, basic services like po-
lice protection, desperate exchanges such as
permission for women and children to
work fourteen hours a day, prizes and honors,
love and friendship, criminally noxious sub-
stances such as heroin. The inclusion of a
number of items on the list is debatable, and
history reveals that most of them have been
traded on occasion in some cultures. The
market, moreover, strikes two lawyers as a
dubious device for making "tragic choices,"
like those in which scarcity confronts human-
istic moral values, for example, allocating
food in famine, children available for adop-
tion, or organ transplants (Guido Calabrese
and Philip Bobbit, 1978). It is difficult to
dissent from Walzers's conclusion that a
radically laissez-faire economy would be like
a totalitarian state, treating every social good
as if it were a commodity (1983, p. 119).
There is, moreover, a similar remark from a


### ---Economics-1986-0-05.txt---
founder of the Chicago school, Frank Knight,
who said that the extreme economic man,
maximizing every material interest, and the
extreme Christian, loving his neighbor as
himself, were alike in that neither had any
friends.'
To admit social goods, not traded in
markets, into our economic calculus does not
call for altruism. Economists are reluctant to
depend on self-denial to any degree (Ken-
neth Arrow, 1975, p. 22), and moral phil-
osophers are not far behind. To a modern
student of ethics, James Fishkin (1982, ch.
ii), obligations to others fall into three cate-
gories: minimal altruism, where the benefit
to the receiver is substantial and the cost
to the altruist low-the acts of a cheap
Samaritan; acts of heroic sacrifice that are
not called for; and a robust zone of indif-
ference where one has no cause to be con-
cerned over the effects of one's acts on others.
This is for positive actions. Acts that harm
others are proscribed by the Golden Rule.
Adam Smith expressed the same viewpoint
forcefully: " Every man is, no doubt, by na-
ture first and principally recommended to his
own care" (1759 (1808), I, p. 193), but goes
on: "Although the ruin of our neighbour
may affect us less than a very small misfor-
tune of our own, we must not ruin him to
prevent that small misfortune, or even to
prevent our own ruin" (ibid., p. 194). Does
this prohibit us from playing zero-sum games
or negative non-zero-sum games? In interna-
tional trade, must we refrain from levying
the optimum tariff? The optimum tariff works
to self-interest mainly in the absence of re-
taliation, and if Adam Smith excludes hurt-
ing our neighbor, he recognizes that "as ev-
ery man doth, so shall it be done to him, and
retaliation seems to be the great law of na-
ture" (ibid., p. 191).
Note parenthetically that today's moral
philosophers cover a wide territory either
side of Fishkin, from Peter Singer (1972) at
one extreme whose criterion of justice re-
quires successive acts of altruism until the
welfare of the recipient has risen to that of
the giver which has fallen, to Robert Nozick
(1974) at the other who believes that self-in-
terest rules out altruism almost altogether.
III
Self-interest then is legitimate over a large
zone of indifference provided that justice
is served by our not hurting others. But
the robust zone of indifference applies to
strangers, and not to those with whom we
have a special relationship, sharing collective
goods. It does not apply in the family, the
neighborhood, in clubs, in the tribe, racial or
religious group, or in the nation. There is
some uncertainty whether it applies in re-
gions within a country-New England, the
West, the South-or to arrangements be-
tween countries short of the world level such
as North America or the European Common
Market. Collective goods involved here are
distributed by mechanisms different from the
market: gifts, grants, unequal exchange,
sharing through a budget according to
need, interest-free loans, inheritance, dowries,
alimony, and the like all have a place.
Membership in these groups is decided in
various ways: by birth, by choice-as in
moving into a certain neighborhood or
migrating between countries, by application
for admission and acceptance. Walzer de-
fends the right of countries to keep out
would-be immigrants motivated by economic
self-interest, but not those subjected to
persecution: "The primary good that we
distribute to one another is membership in
some community" (1981; 1983, ch. ii, p. 1).
He argues, however, that states lack the right
to keep members from emigrating if there is
some other community ready to take them
in. Clubs discriminate against outsiders.
Neighborhoods are more complex, being pre-
sumably open to anyone able to afford and
find a place to live, but, in sociological real-
ity, often exhibiting tendencies to attract their
own kind and repel others, including harass-
ment or unwritten or even legal restrictions
against property ownership. The groupings
are amorphous, but they exist.
The nature of the positive bonds that link
families, neighborhoods, tribes, regions, and


### ---Economics-1986-0-06.txt---
nations is usually taken for granted and left
unexplored, but the consequences are not.
Albert Hirschman (1970), for example, makes
a distinction between voice and exit: voice
-speaking up and trying to persuade-being
the appropriate action when one disagrees
with the course followed by a group to which
one belongs; and exit-resigning or refusal
to buy the good or service-as a response to
what one dislikes in the market. Adam Smith
minimizes the difference between families and
strangers, suggesting that affection is little
more than habitual sympathy produced by
propinquity; despite the greater thickness of
blood than water, he claims that siblings
educated at distances from one another expe-
rience a diminution of affection (1759 (1808)
II, pp. 68-70). In arguing against Walzer's
view that countries owe immigrants the right
to become citizens, Judith Lichtenberg (1981)
echoes Smith's view in saying that the crucial
difference between members and strangers
lies between those with whom one has face-
to-face contact and those with whom one
does not. An accident that kills someone in
one's town or a neighboring community is
likely to be more moving than a catastrophe
at the other end of the world in which
hundreds or thousands die. Adam Smith goes
further, comparing the loss of a little fin-
ger with a catastrophe that swallowed up
China: ". . . if he lost his little finger he could
not sleep, but for China he can snore... pro-
vided he has never seen them" (ibid., I, p.
317).
Some years ago in a book on the brain
drain, Harry Johnson (1968) argued in favor
of a cosmopolitan solution, encouraging
emigration, and Don Patinkin (1968) for a
national one. In discussing the Bhagwati
scheme for taxing professional emigrants
earning more abroad than at home, for the
benefit of the poor sending country-saying
this was akin to paying alimony in a divorce
case for breaking a social taboo-I suggested
(1977) that the Johnson position was equiv-
alent to saying that a person should go where
he or she could earn the highest return, while
Patinkin said that people should stay where
they belonged. Patinkin chided me privately
for this interpretation, and it is admittedly
oversimplified. But the difference between
the Johnson and the Patinkin positions, both
emanating from Chicago, suggests the line
between market and nonmarket areas in eco-
nomics is shadowy.
In writing about the multinational corpo-
ration, I have from time to time suggested
that host countries resist the intrusion of
strangers because "...man in his elemental
state is a peasant with a possessive love of
his own turf; a mercantilist who favors ex-
ports over imports; a Populist who distrusts
banks, especially foreign banks; a mo-
nopolist who abhors competition; a xen-
ophobe who feels threatened by strangers
and foreigners" (1984, p. 39), usually adding
that it is the task of international economics
to extirpate these primitive instincts and to
teach cosmopolitanism. The fact that some
of these reactions remain at a late stage in
the educational process can be tested by the
device of asking students on examinations,
seriatim, a series of questions:
Do you advocate free trade, or at least is
there a strong presumption in its favor?
Do you advocate the free international
movement of portfolio capital?
... of corporate capital in foreign direct
investment?
... free migration of students and pro-
fessional labor?
... immigration of relatives of persons
permanently resident in this country?
... free migration for all?
(It is desirable to feed these questions to the
victims one at a time, without revealing the
whole list before the first answer is given,
and to take up the replies to the first ques-
tions so that there is no chance to go back
and amend early answers.) There will be
sophisticated answers expatiating on the sec-
ond, third, and fourth-best if the marginal
conditions for a Pareto optimal solution are
not met, and I would particularly excuse a
James Meade (1955) solution that would limit
immigration from countries that have not
accomplished their Malthusian revolution, on
the ground that their emigrants will be re-
placed, so that free immigration will reduce
world income per capita, if not world income
as a whole. Most economists and non-
economists alike would agree, however, that
goods are less intrusive than money, money


### ---Economics-1986-0-07.txt---
less so than corporations with control over
our economic decisions.2 Intellectuals with
whom we identify are hardly intrusive at all.
Most of us grant that relatives must be per-
mitted to come together. On the other hand,
free migration of labor in general poses a
threat to the national identity. The Swiss cut
off immigration, despite the appeals of busi-
ness for more labor, when immigrants con-
stituted one-third of the labor force. In
Germany, separate localities felt threatened
and stopped inward migration when im-
migrants reached 12 percent of the resident
population. Feelings differed, of course, de-
pending upon the origin of the migrants and
their appearance, language, and religion.
One early venture of international eco-
nomics into this line of investigation was
Robert Mundell's "optimum currency area"
(1961), initiating a discussion of how large
the area for a single currency should be, that
can readily be extended to economics in
general and to other social sciences. Mundell
defined an optimum currency area as one
where labor moved freely within the area,
but not between it and other areas, taking us
back to the Ricardian criterion distinguish-
ing domestic from foreign trade: factor mo-
bility within but not between countries. In
neither case is the discontinuity in mobility
explained. Perhaps something is owed to low
transport costs, but additionally, factor mo-
bility requires a group with such strong so-
cial cohesion that those moving are willing to
shift, and those at the receiving end are
content to receive them.
Ronald McKinnon (1963) offered a differ-
ent criterion: an optimum currency area was
one that traded intensively at home, but only
to a limited extent abroad. This implied that
tastes within a country are homogeneous for
traded goods (as well as for public goods),
and that regionally specialized production
had grown up to serve those tastes. The
Mundell and McKinnon criteria do not nec-
essarily converge: on Mundell's standard,
Canada is too big to be an optimum cur-
rency area, because of limited movement be-
tween Quebec and the English-speaking parts
of Canada, and the comparative isolation of
the Maritimes and Vancouver. On McKin-
non's criterion, however, it was too small
because so much of its trade is with the
United States.
If one broadens the issue from the opti-
mum currency area to economics more gen-
erally and to the other social sciences,
anomalies arise from the divergence between
the optimum economic area, which on
efficiency grounds I take to be the world, and
the optimum social unit, one that gives the
individual a sense of belonging and counting
-which is much smaller. In shifting to the
optimum political unit, at least two problems
arise, one related to the nature of the ties, the
other to the ambitions of its members. To
take the second point first, for a nation bent
on glory-led by a Bismarck or a de Gaulle
-bigger is better; whereas if one is merely
trying to get along without trouble, like, say,
Denmark, small is beautiful enough.
On the first issue, political ties vary widely.
There are leagues, alliances, commonwealths,
confederations, federations, provinces, states,
principalities, kingdoms. Some lesser units
are "united" in varying degrees, as in the
United Provinces of the Netherlands, the
United States of America, the United King-
dom of Great Britain, and Northern Ireland.
The North in the American Civil War was a
union, as the Union of Socialist Soviet Re-
publics asserts it is. The small amount of
literature I have explored in examining the
differences among these forms is not very
conclusive, but perhaps the main distinction
is between a single state that is centralized,
and federations that are loosely joined, with
greater powers at the local level. Designa-
tions are not always congruent with reality:
the Federal German Republic is highly un-
ified, despite the efforts of the occupation
powers after World War II to spread politi-


### ---Economics-1986-0-08.txt---
cal power widely; the Federal Reserve Sys-
tem was created as a loose agglomeration of
twelve regional money markets but quickly
fused into a single system in World War I.
Centralization and federalization have re-
flections in demography and in finance.
City populations in unified states follow a
Pareto-skewed distribution with a single
dominant city like London, Paris, or Vienna,
and no close rival among the tail of smaller
cities and towns. In federations the distribu-
tion of cities is log normal (Brian Berry,
1961). Parallel to the demographic division is
the financial. Paris has 91.3 percent of French
bank clearings; London 87 percent of those
for Britain. The contrast is with Canada:
Toronto, 37.3 percent; Montreal, 25.5 per-
cent; Vancouver, 6.5 percent. Between these
extremes lies Japan with Tokyo 51.2 percent
and Osaka 19.7 percent (Jean Labasse, 1974,
pp. 144-45).
One explanation for differences between
centralized and federal states is historical:
where larger states were formed later from
unification of lesser units, administrative and
financial functions were already being dis-
charged at the local level, reducing the need
for centralized services. This hypothesis faces
the difficult counterexamples of Italy and
Germany, unified out of smaller units in the
second half of the nineteenth century, that
quickly centralized administrative and finan-
cial functions, in Rome and Milan for Italy,
and in Berlin for Germany. Another ex-
planation runs in terms of size, with larger
states necessarily federal because of the dif-
ficulty of providing administration to local
units over long distances. This fits Canada,
Australia, the United States, perhaps India,
but fails to account for Switzerland, unless
size is a proxy for maintaining a dense net-
work of communication, and division of val-
leys by high mountains produces barriers
equivalent to those of continental states. If
the mathematically minded among you need
an analogue, think of federal states as de-
composable matrices.
The difference between a single state and a
federation may be illustrated with two exam-
ples. Some years ago, Seymour Harris (1952)
wrote a book on New England in which he
claimed that the area got a raw deal from the
rest of the country because it paid more in
taxes to the federal government than it re-
ceived in federal expenditure. This thesis im-
plicitly violated the distinction between a
budget and a market: in a market equal
values are exchanged. A budget, on the other
hand, is a device expressing the cohesion of a
sharing group with monies raised according
to one standard, perhaps ability to pay, and
expenditure distributed according to another,
some combination of efficiency and need.
The other example, equally shocking to an
international trade economist, was the no-
tion of the juste retour, or fair return, pro-
pounded by France in connection with ex-
penditure for joint projects in Europe. France
insisted that all monies contributed by her be
spent in France. Tied sales are a third- or
fourth-best device to limit balance-of-pay-
ments deficits for a given contribution to
joint efforts, or to maximize the contribution
for a given deficit. They are inefficient rather
than fair.
IV
But I want to move on to the geopolitical
unit that produces public goods. It is a cliche
that these have increased in size as costs of
transport and communication have declined.
Under the eighteenth-century Poor Law in
England, the parish resisted immigration
from neighboring parishes because of reluc-
tance to share with outsiders. Fernand
Braudel (1982) and Sir John Hicks (1969)
have each expatiated on the rise of the size of
the economic unit from the city-state to the
nation-state. National and international mar-
kets for goods and money grew slowly, with
entrepot centers that intermediated between
buyers and sellers surviving in money- cheap
to move in space-and largely disappearing
for goods where costs of transport were high
and could be saved by direct selling, rather
than relaying goods through fairs in the Mid-
dle Ages and later through cities such
as Amsterdam, Hamburg, Frankfurt, and
London. The hub-and-spoke system recently
discovered in airplane travel and still in place
for money has long been superceded in goods.
Caroline Isard and Walter Isard's (1945)
point that the most pervasive changes in the


### ---Economics-1986-0-09.txt---
economy came from innovations in transport
and communications remains valid: contem-
plate the rudder (in place of the steering
oar), fore-and-aft sails; the turnpike; canal;
railroad (despite Robert Fogel, 1964); the
steamship; iron-clad ship; telegraph; tele-
phone; refrigerator ship; radio; airplane;
bulk carrier; jet airplane; satellite television.
The numbers of people brought into face-
to-face contact across continents and hemi-
spheres has increased exponentially. It is true,
to be sure, as was said about a well-known
governor and presidential candidate, that it
was impossible to dislike him until one got to
know him, and increases in mobility and
communications have been accompanied by
separatism: of the Walloons from the Flemish
in Belgium, of Scotland and Wales in the
United Kingdom (to pass over the troubled
Irish question), and of the Quebecois in
Canada.3 But it is easier than in Adam
Smith's day to imagine ourselves in the cir-
cumstances of the Chinese, the inhabitants of
the Sahelian desert in Africa, or the
tornado-struck islands of Bangladesh as we
see them nightly on our television screens via
satellite. Do wider communication and trans-
port change the production and distribution
of public goods?
Conflicts between economics and political
science abound, and many arise from the
fact that goods, money, corporations, and
people are mobile, whereas the state is fixed.
The increase in mobility produced by in-
novations in transport and communication
during and after World War II led some of
us to conclude that the nation-state was in
difficulty. A reaction occurred in the 1970's.
It is significant that Raymond Vernon's in-
fluential book Sovereignty at Bay (1971),
showing the multinational corporation ascen-
dant over the state, was followed by his
Storm over Multinationals (1977) in which
the position is reversed. Cooper's The Eco-
nomics of Interdependence (1968) was fol-
lowed by an upsurge of interest in national
autonomy, decoupling, and pluralism among
political scientists, most of whom approve
the nation-state and have as heroes, if they
will forgive me, not Adam Smith and
Woodrow Wilson, but Otto von Bismarck
and perhaps even Charles de Gaulle. The
tension remains, however. Mobility limits the
state's capacity to enforce its writ in taxa-
tion, in foreign policy, in standards on such
matters as antitrust, pure food and drugs,
insider trading in securities, and the like.
Mobility undermines social cohesion through
the easy intrusion of different nationalities,
races, religions, and traditions into the body
politic.
V
I come at long last to international public
goods. The primary one is peace. Economists
are poorly qualified to discuss how, after
war, peace is restored and maintained. Most
of us reject the Marxian view that war grows
directly out of capitalism, and as ordinary
citizens and amateur students of history are
prepared to agree that peace may be pro-
vided by a dominant world power- Pax
Romana or Pax Britannica-or by balance-
of-power maneuvering, although that seems
accident prone. Among the more audacious
economists producing an economic theory or
set of theories on war is Walt Rostow (1960,
pp. 108 ff.). There are views that ascribe war
to population pressure, to ambitious rulers
aggressively seeking power, and to complex
miscalculation. How these are to be avoided
or contained is a question primarily for polit-
ical science.
In the economic sphere, various interna-
tional public goods have been identified: an
open trading system, including freedom of
the seas, well-defined property rights, stan-
dards of weights and measures that may
include international money, or fixed ex-


### ---Economics-1986-0-10.txt---
change rates, and the like. Those that have
interested me especially in a study of the
1929 depression and other financial and eco-
nomic crises have been trading systems, in-
ternational money, capital flows, consistent
macroeconomic policies in periods of tran-
quility, and a source of crisis management
when needed. By the last I mean the mainte-
nance of open markets in glut and a source
of supplies in acute shortage, plus a lender of
last resort in acute financial crisis (see my
1973 book, revised 1986, forthcoming).
Public goods are produced domestically by
government, unless the governmental agenda
is blocked in stalemate among competing
distributional coalitions as described by
Mancur Olson (1982). Voluntary provision
of public goods is plagued by the free rider.
In the international sphere where there is no
world government, the question remains how
public goods are produced. Ralph Bryant is
one of the few economists who has discussed
the public good element in international co-
operation. His vocabulary is different from
that of the political scientists: their "regimes"
are his "supranational traffic regulations"
(1980, p. 470), and he expects leadership in
cooperation in monetary and fiscal policy
from supranational institutions such as the
International Monetary Fund (p. 481). I find
this doubtful on the basis of the interwar
record of such institutions as the League of
Nations.
Political science in this field has produced
two schools: the realists who hold to a na-
tional-interest theory of international politics,
and the moralists, whom Robert Keohane
prefers to call "institutionalists" (1984, p. 7).
Realists maintain that international public
goods are produced, if at all, by the leading
power, a so-called " hegemon," that is willing
to bear an undue part of the short-run costs
of these goods, either because it regards itself
as gaining in the long run, because it is paid
in a different coin such as prestige, glory,
immortality, or some combination of the two.
Institutionalists recognize that hegemonic
leaders emerge from time to time in the
world economy and typically set in motion
habits of international cooperation, called
"regimes," which consist of "principles,
norms, rules and decision-making procedures
around which the expectations of interna-
tional actors converge in given issue areas"
(Stephen Krasner, 1983, p. 1). Under British
hegemony, the regimes of free trade and the
gold standard developed more or less un-
consciously. With subsequent American
hegemony, a more purposeful process of in-
stitution making was undertaken, with agree-
ments at Bretton Woods, on tariffs and trade,
the Organization for Economic Cooperation
and Development, and the like. Political sci-
entists recognize that regimes are more read-
ily maintained than established since margin-
al costs are below average costs; as hegemonic
periods come to an end with the waning of
the leading country's economic vitality, new
regimes needed to meet new problems are
difficult to create. Cooper (1985) has written
of the eighty years it took to create and get
functioning the World Health Organization
despite the clear benefits to all countries
from controlling the spread of disease. And
it takes work to maintain regimes; in the
absence of infusions of attention and money,
they tend in the long run to decay.
I originally suggested that the 1929 depres-
sion was allowed to run unchecked because
there was no leading country able and will-
ing to take responsibility for crisis manage-
ment, halting beggar-thy-neighbor policies
from 1930, and especially acting as a lender
of last resort to prevent the serious run on
the Creditanstalt in May 1931 spreading, as
it did, to Germany, Britain, Japan, the United
States, and ultimately to the gold bloc. Brit-
ain, the leading economic power of the nine-
teenth century, was unable to halt the run;
the United States, which might have had the
ability, possibly assisted by France, was un-
willing. This view has been rejected by one
economic historian who holds that the trou-
bles of the interwar period were more
deep-seated, and that what was needed was
more fundamental therapy than maintaining
open markets and providing a lender of last
resort, something, that is, akin to the heroic
public good after World War II, the Marshall
Plan (D. E. Moggridge, 1982). That may
have been true, though there is no way I see
that the issue can be settled. Leadership at
an earlier stage in the 1920's, presumably
furnished by the United States with some


### ---Economics-1986-0-11.txt---
cost in foregone receipts on war-debt account,
might have resolved the war-debt-repara-
tions-commercial-debt tangle that proved so
destabilizing after the 1929 stock market
crash. I conclude that the existence of an
international lender of last resort made the
financial crises of 1825, 1836, 1847, 1866,
and 1907 more or less ephemeral, like summer
storms, whereas its absence in 1873, 1890,
and 1929 produced deep depressions-short-
ened in the 1890 case by the deus ex machina
of gold production from the Rand. Again
there is room for disagreement.
The point of all this is that after about
1971, the United States, like Britain from
about 1890, has shrunk in economic might
relative to the world as a whole, and more
importantly, has lost the appetite for provid-
ing international economic public goods-
open markets in times of glut, supplies in
times of acute shortage, steady flows of
capital to developing countries, international
money, coordination of macroeconomic pol-
icy and last-resort lending. The contraction
of concern from the world to the nation is
general, and applies to economists as well
as to politicians and the public. In reading
recent books on macroeconomic policy by
leading governmental economists under both
Democratic and Republican administrations,
the late Arthur Okun (1981) and Herbert
Stein (1984), I have been struck by how little
attention the authors paid to international
repercussions. The same observation has been
made by Ralph Bryant (1980, p. xviii) and
by the British economist R. C. 0. Matthews,
reviewing Arjo Klamer's Conversations with
Economists... (1985, p. 621). There has been
a recent upsurge of interest in the interna-
tional dimension because of the connections
among the federal deficit, the exchange rate
for the dollar, and the balance-of-payments
deficit, but the focus of this interest is almost
exclusively on what the connections mean
for U.S. interest rates, industrial policy,
growth, and wealth. The international im-
pact is largely ignored, bearing out the truth
in former German Chancellor Helmut
Schmidt's statement that "the United States
seems completely unconscious of the eco-
nomic efforts of its policies on the Alliance"
(1984, p. 27).
Some of the discussion of international
regimes by political scientists verges on what
my teacher, Wesley Clair Mitchell, used to
call "implicit theorizing," that is, convenient
ad hoc theoretical explanations to fit given
facts that lack generality. Charles Lipson
(1985), for example, suggested that the slip-
page in U.S. hegemony in the 1970's resulted
in a loss of the international public good of
secure property rights and therefore in the
widespread nationalization of foreign direct
investment. He went on to say that the rea-
son less developed countries (LDCs) did not
default on their debts to bank syndicates was
that bank lending was "better institutional-
ized," "a smaller group," "better protected
by legal remedies" (pp. 136, 158, 170). He
was surprised that the decline of British
hegemony in the interwar period did not
result in more LDC aggression against for-
eign property (p. 191), but failed to observe
the widespread default on foreign bonds in
the 1930's, despite the organization of inter-
national finance. In my judgement Keohane
exaggerates the efficacy and importance of
the international regime in oil that was
formed after the first OPEC oil shock of
1973 (see his ch. 10). The crisis caused by the
Yom Kippur embargo of the Netherlands
was to my mind shockingly mishandled by
governments, and the public good of crisis
management was left to the private multina-
tional oil companies. The formation of the
International Energy Agency was a classic
operation in locking the barn door after the
horse had been stolen.
Between national self-interest and the pro-
vision of international public goods, there is
an intermediate position: indifference to
both. An interesting contrast has been ob-
served in the 1930's between Britain which
forced Argentina into a bilateral payments
agreement (the Roca-Runciman Agreement
of 1933) in order to take advantage of its
monopsony position, and the United States
that had a similar opportunity vis-a-vis Brazil
but ignored it (Marcelo de Paiva Abreu,
1984).
It is fairly clear from the historical record
that economic hegemony runs down in decay
-in the British case after 1913 and the
United States about 1971-leading Felix


### ---Economics-1986-0-12.txt---
Rohatyn (1984) to say that the American
century lasted only twenty years. The Nixon
shock of 1973 in cutting off soya bean ex-
ports to Japan-a significant harm to an ally
for a small gain to this country-was the act
of a bad Samaritan. The import surcharge of
the same year may have been required to
move the dollar out from the position of the
nth currency when only n -1 countries are
free to fix their exchange rates, but it would
have been possible to start with the later
attempt at cooperation that resulted in the
Smithsonian agreement. This is especially
true when so much of the case against the
1971 exchange rate was the result of the
easy-money policy of the Federal Reserve
System under Chairman Arthur Burns, at a
time when the Bundesbank was tightening its
money market/go-it-alone policies of both
banks that flooded the world with dollars.
The present U.S. administration claims to
be working for open trade and does fairly
well in resisting appeals for protection. The
positive push for a Reagan round of trade
liberalization in services and agriculture,
however, is in pursuit of a national and not
an international public good. The regime in
capital movements-the World Bank, the re-
gional development banks and that in-last-
resort lending orchestrated by the IMF-
seems to be working, with bridging loans and
an ad hoc purchase of oil from Mexico for
the U.S. stockpile in 1982 when the IMF
finds itself unable to move fast enough. But
there are signs of dissension that may spell
trouble. The June 1985 bridging loan for
Argentina was declined by Germany and
Switzerland on the grounds that Argentina
had not been sufficiently austere and that its
problems were not a threat to the world
financial system (New York Times, June 15,
1985, p. 1). The Japanese contribution,
moreover, was said to have been small, al-
though no figures were given.
What I worry about mostly is exchange
policy and macroeconomic coordination. The
U.S. Treasury under Donald Regan was
committed to the policy of neglect, presum-
ably benign, but in any event ideological.
And the commitment to consultative macro-
economic policies in annual summit meetings
of seven heads of state has become a shadow
play, a dog-and-pony show, a series of photo
opportunities-whatever you choose to call
them-with ceremony substituted for sub-
stance. The 1950's and 1960's, when serious
discussions were held at the lowly level of
Working Party No. 3 of the O.E.C.D., were
superior because the United States and other
countries took them seriously.
I am a realist when it comes to regimes. It
seems to me that the momentum set in mo-
tion by a hegemonic power-if we must use
that expression, I prefer to think of leader-
ship or responsibility-runs down pretty
quickly unless it is sustained by powerful
commitment. The IMF and World Bank were
agreed at Bretton Woods largely as a result
of the U.S. Treasury: the forms were interna-
tional, the substance was dictated by a single
country (Armand van Dormel, 1978). In the
early days of the IMF, Frank Southard told
me, if the United States made no proposal,
nothing happened. Today the same is true of
the European Economic Community: unless
Germany and France see eye to eye, which is
infrequent, nothing happens. Proposals of
great technical appeal from individuals or
small countries are not welcomed as the pre-
paratory phases of the World Economic
Conference of 1933 demonstrated (see my
1973 book, pp. 210-14). There needs to be
positive leadership, backed by resources and
a readiness to make some sacrifice in the
international interest.
The leadership role is not applauded. When
the United States accused the rest of the
world of being free riders, Andrew Shonfield
countercharged the United States of being a
" hard rider," " hustling and bullying the
Europeans," "kicking over chairs when it did
not get its way" (1976, pp. 86, 88, 102).
Furnishing the dollar to the world as interna-
tional money has brought the United States
an accusation of extracting seignorage, al-
though the facts that the dollar is not a
monopoly currency and that foreign holdings
earn market rates of interest deflect that
criticism in sophisticated quarters.
Neglect can verge on sabotage. When the
European central banks collaborated to hold
the dollar down at the end of February 1985,
the conspicuous failure of the United States
to participate on a significant scale encour-
aged speculators not to cover long positions.
A former trader for the Federal Reserve


### ---Economics-1986-0-13.txt---
Bank of New York has expressed concern
that the habits of central bank cooperation
and U.S. official intimacy with the workings
of the foreign-exchange market that have
been built up over thirty years are being
squandered for ideological reasons (Scott
Pardee, 1964, p. 2).
Regimes are clearly more attractive in
political terms than hegemony, or even than
leadership with its overtones of the German
Fuhrerprinzip or of Italy's II Duce, if not
necessarily more so than responsibility. Poly-
centralism, pluralism, cooperation, equality,
partnership, decoupling, self-reliance, and
autonomy all have resonance. But it is hard
to accept the view, so appealing to the politi-
cal right, that the path to achieve cooper-
ation is a tit-for-tat strategy, applied in a
repetitive game, that teaches the other player
or players to cooperate (Robert Axelrod,
1984). As Tibor Scitovsky demonstrated years
ago (1937), this path can readily end by
wiping out trade altogether. Hierarchical
arrangements are being examined by eco-
nomic theorists studying the organization of
firms, but for less cosmic purposes than
would be served by political and economic
organization of the production of interna-
tional public goods (Raj Sah and Joseph
Stiglitz, 1985).
Minding one's own business-operating in
the robust zone of indifference-is a sound
rule on trend when macroeconomic variables
are more or less stable. To the economist it
means reliance on the market to the extent
that the conditions for a Pareto optimum
solution are broadly met. But the fallacy of
composition remains a threat, and one can-
not count on the Categorical Imperative.
Markets work most of the time, as a positive-
sum game in which the gain for one does not
imply a loss for another. Experience teaches,
however, that crises may arise. When they
do, the rule changes from government and
public indifference to the production of pub-
lic goods by leadership or by a standby
regime.
Leadership or responsibility limited to
crises encounters another problem: how to
keep the machinery for handling crises from
obsolescence. In crisis one needs forceful and
intelligent people, capable of making deci-
sions with speed under pressure. It is
sometimes said that the Japanese practice of
decision by consensus with ideas coming up
from below, makes it hard for that country
to discharge in timely fashion the responsi-
bilities of world leadership. In Marcus
Goodrich's Delilah (1941), the amiable prac-
tice of fraternization between a watch officer
and enlisted men on the bridge of the de-
stroyer proved dangerous in a typhoon since
the men had fallen into the habit of discuss-
ing the officer's orders. The paradox is that
the attributes needed in crisis tend to atrophy
in quiet times; for example in the control
room of a Three Mile Island nuclear power
plant.
Let me conclude by emphasizing once
again my concern that politicians, econo-
mists, and political scientists may come to
believe that the system should be run at
all times by rules, including regimes, not peo-
ple. Rules are desirable on trend. In crisis
the need is for decision. I quote once more
the letter of Sir Robert Peel of June 1844
a propos of the Bank Charter Act of that
year:
My Confidence is unshaken that we
have taken all the Precautions which
Legislation can prudently take against
the Recurrence of a pecuniary Crisis. It
may occur in spite of our Precautions;
and if it be necessary to assume a grave
Responsibility, I dare say Men will be
found willing to assume such a Re-
sponsibility.
[Parliamentary Papers,
1857, 1969, p. xxix]
## Economics-1987-0


### ---Economics-1987-0-01.txt---
I want to use this once-in-a-lifetime op-
portunity for pontificating to the profession,
to explore ways of improving the interaction
between what economists do and the politi-
cal process. Tension and conflict are, of
course, inherent in political decisions, espe-
cially on economic policy. Nothing can make
such decisions easy. Nevertheless, it is my
contention that economic policymaking in
Washington in the last decade has been more
frustrating, muddled, and confusing than
necessary. Some of the fault lies with
economists and economics; some with politi-
cians and the political process; some in the
interactions. I want to offer some sugges-
tions for modest improvements.
Most economists probably share my prem-
ise that economics ultimately ought to be
more than just challenging intellectual gym-
nastics. It ought to help us understand how
the economy works and provide a basis for
intelligent political choices among economic
policies. Even those who devote their en-
ergies to resolving purely theoretical issues
imagine that somehow in the end their efforts
will prove socially useful.
The dedicated, idealistic young economist
who aspires to advise a government may well
envision herself someday as the wise and
impartial adviser to the philosopher queen.
In this daydream, the adviser presents the
best forecasts that can be made of the future
course of the economy. She explains the
macroeconomic policy options and what is
likely to happen if each is undertaken. She
elucidates why market solutions are efficient,
when markets are likely to fail, and what can
be done when this occurs. She identifies risks
and uncertainties, which fortunately are not
overwhelming. She represents the best pro-
fessional judgment of her fellow economists,
indicating the major respects in which most
economists agree and scrupulously pointing
out that in minor respects the views of some
of her professional colleagues might differ
from her own. She remains above the po-
litical fray, identifying any values or dis-
tributional biases that may creep into her
judgments and eschewing identification with
interest groups or ideological causes.
The queen for her part listens carefully
and intelligently, asks thoughtful questions,
and weighs the options. She may consult
other experts on noneconomic aspects of the
decisions, but these can be assumed not to
be very important. She then makes final
decisions-even very hard ones-and sticks
to them. The decisions are carried out, the
economy prospers, and a grateful nation ap-
plauds the wisdom of the monarch and her
economist and the usefulness of economics.
But in the real world, both economics and
politics are frustratingly unlike this picture.
Both are pluralistic in the extreme and ap-
pear to be getting more so. Economists and
political leaders not only miscQmmunicate,
but each accuses the other of incompetence,
obfuscation, self-serving motives, and anti-
social behavior.
Economists, of course, do not wait for
others to attack them; they do it themselves.
Walter Heller said in his presidential address
that the "chorus of self criticism has risen to
a new crescendo" (1975, p. 1), and the self-
deprecation has not abated in the interven-
ing decade. If a golden age of economists'
self-confidence ever occurred, it is long past.
Events of recent years have kept reminding
us that our national economy is diverse and
complex, battered by unpredictable shocks,
and increasingly interconnected with the even


### ---Economics-1987-0-02.txt---
more diverse and complex world outside our
borders. Knowledge of how the domestic
economy works and interacts with the rest of
the world is imperfect. Economists keep
coming up with ingeneous theories, but they
have a hard time testing them. Data are
inadequate and controlled experimentation
nearly impossible. Modeling has greatly
enhanced our understanding of the past,
but shows few visible signs of improving
the reliability of macroeconomic prediction.
Forecasting even for short periods remains
an uncertain art in which neither economists
nor politicians can have much confidence.
Many of the most sophisticated and realis-
tic members of the profession, conscious of
all these difficulties, have abandoned the at-
tempt to advise governments on policies
in favor of the more manageable tasks of
adding to the knowledge base. This may be
understandable, but it deprives the economic
policy debate of the input of some very good
minds and runs the risk of leaving the job of
interacting with the political arena dispro-
portionately to those with strong ideological
views.
I. Fragmentation of the Economic Policy Process
The pluralism of economics pales beside
the pluralism of the political system that
policy-minded economists aspire to assist.
Even if one leaves aside the complexities of
federalism, the process by which national
economic policy evolves in Washington is so
fragmented and complicated that it is almost
impossible to explain to the uninitiated how
it is supposed to work, let along how it does
work.
A well-founded distrust of despots led our
forefathers not only to opt for representa-
tive democracy, but to divide power among
the executive and legislative and judicial
branches, and between the House and the
Senate. On matters of taxing and spending,
they were especially protective of the power
of the people's representatives, making it
clear that while the president could propose
taxing and spending, the ultimate authority
lies with the Congress, subject only to pres-
idential veto. This divided power creates a
built-in hurdle to making and carrying out
fiscal policy. The hurdle is low when the
president is articulating a policy that has
broad support in the country and in the
Congress. It can lead to erratic shifts of
policy when the president is indecisive, and
to deadlock when the president is leading
in a direction in which the public and its
elected representatives do not wish to go.
Deadlocks are rare, but can be serious. The
failure to reduce the huge structural budget
deficit of the mid-1980's largely reflects the
fact that the president's solution-drastic
reduction of the federal role in the domestic
economy-does not command broad popu-
lar support.
The separation of powers between the
Congress and the president is basic to our
system of government and probably worth
the price of occasional deadlock. The dif-
ficulties of making economic policy, how-
ever, are strongly compounded by the pro-
pensity of our pluralistic society to diffuse
power and decision-making authority both
within the executive branch and within Con-
gress. With respect to taxing and spending
policy, for example, the simple notion that
the president proposes and the Congress dis-
poses is greatly complicated by the fragmen-
tation of power within each branch. More-
over, periodic efforts to make the policy
process more coherent within each branch,
while often temporarily successful, have
added new power centers without consoli-
dating the old ones.
In the executive branch, the trend since
early in the century has been to centralize
power in the White House in order to make
it easier for the president to formulate and
articulate taxing and spending policy, and to
utilize the growing skills of the economics
profession to that end. But this worthy goal
has been accomplished in stages, with a new
institution added at each stage. The creation
of what is now called the Office of Manage-
ment of Budget (OMB) in the 1920's made it
possible for the president to review and
evaluate spending requests and impose a set
of priorities on his budget proposal to Con-
gress reflecting his administration's view of
the appropriate size and role of government.
The creation of the Council of Economic
Advisers (CEA) in the 1940's provided a


### ---Economics-1987-0-03.txt---
focal point for bringing the advice of the
economics profession into the service of
presidential decision making and a locus
for creating an official forecast of economic
activity.
The creation of OMB and CEA improved
the president's ability to formulate and
articulate macroeconomic policy. It also left
the president, in addition to his other impos-
sible duties, with the job of resolving a built-
in tension over responsibility for economic
policy among the CEA, OMB, and the
Treasury, not to mention the White House
staff and the agencies with line responsibility
for implementing various aspects of eco-
nomic poclcy.
Presidents have tried various coordination
mechanisms including "troika" arrange-
ments and an almost infinite variety of
broader councils and committees with vary-
ing membership, responsibilities, and leader-
ship. The system works tolerably well or
exceedingly creakily, depending on the presi-
dent's personal style and the personalities
involved. But it encourages battling over turf
as well as substance, and is hardly designed
to minimize the amount of presidential en-
ergy needed to evolve a coherent, explain-
able policy on taxing and spending. One
might wonder whether it is not time to do
what so many other countries do and give
our president the equivalent of a responsible
finance minister charged with the functions
now diffused to our budget director, Council
of Economic Advisers, and Treasury Secre-
tary.
The fragmentation of power and responsi-
bility is, of course, even more extreme in the
Congress. The legislative branch also has a
long history of attempts to make taxing and
spending policy in a more coherent fashion
by adding new coordinating institutions-
appropriations committees, a joint economic
committee, budget committees, a congres-
sional budget office-without eliminating or
consolidating any of the old ones.
The most recent attempt to improve con-
gressional economic decision making-one
in which I was an active participant-fol-
lowed the Budget Reform Act of 1974 which
created the budget committees and the Con-
gressional Budget Office. These budget re-
forms succeeded in their main objective of
focusing the attention of the Congress on
overall budget policy, not just individual tax-
ing and spending fragments. They have
forced the Congress to fit the pieces together,
to debate and vote on an overall taxing
and spending plan-a budget resolution-to
which specific taxing and spending matters
must conform. No one can say that the
Congress in the last few years has ignored
fiscal policy! The creation of the Congres-
sional Budget Office, moreover, has given
Congress independent access to forecasts,
projections, and analysis of economic op-
tions.
The downside of the budget reforms, how-
ever, was that the budget process was super-
imposed on the already complex responsi-
bilities of authorizing, appropriating, and tax
committees. It has added to the layers and
stages of congressional policymaking without
removing any of them, has made the process
of budget decision making nearly impossible
even for members of Congress to understand,
and increased the workload so much that
decisions are routinely made late and in an
atmosphere of crisis. Moreover, Congress
now frequently has to deal with two sets of
estimates, those of the OMB and those of
the Congressional Budget Office, which may
differ because they are based on different
forecasts of economic activity, or for even
less obvious technical reasons.
Meanwhile, back in the separate world of
the Federal Reserve, monetary policy is being
decided and carried out. It is a curious
paradox that a nation, which feels it needs
many more hands on the tiller of fiscal policy
than most countries regard as workable, is
content to leave monetary policy to a central
bank with fewer visible ties to the rest of the
government than the central banks of most
countries.
There is plenty of informal communica-
tion, of course, especially between the
Federal Reserve and the hydraheaded eco-
nomic establishment of the executive branch.
More formal cooperation between the mone-
tary and fiscal authorities, as in the United
Kingdom, might contribute only marginally
to making monetary and fiscal policy deci-
sions part of a more coherent strategy for


### ---Economics-1987-0-04.txt---
the economy-and at the cost of depriving
the executive branch of the luxury of blam-
ing the Federal Reserve when things go
wrong. The love-hate relation between the
Congress and Federal Reserve, however,
warrants more attention. Despite occasional
outbursts of anxiety over escalating interest
rates, Congress has shown little inclination
to control monetary policy, or even to in-
quire into the consistency of monetary and
fiscal objectives. The Fed is required to re-
port monetary growth targets to the banking
committees, as though monetary policy were
a matter of banking system regulation, but
has little genuine interaction with the budget
committees whose job is to debate and pro-
pose fiscal policy.
II. The Process under Stress
This whole complicated economic policy
system has been subjected to enormous strain
in recent years. Political economists like to
harken back to the golden years of the 1950's
and 1960's when economists got respect and
the economic policy machinery functioned
smoothly. The nostalgia is only partly a re-
sult of faulty memories. It's not hard to
be satisfied with economists and policy
processes when the economy is growing, pro-
ductivity marches steadily upward, and even
the national debt is obligingly declining in
relative importance. It's much harder when
productivity growth plummets for reasons
that no one honestly purports fully to under-
stand, expectations of public and private
consumers have to be cut back to fit with
slower income growth, and inflation and in-
terest rates are bouncing around at un-
familiar levels.
Adjusting to the energy shocks and slower
growth that began in the 1970's strained the
economic policy processes of all industrial
countries and made the participants feel
frustrated and inadequate. It's not obvious,
even with hindsight, that the fundamental
difficulties facing the industrial world in the
1970's can credibly be blamed on economists
or any particular structure of government
or economic policy responses, but all came
in for their share of the understandable
hostility.
The difficulties of the U.S. economy in the
1980's, by contrast, revolve heavily around
an economic policy mistake: the creation of
a large structural deficit in the federal budget.
I do not believe that the structure of our
economic decision process was the cause of
the mistake. Blaming the deficit on inherent
flaws in the policy process requires an ex-
planation of why the process did not cause
similar mistakes in the past. But the events
of 1981 which produced the deficit illustrate
several of the difficulties of economic pol-
icymaking which make mistakes harder to
avoid:
the uncertainty of macroeconomic fore-
casting;
the isolation of monetary and fiscal
policy;
the contentiousness of economists and
their tendency to let their ideological posi-
tions cloud their judgments about the
likely effects of particular policies.
That a tax cut unmatched by comparable
spending cuts would produce a deficit should
have surprised no economist. That the deficit
was so large reflected both economic and
political miscalculations. The Reagan Ad-
ministration has been faulted for masking
the deficit with a "rosy scenario," but the
fact is that most of the forecasting commun-
ity, including the Congressional Budget
Office, expected positive real growth in the
economy. The administration's official fore-
cast differed from the rest only in its degree
of optimism. Forecasters in and out of
government were oversanguine about growth
largely because they failed to realize how
serious the Federal Reserve was about rein-
ing in the money supply to control inflation.
The Fed was not defying the administration,
which was touting the efficacy of monetary
stringency for controlling inflation, but hard-
ly anyone seemed to remember that the way
tight money controls inflation is by slowing
economic activity. Moreover, as our Associa-
tion's President-elect, Robert Eisner, has
pointed out (1986, p. 146), the economics
community, unfamiliar with a world of high
inflation rates, overestimated the stimulative
effect of the existing deficit. Added to this
was the enthusiasm of the ideological propo-
nents of smaller government, some of whom


### ---Economics-1987-0-05.txt---
exaggerated the possible effects of lower tax
rates on supply and some of whom simply
hoped that deficits would pressure Congress
to cut back domestic spending. The size of
the deficits was also masked by the assump-
tion of unspecified future spending cuts, an
assumption reflecting the view that the U.S.
government was operating a lot of wasteful
programs with little public support which
Congress could soon be persuaded to reduce
or eliminate.
Both in the administration and in Con-
gress, decisions were made at a breakneck
pace, in a highly charged political atmo-
sphere, amid conflicting claims and compet-
ing forecasts, with little attention to the con-
sistency of monetary and fiscal policy and
mostly by people with little experience in
evaluating the reasonableness of any set of
economic estimates. (See David Stockman,
1986, ch. 3.) When the dust settled, we found
ourselves with a serious recession that
nobody expected, and an escalating struc-
tural budget deficit that nobody wanted. It
was hardly economic policy's finest hour.
The agonizing-and so far only partially
successful- struggle to correct the mistakes
of 1981 have kept the economic policy pro-
cess under stress and have continued to
dramatize some of its weakest aspects. The
struggle between the president and the Con-
gress over deficit solutions illustrates the
price we pay for the separation of powers.
The fact that fiscal policy has become an
exercise in damage control, while the Federal
Reserve makes all the important decisions
about the economy, underlines the sep-
aration of monetary and fiscal policy. The
sensitivity of deficits to the pace of the econ-
omy advertises the unreliability of macroeco-
nomic forecasts. The fact that all the actions
that could be taken to correct the deficit are
unpleasant ones drags out the annual agony
of budget setting interminably and drama-
tizes how layered and cumbersome it has
become.
Small wonder that the strains of the last
few years, with a little help from the press,
have reinforced the negative stereotypes that
economists and political decision makers
have of each other. Political decision makers
see economists as quarrelsome folks who
cannot forecast, cannot agree, cannot ex-
press themselves clearly, and have strong
ideological biases. Economists return the
favor by regarding politicians as short-
sighted, interested only in what is popular
with the electorate, and unwilling to face
hard decisions. All of the stereotypes are
partly right.
Politicians embody their stereotype in
economist jokes. Economists have retaliated
more massively by applying the tools of their
trade to the political system itself. Public
choice theory essentially asks the question:
what would economic policy be like if our
stereotype of politicians were entirely true?
The answer provides considerable insight
into observed political behavior and cer-
tainly helps explain why the idealistic econo-
mist so often fails to find the system simulat-
ing the public interest motivation of the
philosopher queen.
III. Some Drastic Nonsolutions
Widespread concern that the economic
policy process is not working well has
spawned proposals for drastic change that
move in two quite different directions: one
toward circumscribing the discretion of
elected officials by putting economic policy
on automatic pilot and the other toward
making elected officials more directly re-
sponsible to the voters for their policies.
The automatic pilot approach 'flows from
the perspective of public choice theory that
the decisions of democratically elected of-
ficials interested in staying in office cannot
be counted on to produce economic policy
in the social interest, but are likely to be
biased toward excessive government spend-
ing, growing deficits, special interest tax and
spending programs, and easier money. A
way to overcome these biases is to agree in
advance on strict rules of economic policy,
such as a fixed monetary growth path or
constitutionally required balance in the
federal budget.
Even if one accepts the premises, however,
firm rules are hard to define in a rapidly
changing world -no one seems to know what
"money" is anymore-and can easily lead
to perverse results. Recent experience with


### ---Economics-1987-0-06.txt---
trying to reduce the federal deficit along
the fixed path specified by the Gramm-Rud-
man-Hollings amendment, for example, has
given us a taste of some of the possible
disadvantages of a balanced budget rule.
There is danger that specific dollar targets
for the deficit will require procyclical fiscal
policy, perhaps precipitating a recession that
would then make budget balance even less
attainable. Moreover, the effort to reach the
targets can induce cosmetic or self-defeating
measures, such as moving spending from one
fiscal year to another for no valid reason,
selling assets to reduce a current deficit while
exacerbating future ones, and accomplishing
desired purposes by regulatory or other non-
budgetary means.
The Gramm-Rudman-Hollings experience,
however, has suggested the usefulness of a
different approach to deficit reduction than a
balanced budget rule; namely, a deficit neu-
tral amendment rule. If legislators advocat-
ing a tax preference are required to propose
a rate increase to pay for it, special interest
tax legislation may falter. Similarly, the re-
quirement that a proposal for additional
spending be accompanied by a simultaneous
proposal to raise taxes or reduce another
spending program may be an effective brake
on deficits.
The other direction of reform reflects the
contrasting view that the separation of
powers and the diffusion of responsibility in
our government make it too difficult for the
electorate to enforce its will by holding offi-
cials responsible for their policies. The
potential for deadlock would be reduced if
the United States moved toward a parlia-
mentary system, or found a way to hold
political parties more strictly accountable for
proposing or carrying out identifiable poli-
cies.
Casual examination of parliamentary de-
mocracies, such as the Untied Kingdom and
Sweden, does not provide striking evidence
of the superiority of parliamentary systems
for making economic choices, even if one did
not have two hundred years of tradition to
contend with in changing our system. The
more modest notion that our system would
work more smoothly if political parties had
better defined positions and disciplined their
elected members more strictly may well be
right, but seems to fly in the face of current
history. Voters are showing less strong party
affiliation and more inclination to choose for
themselves among candidates, while mem-
bers of Congress tend increasingly to be
pragmatists willing to work out nonideologi-
cal compromises across party lines. These
trends seem likely to be the irreversible con-
sequences of greater education, sophistica-
tion, and exposure to public issues among
voters and elected officials alike and to make
a resurgence of party discipline and loyalty
unrealistic.
IV. Making the Economic Policy System
Work Better
My own proposals involve less drastic
changes in the structure of our government.
They reflect a strong faith in the ability of
informed citizens and their elected repre-
sentatives to make policy decisions for the
common good, even to make substantial
sacrifices and take political risks to further
what they perceive as the long-run national
interest-once they understand what the
choices are. I also believe that the separation
of powers between the executive and legisla-
tive branches works pretty well most of the
time. It provides needed protection against
overzealousness in either branch, albeit at
some risk of occasional stalemate.
The main problem, it seems to me, is that
our economic policy system has gradually
become so complex, diffused, and frag-
mented that it impedes rather than fosters
informed choices on major issues. The frag-
mentation imposes two kinds of costs. First,
it makes the decision process itself exceed-
ingly inefficient. Decisions are made too
often, in too great detail, and reviewed by
too many layers of decision makers in the
executive branch and in Congress. Too much
time is absorbed in procedure and in wran-
gling over details, not enough on major deci-
sions. It's time to simplify the process, to
weed out some of the institutions, and to tip
the balance between substance and process
back toward substance.
Second, decisions are made separately that
ought to be made together, or at least with


### ---Economics-1987-0-07.txt---
attention to their impact on each other. The
separation of monetary and fiscal policy is
one example; the separation of tax and
spending decisions is another. Congress has
made a good deal of progress in recent years
in putting spending decisions together with
their revenue or deficit consequences, but
more could be done. I have seven steps to
suggest that might make the economic policy
process work more effectively.
First, seek out decisions that should be
made less frequently and arrange to do so.
This would economize decision-making time
and enhance the chances of thoughtful,
well-informed decisions. It would free up
time and energy for managing the govern-
ment enterprise more effectively, with a
longer planning horizon. It would also re-
duce the inefficiency and sense of unfairness
that goes with frequent changes of the rules.
Making the federal budget every other year
would be a major advance. Major revisions
of the tax code should occur even less fre-
quently. Big ticket acquisitions, such as major
weapons systems, should be reviewed thor-
oughly at infrequent intervals and then put
on a steady efficient track, not constantly
revisited.
With a two-year budget, there would occa-
sionally be major events, such as a sudden
escalation of international tension or a sharp
unexpected shift in the economic outlook,
that would justify reopening the budget in
midstream, but the temptation to tinker fre-
quently should be strongly resisted. The
argument that economists cannot forecast
accurately two years in advance, while quite
true, does not undermine the case for a
multiyear budget. It simply reinforces the
point that discretionary fiscal policy is
hazardous and ought to be viewed with great
skepticism whether the budget is annual or
biennial.
Second, seek out decisions that need not
be made at all and stop making them. Some
spending programs could be consolidated
into block grants or devolved to the states,
not necessarily in the interest of smaller
government, but in the interest of greater
responsiveness to local needs and a less
cluttered federal decision schedule. In other
cases, the responsibility is clearly federal-as
in defense-but Congress would be doing its
job more effectively if it concentrated on
major policy issues rather than on details of
program management.
Third, in the executive branch, consoli-
date authority for tax, budget, andfiscalpolicy
in a single cabinet department. The depart-
ment could retain the name Treasury, but
might better be called the Department of
Economic Affairs. The Secretary of Eco-
nomic Affairs should have a high level chief
economist or economic council with a strong
professional staff. The chief economist should
work closely with the budget director who
also should report to the Secretary. The pur-
pose would be to bring together economic
decisions now made in OMB, CEA, and
Treasury under one high-level responsible
person, to relieve the president of the duty
of adjudicating among so many potentially
warring power centers, and to increase the
chances of building a highly professional
permanent economic staff one step removed
from the short-run political concerns of the
White House.
Fourth, streamline the congressional
committee structure to reduce the number of
steps in the budget process. The authorizing
and appropriating functions should be com-
bined in a single set of "program commit-
tees," one for each major area of public
spending. This would imply a single defense
committee, for example, and a social in-
surance committee. The tax committees
should handle the revenue side-not ad-
ditional spending programs as at present.
The budget committees would be charged
with considering fiscal policy and putting the
spending and revenue sides together into a
budget to be passed by the whole congress.
The Joint Economic Committee should cel-
ebrate the important contributions it made
to economic understanding in the days be-
fore the budget process and then close up
shop.
Fifth, bring monetary and fiscal policy
into the same conversation. This end could be
furthered by closer formal links between the
central bank and the Department of Eco-
nomic Affairs to dramatize the need for con-
sultation and interaction. The Federal Re-
serve chairman should make a report to the


### ---Economics-1987-0-08.txt---
budget committees of Congress laying out
recommended short- and longer-run eco-
nomic goals for the nation and discussing
combinations of monetary and fiscal strate-
gies to achieve them. The Fed's report should
be an important input to congressional de-
liberations on fiscal policy.
Sixth, strive for a government-wide offi-
cial economic forecast to be updated on a
regular schedule. The main purpose of the
common forecast would be to reduce the
confusion generated by conflicting estimates,
but the increased interaction between the
Department of Economic Affairs, the Con-
gressional Budget Office, and the Federal
Reserve necessary to create such a forecast
would increase mutual understanding of what
is happening to the economy and what the
goals of policy should be. Occasionally, it
might be necessary for one of the agencies to
dissent and explain why it disagreed with the
forecast, but these occasions are likely to be
infrequent. There should also be more atten-
tion than at present to the consequences for
policy of the forecast being wrong.
Finally, bring choices explicitly into the
decision process, both in executive branch de-
liberations and, especially, in Congress. Those
proposing spending increases or tax reduc-
tions should routinely be required to specify
what is to be given up and to offer both the
benefit and its cost as a package. In other
words, proposals should be deficit neutral.
V. What Economists Can Do
For their part, how can economists be
more useful in the policy process? The press
and politicians often sound as if they are
telling us to work harder: go back to your
computers and don't come out until you
known how the economy really works and
can give us reliable forecasts. But economists
know that the economic system is incredibly
complicated, and that increasing global in-
terdependence and rapidly changing technol-
ogies and public attitudes are not making it
easier to understand. It is not likely in our
lifetimes that anyone will happen on a
paradigm that explains everything, or even
that forecasting will become appreciably
more accurate. Like the medical profession,
which also deals with an incredibly complex
system, we economists just have to keep
applying our imperfect knowledge as care-
fully as possible and learning from the re-
sults. Both doctors and economists need
humility, but neither should abandon their
patients to the quacks.
The objective of economists ought to be to
raise the level of debate on economic policy,
to make clear what they know and do not
know, and to increase the chances of policy
decisions that make the economy work bet-
ter. Much of the time that means telling the
public and politicians what they would rather
not hear: hard choices must be made. We
are stuck with being the dismal science.
Increased effort in three directions would
make economics more useful in the policy
process. First, economists should put much
more emphasis on their areas of agreement.
The press admittedly makes this difficult.
Agreement is not news, and the press' stereo-
type of economists' diversity of views is so
entrenched that they will go to great lengths
to scare up a lonely dissenter to an almost
universally held economic platitude and give
her equal time.
Economists realize that the breakthrough
insights around which "schools" are built
are at best partial visions of the truth, but
our training leads us to elaborate and dif-
ferentiate these insights, to explain to our-
selves and to others where they lead in
different directions, not where they come
together. Yet areas of agreement are
wide -even in macroeconomics-and a
major effort to make this clearer to ourselves
and our audience would be useful.
Second, economists should devote more
serious attention to increasing the basic eco-
nomic literacy of the public, the media, and
the political community. While the print media
seem to me increasingly knowledgeable and
sophisticated about economic issues, televi-
sion, where most people get most of their
information, lags far behind. Television
coverage of the economy is heavily weighted
to isolated economic statistics reported with-
out context-the wholesale price index in-
creased two-tenths of a percent in October
-and talking heads disagreeing, briefly, for
some obscure reason. Some of the best news-
casters appear to have bad cases of econom-
ics phobia.


### ---Economics-1987-0-09.txt---
Media bashing is not the answer. The
profession needs to take the lead in explain-
ing more clearly what is happening to the
economy, why it matters, and what the argu-
ments are about or ought to be about. This
means more than each of us taking a little
time to make a luncheon speech, write an op
ed piece, or appear on a talk show. It means
sustained efforts on the part of teams of
economists to figure out how to present eco-
nomic ideas more interestingly and under-
standably, developing new graphics and other
teaching tools and getting feedback from
real audiences. The technology is available
and the audiences exist-the number of peo-
ple who will watch long hard-to-follow con-
gressional debates and hearings on cable
television is quite astonishing. We just need
to devote the kind of effort and ingenuity
that goes into explaining to audiences the
complex, fast-moving, jargon-ridden game
of football to our complex, fast-moving,
jargon-ridden game of economics.
Third, economists need to be more careful
to sort out, for ourselves and others, what
we really know from our ideological biases.
George Stigler pointed out in his presidential
address (1965) that economists beginning
with Adam Smith have not hesitated to make
strong assertions, both positive and negative,
about the effectiveness of government inter-
vention without offering serious evidence to
support their claims. For two hundred years,
"the chief instrument of empirical demon-
stration on the economic competence of
the state has been the telling anecdote"
(pp. 11-12). In the more than two decades
since Stigler presided over our Association,
an enormous amount of useful empirical
work has been done, as he predicted it would
be, on the effectiveness of government pro-
grams, the costs and benefits of regulation,
and so forth. Still the arguments among
economists about the merits of larger vs.
smaller government too often revolve around
anecdotes or, worse, misleading statistics
quoted out of context. My own anecdotal
evidence would lead me to believe that liber-
als and conservatives are about equally
guilty.
My concern is not with economists taking
sides on policy issues or acting as advocates
of particular positions. Indeed, I think many
policy debates would be clarified if there
were more formal and informal opportuni-
ties for economists to marshall the evidence
on each side and to examine and cross-ex-
amine each other in front of some counter-
part of judge or jury.
We economists tend to be uncomfortable
in the role of partisans or advocates, prefer-
ring to be seen as neutral experts whether we
are or not. Lawyers move more easily among
roles; and the best are able to serve with
distinction at different times as prosecutors,
defenders, experts, and judges. The system
works well when the roles are played com-
petently and the rules of evidence strictly
observed. Economists might increase their
usefulness to the policy process if they made
clear at any given moment which role they
were playing. More important, we need to
work hard to raise the standards of evidence,
to make clear to the public and the par-
ticipants in the political process what we are
reasonably sure we know and how we know
it, and where we are guessing or expressing
our preferences.
## Economics-1988-0


### ---Economics-1988-0-03.txt---
It is tempting to use the audience captured
by a presidential address to pontificate about
the sad state of economics. You probably
will conclude that I have surrendered to the
temptation. But I do recognize that my good
luck in becoming president of our Associa-
tion does not automatically endow me with
commanding wisdom over all of economics.
I will do my best to stick to my knitting.
And for many years much of my research
has been directly toward investment in hu-
man capital and the understanding of family
behavior.
Modern economists neglected the behav-
ior of families until the 1950s. Since then
economic analysis has been used to explain
who marries whom and when (if ever) they
divorce, the number of children and invest-
ments in each child's human capital, the
extent and timing of labor force participa-
tion by married women, when elderly parents
rely on children for support, and many other
family choices. A fair conclusion, I believe
(need I remind you of my biases?), is that
the economic approach contributes impor-
tant insights toward explaining the large de-
cline in birth rates during the past 100 years,
the rapid expansion in the labor force par-
ticipation of married women after the 1950s,
the explosive advance in divorce rates during
the past two decades, and other major
changes in the family. Family economics is
now a respectable and growing field.
Yet perhaps because family economics is a
new field, only a small literature considers
the implications for other parts of eco-
nomics. The family is such an important
institution that progress in understanding
how it behaves is justification enough for
any discipline. But most economists, includ-
ing the audience here, are not particularly
concerned about family behavior. Your in-
terest must be stimulated through a demon-
stration that its study helps in the analysis of
other problems.
In this address I try to maintain your
interest by exploring the contribution to
macroeconomics from the progress in family
economics. This is a challenge not only be-
cause macro behavior is a central part of
economics but also because its link to the
family may seem remote and unimportant.
By macroeconomics I mean the analysis of
economywide behavior. Much of the time is
spent on long-term economic growth, al-
though I also discuss short and long cycles in
economic activity, and the interaction be-
tween overlapping generations through So-
cial Security, transmission of inequality, and
in other ways.
Of course, one paper even by a macro
expert cannot do justice to these topics, and
I do not pretend to be such an expert. My
purpose is to help you recognize that many
conclusions in these and presumably other
macro areas change radically when family
choices get the attention they deserve. I
apologize for the technical nature of some of
the discussion that may seem out of place in
a presidential address.
I. The Malthusian and Neoclassical Models
In considering the relation between eco-
nomic growth and the family, it is natural to
begin with Thomas Malthus's great contri-
bution. Although usually called the Malthu-
sian theory of population growth, a more
appropriate name is the Malthusian theory


### ---Economics-1988-0-04.txt---
of wages and average income. His first
monograph, subtitled "With Remarks on the
Speculations of Mr. Godwin, M. Condorcet,
and Other Writers," begins with an objection
to the conclusion of these writers that the
economic position of mankind will continue
to improve over time. In the process of re-
butting their arguments, Malthus develops
his famous theory of population growth and
reaches much more pessimistic conclusions
about the long-term economic prospects of
the average family.
You will recall that the Malthusian model
assumes diminishing returns to increases in
the level of population-that is, to increases
in employment-when land and other capital
are fixed. The analytical heart of his model
(I am not concerned with the details of what
he actually said) is consistent with constant
returns to the scale of labor and capital, as
long as the capital stock, including usable
land, does not respond to changes in wages
and interest rates.
The response of fertility and mortality to
changes in income determine the Malthusian
supply of population. Population grows more
slowly when wages are low because the aver-
age person marries later and thereby has
fewer children (the preventive check on
population), and also because deaths in-
crease when families are poorer (the positive
check). Historical studies indicate that the
effect of the economy on age at marriage was
considerably greater, at least in Europe, than
was its effect on death rates (see Ronald D.
Lee, 1987b, pp. 450-51). Therefore, I will
ignore the positive effect and consider only
the preventive check through changes in the
number of children.
The long-run equilibrium wage rate is
found at the point on the positively inclined
population supply curve where the average
family has two children. The economy's pro-
duction function then determines the sta-
tionary level of population that is consistent
with this long-run wage rate. There is no
presumption that this equilibrium wage is at
the subsistence level, especially if the posi-
tive check through death rates is not im-
portant. In this model tastes for marriage
and children, not vague notions of sub-
sistence, determine long-run wages.
The long-run wage is stable in the Mal-
thusian model when shocks push the system
out of equilibrium. For example, if an infec-
tious disease destroys much of the popula-
tion, as the Black Death destroyed perhaps
25 percent of certain European populations
during the fourteenth century, the decline in
population raises the marginal productivity
of labor. The resulting rise in wages encour-
ages families to marry earlier and have more
children. Population begins to grow and its
increase over time lowers wage rates back
toward equilibrium. Ultimately, this dy-
namic process restores both the wage rate
and the level of population to their long-run
levels.
If the amount of usable land increases,
wages rise and that stimulates higher birth
rates. Again, the growth in population con-
tinues to lower wage rates until eventually
the long-run wage is restored. However,
population is permanently higher because
the amount of land is greater.
This example brings out that the equi-
librium wage is more immune to shocks in
the Malthusian system than is the level of
population. Indeed, if tastes are stable over
time-the Malthusian model, along with
George Stigler and myself (1977), assumes
de gustibus non est disputandum -and if
technology does not continue to improve,
the equilibrium wage rate remains fixed by
the point on the stable supply curve where
the typical couple has two surviving children.
The Malthusian model does help some in
explaining very long-term changes in
European wage rates prior to the nineteenth
century (Lee, 1987b, gives a good analysis of
the evidence). People evidently married
earlier when wages were above the equi-
librium level and married later when they
were below.
It is ironic that Malthus's first essay on
population was published in 1798 at the
close of the eighteenth century. Although his
system was accepted by many leading
economists of the nineteenth century (see
John Stuart Mill, 1848, Book I, ch. X), events
after publication were not kind to the the-
ory. Fertility eventually fell sharply rather
than rose as wage rates and per capita in-
comes continued to advance during much of


### ---Economics-1988-0-05.txt---
the nineteenth and twentieth centuries in the
United States, Western Europe, and Japan.
The contradiction between the theory and
events explains why most economists during
the first half of this century showed little
interest in explaining long-term trends in
income and population. But the subject
is too important to remain neglected, and
Robert Solow, David Cass, and others devel-
oped the neoclassical growth model in the
1950s and early 1960s. This model incorpo-
rates two major advances over the Malthu-
sian model. Each person maximizes utility
that depends on present and future con-
sumption. More important is the recognition
that changes in the capital stock respond to
rates of return on investments. Unfor-
tunately, the neoclassical model also takes a
sizable step backward from Malthus by as-
suming that fertility and other dimensions of
population growth are independent of wages,
incomes, and prices.
I trust that the basic properties of a simple
neoclassical model are familiar. What may
not be generally appreciated is that despite
the different assumptions, the analytic struc-
tures of the neoclassical and Malthusian
models are quite close and many of their
implications are similar. If technology and
preferences do not change over time, both
models have stable steady-state levels of per
capita income. The neoclassical equilibrating
mechanism works through changes in the
rate of investment, while the Malthusian
mechanism works through changes in the
rate of population growth. To illustrate, if
the capital-labor ratio exceeds its steady-state
level, the rate of return on capital is below
and the wage rate is above their steady-state
levels. In the neoclassical model this discour-
ages investment, which lowers the capital-
labor ratio over time (with exogenous popu-
lation growth). In the Malthusian model this
encourages population growth, which also
lowers the capital-labor ratio over time (with
exogenous investment in capital). We have
seen that a shock to population in the
Malthusian model has no effect on the level
of population or per capita income in the
long run. Similarly, in the neoclassical model
a shock to the capital stock (perhaps wartime
destruction of capital) has no long-run effect
on the aggregate capital stock or per capita
income.
The persistent growth in per capita in-
comes during the past two centuries is no
easier to explain within the neoclassical
framework than within the Malthusian. Of
course, the neoclassical model postulates ex-
ogenous technological progress to "explain"
continuing growth in per capita incomes, but
the need to rely on "exogenous" progress is
a confession of failure to explain growth
within the model. Moreover, the Malthusian
model can equally well postulate exogenous
progress to "explain" persistent growth.
II. The Family and Economic Growth
After a short while the economics profes-
sion became disenchanted with the neoclas-
sical model, presumably because it too did
not help in understanding progress. The ex-
citement reflected in hundreds of papers that
extended and elaborated this model in the
1950s and 1960s gave way during the past
fifteen years to a lack of interest in the
analytics of growth that is a little remi-
niscent of the situation during the first half
of the century.
Fortunately, a more relevant growth model
is available through combining the best fea-
tures of the neoclassical and MIalthusian
models and by adding a focus on investment
in knowledge and skills. The neoclassicists
are right to emphasize endogenous capi-
tal accumulation and utility maximization.
Malthusians are right to stress the response
of fertility and other components of popula-
tion growth to changes in the economy, and
that these responses can greatly influence
economic change.
I will sketch out a modified neoclassical
model where parents choose both the num-
ber of children and the capital (human or
physical) bequeathed to each child. Parental
altruism or "love" toward children provides
a powerful framework for the analysis of
both the quantity and so-called quality of
children. Altruism means that the utility of
parents depends on the utility of each child.
The assumption of altruism is realistic for
the vast majority of families, although
parent-child interactions are determined also


### ---Economics-1988-0-06.txt---
by other motives. Presumably, the altruism
per child is negatively related to the number
of children, so that an additional child lowers
the utility per child to parents in the same
way as (please excuse the analogy) an ad-
ditional car lowers the utility per car.
Such altruism is easily grafted onto the
neoclassical utility function by letting par-
ents' utility depend on their own life-cycle
consumption and separately on their degree
of altruism per child, the number of children,
and the utility of each child. This formula-
tion has the important implication that pref-
erence for parents' relative to children's con-
sumption (so-called time preference) is not
exogenous but rises as the number of children
increases.
The resources available to parents from
the capital they inherit and labor earnings
are spent either on own consumption, on the
costs of rearing children, or on transfers to
children of human and other capital. Since
child rearing is time intensive, the cost of
rearing children is positively related to the
value of parents' time. Income per capita
would rise between the parents' and the
child's generations if the total capital be-
queathed to each child exceeds the capital
inherited by each parent.
Parents choose optimal values of their own
consumption, the number of children, and
capital transferred to each child while taking
into account the cost of rearing children and
the dependence of their utility on the utility
of children. This analysis has many implica-
tions for the behavior of fertility that Robert
Barro and I explore elsewhere (see 1987 and
1988). Here I concentrate on a few that alter
implications of the neoclassical model about
capital accumulation and growth.
If the number of children demanded by
the typical family is positively related to the
income of parents (the Malthusian assump-
tions), or at least if it is not strongly nega-
tively related, then this model also has stable
steady-state levels of the capital-labor ratio
and per capita income. But these steady
states depend on variables that change the
demand for children.
One example is the consequences of an
extended but temporary decline in income
and productivity-perhaps due to the dis-
organization induced by a lengthy depres-
sion. In the neoclassical model this has no
long-run effect on either per capita or ag-
gregate income. In our modified model an
extended decline in productivity can perma-
nently lower aggregate income because birth
rates may fall when productivity, wages, and
interest rates fall. Recall the sharp decline in
birth rates during the Great Depression.
Just over a decade age, Barro (1974)
showed that a dose of family economics
radically alters traditional conclusions about
the effects of budget deficits on private sav-
ings. For example, deficits to finance Social
Security payments tax future generations to
support the elderly. Altruistic parents who
leave bequests to their children do not seek
an intergeneration redistribution of incomes,
so they would increase their bequests to offset
the effect on children of future taxes. If these
families are common, Social Security pay-
ments and other public expenditures financed
by taxes on future generations would not
have much effect on private savings. This is
the so-called Ricardian equivalence theorem.
A larger dose of family economics gives
more radical implications in some respects
but also has more conventional implications
for the relation between Social Security and
savings. Various comments on Ricardian
equivalence emphasize that some families do
not leave bequests; I will discuss these fami-
lies in Section IV. Development economists
have long recognized that parents value
children who provide support during old age.
A Social Security system that replaces child
support of parents with public support raises
the net cost of children to parents (not to
society) since they are no longer as useful to
elderly parents. As a result, a Social Security
system tends to reduce the demand for
children. Social Security also reduces the
demand for children by parents who do not
receive support but provide bequests. The
net cost of children to these parents also
increases when they raise bequests to offset
the effect of Social Security taxes on children.
For reasons given earlier, a lower demand
for children raises the capital bequeathed to
each child. Therefore, Social Security and
other public transfers between generations
would raise private savings per child, and as


### ---Economics-1988-0-07.txt---
a result, raise wage rates and the capital-labor
ratio in the next generation. Yet total private
savings of the present generations would fall,
as in a conventional life-cycle analysis with
no bequests, if the decline in fertility exceeds
the greater saving for each child.
Consider next an example from tax inci-
dence. A tax on income from capital initially
lowers after-tax returns and discourages in-
vestment. In the neoclassical model, capital
then falls over time until the after-tax rate of
return again equals the given rate of time
preference. In public finance jargon, a tax on
capital would be fully shifted in the long
run.
A difficulty with this conclusion is the
neoclassical assumption that fertility is fixed,
which is especially inappropriate for very
long-term changes in incidence. Fertility
would fall as capital fell in response to the
tax if fertility is positively related to per
capita income. A fall in fertility lowers pref-
erence for present consumption and raises
the demand for investment in each child
through the interaction between the quality
and quantity of children. Then the equi-
librium after-tax rate of return must also
fall, and the tax on capital is only partially
shifted even in the long run.
The conclusion is more radical if fertility
is negatively related to per capita income
(for reasons discussed next). Fertility then
increases when the stock of capital falls.
Since the increase in fertility lowers invest-
ment per child, the equilibrium after-tax rate
of return would have to increase. That is, we
have the paradox that a tax on capital is
eventually shifted by more than 100 percent!
Let me assure the theorists that this strange
result does not violate the second-order con-
ditions.
Does a negative relation between fertility
and per capita income imply that children
are an "inferior" good (to use the economist's
infelicitous language)? The answer is no be-
cause the cost of rearing children increases
when the capital-labor ratio and per capita
income rise since wage rates and the value of
parents' time spent on children rise along
with the capital-labor ratio. Fertility would
fall if the positive effect on fertility of an
increase in income is weaker than the nega-
tive effect due to the rise in cost. The sub-
stitution effect often dominates the income
effect in rich countries, for child care in these
countries requires considerable time and en-
ergy of parents.
If fertility is negatively related to per capita
income, an increase in the capital-labor ratio
above its steady-state level would reduce
fertility and thereby encourage more invest-
ment per child. The capital-labor ratio would
continue to increase over time if this positive
effect on investment dominates the negative
effect of a lower rate of return. Conse-
quently, a negative relation between fertility
and per capita income can destabilize what
is otherwise a stable steady state (see the
formal analysis in Robert Tamura, 1986).
Demographers have long been aware that
fertility eventually declines as a country
develops. Less well appreciated (although
see the earlier literature by R. R. Nelson,
1956; Robert M. Solow, 1956, pp. 90-91;
S. C. Tsiang, 1964, and others on low-level
" traps") is that a negative relation between a
country's fertility and its income can de-
stabilize a steady-state equilibrium and cause
a protracted period of rising per capita in-
comes. However, although a decline in fertil-
ity is an important stimulus in early stages of
development, it alone cannot explain sus-
tained growth over a century or longer. In
the absence of other forces, a growing econ-
omy with neoclassical production functions
but without continuing technological pro-
gress eventually moves to a stable steady
state with low fertility and high per capita
incomes.
A promising approach to sustained growth
that complements the role of fertility builds
on the special properties of education and
other learning. The important property for
this purpose is that investments in education
and other human capital are more produc-
tive when past investments are larger. That
is to say, accumulation of knowledge and
skills in the past eases the acquisition of
additional knowledge. The mastery learning
concept in education pedagogy uses this
property to organize the teaching of math-
ematics and other subjects to children (see
Benjamin S. Bloom, 1976). Such a produc-
tion technology implies that rates of return


### ---Economics-1988-0-08.txt---
on investments in human capital may not
fall and may even rise as the stock of human
capital grows.
Perhaps it was reasonable in Malthus's
time to neglect investments in human capital,
but there is little excuse for the neglect in
neoclassical growth theory. Modern econo-
mies spend enormous amounts on education
and other training of children, and parents'
investments in children are a far more im-
portant source of an economy's capital stock
than are bequests or the life-cycle accumula-
tion of physical capital. Dale Jorgenson and
Barbara Fraumeni (1987) estimate that hu-
man capital comprises over 70 percent of the
total capital stock in the United States. This
estimate may be too low because it does not
include the contribution of human capital to
output in the household sector (the authors
do try to estimate household output). Sev-
enty percent may be higher than the true
fraction because it makes no allowance for
the contribution of "raw labor" to output. I
would guess that the true ratio of human
capital to the total capital stock may be as
high as 90 percent or as low as 50 percent.
Of course, even this lower percentage sig-
nifies a large contribution. The neglect of
human capital in wealth and income accounts
greatly distorts comparisons of savings pro-
pensities and the accumulation of wealth.
Only recently have growth models begun
to appreciate the potential of the learning-
by-having property of human capital for
generating sustained growth in per capita
incomes (see Paul Romer, 1986; Robert E.
Lucas, Jr., 1988; and Robert G. King and
Sergio Rebelo, 1986; pioneering earlier work
includes Kenneth J. Arrow, 1962; Yoram
Ben-Porath, 1967; Hirofumi Uzawa, 1965;
and Sherwin Rosen, 1976). Kevin M. Murphy
and I are developing an analysis that com-
bines such a human capital technology with
unskilled labor, physical capital, and endog-
enous fertility that results from altruism. (See
Gary S. Becker, 1971, pp. 204, 207-208, for
an earlier effort to combine human capital,
unskilled labor, and physical capital.) Our
model has a " Malthusian" equilibrium where
per capita income is constant and low and
fertility is high. However, if this equilibrium
receives big enough technology and other
shocks-good luck may be required-the
economy takes off toward a perpetual growth
equilibrium with a decline in fertility and
increased investment per child. Knowledge
continues to grow through its embodiment
in additional human capital.
Family economics is critical to the analy-
sis since choices about number of children
and investments in each child's human
capital helps determine whether the econ-
omy ends up at a "good" (i.e., growth) equi-
librium or at a "bad" (i.e., Malthusian) equi-
librium. Obviously, we do not have the full
answer to economic growth-public policies,
conglomeration effects, and other considera-
tions are surely important-but I do believe
that our story contributes a sizable part of
the answer.
III. Short and Long Cycles
Let me now turn briefly to the relation
between family behavior and cycles in ag-
gregate output and other variables. For cen-
turies marriages, births, and other family
behavior have been known to respond to
fluctuations in aggregate output and prices.
In an early use of regression analysis in the
social sciences, G. Udny Yule (1906) demon-
strated that English marriages and births
in the nineteenth century moved together
with the business cycle. Subsequent studies
showed that higher order as well as first
births, divorce rates, and possibly the labor
force participation of secondary workers
all fluctuated procyclically in many coun-
tries (see, for example, Becker, 1960, and
Morris Silver, 1965). Birth rates in the United
States apparently became countercyclical
after many married women entered the labor
force. Children are cheaper during recessions
because the value of time spent on children
by working mothers is low then (see William
P. Butz and Michael P. Ward, 1979). Invest-
ments in education and other human capital
are much less procyclical than investments
in physical capital also because the foregone
value of time spent in school is cheaper
during bad times (Linda N. Edwards, 1975).
Of course, none of the competing macro
models of business cycles-be they Keynes-
ian, monetarist, neoclassical, or real-rely


### ---Economics-1988-0-09.txt---
on family behavior to cause business cycles.
However, declining population growth was a
major cause of the secular stagnation feared
by Alvin H. Hansen (1939) in his presiden-
tial address to our Association almost fifty
years ago. Family behavior may play more
than a negligible role even in generating
ordinary business cycles. For example, an
increase in the labor supply of married wo-
men or young people when household work
or school becomes less attractive can induce
cyclical responses in aggregate output and
other variables. Cycles started by shifts in
labor supply induce a negative relation be-
tween wage rates and aggregate output over
business cycles. This would help explain why
cyclical fluctuations in real wages appear to
be less positively related to cyclical fluctua-
tions in aggregate output than is implied by
business cycles models that emphasize the
demand side.
Although family behavior presumably has
only a small part in the generation of
ordinary business cycles, it is likely to be
crucial to long cycles in economic activ-
ity. Malthus claimed that family choices
cause long-term fluctuations in the economy
through the lagged effects first of marriages
on births and then of births on the size of
the labor force (see Maw Lin Lee and David
Loschky, 1987). Modern demographic analy-
sis generates long cycles in population growth
rates through the relation between aggregate
fertility and the age distribution, and per-
haps also between fertility and the size of a
cohort (see, for example, James C. Frauenthal
and Kenneth E. Swick, 1983, and Ronald
Lee, 1987a). In our modified Malthus-neo-
classical model, family choices cause long
cycles not only in population growth, but
also in capital, output, and other variables if
the elasticity of the degree of altruism per
child with respect to the number of children
declines as families get larger, a reasonable
assumption. Fertility and per capita income
then fluctuate in generation-long cycles when-
ever the economy is disturbed away from the
steady state (for a proof, see Jess Benhabib
and Kazuo Nishimura, 1986).
In the 1920s, the Russian economist
Nicholas D. Kondratieff claimed that capi-
talist economies exhibit long-term fluctua-
tions of about fifty years' duration in output
and prices (see Kondratieff, 1935). Simon
Kuznets (1958) later argued that long-term
fluctuations only last about twenty years. If
long cycles of the Kondratieff or Kuznets
type exist-we will need another 200 years
of data to determine whether they do exist
or are just a statistical figment of an overac-
tive imagination-they almost certainly will
depend on fertility and other family deci-
sions that biologically require a long time to
implement.
IV. Overlapping Generations
The intrinsic risks faced by the elderly,
sick, and unemployed are surely no greater
in rich countries like Germany and the
United States than in poor countries like
China and India, nor do these risks rise as a
country develops. Yet the first large-scale
Social Security program was introduced by
Germany a mere 100 years ago. China, In-
dia, and numerous other countries still have
only modest programs that exclude many of
their old people. We take publicly financed
schools for granted, but they were unim-
portant until the latter half of the nineteenth
century. Public and private programs that
protect against the consequences of illness
and unemployment are even newer and less
common than Social Security and public
schools.
Throughout history the risks faced by the
elderly, young, sick, and unemployed have
been met primarily by the family, not by
state transfers, private charity, or private
insurance. Children usually cared for elderly
or infirm parents, the unemployed looked to
their families for temporary support, and
parents have spent much time, money, and
energy to rear and train their children. De-
spite the rapid growth of Social Security
payments in the past few decades, almost 20
percent of women aged 65 and over in the
United States still live with their children.
The altruism and love of parents, children,
spouses, and other relatives have helped pro-
tect family members against the hazards of
childhood, old age, and other risks. When
altruism is insufficient-unfortunately, it
often is-what sociologists call social norms


### ---Economics-1988-0-10.txt---
frequently emerge that pressure children,
parents, spouses, and other relatives into
helping out family members in need. In ad-
dition, family members use their frequent
interaction with one another to raise the
level of guilt experienced by a member when
he or she does not help out.
The formal analysis of the interaction
among overlapping generations began with
Paul A. Samuelson's brilliant paper in 1958.
This spawned an enormous literature that
continues up to the present. Although
Samuelson had relevant obiter dicta about
social compacts, altruism, and family obliga-
tions, his model and that of most of the
subsequent literature assumes that each per-
son enters the analysis as a young adult
without personal connections to older co-
horts. A long review of overlapping genera-
tion models in the recent New Palgrave Dic-
tionary (see John Geanakoplos, 1987) has no
discussion whatsoever of familial relations
between members of overlapping genera-
tions. I claim that the neglect of childhood
and of the intimate relations among parents,
children, husbands-wives, and other family
members misled these studies sometimes into
focusing on minor problems and diverted
attention away from some important conse-
quences of the overlapping of generations
(the discussion in the next few paragraphs
draws partly on Becker and Murphy, 1988).
One example of the emphasis on unim-
portant problems is the concern with the
plight of older people when there are few
durable assets that can finance consumption
at old age. In an influentual literature on the
demand for money, the social role of money
is even attributed to a durability that
enables older people to finance consump-
tion by selling to the next generation money
accumulated when young (see, for example,
Thomas Sargent, 1987, ch. 7, and Neil
Wallace, 1980). Yet when anthropologists
study simple societies that do not have mon-
ey or other durable assets, they find that old
people finance their consumption main-
ly by relying for support on children and
other kin. Indeed, children have been an
important resource and money balances an
unimportant resource of the elderly in prac-
tically all societies, whether simple or com-
plicated.
General equilibrium theorists are con-
cerned about the continuum of equilibria,
inefficiency, and other problems that arise in
models where overlapping-generations per-
sist indefinitely into the future (see, for ex-
ample, Geanakoplos, 1987, or Timothy J.
Kehoe, 1987). Although these problems
would not completely disappear, I conjec-
ture that they would be much less important
if overlapping-generations models incorpo-
rated the informal trades and assistance
available to parents, children, and other
members of the same family.
Ever since Plato's Republic, philosophers
have worried about whether parents invest
sufficiently in the health, skills, and morals
of their children. Overlapping-generations
models usually neglect childhood and con-
centrate on savings by young adults and
their trades with old adults. The treatment of
children by parents not only is so important
in its own right, but it also greatly influences
the relations between older and younger
adults (Allan Drazen, 1978, is one of the few
earlier studies that recognizes the impor-
tance of investments in children for overlap-
ping-generations models.)
I cannot do more on this occasion than
present the bare bones of an analysis of how
families respond to the demands of both old
age and childhood. The analysis is straight-
forward when altruistic parents leave be-
quests to their children. The combination of
altruism and bequests eliminates any dif-
ficulties in financing the wealth-maximizing
investment in children's health, training, and
other human capital. For if the marginal rate
of return on additional human capital ex-
ceeds the rate on assets, both parents and
children would be better off with additional
capital. Parents can save less to offset the
negative effect on their consumption of
greater spending on their children's human
capital, and they can reduce bequests to
offset the effect of lower savings on con-
sumption at old age.
Bequests also partly insulate parents from
many risks of old age. The opportunity to
draw on bequests provides an annuity-like


### ---Economics-1988-0-11.txt---
protection against an usually long life and
other risks of old age. For example, parents
who live longer than expected reduce be-
quests to help finance consumption in the
additional years. If bequests are not a large
part of children's assets, bequests can give
elderly parents excellent protection against
various hazards, and yet changes in bequests
do not have much influence on children's
welfare. In effect, children help support their
parents in old age, although their support is
not fully voluntary.
The analysis is less simple when parents
do not leave bequests, perhaps because they
are not very altruistic or because they expect
their children to be better off than they are.
These families tend to underinvest in children
and underprotect parents against the hazards
of old age because bequests are not available
to finance investments and old-age support.
Social norms, feelings of guilt, and similar
mechanisms may greatly moderate the de-
gree of underinvestments and underprotec-
tion. They can induce even selfish parents to
invest in children and selfish children to care
for sick or poor parents. Economists neglect
concepts like norms and guilt because no
one really knows how they evolve. Moreover,
sociologists (perhaps I should say "we" soci-
ologists since I am now officially also a soci-
ologist) are too prone to use norms as a
deus ex machina to explain behavior that is
difficult to explain in other ways. Neverthe-
less, there can be little doubt that norms and
other intangible mechanisms do greatly affect
the relations between family members in
many societies, although presumably, they
do not work as well as bequests in linking
generations together.
Parents in richer countries have more re-
sources to spend on children and to protect
against the hazards of old age. Why then
have public expenditures on both the young
and old grown rapidly during the 100 years
as western countries as they have become
richer? One reason is that social norms are
weaker in the anonymous urban communi-
ties of industrial countries where elderly
parents often live far from adult children. A
more analytically tractable reason is the high
rates of return in modern industrial societies
on investments in the health and training of
children. Recall my discussion of the role of
human capital in economic development.
Parents are eager to finance profitable in-
vestments in children called for by economic
development, as long as they can draw on
gifts and bequests that they would give to
children. But gifts and bequests would be-
come nil in many families that invest a lot in
their children. These families would underin-
vest in children, particularly when pressure
from norms is weak. The growth in public
support of schooling and other investments
in children as countries develop would then
appear to be mainly a response to the posi-
tive effect of economic development on the
benefits from human capital.
Since families that do not leave bequests
are vulnerable to the hazards of old age, it is
not difficult to understand why public ex-
penditures on Social Security and medical
care for the elderly have also grown rapidly
in industrial countries. However, you may be
surprised to find out that public expendi-
tures on the old have not been at the expense
of the young. Since 1940 in the United States,
the ratio of expenditures per child under age
22 to expenditures per adult age 65 or over
has hardly changed. Our analysis that com-
bines investments in human capital with old-
age support does explain why expenditures
on the old and young grew in tandem. By
contrast, the popular view of generation
fighting-that public expenditures on the
elderly grew rapidly because the old became
politically powerful as they became more
numerous-cannot explain why expendi-
tures on children grew just as rapidly.
The overlapping-generation framework is
also a natural one to consider inequality and
the transmission of wealth and poverty across
generations. Families help perpetuate in-
equality because children inherit abilities and
other "endowments" from parents. More-
over, parents are the major source of the
assets and human capital of children. This
enormous influence of the family led my
esteemed teacher, Frank H. Knight, to claim
that ".where the family is the social unit, the
inheritance of wealth, culture, education-
al advantages, and economic opportunities


### ---Economics-1988-0-12.txt---
tend toward the progressive increase of in-
equality..." (1935, p. 50).
Abilities and other endowments regress
downward from parents to children in suc-
cessful families where parents earn a lot, and
they regress upward in unsuccessful families
where parents earn little. The poor underin-
vest in each child also because they have
larger families and less stable marriages.
Therefore, children from poorer families tend
to earn more than their parents but below
the average of their generation, and children
from richer families tend to earn less than
their parents but above their generation's
average.
Earnings depend not only on endowments
but also on investments in human capital.
Our earlier analysis implies that richer fami-
lies do not tend to underinvest in their
children's human capital because these
families leave gifts and bequests. Poorer
families do tend to underinvest in children
because they are not likely to leave gifts and
bequests. The poor underinvest in each child
also because they have large families and less
stable marriages. Therefore, the relation be-
tween the earning of fathers and sons in
richer families would depend mainly on the
relation between endowments, while the re-
lation between earnings of fathers and sons
in poorer families would depend also on the
degree of underinvestment in children. Put
differently, without offsetting government
subsidies to investments in the human capital
of poorer children, low earnings would be
more persistent across generations than high
earnings -the so-called "culture of poverty"
across generations would exceed the "culture
of privilege."
In every country with data that I have
seen-this includes the United States and
several European countries (see Table 1 in
Becker and Nigel Tomes, 1986), a few Asian
countries, and some Latin American coun-
tries (James J. Heckman and Joseph V. Hotz,
1986, consider the evidence for Panama)
earnings strongly regress to the mean be-
tween fathers and sons. Probably much less
than 40 percent of the earnings advantages
or disadvantages of fathers pass to sons, and
few earnings advantages or disadvantages
survive three generations. Evidently, abilities
and other endowments that generate earn-
ings are only weakly transmitted from
parents to children. This tendency to go
from "shirtsleeves to shirtsleeves" in three
generations began long before industrializa-
tion and government support of education
and other human capital. The fourteenth
Arab historian and philosopher, Ibn Khaldtun
said (I owe this reference to my wife, Guity
Nashat), "Prestige is an accident that affects
human beings. It comes into being and de-
cays inevitably.... It reaches its end in a
single family within four successive genera-
tions." (1958, p. 279)... "As a rule, no dy-
nasty lasts beyond the [span] of three gener-
ations." (p. 343)
In all these countries, low earnings as well
as high earnings are not strongly transmitted
from fathers to sons, and Knight's claim
about family life causing growing inequality
is inconsistent with the evidence. Still, data
for both the United States and England do
appear to confirm the implication of our
theory that low earnings persist more than
high earnings across generations (see W.
Stanley Siebert, 1987). Of course, incomes of
the rich regress down more slowly between
generations than do their earnings because
rich children receive gifts and bequests
from parents (see Becker and Tomes, 1986,
Table 2).
V. Concluding Remarks
I was attracted to the family by its obvi-
ous importance in all countries, no matter
what the economic system or stage of devel-
opment. People spend much of their time
in a dependency relation-toward parents
when children and toward grown children in
old age-marriage is a crucial step for most
people, children absorb time, energy, and
money from their parents, divorce often
causes economic hardship and mental de-
pression, and so forth. Economic studies of
the family are growing at a steady pace and
they are influencing the way other social
scientists look this fundamental institution.
The economic analysis of family behavior
stimulated the development of techniques


### ---Economics-1988-0-13.txt---
and prospectives that already has affected
many parts of microeconomics, especially
agricultural and labor economics, but also
the study of industrial organization and
preference theory. For example, the treat-
ment of marriage as a sorting of men and
women into small "partnerships" through a
reasonably efficient marriage market in-
fluenced the analysis of how workers and
managers are allocated to different firms.
Viewing divorce as a joint decision by
husbands and wives based largely on infor-
mation gathered from living together encour-
aged some studies of employment sep-
arations to blur the analytical distinction
between quits and layoffs and to emphasize
the information about working conditions
and productivity gathered from on-the-job
experience.
The message of this address, however, is
not the importance of the family per se, even
though family welfare is the principal goal of
a well-run economic system. Nor that ana-
lytical techniques developed to understand
family choices are valuable in other parts of
economics. The message is that family be-
havior is active, not passive, and endoge-
nous, not exogenous. Families have large
effects on the economy, and evolution of the
economy greatly changes the structure and
decisions of families. I illustrated how fami-
lies and the economy interact through a dis-
cussion of economic growth and other issues
in macroeconomics. A heightened awareness
of the interaction between economic change
and family choices will hasten the incorpora-
tion of family life into the mainstream of
economics.
## Economics-1989-0


### ---Economics-1989-0-03.txt---
Four decades ago, in a brilliant review of
Burns and Mitchell's classic work on busi-
ness cycles, Tjalling Koopmans (1947)
sounded a warning against "Measurement
Without Theory." Without theoretical hy-
potheses and constructs to orient investiga-
tion and interpret findings, economists risk
the fate of the blind man studying the ele-
phant.
Recent excursions in vector autoregres-
sions possibly aside, modem econometrics
has generally followed the path of specifying
theoretical relations that make sense in terms
of economic behavior and using empirical
data of time-series or cross sections or both
to estimate the parameters of those relations.
A critical problem, only one surface of which
is touched by Robert Lucas' famous "Cri-
tique" (1976, 1981a), is that key arguments
in most functions are expected values-or
worse, probability distributions-of future
variables. These are generally not observed
and we are reduced to estimating parameters
of current and past variables, for which we
have data we can put into our computers,
and making explicit or, more often, implicit
assumptions about the relation between them
and the relevant but unobservable expecta-
tions.
The frailties of all this have long been
apparent in estimation of demand and sup-
ply functions for individual commodities. We
cannot, after all, even be sure of confirming
the "law of demand," that lower prices will
increase quantities demanded. They proba-
bly will not, if they are associated with
expectations of still lower prices in the
future.
Similar critical problems emerged in esti-
mation of key relations in macroeconomics.
Will an increase in the quantity of money
reduce long-term interest rates? Not, we are
told, if it generates an increased expectation
of inflation or, perhaps, an expectation that
the increase in money will be short-lived and
be reversed in future action by the monetary
authority. What, though, were the expecta-
tions, with regard to inflation or future mon-
etary operations, that generated the data used
in estimating money demand functions? Can
we be sure that these same expectational
relations apply when we try to forecast the
results of a proposed easing of monetary
policy? And is the assumption that expecta-
tions are "rational" of much help if they are
frequently, as John M. Keynes argued, built
on such uncertain knowledge as to be a
fragile phenomenon of social interaction?
The problem of bringing in critical expec-
tational variables is brought front and center
in Franco Modigliani's life cycle (1954) and
Milton Friedman's permanent income (1957)
versions of Keynes' consumption function.
Serious problems remain here in consider-
able part because of our difficulties predict-
ing agents' reactions to uncertainty regard-
ing not only future income but expected
length of life. We thus lack two parameters
defining the resources per unit of time avail-
able for lifetime or permanent consump-
tion.
Difficulties are most excruciating with re-
gard to investment, which is entirely forward


### ---Economics-1989-0-04.txt---
looking. We introduce as arguments of in-
vestment functions such variables as current
and past output, sales, or utilization of ca-
pacity, current or past profits, cash flow or
measures of liquidity, and current or past
interest rates, depreciation rates, and relative
rental price or user costs of capital. Yet our
theory tells us that the arguments we gener-
ally need are again the expected future val-
ues of these variables. Firms should invest if
they expect the future demand for output to
be high, if they expect the cost of capital to
be higher in the future than now, and if they
look to higher future profits as a conse-
quence of current investment, but little if at
all in response to current or past values of
these variables.
But these difficulties in finding proxies for
usually unobservable expectations of the fu-
ture are only part of the overall problem.
Somehow, econometricians, theorists, and
economic analysts of all stripes have lost
essential communication with the compilers
and synthesizers of their data. As a conse-
quence, popular discourse, policymaking,
and basic principles of economics have suf-
fered inordinate confusion. I shall offer this
indictment, in particular, with regard to dis-
cussion of the major macroeconomic vari-
ables with which we are most concerned:
income, output, employment, prices, and
productivity; consumption, saving, invest-
ment, and capital formation; wealth, assets
and liabilities, debt, and deficits. To put
matters bluntly, many of us have literally
not known what we are talking about, or
have confused our listeners-and ourselves
-into thinking that what we are talking
about is directly relevant to the matters with
which we are concerned. In some cases the
confusions do not make all that much dif-
ference, but often they do.'
I. Measures of Income and Product
Take income for starters. We all know
what we mean by income, don't we? Or
do we? The theoretical Hicks-Haig-Simons
(J. R. Hicks, 1940, 1946, 1948; Robert Haig,
1921; Henry Simons, 1938) concept of in-
come is that which we can consume while
keeping our real wealth intact. But this is a
far cry from the usual measures of individual
incomes, corporate profits or the aggregates
of personal and national income.
First, we allow for capital consumption-
the depreciation of existing capital-in
measuring income. We may note that capital
consumption allowances with capital con-
sumption adjustment were 8.22 percent of
GNP in 1951 before the move to perma-
nently higher tax depreciation allowances
began, were 9.14 percent of GNP by 1960,
11.69 percent by 1983, and 11.98 percent in
1987. Did production really become more
capital-intensive, did the capital mix truly
turn that much less durable,2 or is it possible
that we are overstating capital consumption
and understating national and personal in-
come and net saving, both in absolute
amounts and as compared to the past?
What about capital gains and losses? If
the value of our stock or bond or house goes
up, can we not consume the gain in addition
to what is usually counted as income, and
still keep our wealth intact? We must indeed
distinguish between the nominal gain and
the real gain, that is, the increase in nomi-
nal value over and above the increase that
would be necessary to compensate for gen-
eral inflation. But should not the real gain, in
conformity with the Hicks-Haig-Simons con-
cept, which I shall denote as "theory," be
included in properly measured income?

### ---Economics-1989-0-05.txt---
If nominal interest rates are 9 percent and
inflation runs at 4 percent, should we include
all of interest receipts in income? Or should
we not recognize that 4 percent of the value
of existing interest-bearing securities is being
eaten away each year by inflation? Must not
this amount be taken out of interest receipts,
to keep capital intact, before we can recog-
nize income? In fact, of course, we do not do
this in our measures of personal income or
national income or the distribution of in-
come or anywhere else, to my knowledge-or
even in the computation of taxable income.
Our national income statistics include im-
putations for a number of nonmarket items
of output including, most importantly, net
rent of owner-occupied housing. But what
about automobiles and other durable goods?
Are the transportation services of a car con-
sumption when we rent one from Hertz or
Avis but not consumption if we own the car
ourselves? But if they are consumption, are
we not obliged to include their value, net of
the car's depreciation (but plus real capital
gains), in income?
If we pay a housekeeper we create income
according to conventional measures. Should
we not record income, as well, if the work of
the housekeeper is done by an unpaid mem-
ber of the household?3 If we did, we would
note an enormous increase, in particular, in
the amount of income earned by women,
and consumed by men, women, and chil-
dren. We would also be forced to lower our
estimates of the increases in national income
as women leave unpaid household work for
jobs in the marketplace; we would have to
offset the increase in market earnings with
the reduction in the value of nonmarket out-
put.
We might also alter our views of the pre-
sumed decline in productivity growth. Aver-
age labor productivity growth falls, in con-
ventional measures, as women entering the
labor force continue to fill disproportion-
ately lower-paying and hence less productive
jobs. But if the jobs they take, while less
productive than the average of those in the
labor force, are actually more productive
than unpaid jobs in the home, as appears
likely if only on the evidence that women do
take them, average total labor productivity
will be increased even as average market
labor productivity may be declining.4
Conventional measures of income include
various items that might better be excluded,
more appropriately viewed as expenses re-
lated to work. If a firm arranges transporta-
tion for its workers or if workers have to
travel in connection with their jobs we do
not include the cost of the transportation
services in income. But if workers have to
pay for their own commuting expense-as
most do-the portion of wages devoted to
this is counted as part of income.
We might include in consumption and in-
come, though, at least some of the value of
three-martini and other lunches and the vari-
ety of amenities-fitness centers, club mem-
berships, vacation retreats, and conventions
combining as much play as work in exotic
locations-supplied in and out of corporate
offices. And we might impute income to cap-
ital invested by government and impute out-
put to the value of services produced by this
capital. The value of public education, we
may note, is taken as the wages and salaries
paid to teachers and janitors. We do not
include, as we would if education were pro-
vided by private business, any of capital
costs that would be measured by interest on
government debt, depreciation on buildings
and equipment or "profit."
We do include in gross national product
all of what we measure as government out-
put. Yet much of it is clearly intermediate in
character. If private firms are forced to hire
more security guards, the result is either no
change in national income or product if the
extra cost is taken out of profits, or an
increase in nominal but not real product if
prices rise. But if government hires more
police, nominal and real national income
and product increase. It may well be argued


### ---Economics-1989-0-06.txt---
that in both cases the security services are
merely inputs which should not be taken to
change our measure of final product. With
the massive increases in expenditures for na-
tional defense in recent years-whether jus-
tifiable or not-the implications for our
measures of growth in GNP are substantial.5
II. Deficits and National Saving
and Investment
Substantial as are the differences between
income as usually measured and its theoreti-
cal construct, they are relatively small com-
pared to the departures of conventionally
measured saving and investment from their
theoretical counterparts.6 Personal saving,
the difference between disposable personal
income and outlays, of which the latter is
chiefly consumption, is immediately suspect
because of the measures of both income and
consumption, as is business or corporate sav-
ing because of questionable measures of
costs, investment, and profits.7 But the prob-
lem is much larger.
Investment is the acquisition or produc-
tion of capital, which in turn contributes to
current and future output. Should not the
production of new automobiles then qualify
as investment, whether they are bought by
business or by households or by govern-
ment? Should research expenses not be con-
sidered investment along with expenditures
for plant and equipment? Are the education
and training of our young not perhaps the
most important investment in future produc-
tivity that we can make?8 Yet we count such
private expenditures as consumption and the
vast if insufficient amount of output in the
form of public education is excluded from
investment under the apparently somewhat
pejorative heading of "government spend-
ing."
With gross income identically equal to
gross output, gross saving is identically equal
to gross investment, including increases in
net claims on the rest of the world, and net
saving is thus the claims on net additions to
capital. Saving should then include the por-
tion of income used to invest in the human
capital of a college education as well as the
portions used to buy corporate bonds or put
into a pension fund.
We have been bombarded for some time
with the arguments in political circles, but
also from many economists, utilizing data
from conventional measures and accounts,
that " national saving" is too low, disas-
trously low. This so-called national saving is
the sum of the personal and corporate sav-
ing, which we have had reason to question,
and government saving or the government
budget surplus.9 These measures are far from
the theoretical constructs to which we might
expect them to correspond.
First, since government budget surpluses
-or deficits-are taken as government re-
ceipts minus all government outlays, without
distinguishing between current and capital



### ---Economics-1989-0-07.txt---
expenditures, a major adjustment is immedi-
ately in order, consistent with the practice of
private business, to exclude the capital ex-
penditures and include in current outlays
only depreciation charges. Second, just as
not all of nominal interest receipts should be
included in income, not all of government
nominal interest payments should be counted
in outlays. Rather these should be adjusted
for the changing real value of government
debt, due both to inflation itself and the
changing market price of securities associ-
ated with changing interest rates, which latter
may relate in part to changing rates of infla-
tion. We should in effect be including in
government revenues the inflation tax on the
private holders of government securities or
the money backed by central bank holdings
of those securities, or including in outlays
only real interest payments.'0
These two adjustments, for capital expen-
ditures and for inflation, make such a huge
difference in the Federal government budget
as to wipe out the much decried "budget
deficit."" The first of them has an identical
effect in raising our measure of national sav-
ing, greatly depressed in its conventional
measure by the negative contribution of the
presumed fiscal dis-saving."
Gross saving is identically equal to gross
private domestic investment plus net foreign
investment. The supposed "twin deficit" in
the U.S. balance of trade or, more exactly,
the current account,"3 is the other side of the
coin of negative foreign investment, that is,
net acquisition by foreigners of claims on the
United States or its residents. If we measure
those claims incorrectly and hence measure
net foreign investment incorrectly, we corre-
spondingly mis-measure gross saving. By un-
derstating gains in the value of our claims on
foreign assets, we understate business and,
to a certain extent, personal income and
saving.
But here again there is a major difference,
not noted by the public and politicians and,
I must add, not noted by most economists
either, between the official measures and
those that would correspond to meaningful
economic theory.'4 Particularly, direct in-
vestment by U.S. firms abroad and by for-
eign firms in the United States are both
taken at original cost. There is then no ad-
justment for the changes in value of the
resulting assets in their own currencies or,
taking into account changing exchange rates,
the value of those changes in dollars.
Saving should correspond to increases in
wealth. National saving should correspond
to increases in national claims to wealth, at
home and abroad, net of increasing foreign
claims to domestic wealth. But to be mean-
ingful, these should surely relate to claims
measured in real, current, or market value.
In fact, they do not. Because they do not, we
have been confronted with repeated asser-
tions that the United States has become " the
world's greatest debtor nation," which is 


### ---Economics-1989-0-08.txt---
generally construed to be a national and
international calamity.
Calamity or not, despite the official figures
which, for the end of 1987, show a negative
"international position" of the United States
of $368 billion, in terms of theoretically
meaningful measures the assertions are sim-
ply not true. The market values of direct
investment of the United States abroad, hav-
ing been undertaken generally in the more
distant past, have appreciated much more in
the currencies of the countries in which the
investment took place than has the dollar
value of foreign investment in the United
States. They have gained enormously more
in dollar value from the fall in dollar ex-
change rates since early 1985. Further, the
official accounts take Treasury gold hold-
ings, which are viewed in effect as an offset
to foreign central bank holdings of dollars,
at its old "statutory" value of $42 an ounce,
roughly a tenth of its value at world market
prices. Adjustments for the value of direct
investment and the value of Treasury gold
have been more than sufficient to wipe out
the entire U.S. "debt" to the rest of the
world.'5
It may be argued, with some validity, that
whatever our current net creditor or net
debtor position, continued current account
deficits will increase U.S. liabilities relative
to assets regarding the rest of the world. But
with proper measures even this judgment
must be hedged. If continued current ac-
count deficits are not financed by foreign
central bank intervention, the dollar is likely
to fall further. As it does, the dollar value of
U.S. assets abroad will rise. This suggests an
adjustment to our measure of the current
account deficit if we are to keep it identically
equal to a true capital account surplus that
measures the increase in the value of foreign
capital in the United States net of increases
in the value of U.S. capital in the rest of the
world.
In order of magnitude, the differences be-
tween conventional measures and those
which might relate more closely to relevant
theoretical constructs are frequently major.
My own estimates for a comprehensive " total
incomes system of accounts" (TISA) put net
national product in 1981 at 30 percent more
than its Bureau of Economic Analysis (BEA)
counterpart,'6 and the contrast is even more
striking when we turn to investment. BEA's
real gross private domestic investment in
1981 was less than one quarter of TISA real
gross capital accumulation (exclusive of cap-
ital gains). Where BEA net private domestic
investment was 5.5 percent of BEA net na-
tional product, TISA net domestic capital
accumulation in current dollars was 19.5
percent of TISA net national product.
Similar proportions show up in the mea-
sures of capital stocks. Business nonresiden-
tial structures and equipment, to which so
much attention is usually given on the ground
of its purported contribution to productivity,
amounted to only 11 percent of total TISA
capital, intangible and tangible, land and
"reproducible," in all sectors-government,
households, and nonprofit, as well as busi-
ness. Government and government enter-
prise structures and equipment came to 8
percent of the total, household durables and
residential capital to 13 percent, and the
intangible capital of R&D, education, train-
ing, and health to no less than 48 percent.'7
Intertemporal and international compar-
isons of total saving, investment, and capital



### ---Economics-1989-0-09.txt---
may or may not look strikingly different
from the pictures presented of narrower bod-
ies of data. It may indeed be hard to know
until we have the fruits of some redirection
of economic research. But is it not clearly
these broader, conceptually relevant mea-
sures on which we should be focusing in
analysis, evaluation, and the determination
of public policy?
III. New Behavioral Relations, Theory
and Policy
All of this is not just a matter of changing
the numbers we associate with familiar vari-
ables. Rather, it alters old relations and re-
veals important new ones. Take the well-
known loglinear production function, for ex-
ample. In its most common Cobb-Douglas
form, we are accustomed to relating output
to private "capital" and "labor." David
Aschauer (1988) reports significant contribu-
tions to private output from government in-
frastructure capital. I have added arguments
for R&D and human capital and found both
significantly positive while the coefficient of
tangible capital is sharply negative.'8 I am
hardly ready to claim on the basis of these
single-equation estimates that more tangible
capital will generally reduce output, and take
my results with some reserve, but I suggest
that a broader view of capital would give
pause to enthusiastic advocates of business
investment tax credits and other "incentives"
of this genre.
Revision of the traditional consumption
function indicates that, along with the ex-
pected coefficient in the neighborhood of .9
for labor income after taxes, we get a (too
high, admittedly) coefficient of about .3 for
the real net debt of the government and .06
for tangible capital. (Household tangible
capital, perhaps a proxy for permanent in-
come, has a coefficient of about .2.) Working
with investment functions, I find that the
acceleration principle explains much of busi-
ness investment in structures and equipment.
But increases in market output do not ap-
pear to have generated subsequent accumu-
lation of the much larger amounts of other
capital which seem to have so much to do
with total output and productivity.
Measures of investment closer to their the-
oretical construct would throw light on some
of the limitations of "q-theory," which pur-
ports to relate business capital expenditures
to the ratio, q, of the market value of the
firm to the replacement cost of its "capi-
tal." When that ratio is high, it is presumed
that firms will sell shares or otherwise see fit
to raise funds to add to their fixed capital.
When q is low, it will rather pay to buy fixed
capital by buying other firms or simply to
use funds to buy back outstanding stock
rather than buy more expensive physical as-
sets.
But does not this theory relate very largely
to a view of dichotomous labor and "capital"
as the factors of production? In truth, firms
invest much in the experience, skills, and
dedication of their labor, which then consti-
tute an important component of capital
value. Much of the value of the firm consti-
tuting the numerator of the q-ratio is deter-
mined by TISA components of capital that
do not enter into its replacement-cost de-
nominator. To the extent these were substi-
tutes for conventionally included capital,
they might even bring about a negative rela-
tion between the conventional measures of
business investment and q. If all capital were
included, the values of q would likely be
vastly different and critical divergences be-
tween average and marginal q exposed. The
remoteness of the relevance of a compre-
hensive q to investment in the small spec-
trum of business plant and equipment would
become clear, and with that an explanation
of some of the well-known difficulties in
empirical implementation of the q-theory
approach.19



### ---Economics-1989-0-10.txt---
One of the more egregious examples of
misplaced concreteness of theoretical con-
cepts involves the role of "money" in many
recent macroeconomic models. The "money"
of the models is frequently a pure-breed of
uniquely perfectly liquid cash. It is somehow
increased or decreased by the government or
monetary authority without changes in the
quantities of other assets. Some theorists then
find that in certain ideal types of costless-
information, perfectly competitive, price-
flexible, market-clearing economies, changes
in the quantity of money have no real effects
and merely bring proportionate changes in
prices.20 Then, to my astonishment, some of
our colleagues derive implications for the
optimal paths of M-1 or M-2 or "monetary
policy."
That the various monetary aggregates
which enter into our empirical formulations
are heterogeneous collections of frequently
endogenous elements in a broad spectrum of
financial assets and liabilities seems, in some
quarters at least, frequently to escape atten-
tion. The theoretical concept of assets of
"outside," government money is a far cry
from the multitide of largely private instru-
ments that enter into transactions and
wealth. To the extent that these are or can be
readily quantified, they are a poor fit indeed
to the money of much economic theory and
the relations in which it is embodied.
While monetary policy is bedeviled by
confusion with regard to measures and vari-
ables of analysis, fiscal policy is one big
mess. And confusion here has contributed
mightily to misdirection in macroeconomic
theory and policy.
As I have pointed out elsewhere,2' moti-
vation for the macroeconomic, rational ex-
pectations revolution, or counterrevolution,
stemmed at least in part from the percep-
tion, as so attributed by Robert Lucas and
Thomas Sargent, that "massive government
budget deficits and high rates of monetary
expansion" in the 1970s were accompanied
not by the decreasing unemployment pre-
dicted by Keynes, but by growing unemploy-
ment and growing inflation.22 I have already
alluded to problems with measures of "mon-
ey." The measured "massive budget deficits"
observed by Lucas and Sargent, and by so
many others, were simply not the deficits of
meaningful economic theory.
The significance of a deficit, any deficit, is
that it adds to net debt. When any agent
spends more than its income it must borrow
or sell off assets. When government runs a
deficit it must therefore add to private assets,
either in the form of holdings of government
debt or the assets government has liquidated.
It is this increase in private assets that, even
more clearly in neoclassical than Keynesian
theory, as noted many years ago by Gott-
fried Haberler (1941), A. C. Pigou (1943,
1947), and Don Patinkin (1948, 1951, and
1965), induces an increase in private spend-
ing.
To have this effect, as the neoclassical
argument made clear, the increase in private
assets must be real. But if the government
"deficit" is accompanied by substantial and
rising inflation, the real, market value of
outstanding government debt may well de-
cline more than the amount of the nominal
deficit. In that case, those alleged deficits
become real surpluses, which economic the-
ory, Keynesian and neoclassical alike, indi-
cate should be a depressant to consumption
and, unless one has inordinate faith that
goods markets always clear, to real aggregate
demand and output.
That is exactly what happened in the late
1970s. The cumulative total of $153 billion
of nominal deficits in the Carter years, from
1977 to 1980, were real surpluses totaling
$72 billion. 24 The federal budget did not



### ---Economics-1989-0-11.txt---
move to significant real deficit until well into
1982. Should any theorist-or policymaker
-have been surprised that the economy evi-
denced mounting unemployment leading up
to the mini-recession of 1980? Or should
they have been surprised that, with the addi-
tion of very restrictive monetary policy, im-
posed as " the only game in town" to combat
inflation given the supposed fiscal stimulus,
this led on to the deep recession of 1982?
Had appropriate measures been used to
illuminate previous policy, we might have
been better prepared to see the predictable
consequences of the very large real deficits
inaugurated in the latter half of 1982. We
might then have been all the more incredu-
lous of those who perceived a recovery from
the trough of a "real business cycle." 25 Who
indeed can really believe that the 12 million
new jobs, about which some have boasted,
were those of otherwise idle workers lured
by higher real wages-brought on, shall we
say, by lower oil prices or higher marginal
products stemming from sweeping new pro-
ductivity gains? Rather, it should have been
clear-dare I say "perfectly clear"?-that it
was the old-fashioned Keynesian stimulus of
real budget deficits that has contributed
mightily to cutting unemployment in half,
from its recession high of almost 11 percent.
There should indeed be some consterna-
tion among those who find the current 5.3
percent unemployment as much as a full
percentage point below their misnamed
"natural" rate. Where, I might add, is that
supposedly excess-demand "accelerating in-
flation" we were taught to fear? Perhaps
waiting to be confused again with the supply
shocks of a new war or oil cartel in the
Middle East!
IV. Provision for the Future: The Case
of Social Security
There is a perennial, legitimate concern in
any nation, and certainly in our mixed econ-
omy, as to the allocation of resources to the
joys of today and the needs of tomorrow. It
is widely argued, however much, as I have
suggested, on the basis of improper mea-
sures, that our presumed budget and trade
deficits will tarnish our golden years or con-
tribute undue and possibly unsustainable
burdens to our children and grandchildren.
Flowing from this argument have been a
number of proposals of new accounting for
our vast Social Security system. However
well-intentioned, they threaten to make our
fiscal mess all the worse.
There have, on the one hand, been sugges-
tions that we bring our huge "contingent
liabilities" into the general federal account-
ing framework. We would, for example, in-
clude the present value of expected payouts
to future retirees, net of their expected "con-
tributions" or tax payments, as federal debt.
Increases in this net debt would then add to
our measure of the deficit; decreases would
reduce it. At first glance, this would seem
sound. The budget would be truly "unified."
But would debt and deficits so measured
really match our theoretical constructs? Can
we expect agents to react in the same fashion
to uncertain and currently illiquid potential
receipts decades in the future as they would
to liquid current cash or Treasury bills? Must
we not recognize that few have any idea
what their Social Security benefits will be, or
what taxes they can expect to pay before
they receive them, whatever is written into
present, and very changeable legislation? Are
Martin Feldstein's changing estimates of net
Social Security wealth (1974, 1982) robust
arguments of anybody's consumption func-
tion? 26
In principle, contingent and uncertain lia-
bilities and assets should be taken into ac-
count in macroeconomic analysis. My objec-
tion to confusing them with the already
mis-measured components of the current
budget should not be taken to deny this. The
move in the opposite direction, though, to
declare Social Security trust funds "off bud-
get" and then ignore them in determining
appropriate fiscal policy is treacherous. Some
advise us now, for example, that a "bal-
anced" overall budget, despite the infirmities
I have pointed out in that measure, is not


### ---Economics-1989-0-12.txt---
enough. We must rather balance the " bud-
get" exclusive of Social Security trust funds.
These latter will be showing increasing sur-
pluses over the years ahead until, by moder-
ate estimate, they will in the year 2030 attain
a total accumulation of $12 trillion. From
that point they would presumably be drained
down to support the final declining years of
the baby boomers of a few decades ago.
Is the fiction of putting what the govern-
ment collects from the public in a different
pot likely to prevent serious deflationary
consequences of years of major real budget
surpluses? Or would the equal fiction that
they are not federal spending avoid the in-
flationary consequences of large payouts in
excess of revenues half a century from now?
Fiscal policy based on such measures can
indeed create havoc.
This is all the more so because of the
interaction of these faulty proposed mea-
sures and others that I have cited. Provision
of generous real support to large cohorts of
future retirees by reduced cohorts of those
working may well prove a problem. Aside
from having more people working and fewer
retired, it can only be met by raising the
productivity of those working. That may be
accomplished in part by increasing their en-
dowment of business plant and equipment,
which dominates conventional measures of
investment, although it may be doubted that
much of current business capital expendi-
tures will have much directly to do with
productivity in 2030.27
I may add that neither good (Keynesian!)
theory nor empirical evidence suggests that
budget surpluses and reduced consumption
are likely to contribute to more business
investment of any kind. To be confident that
they would, one would have to believe that
the reductions in interest rates that they
might generate would increase investment
demand more than the reductions in con-
sumption and output would decrease it. The
reasons for doubt are of course to be found  in John M. Keynes, and their formal theoret-
ical formulation in Oscar Lange's (1938), (I
hope not forgotten) distinguished article of
half a century ago on the "Optimal Propen-
sity to Consume." Some decades of work on
investment functions and the role of output
and accelerator effects versus that of interest
rates and costs of capital, to which I confess
to having contributed my share,28 would
seem to offer ample empirical support for
that doubt.
But fuller and more appropriate measures
of investment and productivity might make
clear that the best and perhaps the only
feasible way to provide the sustenance of our
future aged is to develop our public, social
infrastructure and endow our young with all
of the education, training, research output,
and good health that our society is capable
of offering. One or two more generations
with large proportions of illiterates and
semiliterates will hardly produce a labor
force adequately equipped for productive
employment in the 21st century. This sug-
gests to me that the Social Security surpluses
should be invested in education and training,
research and development, public health, and
the public infrastructure which is the neces-
sary foundation for private production. If we
had federal budget and national accounting
measures that properly classified all of this
vital capital accumulation, the choice of wise
public policy, and the economic analysis on
which it would build, might be much easier.
V. Conclusion
Economic science can boast of many ad-
vances over the years. Too many sins of
policymakers have been falsely attributed to
a profession whose counsel has too fre-
quently been compromised or ignored. I am
fond, to illustrate, of comparing the chal-
lenge to prescribe a (painless?) cure for in-
flation to the cry of the patient who comes to
the doctor complaining of myriad ills and
says "Doc! Make me well, but don't tell me
to exercise, lose the hundred pounds that I


### ---Economics-1989-0-13.txt---
am overweight, cut down my drinking, or
quit smoking." We cannot very easily cure
inflation if we are told that we cannot touch
import quotas and tariffs, price supports, a
variety of entrenched monopolies and anti-
competitive and other costly regulative inter-
ventions in the economy. But we can pride
ourselves on rigorous application of our of-
ten finely honed tools of analysis and our
ability to offer sound policy advice, whether
it is followed or not.
So I would not want my remarks this
evening to be taken as a mea culpa, for
myself or for our profession. But we are not
perfect, and I have endeavored to alert
us-or recall our attention to-certain criti-
cal failings that keep us further from perfec-
tion than we should be.
I have hence noted some pitfalls in using
current and past variables in analyses that
depend critically upon expectations of the
future. I have warned of confusion in em-
ploying narrowly defined measures of in-
come and product in evaluating flows and
trends in comprehensive earnings and out-
put. I have argued that particularly large
dangers abound in basing policy on conven-
tional measures of private and public saving,
investment and capital. I have suggested that
usual estimates of some of the critical behav-
ioral relations of macroeconomics may be
suspect because of a failure to match theo-
retical constructs with appropriate empirical
counterparts.
Very generally, I conclude, it is important
in economics-as elsewhere-to know what
we are talking about.29
## Economics-1990-0


### ---Economics-1990-0-01.txt---
The federal income tax has been under
attack by the economics profession for more
than a decade. The attack comes from two
directions: supply-siders who believe that
progressive income taxation impairs eco-
nomic incentives,' and more traditional
economists who would substitute a progres-
sive expenditure tax for the income tax.2 At
one time, support for the expenditure tax
was confined to a few members of our pro-
fession, including such distinguished names
as John Stuart Mill, Irving Fisher, Nicholas
Kaldor, and James Meade. Today, it is fair
to say that many, if not most, economists
favor the expenditure tax or a flat rate in-
come tax. This group has joined the oppo-
nents of progressive taxation in the attack on
the income tax.
Despite an incessant barrage from both
groups, no country in the world is planning
to abandon the income tax or is even consid-
ering a personal expenditure tax. A wave of
tax reform, beginning with the U.S. reform
in 1986, has been sweeping the world, aimed
at improving the income tax, not at eliminat-
ing it. Tax preferences formerly regarded as
sacrosanct are being removed and there is a
distinct movement toward comprehensive in-
come taxation.3 However, individual income
tax rates are being cut, tax progressivity has
been declining almost everywhere, and re-
liance on the income tax has been diminish-
ing.
It will come as no surprise to this audience
that I approve of the base-broadening fea-
ture of the current tax reform movement,
but I believe that the reduction in the redis-
tributive effect of the income tax has gone
too far. In this paper, I shall show that the
progressivity of the U.S. tax system-never
very pronounced, except during and immedi-
ately after the two world wars-has been
declining for more than two decades and
that the Tax Reform Act of 1986 reversed
this decline, but only slightly. Consequently,
we have a long way to go to improve the
equity of the tax system. I believe this can be
done without punitive tax rates that will hurt
economic incentives.
I begin with a brief review of recent
changes in the U.S. distribution of income
and follow this with an analysis of the effect
of taxes on the income distribution. I next
examine arguments for and against the in-
come tax, with particular emphasis on its
effects on economic incentives and its merits
when compared with the expenditure tax. I
then evaluate the income tax as it emerged
from the 1986 tax reform and conclude with


### ---Economics-1990-0-02.txt---
an agenda for further reform in the context
of the current fiscal crisis. I believe that,
when the nation gets around to eliminating
or substantially reducing the federal deficit,
the income tax should play an important
role.4
Distribution of Income and Tax Burdens
It is well known that, after several decades
of relative stability, the U.S. pre-tax income
distribution has become much more unequal
in the last ten years. Official statistics under-
state the increasing inequality. At the same
time, the tax system as a whole-and the
income tax in particular-has become less
equalizing, so that the trend toward inequal-
ity is even more pronounced after tax than
before tax.
Distribution of Income. The longest contin-
uous and comparable income distribution
series available to us comes from the annual
Current Population Survey (CPS) of the
Census Bureau. The figures show that the
share of total income received by the highest
fifth of the nation's families fell from 1948 to
1952, remained unchanged between 1952 and
1981, and then rose from 1981 to 1988. By
1988, the share of the top fifth was the
highest ever recorded. The figures for the top
5 percent are similar, except that their share
in 1987 had not quite recovered to the 1952
high (Table 1).
It is well known that very high incomes
are virtually unrepresented in the CPS distri-
bution and that official census statistics
greatly understate income inequality in any
year. What is not recognized is that the CPS
data greatly understate the increase in in-
equality that has occurred during the 1980s
because very high incomes have been in-
creasing much faster than the incomes in the
lower part of the distribution.5 This can be
seen by examining changes in the shares of
the top income recipients reported in the
annual Statistics of Income published by the
Internal Revenue Service (Table 2).6
Like the CPS data, the tax data show that
the very rich in the United States-defined
as either the top 1 percent or the top 5
percent of the income distribution-enjoyed
about the same income increases as the aver-
age income recipient in the 1950s, 1960s, and
1970s, but their share of total income has
been rising in the 1980s. From 1952 to 1981,
the share of the top 1 percent of the tax
units remained in a very narrow range-be-
tween 8 and 9 percent of the total income
reported on tax returns. Since 1981, their
share has skyrocketed to 14.7 percent in
1986. The same trends are shown by the top
2, 5, 10, and 15 percent of the tax units.
Much of the increase in the share of the
top tax units reflects the large increase in
realized capital gains that accompanied the
bull market of the 1980s. But salaries and
other incomes of the top units have also
been increasing faster than average.7 In fact,
the movement toward inequality must have
been even greater than the tax data show
because they do not include the large
amounts of income taxpayers were able to
shelter before the enactment of the Tax Re-
form Act of 1986.
Many economists and statisticians have
examined these trends, but nobody has been
able to explain them fully. The declining
share of incomes received by the lower in-
come classes has been attributed to the in-
crease in the number of single-parent fami-
lies, slow growth in earnings of production
workers, the disappearance of middle-
income jobs, and other factors.8 But these
explanations do not account for the recent
explosion of earned and property incomes of
those in the top tail of the distribution.
The trend toward greater inequality has
developed despite the existence of an income
tax in the United States for seventy-six years
and of an estate tax for eighty years. Clearly,
the tax system never reduced inequality very
much and other forces in the 1980s have
swamped whatever equalizing effect it may
have had earlier. I turn now to an examina-
tion of the burdens imposed by the tax sys-
tem and how they have affected the distribu-
tion of income after tax.
Distribution of Tax Burdens. I have been
estimating federal, state, and local tax bur-
dens by income classes for the last two
decades on the basis of the Bookings
MERGE files.9 These files are based on the
CPS surveys, modified at the top by the
incomes reported on federal individual in-
come tax returns. As shown in Table 3, the
tax burdens of the bottom 90 percent of the
income distribution did not change very
much from 1966 to 1985. By contrast, the
tax burdens of the top ten percent of income
recipients fell, especially those of the top 5
percent and 1 percent. Effective tax rates of
the top 5 percent dropped by one-fifth be-
tween 1966 and 1985 (from 32.7 percent to
26.0 percent); for the top 1 percent, the
reduction was more than one-third (from
39.6 percent to 25.3 percent).
Tax burdens of the highest income recipi-
ents fell because top federal individual tax
rates were reduced throughout this period,
from 70 percent in 1966 to 50 percent in
1985. Furthermore, the federal corporation
income tax dwindled to relative obscurity,
falling from 4.1 percent of GNP in 1966 to
1.6 percent in 1985. The proliferation of
personal deductions (for example, state and
local taxes, interest payments, and IRAs),
tax-exempt bonds, and tax shelters were also
major factors in the reduction of the tax
burdens in the top part of the income distri-
bution. The reduction in the corporate tax


### ---Economics-1990-0-04.txt---

reflected primarily the investment incentives
introduced in the 1960s and liberalized in
the 1970s and 1980s, as well as a reduction
in the profitability of the corporate sector.10
Since 1985, the distribution of tax burdens
has changed largely because of the enact-
ment of the landmark Tax Reform Act of
1986. This act increased the progressivity of
the tax system, most notably by raising the
personal exemptions, standard deductions,
and the earned income credit, and by shift-
ing about $25 billion of tax annually from
individuals to corporations. However, this
change in tax policy restored only a small
fraction of the progressivity lost in the pre-
ceding two decades. At the very top of the
income distribution, the 1986 federal tax re-
form restored about half the reduction in
effective tax rates between 1980 and 1985,
but left them far below the 1966 levels: the
top 1 percent paid only 26.8 percent in taxes
in 1988 as compared with 39 percent in 1970
(Table 3).
The inescapable conclusion from these
figures is that the well-to-do in our society
had very large reductions in tax rates in
recent years, while the tax rates at the low
and middle income levels have not changed
much. Since the before-tax distribution has
become much more unequal in the 1980s, it
follows that inequality has increased even
more on an after-tax basis.'1
Transfer Payments. The other major ele-
ment of government policy affecting the dis-
tribution of income is the system of transfer
payments, or negative taxes. This system in-

### ---Economics-1990-0-05.txt---
cludes programs of public assistance that are
designed explicitly to help the poor, but it
also includes others that are not designed
primarily for this purpose (for example, re-
tirement and unemployment benefits and
health insurance). To evaluate the impact of
the tax-transfer system on the distribution of
income, cash and in-kind transfers must be
added to market incomes while taxes are
deducted.
While I cannot separate the effects of
transfer payments and of taxes on the recent
changes in the after-tax income dis-
tribution,12 a snapshot for a recent year-
1985-suggests what happened (Figure 1).
When family units are arrayed by their in-
comes from market production (wages,
salaries, interest, dividends, etc.), the U.S.
tax system is only mildly progressive. On the
other hand, transfer payments are highly
progressive. Taxes in 1985 were regressive in
the lowest deciles and proportional there-
after, while transfer payments declined from
over 200 percent of market incomes in the
lowest decile to 1.4 percent in the highest.
On balance, families in the lowest three
deciles received more in transfers than they
paid in taxes, while those in the top seven
deciles paid more in taxes than they received
in transfers.
Clearly, the tax-transfer system is progres-
sive, mainly because of transfers, not taxes.
What we are doing in the United States is
financing redistributive transfers with taxes
that are roughly proportional to incomes.
Moreover, the tax system has been getting

### ---Economics-1990-0-06.txt---
less progressive in the last two decades, while
the ratio of transfers to income has been
increasing.-3 In other words, the recent in-
creases in transfer payments in the United
States have been financed by the low and
middle income groups, while the rich have
been getting tax cuts.
What Role for the Income Tax?
Most people support tax progressivity on
the ground that taxes should be levied in
accordance with ability to pay, which is as-
sumed to rise more than proportionately with
income. Economists have long had trouble
with the "ability to pay" concept. In recent
years they have revived the old notion that
consumption measures ability to pay better
than income does. I believe that the person
in the street is right and that we should
continue to rely on the income tax to raise
revenue in an equitable manner.
Ability to Pay. In the latter half of the
nineteenth century, progressive income taxa-
tion was justified by "sacrifice" theories that
emerged from discussions of ability to pay.
Under this doctrine, ability to pay is as-
sumed to increase as incomes rise, and the
objective is to impose taxes on a basis that
would involve "equal sacrifice" in some
sense. If the marginal utility of income de-
clines more rapidly than income increases
and the relation between income and utility
is the same for all taxpayers, equal sacrifice
leads to progression."4 Whether or not one
believes in sacrifice theory, the ability to pay
idea has been a powerful force in history and
has doubtedly contributed to the widespread
acceptance of progressive taxation.15 Young
has found that the equal sacrifice model fits
most U.S. tax schedules in the postwar pe-
riod, with the notable exception of the
schedule adopted in 1986. Similar results
hold for Italy, West Germany, and Japan.16
Henry Simons vigorously attacked sacri-
fice theory although he argued strongly that
the purpose of the progressive income tax is
to reduce economic inequality.17 Simons was
vague on how far progression should be
pushed, but he clearly felt that it had not yet
gone too far in most countries. His prescrip-
tion was the pragmatic one that the tax rates
should not impair economic incentives. In
his policy statements, he argued in favor of a
broad base and graduated rate schedule that
rises to a maximum of 50 percent.18
I agree with Simons that the income tax
should be used to reduce the great disparities
of welfare, opportunity, and economic power
arising from the unequal distribution of in-
come. I also recognize that this view is not
widely held and has probably not been the
major rationale for income tax legislation in
the United States or in most other countries.
The income tax is widely used primarily
because it raises large amounts of revenue in
a moderately progressive way. Recent in-
come tax reforms have concentrated mainly
on eliminating tax preferences to improve



### ---Economics-1990-0-07.txt---
horizontal equity; where income tax rates
had been pushed to very high levels, they are
being moderated. Curiously, the world ap-
pears to be moving toward a consensus on
the Simons' view that the income tax should
be levied on a broad base with graduated
rates reaching a maximum of 50 percent or
less, though not for his reasons.
Economic Incentives. The effects of the
progressive income tax on incentives to work
and to save are hard to measure. As is well
known, the substitution and income effects
of taxation work against each other, and the
net result cannot be predicted.
Sample surveys have revealed that profes-
sional personnel do not vary their hours of
work in response to high tax rates."9 How-
ever, recent econometric studies suggest that
the pre-1986 income and payroll taxes re-
duced the work effort of primary earners in
the United States by about 8 percent, while
secondary earners-who have a greater op-
portunity to vary their labor input-reduced
their work effort by as much as 30 percent.20
According to this approach, the 1986 reform
may have increased labor supply of married
men by only 1 percent and of married women
by less than 3 percent, largely because the
marginal tax rates of most workers were not
reduced very much.2" Burtless estimates that
the Reagan tax and transfer policies in-
creased average annual taxes of men aged
25-54 by no more than 2-4 percent and of
women in the same age group by no more
than 3.5 percent.22
Historical trends in U.S. labor supply are
not consistent with the finding that taxes
have reduced work effort. Adult males have
been reducing their labor supply over the
last forty years, largely through earlier retire-
ment little of which is the effect of tax rates.
The labor force participation of women has
risen sharply in recent years, despite high
marginal rates resulting from the require-
ment that married couples must file joint
returns to benefit from income splitting.
Studies in other countries are not reliable
enough to support conclusions about the re-
lationship between taxes and labor supply.
The effect of taxes on saving is even more
ambiguous. A few studies claim that they
have found a significant response to an in-
crease in the real after-tax return on saving;
others find that the response, if any, is close
to zero.23 The reduction in the personal sav-
ing rate in the United States in the 1980s
confounded most economists in view of the
reductions in the marginal tax rates, the in-
centive provided by individual retirement ac-
counts (IRAs), and the high real interest
rates, all of which should have increased the
incentive to save.
The strongest conclusion one can draw
from the available evidence is that the incen-
tive effects of taxation have been relatively
small. Yet the supply siders were convinced
that the incentive effects were so large that
rate cuts would increase revenues when tax
rates- are reduced.24 U.S. tax rates were cut
sharply in 1981 and 1986, but these cuts had
little effect on labor supply and no effect on
saving. Under the circumstances, so long as
tax rates are not pushed to punitive levels,
incentive considerations do not justify ne-
glect of the distributional objective of tax
policy.
Income vs. Expenditure Tax. The revival
of interest in the expenditure tax can be
traced to the difficulties of taxing income
from capital under the income tax. However,
economists and tax lawyers have also found 


### ---Economics-1990-0-08.txt---
efficiency reasons to prefer the expenditure
tax and these need to be addressed. S
A basic difference between the income and
expenditure taxes is in the time perspective
of the two taxes. The perspective of the
income tax is relatively short run-a year or
several years to allow for short-run income
fluctuations. Consumption is more stable
than income and is alleged, therefore, to be a
better measure of long-term well-being. In
fact, under certain simplifying assumptions,
the bases of taxes on the discounted present
value of income and expenditure are the
same over a lifetime. Assuming perfect capi-
tal markets, constant discount rates that ap-
ply equally to all people under all circum-
stances, tax rates that are constant and
proportional, and no gifts and bequests, the
present values of lifetime expenditures of
people with the same (discounted) lifetime
incomes are the same regardless of when the
incomes are consumed.26
Advocates of the expenditure tax regard
the lifetime perspective as a major advastage
because it permits them to pretend that tax-
ing consumption is equivalent to taxing per-
sonal endowments. A tax on endowments, if
they could be measured, would avoid the
distortionary effects of either an income tax
or an expenditure tax. If it is assumed that
lifetime consumption approximates exidow-
ment, then taxing consumption at flAtXand
constant rates treats equally all taxpayers
with the same endowment.27 The totaly' un-
realistic assumptions underlying this line of
reasoning strain credulity, but it doestteem
to lie behind the strong support for thQ ex-
penditure tax by many economists.
The lifetime perspective has little merit
even without the endowment rationale. In
my view, it is difficult enough to measure
economic circumstances over relatively short
periods. Taxation of lifetime consumption
(or income) hardly seems appropriate in a
world of changing tax rates, substantial fam-
ily instability, economic and political change,
and uncertainty. Except for the attractive-
ness of the arithmetic, lifetime economic
circumstances as measured by discounted
lifetime incomes or consumption cannot be
regarded as satisfactory indexes of ability to
pay.28 Moreover, taxation of annual con-
sumption expenditures at graduated rates
would destroy the identity of lifetime taxes
of taxpayers with the same (discounted) life-
time incomes.
The expenditure tax is alleged to be supe-
rior to the income tax on the additional
ground that the income tax reduces the re-
turn on saving and therefore encourages cur-
rent as against future consumption. Even if
saving remained unchanged, the distortion
generates a welfare loss for consumers. It has
been pointed out by many economists that
this effect must be balanced against the wel-
fare cost of further distorting the choice
between labor and leisure. There is no theo-
retical basis for judging whether the welfare
gain from eliminating the intertemporal dis-
tortion of consumption would exceed the
welfare loss from increasing the intratempo-
ral distortion of the labor-leisure choice.29
A tax that omits saving from the tax base
can be shown to be the same as a tax apply-
ing only to labor income and exempting all
property income.30 Several expenditure tax


### ---Economics-1990-0-09.txt---
advocates have, in fact, proposed a tax on
labor income on grounds of simplicity and
administrative feasibility.3" Most people
would be appalled by a proposal to substi-
tute a wage tax for income tax, yet that is
essentially what expenditure tax proponents
are advocating.
Many economists are attracted to the ex-
penditure tax because it would not tax in-
come from capital and would thus eliminate
all the income tax problems arising from the
use of the realization principle for calculat-
ing capital gains and losses and from the
accounting conventions for inventories, de-
preciation, and depletion used in arriving at
net business profits. There would also be no
need to adjust the tax base for inflation, as
consumption would be measured appropri-
ately in current dollars. These are serious
problems for income taxation and I shall
deal with them later, but it would be unfor-
tunate to abandon the income tax for admin-
istrative and compliance reasons alone.
The transition from the income tax to an
expenditure tax would be troublesome. The
retired elderly would draw down assets, some
of which had previously been taxed under
the income tax, to finance current consump-
tion that would be taxed yet again. To avoid
this double tax, some method would need to
be devised to identify consumption from
previously taxed accumulations. Grand-
fathering all assets at the time an expendi-
ture tax is initiated would leave a big loop-
hole for people with large amounts of
untaxed accrued capital gains. But I have
not seen any practical method of making the
necessary distinctions in order to prevent
wholesale tax avoidance and to achieve
equity.32
Under an expenditure tax, taxpayers who
save could accumulate large amounts of
wealth over a lifetime. Many, but by no
means all, expenditure tax advocates support
wealth or estate and gift taxes to prevent
excessive concentrations of wealth. But the
history of transfer taxation in this country
and abroad provides little assurance that
effective death and gift taxes would be levied
to supplement an expenditure tax.
Proponents of expenditure taxation often
compare the merits of a comprehensive ex-
penditure tax with the income tax as it has
developed. It is hard to believe that an ex-
penditure tax would be enacted without nu-
merous exemptions and exclusions. In fact,
most of the eroding features of the income
tax (for example, preferences for housing,
fringe benefits, child care, state-local borrow-
ing, etc.) might be carried over to the expen-
diture tax. Thus, an expenditure tax is no
less immune to erosion than the income tax
and, in such circumstances, it loses much of
its attractiveness.
I conclude that income is a better indica-
tor of ability to pay than consumption and
that the major upheaval of substituting an
expenditure tax for an income tax cannot be
justified on theoretical or practical grounds.
How Much Progression? The effective de-
gree of progression of the income tax de-
pends on the comprehensiveness of the tax
base as well as on the tax rates. We have
learned from experience that high, graduated
tax rates do not assure progressivity of the
income tax. For most of the period since the
end of World War II, the top U.S. income
tax rates were 70 percent or higher. Yet little
equalization resulted because of the erosion
of the base of the individual and corporate
income taxes and because of increases in the
payroll tax for Social Security.33 According

### ---Economics-1990-0-10.txt---

to estimates of the Congressional Budget
Office (CBO), in 1977, when the top income
tax rate was 70 percent and the general
corporate tax rate was 48 percent, the Gini
coefficient of inequality was 0.4502 before
tax and 0.4185 after federal taxes (more than
half of which were individual and corporate
income taxes). In 1980, when the top tax rate
was still 70 percent (though only on un-
earned income) and the corporate rate was
46 percent, the Gini coefficient was 0.4627
before tax and 0.4320 after the same taxes.
Thus, as measured by the Gini coefficient,
the equalization achieved by the federal tax
system declined from a modest 0.0317 points
(7.0 percent) in 1977 to an even more modest
0.0307 points (6.6 percent) in 1980 (Table 4).
Two major pieces of tax legislation were
enacted during the 1980s. One increased in-
equality, the other reduced it. The 1981 Act,
enacted after Ronald Reagan's sweeping vic-
tory in the 1980 presidential election, in-
creased inequality by reducing income tax
rates by 23 percent across the board (with a
top rate on ordinary income of 50 percent),
lowering the capital gains rate to a maxi-
mum of 20 percent, introducing generous
deductions for individual retirement ac-
counts, and providing very liberal deprecia-
tion allowances for business investment on
top of the previously enacted investment tax
credit. The Tax Reform Act of 1986 reduced
inequality by increasing personal exemptions
and the standard deduction, equalizing the
tax rates on capital gains and ordinary in-
come, and closing numerous loopholes. At
the same time, income tax rates were re-
duced to a maximum of 33 percent on indi-
viduals and 34 percent on corporations.
Despite the large rate cuts at the top of
the income scale, the 1986 act increased in-
come tax progression, though not to the 1980
level. By 1984, the equalization provided by
the federal tax system had declined to 0.0184
points (3.8 percent) in terms of the Gini
coefficient. As a result of the 1986 act, the
degree of equalization increased to 0.0218
points (4.4 percent) in 1988 (Table 4). While
this change is modest, it is noteworthy as the
first movement toward greater income tax
progressivity at least since 1964, when the
Kennedy-Johnson tax cut was enacted.
I suggest that a minimal goal of federal
tax policy in the next several years should be
to restore the equalization achieved by the
federal tax system in the mid-1970s.34 While
this may appear to be a modest goal, it turns
out to be a rather ambitious undertaking,
particularly if income tax rates are to be
kept to moderate levels. Before calculating
the tax rates, it is necessary first to establish
the appropriate tax base for a modem in-
come tax.
Reform of the Income Tax
The proper base for the income tax was
described fifty years ago by Henry Simons,
who argued that it should conform with an
economic definition of income.35 Admittedly,
the use of a comprehensive income tax con-


### ---Economics-1990-0-11.txt---
tradicts the principle of optimal taxation that
tax rates should vary with a number of elas-
ticities. However, the optimal tax models are
based on strong assumptions that are often
implausible or virtually impossible to vali-
date. Consequently, there is no empirical
basis for determining how different com-
modities and sources of income should be
taxed. Moreover, the compliance and en-
forcement costs of such a system could be
large enough to more than offset the poten-
tial inefficiencies of a uniform tax. In the
absence of reliable data, it is safer to rely on
the comprehensive approach rather than to
introduce tax differentials that will generate
their own distortions.36
According to Simons and others, income
is the sum of an individual's consumption
and change in net worth during a particular
time period. For a long time, the federal
income tax base was a far cry from a com-
prehensive definition of income. In 1986,
however, Congress reversed its previous
practice and enacted a wholesale tax reform
that moved the income tax a long way to-
ward the Simons' ideal. This remarkable
piece of legislation can provide the basis for
achieving the distributive objectives dis-
cussed earlier with moderate tax rates.
The 1986 Tax Reform.37 The Tax Reform
Act of 1986, a major step toward compre-
hensive income taxation, greatly improved
the fairness and efficiency of the tax system.
The major accomplishments of the act are as
follows:
By doubling personal exemptions and in-
creasing the standard deduction, the act re-
lieved about 5 million poor people from
paying any income tax. This step restored
the principle (abandoned by Congress in
1978) that people who are officially desig-
nated as "poor" should not be required to
pay income tax. The principle was perpetu-
ated by the resumption in 1989 of an auto-
matic annual adjustment of the exemptions
and standard deduction for inflation.
Significant increases were made in the
earned income credit for wage earners with
families. These increases eliminated almost
the entire Social Security payroll tax (includ-
ing the employer's share) for those eligible
for the full credit and reduced the tax bur-
den for many low-income workers.
For the first time since 1921, realized capi-
tal gains were made taxable as ordinary in-
come. This is the keystone of comprehensive
tax reform: it reduces the incentive to con-
vert ordinary income into capital gains and
removes one of the major elements of tax
shelter arrangements. Moreover, this change
made it possible to reduce tax rates without
reducing the progressivity of the income tax.
A good start was made to reverse the
erosion of the individual income tax base.
For example, unemployment benefits, which
were previously taxable only if a married
taxpayer's income exceeded $18,000 ($12,000
if single), were made taxable regardless of
the size of income. Deductions for state and
local sales taxes were eliminated and those
for consumer interest were phased out. For
administrative reasons, deductions for unre-
imbursed business expenses, costs incurred
in earning investment income, and other
miscellaneous expenses were allowed only to
the extent that they exceed a floor of two
percent of income.
Some of the most egregious loopholes and
special tax benefits were eliminated. Many
tax shelters were rendered unprofitable by
denying deductions for losses from passive
activity against income from anything but
passive activities.3' Tax subsidies for bor-
rowing (other than for mortgages) were elim-
inated by another limitation on the deduc-
tion for interest expenses to the amount of
investment income reported on the individ-
ual's tax return.39 Deductions for contribu-

### ---Economics-1990-0-12.txt---
tions to individual retirement accounts were
curtailed. Deductible business expense ac-
counts for meals, travel and entertainment
were limited to 80 percent of outlays. Tax
preferences benefiting defense contractors,
banks, oil companies and other industries
were narrowed. On top of all these changes,
the minimum tax for both individuals and
business was retained and strengthened.
Finally, the individual and corporate tax
rates were cut drastically. Under the individ-
ual income tax, two rates-15 and 28 per-
cent-were substituted for the earlier sched-
ule of 14 rates, which rose to a maximum of
50 percent. However, the benefits of the low-
est rates and of the personal exemptions
were phased out for higher income taxpayers
at a 5 percent rate. As a result, the new
individual income tax rate structure has four
brackets, with rates of 15, 28, 33, and 28
percent (see Table 7). The general corporate
rate was cut from 46 percent to 34 percent.
Despite these large rate cuts, the act was
expected to be roughly revenue neutral in
total over the first five years, but to shift
about $25 billion of tax annually from indi-
viduals to corporations.
The distributional effect of the 1986 act is
distinctly progressive, especially if the in-
crease in corporate tax liabilities is taken
into account. I have calculated the change in
average effective tax rates of the nation's
families on the basis of the distribution of
income estimated from the Brookings
MERGE file (Table 5). Total federal tax
burdens decline in the lower nine deciles and
rise in the top decile. In the lower deciles,
the tax reductions result from increases in
the personal exemptions, standard deduc-
tion, and the earned income credit under the
individual income tax. The increases at the
top reflect the broadened individual income
tax base, as well as the increase in corporate
tax liability, which is assumed to fall on
owners of capital in these calculations. How-
ever, as already noted, this increase in pro-
gressivity only partially reversed the reduc-
tions that had taken place in the 1970s and
early 1980s.
The Unfinished Agenda. Despite the pro-
gress made in 1986, the federal income tax in
the United States falls considerably short of
the comprehensive income target.40 I assume
that we shall continue to tax capital gains on
a realization, rather than accrual, basis, and
that gifts and bequests will be taxed under a
separate transfer tax. Nevertheless, a great
deal more could be done to broaden the tax
base for equity, efficiency, and revenue rea-
sons.
The personal exemptions, standard deduc-
tions, and rate bracket limits are adjusted
annually for inflation, but the tax base is
not. Of the two types of adjustment, adjust-
ment of the tax base would be by far the
more important. Perhaps the major reason
why the income tax tends to be in disrepute
is the discrimination against capital income
inherent in a nominal income tax. An infla-
tion adjustment of asset prices should be


### ---Economics-1990-0-13.txt---
incorporated in the tax law as part of the
computation of real capital gains and losses,
real interest income expense, and real inven-
tory and depreciation allowances. The ad-
justment of interest is admittedly difficult,
but the widespread use of computers should
ease the administrative and compliance
problems.
Restoration of a tax differential between
capital gains and ordinary income should be
resisted at all costs. Equalization of the tax
rates lowers the incentive to convert other
income into capital gains, simplifies business
and financial decisions, and reduces income
tax complexity. Aside from the correction
for inflation, the one additional reform
needed in the capital gains tax is to include
in the tax base unrealized capital gains
transferred by gift or at death. Taxing such
gains would reduce the lock-in effect of the
tax on transfers of assets and eliminate a
source of horizontal inequity.
A major neglected problem in most coun-
tries is the erosion of the tax base from the
exclusion of employee fringe benefits. Trade
unions, as well as employers, staunchly de-
fend the continued exclusion of fringe bene-
fit income, but in fact the largest subsidies
go to the highest paid employees. Loopholes
for union members and other workers are no
more defensible than those for the rich. Tax-
ation of fringe benefits would encourage their
conversion into cash compensation, thus giv-
ing employees more control over the disposi-
tion of their income and the choice of the
providers of their services. Australia and New
Zealand have shown the way to reform in
this area by taxing fringe benefits (other
than contributions to pension plans) at the
corporate tax rate. This method of handling
a difficult, but urgent, problem is simple and
effective.
Social Security benefits continue to receive
favorable treatment, even though the elderly
can no longer be regarded as a disadvan-
taged group. Under current law, the medical
insurance subsidies they receive are not sub-
ject to tax, and less than half of retirement
and disability benefits is taxable to married
couples with income above $32,000 ($25,000
if single). The value of the medical insurance  subsidies should be subject to tax in full"4
and retirement and disability benefits should
be treated like private pensions without any
income thresholds, which would mean that
roughly 85 percent of the benefits would be
currently taxable.
The treatment of owner-occupied housing
remains unsatisfactory. I assume that the
exclusion of imputed rent from the tax base
and the deduction of mortgage interest by
most homeowners are sacrosanct, but it is
possible to limit the encouragement of bor-
rowing without promoting rearrangements of
debt for tax purposes. The solution is to
broaden the limitation on deductions of in-
vestment interest to include all interest pay-
ments. That is, a deduction for all interest
payments would be allowed, but limited to
the amount of reported investment income.
To accommodate the home-owner lobby, the
limit could be raised to net investment plus
an arbitrary amount, say, $10,000-enough
to take care of the vast majority of home
owners. The broader interest limitation
would remove the discrimination against
borrowing for other purposes and the incen-
tive to substitute home equity loans for other
types of borrowing.
Deductions other than for interest are still
too generous. The Simons' definition of in-
come includes all sources of income, without
any deductions for the uses of that income.
For equity reasons, it is appropriate to per-
mit deductions for such unusual expenses as
medical payments and casualty losses. I
would retain the deduction for state income
taxes to moderate interstate tax dif-
ferentials.42 However, the property tax is
largely a benefit tax and therefore should not
be deductible. Nor is it necessary to allow a
deduction for the first dollar of charitable
contributions on incentive grounds. Little or


### ---Economics-1990-0-14.txt---
no charitable giving would be lost43 and
much revenue would be gained or reductions
in tax rates would be possible if the federal
deduction for property taxes were disallowed
and the deduction for charitable contribu-
tions were restricted to amounts in excess of
two percent of income. In addition, the tax-
exemption for interest on newly issued state
and local bonds should be removed.
Although income tax compliance is better
in the United States than in most other
countries, roughly 15 percent of individual
income is still unreported, according to IRS
estimates.44 Extension of withholding to in-
terest and dividends would improve compli-
ance. Congress enacted a withholding system
for these income items in 1982, but repealed
it the following year under pressure from the
financial institutions. Since information re-
turns are required for annual interest and
dividend payments of $10 or more, the
marginal costs of compliance with a with-
holding system would be small.
One of the major features of the 1986 tax
law was to telescope the schedule of tax rates
into two acknowledged and two concealed
brackets, a bizarre four-bracket rate struc-
ture of 15, 28, 33, and 28 percent. The reduc-
tion in the number of brackets was a re-
sponse to the flat tax proposals that were
being promoted when the tax reform bill
began its journey through Congress, while
the unsightly bulge in the rate schedule was
motivated by revenue considerations. It is
not necessary to return to 14 brackets, but
there is room for more rate graduation with-
out the bulge.
In this connection, consideration needs to
be given to improving the structure of estate
and gift taxes to compensate for their low
average rates. These taxes were almost gut-
ted by increases in the exemptions and re-
ductions in the tax rates when income tax
rates were cut in 1981. Now that the top  income tax rates are even lower, it is time to
rely more heavily on the estate and gift
taxes.
The reduction in the tax rates led to two
additional changes in the 1986 act that I
believe were unfortunate. Congress elimi-
nated the deduction for two-earner couples
and ended the privilege of averaging income
for tax purposes.45 Both provisions should
be restored in the interest of horizontal eq-
uity.
Finally, contrary to the prevailing view
among public finance experts, Congress
clearly believes that a separate, unintegrated
corporate tax is essential for effective income
taxation. A separate tax prevents individuals
from avoiding the income tax by accumulat-
ing earnings at the corporate level, although
some might question whether corporations
should be taxed at a higher rate than the top
bracket individual rate. But in its present
form, the corporate tax encourages debt fi-
nancing. It is alleged to be a major cause of
the recent upsurge in leveraged buyouts and
mergers. The remedy is not to allow a deduc-
tion or credit for dividends received at the
individual level. Rather, the deduction of
interest by corporations should be denied
while reducing their tax rate to the neighbor-
hood of 15 percent to maintain the revenues
now produced by the corporate tax.46 The
corporate tax would become a low-rate tax
on net corporate income before distribu-
tions.
Tax Rates and Progressivity. The reforms I
have suggested would greatly increase the
income tax base and permit a realignment of
the tax rates to achieve the distributional
objectives described earlier. At calendar year
1990 levels, the tax base would increase from
$2.4 trillion to $2.8 trillion (Table 6). The
increase in the base leaves enough room to
cut rates in the lowest taxable income brack-
ets and still keep the top tax rates at reason-
ably modest levels.



### ---Economics-1990-0-15.txt---

In redesigning the rate structure, I suggest
scrapping the multiple schedule system which
was developed to reduce the tax advantage
of married couples relative to single people
under income splitting. It is simpler to use
one set of rates and to rely on the personal
exemptions to take into account differences
in ability to pay of families of different size.47
The restored deduction for two-earner cou-
ples (20 percent of the earnings of the spouse
with the lower earnings up to $70,000) would
help avoid a significant marriage penalty.
The same revenue and progressivity of
present law could be generated by a tax
schedule ranging from 7 percent on the first
$5,000 of taxable income to 26 percent on
taxable income in excess of $35,000, without
the bulge in tax rates under current law (see
Plan I, Table 7).48 Thus, a wide margin
exists for increasing progressivity at the top
of the income scale, while keeping rates
moderate. To restore the progressivity of the
federal tax system to its 1977 level, the range
of graduation would have to be expanded
and the rate of graduation increased. A start-
ing rate of 4 percent on the first $5,000 of
taxable income rising to 48 percent on tax-


### ---Economics-1990-0-16.txt---


### ---Economics-1990-0-17.txt---
able income above $250,000 would accom-
plish this objective (see Plan II, Table 7).49
Another change to increase progressivity
would be to increase the earned-income
credit for low-income families. Today, the
credit is the same for all families, regardless
of the number of children. The credit would
be more effective in combatting poverty if it
increased with family size. For example, the
current 14-percent credit could be main-
tained for families with one child and four
percentage points, or roughly $250, could be
added for each additional child. With this
modification, the earned income credit would
increase the likelihood that a family with
several children could earn enough to remain
outside the welfare system.
Table 8 reports the average effective fed-
eral income tax rates by population deciles
under the schedule that restores overall pro-
gressivity to 1977 levels (Plan II) and under
the schedule that matches 1990 distribution
with a broadened base (Plan I). The average
effective rates in Plan II are lower than those
under present law in the bottom nine deciles
and higher in the top decile. For the top 1
percent of the family units, the average ef-
fective rate rises from 21 percent to 30 per-
cent, which cannot be regarded as punitive.
I recognize that few people would go as
far as I would in broadening the tax base.
But that does not mean that the objective of
greater progressivity must be abandoned.
Even if there were no additional base-broad-
ening between now and 1990, the same de-
gree of progressivity that prevailed in 1977
could be achieved with rates ranging from 7
percent at the bottom to 56 percent at the
top.
Conclusion
I conclude that there is no good reason for
the disenchantment of economists with the
income tax. The main rival of the income tax
-the consumption expenditure tax- is dis-
tinctly inferior on theoretical as well as prac-
tical grounds. The endowment or lifetime
perspective of the expenditure tax is indefen-
sible in a world of financial, political, and
family instability. The transition problems in
moving from an income tax to an expendi-
ture tax are extremely difficult. There is also
a danger that the substitution of an expendi-
ture tax for the income tax would greatly
increase the concentration of wealth. More-
over, the public regards income, not expen-
diture, as the best index of ability to pay,
and it would be unwise to abandon this
familiar and widely approved basis of taxa-
tion.
The 1986 reforms have greatly improved
the federal income tax by broadening the
base and lowering rates. But the progressiv-
ity of the federal tax system has been declin-
ing for the last two decades. As a result, the
distribution of before-tax income, which has
been growing more unequal in the 1980s, has
become even more unequal on an after-tax
basis. I have suggested that the goal of tax
policy should be to restore the progressivity
of the income tax at least to its level in the
mid-1970s.
The 1986 tax reform went a long way
toward comprehensive income taxation, but
much more can be done to enlarge the tax
base and to remove the preferences for capi-
tal income. Among the more urgent base-
broadening reforms are the inclusion in tax-
able income of capital gains transferred by
gift or at death, elimination of the tax ex-
emption for newly issued state-local securi-
ties, taxation of employee fringe benefits,
treatment of Social Security benefits like pri-
vate pensions, reduction of the tax subsidy
for home owners, pruning of the personal
deductions, and withholding on interest and
dividends. To correct the measurement of
capital income for inflation, asset prices
should be adjusted for changing prices in
order to convert nominal to real incomes for
tax purposes. The two-earner deduction and
income averaging should be restored to re-
duce the marriage penalty and equalize the
treatment of fluctuating and stable incomes.  


### ---Economics-1990-0-18.txt---
A comprehensive income tax along these
lines would permit further rate reductions
throughout the income scale if the degree of
progression enacted in 1986 were to be re-
tained. However, the progressivity of the
federal tax system has declined since the
mid-1970s, even after taking into account
the effect of the 1986 act. To restore the
degree of progressivity of the mid-1970s, the
rate of graduation of the tax rates would
need to be increased. I estimate that this can
be accomplished with a rate schedule rang-
ing from 4 percent at the bottom to 48
percent at the top of the taxable income
scale-a moderate schedule of rates by any
standard.
It is clear from this analysis that the rev-
enue potential of the income tax has not
been exhausted in this country. Even if the
base is not broadened, the income tax can be
used to raise considerable additional rev-
enues in order to eliminate the recurring
federal deficits. Each percentage-point in-
crease in the individual and corporate in-
come tax rates would bring in about $30
billion in 1994, so that three points would
come close to balancing the overall budget in
that year. A top individual income tax rate
of 31 percent and a corporate rate of 37
percent cannot be regarded as punitive or
harmful to economic incentives.
What is inappropriate in my view would
be to introduce a value-added tax, as some
are suggesting. The value-added tax is re-
gressive and imposes unnecessarily heavy
burdens on the lower income classes. With
tax rates as low as they are today, more
revenues should come from the income tax,
the tax paid by those who have the ability to
pay. In view of the recent reductions in the
progressivity of the federal tax system, it
would be unconscionable to enact the dis-
tinctly inferior alternative of a value-added
tax.
## Economics-1991-0


### ---Economics-1991-0-03.txt---
I
As the Second World War was drawing
near its resolution, economic theory entered
a phase of intensive mathematization that
profoundly transformed our profession. In
several of its main features that phase had
no precedent, and it will have no successor.
Assessing it requires a multidimensional
analysis acknowledging the contributions to
economics that were made, as well as the
tensions among economists that were
heightened.
The development of mathematical eco-
nomics during the past half-century can be
read in the total number of pages published
each year by the leading periodicals in the
field, an index that I will follow at first.
From 1933, the date when they both started
publication, to 1959, those periodicals were
Econometrica and the Review of Economic
Studies, and the index tells of the decline
from a high point, above 700 pages in 1935
to the lowest point, below 400 pages in
1943-1944. But 1944 marked the beginning
of a period of explosive growth in which
Econometrica and the Review of Economic
Studies were joined in 1960 by the Interna-
tional Economic Review, in 1969 by the
Journal of Economic Theory, and in 1974 by
the Journal of Mathematical Economics. In
1977, these five periodicals together pub-
lished over 5,000 pages. During the period
1944-1977, the index more than doubled
every nine years. By that measure, 1944 was
a sharp turning point in the history of math-
ematical economics. It was also the year in
which John von Neumann and Oskar
Morgenstern published the Theory of Games
and Economic Behavior.
While the professional journals in the field
of mathematical economics grew at an un-
sustainably rapid rate, the American Eco-
nomic Review underwent a radical change
in identity. In 1940, less than 3 percent of
the refereed pages of its 30th volume ven-
tured to include rudimentary mathematical
expressions. Fifty years later, nearly 40 per-
cent of the refereed pages of the 80th vol-
ume display mathematics of a more elabo-
rate type.
At the same time, the mathematization of
economists proceeded at an even faster pace
in the 13 American departments of eco-
nomics labeled by a recent assessment of
research-doctorate programs in the United
States (Lyle V. Jones et al., 1982) as "dis-
tinguished" or "strong" according to the
scholarly quality of their faculties. Every
year the Fellows of the Econometric Society
(ES) certify new members by election into
their international guild, which increased in
size from 46 in 1940 to 422 in 1990. For
those 13 departments together, the propor-
tion of ES Fellows among professors was
less than 1 percent in 1940; it is now close
to 50 percent. It equals or exceeds 50 per-
cent for six of them, which were among
those assessed as the eight strongest. So
mathematized a faculty expects its students
to have what it considers to be minimal
mathematical proficiency, and knowledge of
calculus and linear algebra is required, or
forcefully recommended, for admission to
all 13 graduate programs.
Several scholarly recognitions lay addi-
tional emphasis on the role that mathemati-
cal culture is now playing in our profession.
Of the 152 members of the economics sec-
tion of the American Academy of Arts and
Sciences, 87 are Fellows of the Econometric
Society; and of the 40 members of the eco-
nomics section of the National Academy of


### ---Economics-1991-0-04.txt---
Sciences of the United States, 34 are ES
Fellows. From 1969 to 1990, 30 economics
Nobel awards were made, and 25 of the
laureates are, or were, ES Fellows. Since it
was first presented to Paul Samuelson in
1947, the John Bates Clark medal of the
American Economic Association has been
given to 21 economists, of whom 20 are ES
Fellows; and of the 26 living past presidents
of our Association, 13 are ES Fellows.
One may wish that those counts had not
been made. One may argue about points of
their interpretation. But they belong in our
common knowledge, and their thrust is un-
equivocal. They indicate how extensive the
mathematization of economics and how
deep the accompanying change of our field
were over the past five decades.
The perception of the depth of that
change is reinforced by a comparison of the
levels of mathematics required in 1940 and
in 1990 to follow the development of eco-
nomic theory in every direction it was tak-
ing. Fifty years ago, basic undergraduate
preparation in mathematics was almost al-
ways sufficient. Today, graduate training in
mathematics is necessary. If, instead of be-
ing a follower, one wishes to be an active
participant in that development along its
most technical avenues, a high degree of
mathematical professionalism is called for.
Several faculty members of the 13 depart-
ments of economics mentioned previously
were actually identified as mathematicians
by their doctorates; four of them served as
chairmen of those departments during the
past 25 years. If still sharper focus brings
out the intellectual leaders of that develop-
ment, prominent among them is John von
Neumann, one of the foremost mathemati-
cians of his generation.
In that development process, mathemati-
cal economics was continuously redefined as
new territories were included within its out-
ward-moving frontier and as topics that were
once at that frontier became standard parts
of the graduate, if not of the undergradu-
ate, economic-theory curriculum.
II
Before the contemporary period of the
past five decades, theoretical physics had
been an inaccessible ideal toward which
economic theory sometimes strove. During
that period, this striving became a powerful
stimulus in the mathematization of eco-
nomic theory.
The great theories of physics cover an
immense range of phenomena with a
supreme economy of expression. Of this,
James Clerk Maxwell (1865) had given a
notable example, as he described the elec-
tromagnetic field by means of eight equa-
tions at the time when mathematical eco-
nomics was born and came of age in the
middle of the 19th century. This extreme
conciseness is made possible by the privi-
leged relationship that developed over sev-
eral centuries between physics and mathe-
matics. In turn, the former presented the
latter with open problems, or found to ques-
tions raised by physical theory ready-made
answers discovered by mathematicians in
their abstract universe. Sometimes the
causal linkage of research done in each one
of the two fields could not easily be unrav-
eled; and, on occasion, the same scientist
made inextricably intertwined contributions
to both disciplines.
The benefits of that special relationship
were large for both fields; but physics did
not completely surrender to the embrace of
mathematics and to its inherent compulsion
toward logical rigor. The experimental re-
sults and the factual observations that are at
the basis of physics, and which provide a
constant check on its theoretical construc-
tions, occasionally led its bold reasonings to
violate knowingly the canons of mathemati-
cal deduction.
In these directions, economic theory could
not follow the role model offered by physi-
cal theory. Next to the most sumptuous
scientific tool of physics, the Superconduct-
ing Super Collider whose construction cost
is estimated to be on the order of $1010
(David P. Hamilton, 1990; see also Science,
5 October 1990), the experiments of eco-
nomics look excessively frugal. Being denied
a sufficiently secure experimental base, eco-
nomic theory has to adhere to the rules of
logical discourse and must renounce the
facility of internal inconsistency. A deduc-
tive structure that tolerates a contradiction
does so under the penalty of being useless,


### ---Economics-1991-0-05.txt---
since any statement can be derived flawlessly
and immediately from that contradiction.
In its mathematical form, economic the-
ory is open to an efficient scrutiny for logi-
cal errors. The rigor that has been reached
as a consequence is in sharp contrast to the
standards of reasoning that were accepted
in the late 1930's. Few of the articles pub-
lished then by Econometrica or by the Re-
view of Economic Studies would pass the
acid test of removing all their economic
interpretations and letting their mathemati-
cal infrastructure stand on its own. The
greater logical solidity of more recent analy-
ses has contributed to the rapid contempo-
rary construction of economic theory. It has
enabled researchers to build on the work of
their predecessors and to accelerate the cu-
mulative process in which they are partici-
pating.
But a Grand Unified Theory will remain
out of the reach of economics, which will
keep appealing to a large collection of indi-
vidual theories. Each one of them deals
with a certain range of phenomena that it
attempts to understand and to explain.
When it acquires an axiomatic form, its
explicit assumptions delimit its domain of
applicability and make illegitimate overstep-
ping of its boundary flagrant. Some of those
theories take a comprehensive view of an
economic system and bring insights into the
solutions of several global problems. For
instance, prices contribute to achieving an
efficient use of resources, to equalizing sup-
ply and demand for commodities, and to
preventing the formation of destabilizing
coalitions. In every case, a theoretical expla-
nation must be provided. The assumptions,
which cannot be satisfied by all economic
observations, are the present outcome of a
continuing weakening process.
A global view of an economy that wants
to take into account the large number of its
commodities, the equally large number of
its prices, the multitude of its agents, and
their interactions requires a mathematical
model. Economists have successfully con-
structed such a model because the central
concept of the quantity of a commodity has
a natural linear structure. The action of an
agent can then be described by listing the
quantity of its input or output for each
commodity (opposite signs differentiating
inputs from outputs). That list can be treated
as the list of the coordinates of a point in
the linear commodity space. Similarly, the
price system of an economy can be treated
as a point in the linear price space, dual of
the commodity space, whose dimension is
also the number of commodities.
In those two linear spaces, the stage was
set for sometimes dazzling mathematical
developments that began with the elements
of differential calculus and linear algebra
and that gradually called on an ever broader
array of powerful techniques and funda-
mental results offered by mathematics. Thus,
the three roles of prices given earlier as
instances were illuminated by basic mathe-
matical theorems: the first, the achievement
of an efficient use of resources, by results of
convex analysis; the second, the equaliza-
tion of supply and demand for commodities,
by results of fixed point theory; the third,
the prevention of the formation of destabi-
lizing coalitions, by results of the theory of
integration and of nonstandard analysis. In
those three cases, the lag between the date
of a mathematical discovery and the date of
its application to economic theory de-
creased over time. It was notably short for
nonstandard analysis, founded at the begin-
ning of the 1960's by Abraham Robinson1
and applied to economics by Donald Brown
and Abraham Robinson (1972).
The last, and most recently developed, of
those three instances can be chosen, as can
either of the other two, for a more detailed
illustration. Competition is perfect when ev-
ery agent's influence on the outcome of
economic activity is insignificant. The in-
fluence of their totality on that outcome is,
however, significant. It is to solve the prob-
lem of aggregating negligible quantities so
as to obtain a nonnegligible sum that inte-
gration was invented. In this perspective,
the application of integration theory to the
study of economic competition is entirely
natural. That application requires the set of
agents to be large-larger than the set of
integers. Treating the set of the agents of an
economy as the rich collection of the points


### ---Economics-1991-0-06.txt---
of an interval of real numbers has long been
familiar in descriptions of economic data. It
became familiar in economic theory as well
after Robert J. Aumann (1964) showed that,
in a pure exchange economy composed of
insignificant agents, the formation of desta-
bilizing coalitions is prevented if and only if
all those agents base their decisions on a
price system.
The concept of a convex set (i.e., a set
containing the segment connecting any two
of its points) had repeatedly been placed at
the center of economic theory before 1964.
It appeared in a new light with the intro-
duction of integration theory in the study of
economic competition: if one associates with
every agent of an economy an arbitrary set
in the commodity space and if one averages
those individual sets over a collection of
insignificant agents, then the resulting set is
necessarily convex.2 But explanations of the
three functions of prices taken as examples
can be made to rest on the convexity of sets
derived by that averaging process. Convexity
in the commodity space obtained by aggre-
gation over a collection of insignificant
agents is an insight that economic theory
owes in its revealing clarity to integration
theory.
An economist who experiences such an
insight belongs to the group of applied
mathematicians, whose values he espouses.
Mathematics provides him with a language
and a method that permit an effective study
of economic systems of forbidding complex-
ity; but it is a demanding master. It cease-
lessly asks for weaker assumptions, for
stronger conclusions, for greater generality.
In taking a mathematical form, economic
theory is driven to submit to those demands.
The gains in generality that it has achieved
as a result, in little more than a century,
stand out when the first formulations of
the theories of general equilibrium (Leon
Walras, 1874-1877) and of the core of an
economy (Francis Y. Edgeworth, 1881 pp.
34-8) are placed side by side with the re-
cent treatments of those subjects to which
The New Palgrave is an introduction and a
bibliographical key (John Eatwell et al.,
1987-1989). Walras's consumers and pro-
ducers have been freed from many of their
constraining characteristics; Edgeworth's
universe of two consumers and two com-
modities has been vastly expanded.
Mathematics also dictates the imperative
of simplicity. It relentlessly searches for
short transparent proofs and for the theo-
retical frameworks in which they will be
inserted. Participating in that pursuit, eco-
nomic theory was sometimes drawn by drives
toward greater generality and toward greater
simplicity in the same direction, rather than
in opposite directions. Cohort after cohort,
students of consumer theory have learned
about the concept of decreasing marginal
rate of substitution for two commodities on
an indifference curve and about its exten-
sion to the multicommodity case. Notably
more general, and notably simpler, is the
concept of convexity of the set of points
preferred to a given point in the commodity
space. Welfare economics presents another
instance. One of its main theorems formu-
lates precisely the principle enunciated by
Adam Smith (1776). If all the agents of an
economy are in equilibrium relative to a
price system, then they utilize their collec-
tive resources optimally. The proof of that
theorem (Kenneth J. Arrow, 1951) has be-
come so simple that it can be given without
mathematical symbols. It is, at the same
time, of utmost generality; in relating two
basic concepts of economic theory to each
other, it uses no assumption.
In its attempts to attain its many objec-
tives, economic theory was helped by greater
abstraction. Preference theory supplies an
example again. Significant research efforts
were expended on solutions of the integra-
bility problem. That problem can be by-
passed altogether, and greater simplicity can
be achieved by moving from the commodity
space to the more abstract space of the
pairs of its points. In this space, whose
dimension is twice the number of commodi-
ties, the pairs of commodity points indif-
ferent to each other are now assumed to
form a smooth (hyper)surface. As another
instance of the generality permitted by ab-
straction, consider the notion of a commod-



### ---Economics-1991-0-07.txt---
ity, which can be treated as a primitive
concept, with an unspecified interpretation,
in an axiomatic economic theory. A newly
discovered interpretation can then increase
considerably the range of applicability of
the theory without requiring any change in
its structure. Thus, by making the transfer
of a good or service between two agents
contingent on the state of the world that
will obtain, Arrow (1953) made possible the
immediate extension of the economic theory
of certainty to an economic theory of uncer-
tainty by a simple reinterpretation of the
concept of a commodity. The theory of fi-
nancial markets has been influenced by that
view of uncertainty, and their practice has
not been unaffected. Finally, take the prob-
lem of existence of a general equilibrium,
once considered to be one of the most ab-
stract questions of economic theory. The
solutions that were proposed in the early
1950's paved the way for the algorithms for
the computation of equilibria of Herbert E.
Scarf (1973) and for several of the develop-
ments of applied general equilibrium analy-
sis (Scarf and John B. Shoven, 1984). In this
case, abstraction in economic theory led to
the study of fundamental problems of great
generality, but also to a broad range of
applications.
III
The list of advances that the mathemati-
zation of economic theory helped or permit-
ted is already long; and in one aspect it may
appear lengthy. Ceteris paribus, one cannot
prefer less to more rigor, lesser to greater
generality, or complexity to simplicity; but
other things are not equal, and in the esti-
mate of many members of our Association
the cost of that mathematization sometimes
outweighs its benefit. Two of its presidential
addresses notably confronted that difficult
analysis and stressed the price that eco-
nomics paid for its increased use of mathe-
matics. Wassily Leontief's (1971) observa-
tions were factual, and Robert A. Gordon's
(1976) comments relevant when they were
made in 1970 and in 1975. They still are
today, for, in spite of their authorities, en-
hanced by the platform from which they
were speaking, and in spite of the wide
diffusion of their critiques, neither Leontief
nor Gordon altered the course of the devel-
opment they were assessing. In the past two
decades, economic theory has been carried
away further by a seemingly irresistible cur-
rent that can be explained only partly by the
intellectual successes of its mathematiza-
tion.
Essential to an attempt at a fuller expla-
nation are the values imprinted on an
economist by his study of mathematics.
When a theorist who has been so typed
judges his scholarly work, those values do
not play a silent role; they may play a deci-
sive role. The very choice of the questions
to which he tries to find answers is influ-
enced by his mathematical background.
Thus, the danger is ever present that the
part of economics will become secondary, if
not marginal, in that judgment.
The reward system of our profession rein-
forces the effects of that autocriticism. De-
cisions that shape the career of an economic
theorist are made by his peers. Whether
they are referees of a journal or of a re-
search organization, members of an ap-
pointment or of a promotion committee,
when they sit as judges in any capacity, their
verdicts will not be independent of their
own values. An economist who appears in
their court rarely ignores his perception of
those values. If he believes that they rate
mathematical sophistication highly, and if
he can prove that he is one of the sophisti-
cates, the applause that he expects to re-
ceive will condition his performance.
The same effects are also amplified by the
relentless pressure to publish exerted by his
environment. There are indeed instances of
extreme restraint in scientific publication,
and some of them have become legend. The
mathematical papers of Bernhard Riemann
(1826-1866) take 506 pages in the volume
that collected them (Riemann, 1876). The
molecular structure of DNA was announced
by James Watson and Francis Crick (1953)
in a one-page article. But it is easier to
explain those examples away than to follow
them. The environment of a scholar de-
mands papers, and the temptation to supply
them without restraint may become over-


### ---Economics-1991-0-08.txt---
powering to an economic theorist who has
developed proficiency in his research style.
The precocious development of that profi-
ciency is a comparative advantage that a
mathematical approach bestows on him.
The spread of mathematized economic
theory was helped even by its esoteric char-
acter. Since its messages cannot be deci-
phered by economists who do not have the
proper key, their evaluation is entrusted to
those who have access to the code. But
acceptance of their technical expertise also
implies acceptance of their values. Our pro-
fession may take pride in its exceptional
intellectual diversity, one of whose clearest
symbols is an Ely lecture given by an eco-
nomic historian at a session chaired by a
mathematical economist. Yet that diversity
is strained by the increasing impenetrability
to the overwhelming majority of our Associ-
ation of the work done by its most mathe-
matical members.
IV
The bond that ties economists together in
their study of a common subject has not
been tested only by differences in method-
ologies. It has also been tried by differences
in ideologies. In their endeavors to make
their field into a science, economists must
renounce a favorite mode of thinking-
wishful thinking; they must be impartial
spectators of a play in which they are the
actors. While they attempt to keep that
inhuman stance, they are pressed to give
immediate answers to societal questions of
immense complexity and thereby to aban-
don the exacting slowness of the step-by-step
scientific approach. Divisions according to
methodologies and ideologies, criticism from
outside and from inside, and intellectual
fashions that sweep our discipline make each
one of its steady developments remarkable.
The mathematization of economic theory
was one of them for a century and a half.
During the past five decades it became one
of the prime movers in the transformation
of our field. The extent of that mathemati-
zation has given rise to discordant assess-
ments of its effects and to attempts to
change its heading. The quality of assess-
ments of the phase that economic theory
underwent and the effectiveness of attempts
to alter the course of its evolution will gain
from a detailed analysis of the processes
that led to its present state.
## Economics-1992-0


### ---Economics-1992-0-03.txt---
Global warming from carbon dioxide was
an esoteric topic 15 years ago, unknown to
most of us. But in a few years, helped along
by some hot summers, it has climbed to the
top of the international agenda. Cabinets,
Parliaments, and heads of government have
issued pronouncements on reducing carbon
emissions, and in June of this year more
than a hundred governments will be repre-
sented by ministers or heads of government
at a great United Nations Conference on
Environment and Development to be held
in Rio de Janeiro. Together with non-
governmental organizations representing la-
bor, business, students, environmentalists,
scientists, and groups concerned with health
and child development and family planning,
these representatives are expected to need
25,000 hotel rooms. A "framework agree-
ment" is widely expected, together with
some institutional arrangements that will
keep global environmental issues perma-
nently on every government's agenda. And
at the center of these issues will be the
phenomenon that has come to be known as
the "greenhouse effect."
The greenhouse effect itself is simple
enough to understand and is not in any real
dispute. What is in dispute is its magnitude
over the coming century, its translation into
changes in climates around the globe, and
the impacts of those climate changes on
human welfare and the natural environ-
ment. These are beyond the professional
understanding of any single person. The
sciences involved are too numerous and di-
verse. Demography, economics, biology, and
the technology sciences are needed to pro-
ject emissions; atmospheric chemistry,
oceanography, biology, and meteorology are
needed to translate emissions into climates;
biology, agronomy, health sciences, eco-
nomics, sociology, and glaciology are needed
to identify and assess impacts on human
societies and natural ecosystems. And those
are not all.
There are expert judgments on large
pieces of the subject, but no single person
clothed in this panoply of disciplines has
shown up or is likely to. So, I venture to
offer my judgment.
First on the principle. The metaphor of
the greenhouse is not quite appropriate, but
the basic idea is not in dispute. The earth is
bathed in sunlight, some reflected and some
absorbed. If the absorption is not matched
by radiation back into space, the earth gets
warmer until the intensity of that thermal
radiation matches the absorbed incoming
sunlight. Some gases in the atmosphere that
are transparent to sunlight absorb radiation
in the infrared spectrum, blocking that out-
ward radiation and warming the atmo-
sphere. When the atmosphere has warmed
enough to intensify the thermal radiation so
that it matches the absorbed incoming sun-
light, equilibrium is achieved at the higher
temperature. These so-called "greenhouse"
gases can be identified in the laboratory.
Carbon dioxide is one of them; methane is
another, as is nitrous oxide, as are the chlo-
rofluorocarbons (CFC's).
The principle has been in practice for
decades. On a clear day in January, the
earth and its adjacent air in Orange County
California warm nicely, but the warmth ra-
diates rapidly away during the clear nights,
and frost may threaten the trees. Smudge
pots, burning cheap oil on a windless night,
produce substances, mainly carbon dioxide,
that absorb the radiation and protect the
trees with a blanket of warm air. Green-
houses, in contrast, mainly trap the air
warmed by the earth's surface and keep it


### ---Economics-1992-0-04.txt---
from rising to be replaced by cooler air. The
phenomenon should have been called the
"smudgepot effect," but it is too late to do
anything about it.
A first step in pursuing this phenomenon
is to assess how much warming might go
with an enhanced concentration of these
gases. That cannot be done in the labora-
tory; there are too many feedbacks. A
warmer atmosphere will contain more water
vapor; water vapor itself is a greenhouse
gas. Changes in temperature and humidity
will change cloud cover; clouds can reflect
or absorb incoming or outgoing light accord-
ing to their composition and altitude. The
average temperature is only one dimension;
temperatures at different altitudes and dif-
ferent latitudes matter. But a starting point
has been the change in average surface at-
mospheric temperature expected to accom-
pany a specified increase in the concentra-
tion of greenhouse gasses; and arbitrarily,
but reasonably, the base case is taken as a
doubling of the concentration.
A moment on why a doubling is the
benchmark. To compare estimates of warm-
ing, people must use the same hypothesized
concentration of greenhouse gases in the
atmosphere. (Alternatively, they could use
the same hypothesized temperature in-
crease and estimate the corresponding con-
centration.) Doubling, like a half-life in re-
verse, is a natural unit if it is within the
range of practical interest, and it is. A dou-
bling is expected sometime in the next cen-
tury, so it is temporally relevant; and a
doubling is estimated to make a substantial
but not cataclysmic difference. If fixation on
a doubling seems to imply an upper limit on
any expected increase, the implication is
unfortunate: enough fossil fuel exists to sup-
port several doublings.
In 1979, a committee of the National
Academy of Sciences (NAS) (1979 p. 2)
estimated the change in average tempera-
ture to accompany a doubling of carbon
dioxide in the atmosphere: three degrees
Celsius, with a range of 1.5 degrees to ei-
ther side. (In the last 15 years other green-
house gases have received attention; these
other gases can be converted to their car-
bon dioxide equivalents and the original
estimate applied to the mixture.) The NAS
appointed another committee a few years
later to reexamine that estimate, and the
new committee saw no reason to change it
(NAS, 1982 p. 51). An intergovernmental
panel on climate change (IPCC), consisting
of scientists from many nations, revisited
the estimate in 1990 and concluded, from
the several climate models they had exam-
ined, that "the models results do not justify
altering the previously accepted range of 1.5
to 4.5 degrees C" (IPCC, 1990 p. xxv). Thus,
the estimate appears to be robust over time,
but the spread of uncertainty remains large:
the upper limit is three times the lower
limit. (No quantitative interpretation of
these upper and lower "limits" has been
made public. Both National Academy re-
ports referred to them as "probable error.")
II
The uncertainties are even greater in
translating a temperature change into cli-
mates. The media support a popular view
that things will just get hotter; a news maga-
zine cover was a sweating global face. But
the laboratories that do the meteorology do
not simply predict warming; they do not
even predict that the most noticeable effects
will necessarily be temperature changes.
Among the great driving forces of weather
and climate is the temperature differential
between equatorial and polar regions; con-
vection currents coupled with the rotation
of the earth are engines of atmospheric
circulation and, ultimately, ocean circula-
tion. The models predict greater tempera-
ture change in the polar regions than near
the equator. This change in gradient can
drive changes in circulation. The results may
be warmer in some places and colder in
others, wetter in some places and drier in
others, cloudier in some places and sunnier
in others, stormier in some places and less
stormy in others-generally a complex of
changes that would bear no easy relation to
an average change in global temperature.
The change in average temperature is
useful as an index of climate change. It is


### ---Economics-1992-0-05.txt---
thought, and the models demonstrate, that
the greater the change in average tempera-
ture the greater the departure of current
climates from what they are now. Thus,
while it is wrong to think that what is going
to happen can be readily characterized as
"warming" it is not erroneous to take that
average warming as a rough measure of the
extent or severity of change to be expected.
Unfortunately the widespread reference to
"global warming" promotes the notion that
things will simply get hotter. (Interestingly,
virtually all public discussion is on hotter
summers, not warmer winters; a hundred
years ago popular discussion of a warming
trend would likely have concentrated on the
milder winters to be expected.)
If three degrees Celsius is taken as an
index of climate change to come within the
next century or so, how big is that compared
with what has happened within the last cen-
tury, or the last 10,000 years? From what I
have just said, this cannot be answered in
terms of whether anyone would notice the
difference if every night and every morning,
every winter and every summer, tempera-
tures were exactly three degrees higher than
they otherwise would have been. The ques-
tion is: how would a three-degree change in
a global average compare with what has
been experienced in the past?
The answer is that for 10,000 years, since
the disappearance of the last ice age, aver-
age temperature appears never to have var-
ied over anything like three degrees. A band
of one degree Celsius would cover the cur-
rent estimates of what average tempera-
tures have been since the dawn of recorded
history. We will be moving into a climatic
regime that has never been experienced in
the current interglacial period.
"Mankind will undergo greater climate
change in the next 100 years than has been
experienced in the last 10,000." Properly
qualified, the statement is true; what it ne-
glects is that peoples have been migrating
over great distances for at least several
thousand years. Goths and Vandals, Huns,
West Europeans who populated North and
South America, Southerners who went
North during the Great Depression, and
Northeasterners who moved southwest after
World War II all experienced changes in
climate greater than any being forecast by
the models. Almost everybody who attends
this lecture in New Orleans will have under-
gone a greater change in the past few days
than is expected to occur in any fixed local-
ity during the coming century.
The changes that the models produce are
gradual both in time and in space. The
models do not produce discontinuities. Cli-
mates will "migrate" slowly. The climate
of Kansas may become like Oklahoma's,
Nebraska's like that of Kansas, South
Dakota's like Nebraska's, but none of these
is expected to become like the climates of
Oregon, Louisiana, or Massachusetts.
A caution: the models probably cannot
project discontinuities-just gradual change
-because nothing goes into the models that
will produce catastrophes. There may be
phenomena that could produce drastic
change, but they are not known with enough
confidence to introduce them into the mod-
els. So the reassuring gradualness may be
an artifact of the methodology. I will return
to this point later.
This greenhouse problem, if problem it
proves to be, is truly one of the "global
common." A ton of carbon emitted any-
where on earth has the same effect as a ton
emitted anywhere else. And carbon dioxide
has a long residence time in the atmo-
sphere: a century or more. There may be
ways to remove it, but it doesn't disappear.
The greenhouse influence on any national
territory depends solely on the global con-
centration, not in any way on what part of
the total is due to a nation's own emissions.
As I shall detail later, the costs of reduc-
ing carbon emissions will be large compared
with any other emissions that have caused
concern. The costs of phasing out CFC's
will be in the billions of dollars per year for
some years, and complete elimination is ex-
pected to be feasible. The cost of reducing
sulfuric acid may be in the tens of billions of
dollars. Proposals to hold emissions of car-
bon dioxide constant (with a linear increase
of concentration in perpetuity) or to reduce
emissions by 50 percent below what they


### ---Economics-1992-0-06.txt---
would otherwise be, beginning perhaps in
2010, are expected to cost in the hundreds
of billions in perpetuity.
There are a few numbers worth carrying
in mind. There are 700 billion tons of car-
bon in the atmosphere. (Quotations are
sometimes in tons of carbon dioxide, rather
than carbon; the figure is then 32 times as
large, about 2,600 billion.) Annual emis-
sions are 6 billion tons. Close to half disap-
pears somewhere, and a little over half
remains in the atmosphere; so the concen-
tration is increasing by one-half percent per
year. It has increased 25 percent in the last
hundred years. (Concentration is reported
more often than tonnage; it is currently
about 350 parts per million.) And there are
upwards of ten trillion tons of carbon fuels
out there to be burned; if it were all burned
and half stayed in the atmosphere, the con-
centration could double at least three times.
If the carbon in the atmosphere has al-
ready increased by a quarter, has the aver-
age temperature gone up as predicted? And
were the recent hot American summers that
stirred popular interest harbingers of green-
house summers to come?
To the first question, the answer is that
average global temperature-summer and
winter, both hemispheres, night and
day-has apparently risen by half a degree
in the last hundred years, but whether "as
predicted" depends on what qualifications
one reads into the predictions. The pattern
differed between the Northern and South-
ern Hemispheres. The global average rose
during the first 40 years of this century, was
level for the next 40 years, and rose during
the past decade. This pattern demonstrates
that, whether or not we are witnessing the
greenhouse effect, there are other decades-
long influences that can obscure any smooth
greenhouse trend. (The carbon concentra-
tion is not at issue; it is well measured and
shows steady rise on a decade scale.) There
are known phenomena that could account
for the irregular temperature increase of
the past century, and whether we are wit-
nessing the "signal" probably depends on
whether one wants high confidence to reject
a null hypothesis or is about to bet money
on whether, another 25 years from now,
looking back, all doubt will have been re-
moved. I don't know what bets are being
placed by "greenhouse scientists," but they
are cautious in public on the question.
To the second question-do the hot
American summers of the past few years
announce the arrival of a greenhouse, con-
firming predictions?-the answer is in two
parts: maybe it's the greenhouse; but it's not
what the greenhouse models predict. The
global average in the four hot years of the
past seven was only 0.2 degrees above the
level of the preceding 40 years; and sudden
hot American summers are not what the
models predict.
III
In anticipating the impact on human wel-
fare or natural systems, two kinds of uncer-
tainty are unlikely to be dispelled soon. One
is simply the question of what the changes
will be in each region or locality. Current
models are severely limited in their agree-
ment with each other, in their handling of
such topographical variables as mountain
ranges, and in the fineness of the grids they
superimpose on the globe. There is no great
confidence that the models will be greatly
improved within the next decade or two. A
chaos-like process may defeat efforts to im-
prove local predictions; and uncertainties in
gross phenomena, such as the behavior of
ocean currents under changed climatic con-
ditions, may not be much better understood
soon.
Even if we had confident estimates of
climate change for different regions of the
world, there would still be uncertainties
about the kind of world it is going to be 50,
75, or 100 years from now. Imagine it were
1900 and the climate changes associated
with a three-degree average temperature in-
crease were projected to 1992. On what
kind of world would we superimpose either
a vaguely described potential change in cli-
mate or even a specific description of
changes in the weather in all the seasons of
the year, even for our own country. There
would have been no way to assess the im-
pact of changing climates on air travel, elec-
tronic communication, the construction of


### ---Economics-1992-0-07.txt---
skyscrapers, or the value of California real
estate. Most of us worked outdoors; life
expectancy was 47 years (it is now 75); barely
a fifth of us lived in cities of 50,000 or more.
Anticipating the automobile, we might have
been concerned with whether wetter and
drier seasons would bring more or less mud,
not anticipating that the nation's roads would
become thoroughly paved. The assessment
of effects on health would be without anti-
biotics or inoculation. And in contrast to
most contemporary concern with the popu-
lar image of hotter summers to come, I
think we would have been more concerned
about warmer winters, later frost in autumn,
and earlier thaw in the spring.
If the world, both North America and the
other continents, is going to change as much
in the next 90 years as it has changed in the
90 just past, we are going to be hard put to
imagine the effects of climate changes.
Another thought experiment: suppose the
kind of climate change expected between
now and, say, 2080 had already taken place
since 1900. Ask somebody 50, 60, or 80
years old what is different compared with
when he or she was a child. Would the
climate change be noticed? Even ask a 70-
year-old farm couple living on the same
farm where they were born: would the
change in climate be among the most dra-
matic changes in either their farming or
their lifestyle? I expect changing from horses
to tractors and from kerosene to electricity,
the arrival of the telephone and the auto-
mobile and the paving of roads, the devel-
opment of pesticides and artificial fertilizer,
the discovery of soy beans and the develop-
ment of hybrid corn, and even improve-
ments in outdoor clothing, veterinary
medicine, and agricultural practices gener-
ally would swamp the climate change. And
if instead of living and working conditions
we inquire about changes in wildlife and
natural ecosystems, changes in regional cli-
mates would have been competing, in their
impact on nature, with population growth
and economic development.
A conclusion we might reach is that a
climate change would have appeared to
make a vastly greater difference to the way
people lived and earned their living in 1900
than to the way people live and earn their
living today. Today very little of our gross
domestic product is produced outdoors, sus-
ceptible to climate. Agriculture and forestry
account for less than 3 percent of GDP, and
little else is much affected. Some activities
-tourism and holidays, professional sports,
and school teaching-are seasonal, but
many of the seasonalities are conventions
that reflect the influence of climate in ear-
lier times. (Children were needed in the
fields in summer and could start school when
the harvest was in; hockey and basketball
used to be winter sports because one de-
pended on ice and the other could fit in a
building.)'
Manufacturing rarely depends on climate,
and where temperature and humidity used
to make a difference, air conditioning has
intervened. When Toyota chooses among
Ohio, Alabama, and Southern California for
locating an automobile assembly, geographi-
cal considerations are important, but not
because of climate. Minerals are extracted
where they happen to occur, and oil fields
and coal mines inhabit all kinds of climates
and are little affected. The U.S. Postal Ser-
vice's vow that neither snow nor rain nor
heat nor gloom of night will "stay these
couriers from the swift completion of their
appointed rounds" sounds quaint in the era
of e-mail and fax.
Finance is little affected by climate; simi-
larly for health care, or education, or broad-
casting. Transportation can be affected, but
improvements in all-weather landing and
take-off in the last 30 years are greater than
any differences that climate makes. If the
average effect is a warming, iced waterways
and snow removal may decline in impor-
tance. Construction is affected, mainly by
cold, and if the average effect is in the
direction of warming, construction may ben-
efit slightly.
It is really agriculture that is affected. But
even if agricultural productivity declined by
a third over the next half century, the per



### ---Economics-1992-0-08.txt---
capita GNP we might have achieved by 2050
we would achieve only in 2051. Considering
that in most of the developed countries-the
United States, Japan, France, the United
Kingdom, the Netherlands, and Israel-the
agricultural problem has been protecting
farmers, that agricultural productivity in
most parts of the world continues to im-
prove, and that many crops and cultivated
plants will benefit directly from enhanced
photosynthesis due to increased carbon
dioxide, one cannot be certain that the net
impact on agricultural productivity will be
negative or, if negative, will be noticed in
the developed world.
I conclude that in the United States, and
probably Japan, Western Europe, and other
developed countries, the impact on eco-
nomic output will be negligible and unlikely
to be noticed.2 And there is no reason to
believe that in these countries there could
be a noticeable impact on health. Any in-
fluence of climate on health in this country
would be more in the regional distribution
of the population than in changes in local
and regional climates.
Comfort is worth considering. Fortu-
nately, the climate models predict a greater
warming in winter than in summer. Most
people in the United States, Japan, and
Western Europe go south for vacation, both
summer and winter; and when people move
upon retiring in the United States they typi-
cally move toward warmer climates. In fu-
ture years, elderly people may suffer more
heat stroke in summer in St. Louis, but we
can hope for fewer broken bones from ice
in Boston. (Inhaling air richer in carbon
dioxide has no effect on health.)
IV
This complacent assessment cannot be
extended to the much larger population of
the underdeveloped world. The livelihoods
earned in agriculture and other climate-
sensitive outdoor activities, 3 percent in the
United States, comprise 30 percent and
more of all livelihoods in most of the devel-
oping world. Reliable forecasts of likely
climate changes in the different areas so
dependent on agriculture are simply not
available, so no assessment, region by re-
gion, of the effect on productivity can be
provided. There is no strong presumption
that the climates prevailing in different re-
gions 50 or 100 years from now will be less
conducive to food production. But there is
also no assurance that climate changes will
not be harmful, and even if on balance the
impact is neutral, there may be large areas
with large populations that suffer severely.
Those people are vulnerable in a way that
Americans, Western Europeans, and
Japanese are not.
Nor can the impact on health be dis-
missed or readily subsumed among gener-
ally improving health conditions, as for the
developed world. Numerous parasitic and
other vector-borne diseases affecting hun-
dreds of millions of people are sensitive to
climate. Again, there is no strong presump-
tion that malaria mosquitos, to take an ex-
ample, will on balance benefit from climate
changes, but the risk is there.
It is with the less-developed countries that
we have to be most careful about superim-
posing the climates of the future on the
economies and societies of today. As it was
in our own country during this century, the
trend in developing countries is to be less
dependent on agriculture and less vulnera-
ble to climate in transportation and other
activities and health. If per capita income
growth in the next 40 years compares with
the 40 years just past, vulnerability to cli-
mate change should diminish, and the re-
sources available for adaptation should be
greater. I say this not to minimize concern
about climate change, but to anticipate the
question of whether developing countries
should make sacrifices in their development
to minimize the emission of gases that may
change climate to their disadvantage. Their
best defense against climate change may be
their own continued development.
This is a point worth emphasizing. Some
environmentalists argue that developing



### ---Economics-1992-0-09.txt---
countries should sacrifice some of their
hopes for economic development in the in-
terest of slowing the climate change that
may prove disastrous. But the advice con-
tains a contradiction Any disaster to devel-
oping countries from climate change will be
a disaster to their economic development.
What is desired is to optimize development
by investing in greenhouse-gas abatement
only when that appears, subject to all the
uncertainties, to contribute more to their
development in the future than the alterna-
tive direct investment in development. It is
not economic growth versus environment; it
is growth with the environment taken into
account.
A related point: population growth is im-
portant for the climate change, in two re-
spects. One is that carbon emissions in de-
veloping countries are positively driven by
population; population growth does not
merely dilute carbon emissions per capita,
but for a number of reasons more people
means more carbon. If China succeeds in
holding population growth to near zero for
the next couple of generations, it may do as
much for the earth's atmosphere as would a
heroic Chinese anticarbon program coupled
with 2-percent annual population growth.
The other population effect is simply that
the most likely adverse impact of climate
change on human productivity and welfare
would be on food production. In the poor-
est parts of the world, the adequacy of food
depends on the number of mouths and
stomachs. In a hundred years, adverse
changes in climate for food production
would be far more tragic if the countries we
now associate with the developing world
had populations totaling 12 billion than if
they totaled 9 billion. For the developing
world, the increasing concentration of peo-
ple is probably more serious than the in-
creasing concentration of carbon dioxide.
At this point, I appear to have reached
the conclusion that the developed world has
no self-interest in expensively curtailing car-
bon consumption and that the developing
world cannot afford to incur economic
penalties to slow the greenhouse effect.
There is a mismatch between those who
may be vulnerable to climate change and
those who can afford to do anything about
it.
V
Why should the rich developed countries
care enough about climate change to do
anything about it? The answer must depend
partly on how expensive it is going to be to
do anything about it. Abatement programs
have been examined in a number of econo-
metric models that suggest we might want
to treat as pertinent the sacrifice of perhaps
2 percent of world GNP in perpetuity.
A strong argument for trying seriously to
slow climate change is that the developing
countries are vulnerable and we care. De-
veloped countries are currently providing
$50 billion per year of assistance to the
developing world; we would be talking about
expending or forgoing perhaps 4-8 times
that much to slow emissions and slow cli-
mate change. Whether people in the devel-
oped democracies could be mobilized to
contribute so much to benefit, half a cen-
tury from now, the people in the countries
we now call developing I do not know, but I
believe that if the developed countries were
prepared to invest, say, $200 billion per year
in greenhouse-gas abatement, explicitly for
the benefit of developing countries 50 years
or more from now, the developing countries
would clamor to receive the resources im-
mediately in support of their continued de-
velopment. There would undoubtedly be
abatement opportunities so cheap that they
could compete with direct aid to developing
countries, but it would be hard to make the
case that the countries we now perceive as
vulnerable would be better off 50 or 75
years from now if 10 or 20 trillions of dol-
lars had been invested in carbon abatement
rather than in their economic development.
A second argument for an expensive pro-
gram of carbon abatement is that, while our
production of material goods and services
may not suffer from climate change, our
natural environment may be severely dam-
aged. Natural ecosystems will be destroyed;
plant and animal species will become ex-
tinct. Places of natural beauty will be de-
graded. Valuable chemistries of plant and


### ---Economics-1992-0-10.txt---
animal life will be lost before we learn their
genetic secrets. And the earth itself de-
serves our respect. For many people, some-
thing close to religious values are at stake.
This issue is doubly difficult to assess. It is
difficult to know how to value what is at
risk, and it is difficult to know just what is at
risk. Even if climate changes at each point
in time could be predicted accurately, the
impacts on natural ecosystems could not yet
be determined. And the benefits of slowing
climate change by some particular amount
would be even more uncertain. We know
that carbon fuels are not going to be discon-
tinued; the issue is the marginal gains, from
carbon abatement and a slowing of climate
change, in the survival of species and
ecosystems and the preservation of enjoy-
able environments. This is an issue that
simply has not been addressed.
The third argument for spending heavily
to slow climate change is that the conclu-
sions I reported earlier may be quite wrong.
I said that the climate models predict that
climates will change slowly and not much;
the models do not produce discontinuities,
surprises, catastrophes. What is known about
weather and climate constitutes an equilib-
rium system.
The possibility has to be considered that
if global temperature increases, not by the
median estimate of three degrees Celsius
for a doubling of carbon in the atmosphere,
but by four or five degrees and continues to
rise beyond the doubling because carbon
fuels are still in use worldwide, some atmo-
spheric or oceanic circulatory systems may
switch to alternative equilibria, producing
regional changes that are both sudden and
extreme.
Have any such possibilities been thought
of? One that was thought of but diminished
upon further investigation was the possibil-
ity that the west Antarctic ice sheet might
glaciate into the ocean and raise the sea
level by 20 feet. As recently as 15 years ago,
the best scientific judgment was that this
could happen within 75 years as a result of
global warming. This prospect naturally at-
tracted attention, and further investigation
with the help of newly available satellite
sensing of glacial movement led to reassur-
ing estimates that if that catastrophic rise in
sea level were to happen it would take at
least a few hundred years and be gradual,
not sudden. But there isn't any scientific
principle according to which all alarming
possibilities prove to be benign upon further
investigation.
A currently discussed likely source of dis-
continuous change is in the way oceans be-
have. Amsterdam is north of Newfound-
land, yet is warmer, courtesy of the Gulf
Stream. There is some indication that in
earlier interglacial periods ocean currents
may have pursued different courses. If a
current like the Gulf Stream, or the
Japanese Current for the United States,
switched into an alternative pattern, the cli-
matic consequences might be both sudden
and severe. (Paradoxically, global warming
might freeze Western Europe.)
Insurance against catastrophes is thus an
argument for doing something expensive
about greenhouse emissions. But to pay a
couple percent of GNP as insurance pre-
mium, one would hope to know more about
the risk to be averted. I believe research to
improve climate predictions should be con-
centrated on the extreme possibilities, not
on modest improvements to median projec-
tions.
I said that current estimates suggest that
it might cost a couple percent of GNP to
postpone the doubling of carbon in the at-
mosphere by several decades. Is 2 percent a
big number or a small one?
That depends on your perspective and on
what the comparison is. In recent years 100
billion dollars per year in budgets or taxes
has been a politically unmanageable magni-
tude in the United States. On the other
hand, subtracting 2 percent from GNP in
perpetuity lowers the GNP curve by not
much more than the thickness of a line
drawn with a number-two pencil, or to for-
mulate it as I did earlier, it postpones the
GNP of 2050 until 2051. I say this not to
belittle the loss of 10 trillion dollars from
the American GNP over the next 60 years,
but only to point out that the insurance
premium, if we choose to pay it, will not
send us to the poorhouse. The proper ques-
tion is whether, if we were prepared to
spend 2 percent of our GNP in the interest
of protecting against damage due to climate


### ---Economics-1992-0-11.txt---
change, we might find better use for the
money.
I have mentioned one use: directly invest-
ing to improve the economies of the poorer
countries. Another would be direct invest-
ment in preserving species, ecosystems, or
wilderness areas. There is concern that many
ecosystems could not migrate as rapidly as
climate may change in the coming century;
there has been little investigation of what
might be done to facilitate the migration of
ecosystems if the alternative is to invest 5 or
10 trillions of dollars in the reduction of
carbon emissions.
VI
What can be done to reduce or offset
carbon emissions? Reducing energy use and
the carbon content of energy have received,
I believe properly, most of the attention,
especially the attention of economists. There
are other possibilities to mention.
Trees store carbon. In growing, they take
it out of the atmosphere. When they rot or
burn it goes back into the atmosphere. A
new forest will absorb carbon until it reaches
maturity (i.e., maximum carbon density) in
75 or 100 years. If it then merely replen-
ishes itself, with new growth replacing the
oxidized dead trees, it holds its carbon but
does not absorb more. If trees are har-
vested, the lumber that becomes house
frames or furniture may last a hundred years
or more; removing mature trees and storing
them anaerobically is possible but expen-
sive. The most recent report of the National
Academy of Sciences considered that refor-
estation in the United States might se-
quester 2-3 percent of current global
carbon dioxide emissions.3 The prospects
for that kind of reforestation in the rest of
the world are not nearly so promising, and
we should conclude that reforestation can
contribute, but not greatly.
Stopping or slowing deforestation is im-
portant for reasons other than carbon emis-
sions but is quantitatively more important
than reforestation. Reforestation is unlikely
to take up as much as 100 billion tons of
carbon; deforestation, in areas where defor-
estation is likely, could contribute several
hundred billion tons of carbon, partly be-
cause forest subsoils contain carbon typi-
cally greater than the amount in the trees
themselves, and this carbon is subject to
oxidation when the trees are removed.
Carbon can be "scrubbed" from stack
gases, probably not with any known technol-
ogy that would make such removal econom-
ically competitive with reducing emissions.
(Part of the expense is disposing of sludge;
where gaseous carbon might be pumped
into the ocean or into underground cavities,
economical disposal may prove feasible.)
Parallel to reforestation is the idea of en-
hancing oceanic photosynthesis, by "fertiliz-
ing" the oceans, possibly with iron, if enough
of the carbon residues from the enhanced
growth will sink rather than remain near the
surface. Experiments would probably be re-
versible and modest in scale; their political
acceptability may be tested in the near fu-
ture.
Finally-although nothing is final in a
subject as new as the one we are talking
about-there are numerous possibilities for
putting substances or objects in orbit or in
the stratosphere to reflect something like 1
percent of incoming sunlight to offset a large
part of the radiation imbalance caused by
greenhouse gases. Some of these are as
apparently innocuous as stimulating cloud
formation, and some are as dramatic as
huge mylar balloons in low earth orbit. Un-
til very recently these possibilities were
nearly unmentionable, but they have re-
cently been dignified by inclusion, along with
caveats about "large unknowns concerning
possible environmental side effects," in the
1991 report of the National Academy of
Sciences. I shall not pursue them here, ex-
cept for two observations. First, if in decades
to come the greenhouse impact begins to
confirm the more alarmist expectations, and
if the economic sacrifices required to reduce



### ---Economics-1992-0-12.txt---
emissions prove unmanageable for eco-
nomic or political reasons, some of these
"geoengineering" options will invite atten-
tion. Second, if they do, and especially if
they prove to be within the budgetary capa-
bilities of individual nations, international
greenhouse diplomacy will be transformed.
VII
What remains nearly certain is that the
main responses to the greenhouse threat
will be adapting to climate as climate
changes and reducing carbon emissions.
(CFC's are potent greenhouse gases and, if
unchecked, might rival carbon dioxide in
decades to come; but international actions
are making good progress and are among
the cheapest ways of reducing greenhouse
emissions.)
Like estimates of warming, estimates of
the costs of reducing emissions require some
common but arbitrary objective to be com-
parable. A doubling of carbon became the
conventional benchmark for warming esti-
mates; no such benchmark for reduced car-
bon emissions has been adopted for estimat-
ing costs. (In principle, the estimates could
adopt that doubling: the issue could be for-
mulated as the cost of retarding the dou-
bling time by a decade, two decades, or half
a century.) Most estimates take as their
target a reduction of emissions either to a
specified fraction of what they would be in
the absence of controls, or to some fixed
ratio to the emissions of 1990 or the pro-
jected emissions of 2000 or 2010. The esti-
mates examine minimum-cost trajectories,
implicitly or explicitly assuming something
like a uniform tax on the carbon content of
fuel as the policy instrument. They typically
make some assumption about a "fallback"
energy technology, at least for electricity,
available at some price in some decade of
the next century. They have to project esti-
mates of non-price-induced improvements
in the use or avoidance of energy by indus-
tries and households. And if they deal with
global emissions, they have to make some
assumption about the distribution of abate-
ment efforts among nations, especially
among the developing countries, which, in-
cluding China, account for about a quarter
of emissions now and would be expected to
account for half by the middle of the next
century.
Any estimate of the cost of abatement
needs therefore to specify at least half a
dozen target assumptions. Furthermore, the
estimates are produced by people and insti-
tutions that do not simultaneously estimate
the costs associated with climate change,
either damages or costs of adapting; the
estimates do not optimize the combined
costs of abatement and climate change. A
"not unreasonable" target for reduction
might be delaying a doubling by, say, four
decades. One decade might be too trivial, a
century too ambitious, and four decades an
objective in which most audiences would be
interested. But nobody who makes such an
estimate wishes to be interpreted as propos-
ing that when all the uncertainties about
climate changes and their impacts have been
resolved, if they ever are resolved, the opti-
mum reduction in emissions will be found
to retard doubling by 40 years, or any other
specified period of time.
All I can do to summarize a multitude of
estimates is to specify an order of magni-
tude that many economists and the Con-
gressional Budget Office would not consider
outrageous. That is the figure I mentioned
earlier, possibly 2 percent of GNP for the
developed countries and a similar, but even
much more uncertain, percentage of GNP
for the developing world. The uncertainty
for the developing world is partly due to the
estimates being mainly derived from the
American economy.4
Two characteristics of these estimates
need to be emphasized. One is that they
tend to assume optimal technological ad-
justment, as in response to a carbon tax. To
the extent that carbon emissions are con-
trolled by direct regulatory measures, there
may be the usual expected inefficiencies,
and I leave the reader to make his own
adjustment.


### ---Economics-1992-0-13.txt---
The second is that, since the early years
of the energy crisis in the 1970's, there have
been enthusiastic portrayals of currently
available technologies, ranging from light
bulbs to electric motors, double-glazed win-
dows and improved internal-combustion en-
gines, that for some reason have not been
successfully marketed. The interest contin-
ues, and the recent National Academy of
Sciences study gave sympathetic attention,
but no analysis, to a number of proposals
for residential, commercial, industrial, and
transportation energy management and for
improved electricity production and fuel
supply and concluded that, including reduc-
tions in CFC's, "The United States could
reduce or offset its greenhouse gas emis-
sions by between 10 and 40 percent of 1990
levels at low cost or at some net saving, if
the proper policies are implemented" (1991
p. 73).
All of these ideas are completely orthogo-
nal to the econometric estimates. The
Academy panel that produced the report
was unable to offer an explanation for why
these low-cost or negative-cost technologies
have not caught on. Its quantitative assess-
ment, including an allowance for elimina-
tion of CFC's, ranged from as little as 10
percent to as much as 40 percent of current
U.S. emissions; CFC's aside, their range of
possibility is from zero to about 30 percent.
Whatever the correct figure, this is probably
a once-and-for-all backlog of accumulated
technologies, which once exploited may be
permanent but not progressive. But the
strong suggestion is that there is a lot to be
accomplished in the next two or three
decades.
VIII
With these qualifications, let us look at
that 2 percent of GNP as a permanent
reduction over the coming century. I con-
sider it altogether improbable that the de-
veloping world, at least for the next several
decades, will incur any significant sacrifice
in the interest of reduced carbon (nor would
I advise developing countries to do so).
Anything done to reduce emissions in China,
India, or Nigeria will be at the expense of
the richer countries.
Financing energy conservation, energy
efficiency, and switching from high-carbon
to lower-carbon or noncarbon fuels in Asia
and Africa would not only be a major eco-
nomic enterprise but a complex effort in
international diplomacy and politics. If suc-
cessful, it would increase the costs to the
developed world by at least another percent
or two on top of the 2 percent I mentioned.
It is furthermore not easy to hide the trans-
fer of resources on the order of a couple of
hundred billion dollars, dollars "budgeted"
somehow or other, compared with hiding
some of the costs due to regulation, such as
automobile fuel-efficiency standards in the
United States. The kind of thing we are
talking about is inducing the Chinese,
through our somehow offsetting their cost,
to forgo a massive electrification based on
coal and the cheapest coal-combustion tech-
nology. Without engaging in blackmail, the
Chinese can assert that it is not in their
interest to do that at their own expense,
even if they are the keystone of a "social
contract" and no other nation will do any-
thing unless the Chinese fully participate.
I shall sketch what I can imagine as a
major attack on the greenhouse problem.
And I should be explicit about what I can-
not imagine. For reasons that I would be
delighted to elaborate but for which I can-
not take space here, a universal uniform
carbon tax is not a solution that I can imag-
ine. My reason is simple. A carbon tax suf-
ficient to make a big dent in the greenhouse
problem would have to be roughly equiva-
lent at least to a dollar per gallon on motor
fuel, and for the United States alone such a
tax on coal, petroleum, and natural gas
would currently yield close to half a trillion
dollars per year in revenue. No greenhouse
taxing agency is going to collect a trillion
dollars per year in revenue; and no treaty
requiring the United States to levy internal
carbon taxation at that level, keeping the
proceeds, would be ratified by the Senate.
Reduce the tax by an order of magnitude
and it becomes imaginable, but then it be-
comes trivial as greenhouse policy.5

### ---Economics-1992-0-14.txt---
Tradable permits have been proposed as
an alternative to the tax. There are two
main possibilities: (i) estimating "reasona-
ble" emissions country by country and es-
tablishing commensurate quotas or (ii) dis-
tributing tradable rights in accordance with
some "equitable" criterion, such as equal
emissions per capita (a possibility that has
actually been discussed). Depending on how
restrictive the aggregate of such tradable
emission rights might be, the latter is tanta-
mount to distributing trillions of dollars in
discounted value and making, for a country
like Nigeria, the outcome of its population
census the country's major economic policy.
If, instead, quotas are negotiated to corre-
spond to every country's currently "reason-
able" emissions level, they will surely be
renegotiated every 5 or 10 years, and selling
an emissions right will be perceived as evi-
dence that a quota was initially too gener-
ous. It is unlikely that governments will en-
gage in trades that acknowledge excessive
initial quotas.
I do not foresee negotiated national quo-
tas subject to serious enforcement, espe-
cially enforcement through financial penal-
ties. I think any international regime for
carbon abatement can seriously include only
the developed countries, and I exclude from
this category the countries that we used to
call the Eastern Bloc. I can easily imagine
institutional arrangements that are univer-
salist, some kind of "framework agreement"
to which every country subscribes, with spe-
cific commitments to be negotiated later.
But I expect serious commitments to be
undertaken only by the countries that can
afford to, and I am undecided whether an
institutional pretense of a universalist sys-
tem has advantages or, instead, the devel-
oped world should proceed independently
and unencumbered with the need for a uni-
versalist facade.
The model that I find most helpful in
conceptualizing a greenhouse regime among
the richer countries is the negotiations
among the countries of Western Europe for
distributing Marshall Plan dollars among
themselves and the negotiations, beginning
in 1951, on "burden sharing" in NATO.
There was never a formula for distributing
Marshall Plan dollars; there was never an
explicit criterion, such as equalizing living
standards, equalizing growth rates, maximiz-
ing aggregate output or growth, or establish-
ing a floor under levels of living. Baseline
dollar-balance-of-payments deficits were a
point of departure, but the negotiations took
into account investment needs, traditional
consumption levels, war-induced capital
needs, opportunities for import substitution
and export promotion, and opportunities to
substitute intra-European trade for trade
with hard-currency countries.
The United States insisted that the recip-
ients argue out and agree on shares. In the
end, they did not quite make it, the United
States having to make the final allocation.
But all the submission of data and open
argument led, if not to consensus, to a rea-
sonable appreciation of each nation's needs.
The negotiations were professional; they
were assisted by a proficient secretariat. The
resources involved for most recipient coun-
tries were immensely important. Good rela-
tions were observed throughout; and profi-
ciency in debate, acceptance of criteria, and
negotiating etiquette steadily improved.
That is the only model I find plausible,
and I believe distribution of Marshall Plan
and defense-support funds to Europe is the
only model of multilateral negotiation in-
volving resources commensurate with the
cost of greenhouse abatement. (In the first
year, Marshall Plan funds were about 1.5
percent of U.S. GNP and-adjusting for
overvalued currencies-probably 5 percent
of OEEC GNP).
What that model suggests is that the main
participating countries in a greenhouse-
abatement regime would submit for each
other's scrutiny and cross-examination plans
for reducing carbon emissions. The plans
would be accompanied by estimates of
emissions or emissions reduction from some
projected level, but any commitments un-
dertaken would be to the policies, not the
emissions. And not all of the plans would
necessarily be commitments.
The United States, for instance, could
present a plan for the introduction of a new
generation of nuclear power reactors begin-
ning sometime in the next century, but it is


### ---Economics-1992-0-15.txt---
difficult to see how the federal government
can commit itself to what reactors public
utilities will be purchasing 20 years from
now. The United States can have a plan to
mandate fuel-efficiency standards for auto-
mobiles, but it takes 10 years for the stan-
dards to work their way into the automobile
fleet, and there is no accounting procedure
that will estimate the effect on motor-fuel
consumption of any level of average fuel
efficiency a decade from now.
The current popular expectation is that
participation in any greenhouse regime will
take the form of commitments to specified
percentage reductions of emissions below
those of some specified year, like 1990 or
2000. I cannot help believing that adoption
of such a commitment is an indication of
insincerity. A serious proposal would spec-
ify policies, like taxes, regulations, and sub-
sidies and would specify programs (like re-
search and development), accompanied by
very uncertain estimates of their likely ef-
fect on emissions. In an international public
forum, governments could be held some-
what accountable for the policies they had
or had not put into effect, but probably not
for the emissions levels achieved.
Such a modest beginning will require
finding a way to sublimate the current inter-
national enthusiasm for a new universalist
greenhouse regime into institutional ar-
rangements that are helpful but noncom-
mittal when the U.N. Conference on Envi-
ronment and Development convenes next
June. This will require an understanding
among the developed countries that it is
initially up to them to find a way to mobilize
their populations in support of national
greenhouse policies.
Ix
A major commitment to financing emis-
sions abatement in the developing world is
surely too far away to need specific plans
now. A developing-world carbon-abatement
effort would, in principle, be altogether dif-
ferent from foreign aid as we have known it
since World War II. In principle it would all
be directed, from whatever sources and
through whatever channels, to protecting
that same global common. There would be,
for the first time, a single criterion: econo-
mizing carbon. In the abstract, aid recipi-
ents in the war on greenhouse gases would
not compete; they would not make India-
Pakistan comparisons, or Arab-Israel, or
Poland-Czechoslovakia. All would in prin-
ciple benefit equally from maximum carbon
conservation, wherever it could be achieved.
Trees may grow more rapidly, in carbon
content, in Madras or Szechuan or Borneo
or Alaska or South Carolina, but if someone
were willing to finance the growth of a tree
to absorb carbon dioxide, the citizens of
those states should not have the slightest
care where the tree were to be planted; they
all benefit solely from the carbon fixed in
the tree and benefit more, the faster the
tree grows, no matter where it grows.
It wouldn't work that way, of course.
Somebody gets the shade, or leases land for
the tree; and if it's not a tree but a nuclear
power plant to supplant coal, there are local
impacts that make huge differences, and
negotiations over sharing the cost differen-
tial between the coal and the nuclear plants.
But it is worth noticing that if there were a
"pure" carbon-abatement or carbon-absorb-
ing technology, one that accomplished noth-
ing else, there should be no dispute about
locating it wherever it would be most effec-
tive. That is new in foreign aid and foreign
investment.
If the developed countries ever manage
to act together toward the developing coun-
tries, their bargaining position is probably
enhanced by the fact that cleaner fuels and
more efficient fuel technologies bring a
number of benefits other than reduced car-
bon, and recipients of greenhouse aid will
be actively interested parties, not merely
neutral agents attending to the global atmo-
sphere. At the same time, large nations like
India and China will be aware of the extor-
tionate power that resides in ambitious
coal-development projects.
On a greatly reduced scale, there may be
something constructive to do more immedi-
ately. There is a huge difference between
transferring "technology" and transferring
capital goods that embody technology or,
going further, financing entire investments


### ---Economics-1992-0-16.txt---
(local construction, etc.) in which the tech-
nology is embedded. The difference in cost
is at least an order of magnitude. While the
developed countries are feeling their way
into some common attack on their own car-
bon emissions, a tangible expression of their
interest and an effective first step would be
to establish a permanent means of funding
technical aid and technology transfer for
developing countries, as well as research,
development, and demonstration in
carbon-saving technologies suitable to those
countries. Eventually the rural Chinese
household may cook more efficiently with
nuclear-powered electricity, but for another
generation or two what is important is less
carbon-wasteful ways of cooking and heat-
ing.
Maybe there is a role here for the carbon
tax. Western Europe, North America, and
Japan will be burning 3 or 4 billion tons of
carbon per year for the next decade. Taxing
themselves, that is, contributing in propor-
tion to the carbon they consume, at one,
two, or three dollars per ton, they could
contribute to a fund that might begin at $3
billion per year and grow to $10 billion. The
carbon tax is a little arbitrary here, and a
U.S. administration may be wary about a
precedent that carries over when the tax
rises an order of magnitude, but compared
with alternative criteria for sharing costs it
might not even be a bad precedent.
## Economics-1993-0


### ---Economics-1993-0-03.txt---
I. The Allocation Task of Yesteryear
Nearly two score years ago, on the occa-
sion of Columbia's bicentennial celebration,
Sir Dennis Robertson gave an address enti-
tled "What Do Economists Economize," the
burden of which was that, since presumably
economists are the most expert economiz-
ers, they should economize the most pre-
cious thing in the world, namely, love, or
altruism. This would be done in part by so
arranging things that in the ordinary con-
duct of life individual choices made on the
basis of self-interest in terms of market
prices would at least be consistent with max-
imizing social welfare, so that the exercise
of scarce resources of altruism could be
concentrated on situations where Adam
Smith's unseen hand could not be made to
serve. To me, one implication of this was
that economists should see to it that market
prices correctly reflect the relevant marginal
social cost of various alternatives. I have
devoted a major part of my career to the
promotion of such marginal-cost pricing, but
thus far with a notable lack of practical
success outside academia.
At the time of Robertson's address, in-
deed, there was a certain euphoria prevail-
ing among at least part of the economics
profession over the prospect of curbing the
business cycle and maintaining a high level
of economic activity through Keynesian fis-
cal policy. Under these circumstances it was
reasonable to think that the chief remaining
job of the economist was to assure a
Pareto-efficient allocation of a given aggre-
gate of resources. The event, however,
proved otherwise. The conventional wisdom
of regarding budget deficits as improvident
prodigality, and government debt as the
legacy of a craven deferral of burden to the
future, resumed command.
One eminent economist is said to have
remarked, in effect, that it was the function
of the science of public finance to see to it
that nothing of importance is ever done or
left undone merely for financial reasons.
Alas, the financial reasons have thus far
carried the day, and we have not had any-
thing approaching real full employment
since the Korean War, or indeed in peace-
time at any time since 1925, if then, at least
in terms of the Beveridge definition of full
employment as a situation wherein there
are at least as many unfilled job openings as
there are unemployed individuals seeking
work.
In the Eisenhower years, the conven-
tional wisdom held sway in spite of the
absence of serious contraindications to the
Keynesian prescription. In the 1960's, the
simple Keynesian analysis began to be called
into question by the emergence of stagfla-
tion, a phenomenon not contemplated by
the earlier Keynesian models. A new rela-
tionship, the Phillips curve, relating the
evolution of inflation to the level of unem-
ployment was added to the economists'
armamentarium, with its "non-inflation-
accelerating rate of unemployment" or
NIARU.
This NIARU is of course not a fixed
datum, but varies over time and place ac-
cording to the sociopolitical ambience, the
mechanics of the labor market, and the
vigor of competition. It may have been ris-
ing over time as a result of the increased
sophistication and differentiation of prod-
ucts, real and factitious, giving sellers, as
the ones most knowledgeable about the
characteristics of their products and their
markets, considerable leeway to raise their
prices without unacceptable loss of sales.
This process is ultimately held in check only


### ---Economics-1993-0-04.txt---
by the presence of underutilized labor and
other resources. Currently in the United
States the NIARU appears to be around
4-6 percent.
In some quarters this NIARU has even
been termed the "natural" rate of unem-
ployment, in one of the most vicious eu-
phemisms ever coined. Some have even gone
so far as to define "full employment" as
being the NIARU. But while 5-percent un-
employment might be barely tolerable if it
meant that everyone would be taking an
additional two weeks of vacation every year
without pay, it is totally unacceptable as a
social goal when it means unemployment
rates of 10, 20, or even 40 percent among
disadvantaged groups, with resulting in-
creases in poverty, homelessness, poor
health, drug addiction, and crime. Yet the
hard political fact is that at such a NIARU
the great majority of the voting population,
including most of the politically active up-
per and middle classes, will have relatively
little personal experience of severe unem-
ployment, while nearly everyone will have
some direct experience of inflation. Many
seem to feel that if only prices would stop
rising they would benefit correspondingly by
having their income go further, giving rela-
tively little thought to the effect on their
incomes. Even those with large mortgages
or other debts, who would actually gain
from inflation, tend to concur in the notion
that they suffer from it. It is thus extremely
difficult to get political support for anti-
unemployment measures that are perceived
as involving a threat of inflation, at least
until unemployment reaches 7 percent or
more, at which point unemployment be-
comes a more widespread threat.
Actually it is the uncertainty as to the
rate of inflation, and not its level, that does
the damage. An assured, moderate rate of
inflation can be adapted to by adjusting
nominal rates of interest and the terms of
long-term contracts involving money pay-
ments. The "menu cost" of changing price
tags and catalog quotations is probably less
important than the mental effort required
of consumers in forming an idea of what an
appropriate current price is for infrequently
purchased items, such as furniture or cloth-
ing. An inflation rate assured to stay be-
tween 5 percent and 6 percent, say, might
even have advantages. Monetary policy
would be more powerful in stemming a
downturn in that very low and even negative
real rates of interest would become feasible
as a stimulus to investment. It might in
principle be easier to keep inflation within a
1-percent range between 5 percent and
6 percent, than to keep it within a 2-percent
range between - 1 percent and + 1 percent,
given the smaller real value of non-
interest-bearing moneys in circulation, even
allowing for the superior political focusing
power of a target of 0 percent as compared
to one of 5.5 percent.
The base of the income tax would be
broadened also, making it possible to have a
tax that is more progressive and more pro-
ductive of revenue with lower marginal rates
and less of a distortionary effect. A tax
based on nominal accrued income would in
effect be a tax on a base consisting of real
income plus a percentage of net worth.
While this is not what is meant by an ideo-
logically pure income tax, in terms of its
practical effects it can be deemed a superior
tax.
It is the possibility of substantial changes
in the rate of inflation, either up or down,
that does the damage. Such changes involve
a disappointment of expectations and a re-
distribution of wealth and income derived
from a given national product that is capri-
cious and often inequitable, but it does not
of itself substantially reduce the amount to
be distributed. Unemployment, on the other
hand, directly and definitely reduces the
total product to be distributed. Unantici-
pated changes in the rate of inflation, up or
down, may be considered to be a form of
legitimized embezzlement, whereas unem-
ployment is vandalism.
Nevertheless, the stance of the politico-
financial establishment is still to look at the
bottom line as the ultimate reality, whether
of the corporation or the national budget,
and since money is the measure of all good
and evil in this kind of calculus, anything
that impugns the value of money is viewed
as a kind of sacrilege reinforced by a lurking
fear of starting down a slippery slope to


### ---Economics-1993-0-05.txt---
hyperinflation. We find the Federal Reserve
System poised to slam on the brakes at the
first sign of a resurgence of inflation, a
posture not calculated to inspire investment
in durable capital.
On the political side, we see the House
voting by a substantial majority in favor of a
constitutional amendment to require a bal-
anced budget, fortunately falling short of
the required two-thirds. This was done in
spite of the fact that the nominal budget as
currently computed is not a valid measure
of any significant economic quantity. The
nominal deficit would be reduced by selling
the Pentagon to a life insurance company
subject to a long-term lease-back and repur-
chase option; this at least would do no
harm, unlike the sale of natural resources to
private exploiters which would actually de-
crease the real heritage handed down to the
future, on the pretext of reducing the trans-
fer requirements embodied in the national
debt.
II. Recycling Savings Through Public
Capital Formation
From a classical standpoint, of course,
the difficulty is that no account is taken
of the distinction between transactions on
current account and on capital account. If
AT&T, General Motors, and households
had been constrained to operate under the
restrictions of the proposed balanced-budget
amendment, we would now have far fewer
telephones, automobiles, and houses. A
capital budget, with a vast expansion of
government capital outlays on roads,
bridges, research, education, and the like,
financed by borrowing, might go a consider-
able way toward improving the unemploy-
ment situation. But there is no assurance
that it could do the whole job.
III. Eliminating the Corporation Income Tax
Other classical approaches to improving
the unemployment situation exist but have
their own political opposition and in any
case are too weak to make much of a dent
in a very large need. One such measure
would be the abolition of the corporation
income tax, which is by far the most serious
hurdle in the way of private capital forma-
tion of a kind requiring equity funding. Un-
like the capital-gains tax, the corporate in-
come tax is a tax largely above or before the
market, requiring a rate of return on invest-
ment sufficient to cover the corporation tax
and leave a rate of return after tax compa-
rable to other investments, whereas the
capital-gains tax operates largely as a reduc-
tion in the return to the investor after or
below the market, comparable to the reduc-
tion of net income to the taxpayer resulting
from the personal income tax on other in-
come. In addition, the corporation tax
causes inefficient allocation of investment
between equity-type and loan-type invest-
ments; it encourages thin equity and result-
ing bankruptcies and reorganizations, and it
lubricates takeovers and mergers of dubious
intrinsic merit.
Reduction of the tax on capital gains, on
the other hand, might actually depress eco-
nomic activity if the additional savings out
of the tax reduction were to exceed the
additional capital formation induced. This is
the more likely in that most of the tax
reduction is likely to be saved immediately,
whereas the inducement to capital forma-
tion is in terms of a tax reduction in a
relatively remote future, subject to legisla-
tive vicissitudes. At best, special treatment
of capital gains greatly increases the com-
plexity of the tax law and diverts investment
flows from their most efficient use. There is
nothing to indicate that investments likely
to yield returns in forms defined by the tax
code as capital gains will have any superior
social value: gains from land speculation, in
particular, add nothing to the real availabil-
ity of resources.
As for the corporate income tax, in spite
of its many defects from the standpoint of
economic efficiency, it has enormous politi-
cal popularity due to the fact that nearly
everyone thinks that it is paid by someone
else. Indeed economists have differed widely
in their assignment of the "burden" of the
tax, owing to a failure to specify, or even to
consider, the macroeconomic policy changes
necessarily involved in a change in the tax.
Unlike most other taxes, the corporation tax


### ---Economics-1993-0-06.txt---
inflicts a double whammy on the economy
in that it both extracts income from the
stream of purchasing power and reduces the
recycling of savings through investment. If
imposed on a revenue-neutral basis it causes
unemployment, while if a budgetary adjust-
ment is made to maintain employment con-
stant, its burden can be thought of as falling
on future wage earners, who will have less
capital with which to work.
Problems of the deferral of income
through undistributed profits, as well as the
deferral of taxation to the time of realiza-
tion of capital gains, would ideally be met
by putting the personal income tax on a
cumulative basis, along lines I developed
while working with Carl Shoup in 1938,
whereby the deferral of the reporting of
income, by whatever means, merely involves
the borrowing of the deferred tax at a suit-
able rate of interest. About two-thirds of
the internal revenue code would become
redundant, with the possible exception of
the need to deal with the international jet
set and revolving-door marriages; large
numbers of tax techies would be able to
apply themselves to more productive em-
ployment.
Failing this, an approximation to a level
playing field might be had by imposing a
small annual tax on the accumulated undis-
tributed surplus of corporations, roughly
equal to the interest on the stockholders'
postponed individual income tax. Similarly,
there should be a surcharge on realized
capital gains, proportionate to the length of
time held, to offset the gain from the defer-
ral of the tax.
If there is nevertheless a need to cater to
a political demand for something that can
be labeled a corporation tax, this might be
satisfied by levying a corporation tax on
dividends, interest, and retained earnings at
a rate corresponding to the first-bracket rate
of the individual income tax and exempting
such interest and dividends from this "nor-
mal" rate, going back to the pre-1934 prac-
tice of dividing the income tax into a normal
tax and a progressive surtax. To even things
up neatly, normal tax paid on other forms of
income should be deductible in computing
the base for the progressive surtax paid by a
minority of taxpayers. It would still be ap-
propriate to have an undistributed surplus
tax to correspond to this surtax.
IV. Tax-Exempt Bonds
Another measure that might slightly im-
prove investment allocation would be to re-
place the exemption of interest on state and
local bonds by a taxable tax credit at a rate
that would maintain the market value of the
bonds. Low-bracket taxpayers would be lit-
tle affected, while the entire loss of revenue
to the Treasury would accrue as a subsidy to
the issuers. Upper-bracket taxpayers would
no longer have an incentive to invest in such
bonds rather than in riskier investments
more suitable to their status.
V. Taxing Imputed Income
A more important but politically more
difficult measure would be to require the
inclusion in taxable income of the rental
value of owner-occupied residences. This
would not only improve the equity and pro-
gressivity of the income tax but go a sub-
stantial way toward making more units
available for rental and, to a modest extent,
promoting the construction of additional
affordable rental housing and abating the
problem of homelessness. A similar case
can be made for including in the income tax
base a net rental value of nonbusiness auto-
mobiles (equal to interest on the market
value of the car), in this case reducing the
discrimination against the use of public
transit.
VI. Shifting Property Taxes from
Improvements to Land
A measure that could provide a powerful
stimulus to investment in property improve-
ments would be to replace part or all of the
property tax by a tax on land value only, a
proposal that can be traced all the way back
to Franqois Quesnay and the French phys-
iocrats but which is more recently associ-
ated with the name of Henry George. This


### ---Economics-1993-0-07.txt---
would remove the very serious deterrent
effect of the property tax on improvements.
Unfortunately from the standpoint of a na-
tional employment policy, this tax is largely
levied by local governments, which are often
constrained by constitutional provisions or
state laws. Nevertheless some means of
bringing pressure to bear on these govern-
ments to make this change might be found.
Some Pennsylvania governments are already
doing this. When levied for municipal pur-
poses, it might be appropriate to exempt
from the tax a flat amount per square foot
as representing the value of circumambient
agricultural land for which the urban gov-
ernment can claim no credit; this would also
mitigate discriminations at jurisdictional
boundaries.
It is perhaps worth noting that the signif-
icance of a government debt would be dras-
tically different in a community relying ex-
clusively on a land-value tax. Such a debt
would in effect be a collective mortgage on
the land, especially if it can be assumed that
land values in the community will vary pro-
portionately over time. Since the interest on
the community debt will generally be lower
than interest charged on individual mort-
gages, it can be in the general interest of all
the taxpayers of the community for the gov-
ernment to borrow as much as the market
will take, even to finance current outlays,
provided a suitable margin is left to deal
with emergencies. On the other hand such
debt financing performs no recycling of sav-
ings, there is no room for Keynesian fiscal
policy, and Ricardian equivalence is in full
sway. This does not detract, however, from
the powerful stimulating effect of a reduc-
tion in the tax on improvements.
VII. Limitations of "Supply-Side" Measures
Under current conditions, however, such
"supply-side" measures designed to operate
by reducing the cost of capital are likely to
be severely limited in their effect as long as
nearly all types of capital facilities are idle
or underutilized. Very little "widening" in-
vestment is likely to take place as long as
there is excess capacity in place. At most,
some "deepening" investment in new prod-
ucts or technologies may take place, or there
may be corners of the economy where rela-
tively rapid growth has kept capacity fully
utilized. Even in such cases, investment in
capital facilities may depend more on ap-
praisals of an uncertain market for the
product than on the cost of capital.
This is likely to be true not only of tax
policy but even more of monetary policy. In
any attempt to emerge from present rates of
unemployment even only down to the
NIARU within any reasonable time period,
monetary policy is likely to prove a weak
reed, sometimes aptly described as pushing
on a string. The main difficulty is that mon-
etary policy bears primarily on short-term
interest rates and credit availability and in
its usual practice does not directly control
long-term rates, which are the important
rates for most decisions involving real
durable capital formation. The posture of
the Federal Reserve System in holding itself
ready to slam on the brakes at the first sign
of resurgent inflation is poorly adapted to
bringing long-term rates down. It does not
appear that the Fed has either the will or
the resources to do enough about long-term
rates to do very much to increase capital
formation, especially when idle and under-
used capacity pervades much of the econ-
omy.
VIII. Savings Recycling by Government
This brings us inevitably around to fiscal
policy. Here it is necessary to stop thinking
of the conventional nominal budget deficit,
or even of a current-account deficit in a
budget drawn up in terms of distinguishing
capital and current-account items, and to
start thinking of fiscal policy in terms of its
role in recycling savings, in excess of what is
recycled by private investment, into the
stream of purchasing power. The conven-
tional wisdom seems to argue that increased
employment requires that the economy
grow, growth requires investment, and in-
vestment requires savings; therefore let's
encourage saving through IRA's, tax expen-
diture rather than income, and tighten our


### ---Economics-1993-0-08.txt---
belts to restore the economy to its normal
state of health.
It doesn't work that way. Savings are not
like a sack of potatoes which if not sold at
the current price will stay on hand and put
a downward pressure on the price until sold.
Savings not immediately taken up to create
capital simply vanish in reduced income,
without even exerting a downward pressure
on interest rates. If I yield to the allure-
ments of tax concessions to IRA's to the
point of not having my hair cut, this puts $8
more in my bank account, but $8 less in the
barber's account; there is nothing that makes
it any easier for anyone to obtain funds with
which to create capital, nor anything that
makes the prospect more attractive. As
Gertrude Stein remarked, "the money is
always there, it's the pockets that keep
changing." If the barber reacts by curtaling
his consumption, this further reduces na-
tional income and saving. I may succeed in
my attempt to save, but only by reducing the
saving of others by even more. Savings are
an extremely perishable entity. Say's law
fails as soon as part of the income gener-
ated in the process of producing the supply
is shunted off into savings that fail to get
converted into new capital goods.
On the other hand, if some genius invents
a new product or process and obtains a
credit or borrows the funds needed to fi-
nance the capital involved in its production,
this added real wealth is, ipso facto, some-
one's saving. Instead of Say's law, we have
"capital formation creates its own saving."
Similarly, if the government borrows funds
created by credit expansion and recycles
them into purchasing power through out-
lays, whether on current or capital account,
this creates both income out of which addi-
tional savings will be attempted and de-
mand that may induce the private invest-
ment to meet it.
Not all deficit financing, however, results
in recycling of savings, whether measured by
the current capriciously defined nominal
deficit or by a more rational definition in-
volving accounting for government assets.
We have seen that in a community relying
exclusively on a land tax, recycling does not
take place. Nor would the sale of the Pen-
tagon, or the purchase of an office building
currently being rented by the government,
offset by bond transactions, involve any
change in the level of recycling. Government
recycling is in principle the excess of those
government outlays that are regarded by
their recipients as income over those govern-
ment receipts that are regarded by their
payors as reductions in their disposable in-
come. Even this is subject to some caveats: if
government investment in a power plant, for
example, substitutes for investment that
would otherwise have been made by private
enterprise, there is no net recycling.
On the whole, however, recycling tends to
vary in rough correlation with the nominal
deficit, and the strength of the notion in the
minds of the public and their representa-
tives that deficits are bad and that the
"budget" should be balanced may make it
difficult to achieve an adequate level of
recycling. Some help in this respect may be
obtained by going to a capital budget sys-
tem, in which balance would be sought only
for the current-account part of the budget,
borrowing for the capital account being jus-
tified by comparisons with corresponding
private practices and by the thought that
future generations being burdened with the
debt would also reap benefits from the capi-
tal passed on to them. While this may con-
strain choice away from what rational voters
would have chosen as the optimal level of
government capital formation, there would
seem to be sufficient scope for government
capital investment to provide sufficient recy-
cling to bring about full employment, partic-
ularly if investments in education, research,
space exploration, and the like are consid-
ered eligible for treatment as capital invest-
ment. Some of these projects, even if they
would not stand scrutiny aside from their
function in justifying income recycling, may
nevertheless have the same kind of justifi-
cation as the building of the Egyptian pyra-
mids had for Keynes. On general welfare
grounds, one might well prefer recycling in
terms of borrowing to finance health care to
borrowing to finance space stations, but if
borrowing for health care is deemed to cre-
ate an ideologically sinful current-account
deficit, space stations it will have to be.


### ---Economics-1993-0-09.txt---
IX. The Need for Direct Inflation Control
Long before the economy reaches a really
satisfactory level of full employment, how-
ever, as employment gets to the NIARU
level, and inflation threatens to accelerate,
the Fed is likely to try to slam on the
brakes, and demands for a more stringent
budget balancing and cutback of "govern-
ment waste" are likely to be heard in the
halls of Congress. To get anywhere near a
satisfactory level of unemployment, some
method of dealing with inflation will have to
be devised. We are short of tools.
In effect, the economy can be thought of
as having three major parameters that we
would like to control: the level of employ-
ment of human and other resources, the
price level, and the division of the resulting
total product between provision for current
wants and investment in growth and the
future. At the same time, we have only two
major policy tools: monetary and fiscal pol-
icy. In an era when inflation was not a
threat, one could think of these two tools as
controlling the level of employment and the
rate of growth, with low interest rates com-
bined with a deficit or surplus sufficient to
maintain full employment leading to high
investment and growth, and conversely.
However, with a need to control inflation as
well, relying on only two dimensions of con-
trol is like trying to fly an airplane without
ailerons, which were the third dimension of
control that was the key to the success of
the Wright brothers. A new tool is needed.
Over the past three decades a number of
proposals for direct control of inflation have
been made, but none has achieved general
acceptance. Wartime control of specific
prices, accompanied by rationing, was ac-
cepted as an emergency measure and
worked in part because of patriotic willing-
ness to conform and in part because, being
temporary, past prices could be continued
without becoming absurd. As a perma-
nent scheme this is probably unworkable
and certainly unacceptable. More recent
schemes have involved tax incentives of
various kinds to provide a countervailing
downward pressure against the inherent
inflationary tendency of an imperfectly
competitive system. Such schemes have
generally suffered from difficulties in mea-
suring price changes at an individual-firm
level, capriciousness of results when tied to
such taxes as the corporation income tax,
and possible time lags in adjusting the
strength of the incentives to changing cir-
cumstances.
X. Market-Based Inflation-Control Plans
A few years ago David Colander came to
visit me and reported on a proposal by
Abba Lerner for a market in rights to raise
prices. Those wishing to raise their prices
would be required to purchase the right
from those prepared to lower their prices,
thus assuring a constant overall price level.
While this neatly circumvents the problem
of adjusting the strength of incentive to
changing inflationary pressures, the prob-
lem remains of how to measure price
changes in the face of quality changes, new
products, and variations in the terms of sale
such as delivery, reliability, service, credit
terms, tie-in sales, and the like.
More pregnant was the question of how
to deal with cases in which prices paid to
suppliers have risen. A somewhat similar
problem arises with gross receipts taxes,
which discriminate in favor of vertically in-
tegrated operations and against situations in
which the product passes through several
hands on the way to the market. In Europe
this problem has been solved by shifting
from gross receipts taxes and retail sales
taxes to value-added taxes, which immedi-
ately suggests that instead of a market in
rights to raise prices we have a market in
rights to value added.
XI. Control with Marketable Gross
Markup Warrants
For semantic reasons I have chosen to
speak in terms of "gross markups" rather
than value added, as being more suggestive
of something to be restrained rather than
promoted. In principle, gross markups sim-
ply refers to the excess of sales revenue over
amounts paid for nonprime inputs. In oper-
ation, warrants for gross markups for a


### ---Economics-1993-0-10.txt---
prospective accounting period would be is-
sued to each firm on the basis of the gross
markups for a corresponding preceding pe-
riod, plus or minus adjustments for changes
in prime inputs such as labor and invested
capital. These warrants would be issued in
sufficient total face value to correspond to
the value at a desired price level of the
output expected to be produced by the in-
puts against which the warrants were issued.
They would be freely tradable for cash in a
competitive market, and if at the end of the
accounting period a firm is found to have
retained or acquired fewer warrants than
the actual amount of its gross markups for
the period, a penalty tax would be assessed.
This tax would not be a substantial source
of revenue, but would serve merely as an
enforcement device. It could be set at a
level fairly certain to be higher than the
market price of the warrants.
Adjustment of the warrant issue for
changes in investment could be made simply
on the basis of a uniform percentage of
such change. Adjustment for changes in em-
ployment is somewhat more difficult: a flat
amount per employee or man-hour takes
too little account of variations in qualifica-
tions, while to allow adjustments equal to
payrolls would run a danger of allowing
inflationary wage increases. Some formula
such as a percentage of payrolls plus a flat
amount per employee might be satisfactory;
such a formula would involve a certain bias
in favor of the employment of low-skill la-
bor, which may be considered desirable in
view of the fact that this is where the unem-
ployment problem is most serious.
Administration would seem to pose no
insurmountable problems. Determination of
gross markups is essentially no different than
the assessment of a value-added tax such as
is widespread in Europe. Adjustment for
investment can be made on the basis of
accounts already needed for income-tax
purposes, while adjustments for employ-
ment can be related to the social-security
records. Some special methods may have to
be developed for dealing with the self-
employed and very small firms, and possibly
some classes of firms could be excluded
from the scheme, as is sometimes done with
the value-added tax.
XII. Prospects for Rapidly Reaching
Genuine Full Employment
With such a scheme in place, what can we
plan for in terms of getting from where we
are to full employment? Currently unem-
ployment is reported as about 7.5 percent,
and full employment can be reckoned at
about 1.5 percent, giving a slack to be made
up of 6 percent. Using Okun's ratio of per-
centage change in GNP to percentage
change in reported unemployment of 2.5,
we have a slack of 15 percent to be made
up. If this slack can be taken up within two
years, this will be 7.5 percent per year; if to
this we add 2.5 percent for growth in the
labor force and in productivity, we get 10-
percent annual growth in GNP over two
years. After two years, we hit the full-
employment ceiling, and growth thereafter
will be limited to the labor force and pro-
ductivity factor, possibly between 2 percent
and 4 percent.
Is public finance up to the job of reaching
the goals thus defined in terms of the limits
of our real resources? Possibly, but it re-
quires breaking new ground. One would
have to begin with increasing government
recycling as rapidly as possible by 8-10 per-
cent of GNP in order to inaugurate the
1.0-percent growth rate. How rapidly this
could be done would of course depend on
the political and legislative ambience. From
some points of view the fastest and easiest
way to do this is by tax cuts. Unfortunately,
if tax cuts are temporary they tend to be
viewed as windfalls to be saved rather than
spent, so that only part of the tax cuts are
effectively recycled. Alternatively, if not an-
nounced as temporary, tax cuts tend to cre-
ate a resistance to later tax increases called
for by full-employment conditions and large
debt-service requirements. This is especially
threatening in the present context of politi-
cal campaigning on the basis of promises of
no new taxes. Perhaps the best tax cut would
be a cut in the payroll taxes, as promising
the maximum proportion of recycling, if this


### ---Economics-1993-0-11.txt---
can be done in the face of outcries that this
would be jeopardizing the financial sound-
ness of the social-security system.
Outlays on actual programs, on the other
hand, are somewhat harder to start and
stop rapidly. There is also the need not to
get too far ahead of the effective operation
of whatever anti-inflation program is put in
place, whether the program of gross markup
warrants proposed above or some other, lest
anticipatory speculation and inflation get
out of hand. The exact program for the
start-up period will require careful study.
What happens after the first few months
will depend to a large extent on what Keynes
called the "animal spirits" of the financial
community. At one extreme there could be
such horror and alarm at the violation of
the conventional wisdom concerning the
sinfulness of deficits as to produce a
widespread hibernation and flight to foreign
shores. More likely, once the financial com-
munity has become convinced of the seri-
ousness of the administration's purpose to
bring about full employment, and once it is
anticipated that demand will shortly use up
the spare capacity of existing productive
facilities, private capital formation may pick
up to the point of absorbing and recycling
individual savings sufficiently so that gov-
ernment recycling may for the time being
become unnecessary. At the same time, gov-
ernment revenues from increased GNP will
increase and outlays for unemployment in-
surance and welfare will decrease. Also,
there may be a need to shut down those
governmental programs that compete for
real resources with private capital forma-
tion, in order to avoid a real "crowding out"
(as contrasted with the financial crowding
out alleged to occur as a result of govern-
ment borrowing associated with a tax cut).
As a result, a brief period of budget balance
or even of surplus may become appropriate.
As the economy hits the ceiling of full
employment, however, still another transi-
tion becomes necessary. For a while capital
formation may continue on its momentum,
recycling savings but producing excess ca-
pacity that either cannot find labor with
which to operate or cannot find markets in
which to sell its product. Within a short
time after hitting the full-employment ceil-
ing, capital formation will have to drop from
that appropriate to a 10-percent growth rate
to that suited to a far slower growth rate. At
this point attempted savings may again ex-
ceed what can be absorbed by private capi-
tal formation, even at very low rates of
interest. Other ways to recycle the excess
will again become necessary, one of which
will be renewed government recycling.
XIII. Long-Term Excess of Demand Saving
over Private Investment
There is, indeed, no principle of eco-
nomics that says that there will always be a
feasible rate of interest that will equate
desired savings and private capital-forma-
tion under conditions of steady full employ-
ment. Current trends seem to be such as to
make such a possibility unlikely. One factor
has been a spate of capital-saving innova-
tions and practices. Fiber optics, when fully
utilized, costs less per unit of service than
previous technologies by orders of magni-
tude, leaving ductways planned for copper
conductors forever surplus; electronic ex-
changes occupy a fraction of the space
formerly required by equivalent electro-
mechanical exchanges; just-in-time practices
reduce investment in inventory; improved
communications enable more freight to be
carried on a single track line with sidings
than was formerly carried by a full two-track
line; a man assembling electronic gear with
a soldering iron uses far less capital than
the man in the pulpit of a rolling mill, and
service industries generally use less capital
per employee than manufacturing, mining,
or transportation.
Moreover, before gross investment can
begin to recycle private savings, it must first
recycle funds set aside in depreciation,
amortization, depletion, and obsolescence
charges, while rapid obsolescence due to
accelerating technological progress makes
capital formation relatively insensitive to
changes in interest rates. Very low or nega-
tive interest rates may stimulate investment
in nondepreciating assets such as land, but


### ---Economics-1993-0-12.txt---
even this is limited by the possibility that
speculative bubbles may burst, and in any
case relatively little recycling is produced
thereby, except to the extent that the en-
hanced asset values cause owners to feel
wealthier and spend more.
On the savings side, increased longevity
and the high cost of old-age illness lead to
increased savings through funded pensions
and other provisions for retirement. For this
purpose, the lower the rate of interest, the
greater is the amount of current savings that
must be put aside to provide a given level of
retirement security. More recently the in-
creased concentration of income among the
very wealthy, who have a high propensity to
save, not so much for eventual consumption
but largely to accumulate chips with which
to play financial games and exercise eco-
nomic power, has further added to the sav-
ings-recycling problem. Some recycling may
take place through investment abroad, re-
flected in a positive trade balance and the
production of goods for export, though it is
uncertain how far this can be carried in the
face of political instability, the danger of
creating repayment problems, and the resis-
tance of foreign governments that do not
have an effective full-employment policy of
their own to our exporting our unemploy-
ment to them in this way.
On balance, it may prove impossible, for
the foreseeable future, to maintain a steady
state of genuinely full employment without
a substantial amount of government recy-
cling of savings, a chronic budget deficit,
and a long-term increasing trend in the na-
tional debt, however distasteful this may be
to those ideologically addicted to a bal-
anced budget. It may even prove necessary
for the debt to grow at a rate faster than the
growth of GNP. The burden of servicing
this debt might be kept within bounds by
reducing real interest rates, close to zero if
need be, though this might imply a higher
level of private investment than would be
chosen on its own merits. Even contemplat-
ing such prospects calls for a significant
expansion in our range of habitual thought.
XIV. The Task Before Us
This, then, is the challenge I lay before
the economics profession. There is no rea-
son inherent in the real resources available
to us why we cannot move rapidly within
the next two or three years to a state of
genuinely full employment and then con-
tinue indefinitely at that level. We would
then enjoy a major reduction in the ills of
poverty, homelessness, sickness, and crime
that this would entail. We might also see
less resistance to reductions in military ex-
penditure, to liberalization of trade and im-
migration policy, and to conservation and
environmental protection programs.
I lay before you a plan I believe can
accomplish this. It involves government re-
cycling of excess savings plus a method of
keeping inflation under control. I believe it
can do the job while preserving the essen-
tials of a free-market system. There may be
some details to be worked out, but I am
confident that the basic concept is sound
and workable.
We simply cannot carry on as we have
been doing without falling apart as a com-
munity and losing what is left of our status
of world leadership. If you don't think that
something like this can be made to work,
then it is up to us to get together to find
something that will. Otherwise, if we con-
tinue to tie our hands with financial shibbo-
leths and models that tacitly assume a fixed
total of resource utilization, we are no bet-
ter than the feckless castaway whose contri-
bution to the solution of the problem of
dealing with cases of canned goods was "let's
just assume we have a can-opener."
## Economics-1994-0


### ---Economics-1994-0-03.txt---
Forty years ago economists discovered the
"residual." The main message of this litera-
ture, that growth in conventional inputs
explains little of the observed growth in
output, was first articulated by Solomon
Fabricant in 1954 and emphasized further
by Moses Abramovitz (1956), John Kendrick
(1956), and Robert Solow (1957).1 The pio-
neers of this subject were quite clear that
this finding of large residuals was an embar-
rassment, at best "a measure of our igno-
rance" (Abramovitz, 1956 p. 11). But by
attributing it to technical change and other
sources of improved efficiency they turned
it, perhaps inadvertently, from a gap in our
understanding into an intellectual asset, a
method for measuring "technical change."
Still, it was not a comfortable situation, and
a subsequent literature developed trying to
"explain" this residual, or more precisely, to
attribute it to particular sources (Griliches
1960, 1963a,b, 1964; Edward Denison, 1962;
Dale Jorgenson and Griliches, 1967). The
consensus of that literature was that, while
measurement errors may play a significant
role in such numbers, they could not really
explain them away. The major sources of
productivity growth were seen as coming
from improvements in the quality of labor
and capital and from other, not otherwise
measured, sources of efficiency and techni-
cal change, the latter being in turn the
product of formal and informal R&D in-
vestments by individuals, firms, and govern-
ments, and the largely unmeasured contri-
butions of science and other spillovers. The
prescription of additional investments in ed-
ucation, in science, and in industrial R&D
followed from this reading of history as did
also the hope and expectation that the re-
cently observed rates of "technical change"
would continue into the future.
This general view of the sources of growth
was put into doubt by the events of the
1970's and 1980's. Beginning in 1974 (or
perhaps already in 1968) productivity growth
slowed down significantly in the United
States and abroad, and it has not fully re-
covered yet, at least as far as national aggre-
gates are concerned. The many explanations
that were offered for these events were not
very convincing (see e.g., Denison, 1979;
Martin Baily and Robert Gordon, 1988;
Griliches, 1988). As time went on and the
direct effects of the energy-price shocks
wore off but the expected recovery did not
come or came only weakly, more voices
were heard arguing that the slowdown might
not be temporary; that the energy-price
shocks just revealed what was already there
-a decline in the underlying trend of tech-
nical change in the world economy; that the
growth opportunities that had opened up in
the late 1930's and had been interrupted by
World War II have been exhausted, reflect-
ing perhaps the completion of an even
longer cycle, going back to the beginnings of
this century (see e.g., Alfred Kleinknecht,
1987; Gordon, 1993a). Even more omi-
nously, the slowdown was blamed on dimin-
ishing returns to science and technology in
general and the onset of widespread socio-
economic sclerosis (see e.g., William Nord-
haus, 1972, 1989; Mancur Olsen, 1982;


### ---Economics-1994-0-04.txt---
F. M. Scherer, 1983, 1986; Robert Evenson,
1984; Baily and A. K. Chakrabarti, 1988).
This is a rather pessimistic view of our
current situation, and I would like to argue
that the observed facts do not really support
it. But that will not be easy, both because
some of the "facts" are contradictory and
because our measurement and observa-
tional tools are becoming increasingly inad-
equate in the context of our changing econ-
omy. Nevertheless, I will review some of the
evidence for such views and argue with their
interpretation. There are several possibili-
ties here: (i) this view is true and that is sad;
(ii) it is not true and recovery is around the
corner if not already underway; (iii) it may
be true, but whatever is or is not happening
has little to do with diminishing returns to
science or industrial R&D. Or, (iv) it may
be that we just do not know. As is the case
with global warming, we may not have an
adequate understanding of the mechanisms
producing growth or adequate data to adju-
dicate whether there has or has not been an
underlying trend shift. If that is true, as is
most likely, the question arises as to why we
don't know more after years of research
done by so many good people. What is it
about our data and data acquisition struc-
ture, and possibly also our intellectual
framework, that prevents us from making
more progress on this topic?
In discussing this range of topics, I will
concentrate primarily on the R&D compo-
nent of this story-not because it can ex-
plain much of the productivity slowdown (it
cannot), and not just because this is where I
have done most of my recent work, but
because it illustrates rather well the major
point I want to make here tonight: that our
understanding of what is happening in our
economy (and in the world economy) is con-
strained by the extent and quality of the
available data. I will also allude briefly to
similar issues which arise in interpreting the
productivity contribution of computers in
the economy. Parallel tales about data con-
straining our understanding could also be
told about other potential productivity-
slowdown villains: energy-price shocks, in-
sufficient investment in'physical capital, and
possible declines in human-capital invest-
ments. Having reached the verdict of "not
proven," largely on account of insufficient
evidence, I shall make a number of more
general remarks on the state of our data
and the possible reasons for it. The major
message that I will be trying to convey is
that we often misinterpret the available data
because of inadequate attention to how they
are produced and that the same inattention
by us to the sources of our data helps ex-
plain why progress is so slow. It is not just
the measurement of productivity that is af-
fected. Other fields of empirical economics
are also struggling against the limitations
imposed by the available data. Great ad-
vances have been made in theory and in
econometric techniques, but these will be
wasted unless they are applied to the right
data.
I. The "Facts"
There are three sets of "facts" to look at:
what has happened to productivity, what
has happened to investment in R&D and
science, and what has happened to the rela-
tionship between them. Sometime in the
late 1960's measured productivity growth in
the United States started to slow down.
After a mild recovery in the early 1970's,
the world economy was hit by two succes-
sive oil-price shocks which dropped eco-
nomic growth rates in most of the devel-
oped economies to levels significantly below
those experienced in the 1960's and early
1970's. While the effects of the oil-price
shocks wore off and real energy prices de-
clined to close to their earlier levels, pro-
ductivity growth rates did not recover much.
At this point, and also somewhat earlier,
many observers started wondering whether
something more fundamental than just an
energy-price-shock-induced business cycle
was afoot. Standing in the early 1980's and
looking back at the recent past, one would
have observed a decline in total patents
granted in the United States beginning in
the early 1970's and a decline in the share
of GNP being devoted to industrial R&D
starting in the mid-1960's, the timing look-
ing suspiciously appropriate for declining
productivity growth rates 5-10 years later.


### ---Economics-1994-0-05.txt---
One could also see a continuous and worri-
some decline in the number of patents re-
ceived per corporate R&D dollar (see be-
low). But there were also many other events
clouding this picture, making one wonder
whether faltering R&D and scientific efforts
are really the culprits behind our current
woes.
A number of discordant facts are impor-
tant for an understanding of what hap-
pened. First, the productivity-growth de-
cline in many other countries was larger,
absolutely, than in the United States, and
there it was not associated with declines in
R&D investment.2 Second, as illustrated in
Figure 1, the sectors where the productivity
slowdown has persisted in the United States
are largely outside of manufacturing, com-
munications, and agriculture (see Gordon,
1987). Besides mining and public utilities,
which were affected more specifically by the
energy-price shocks, it has lingered particu-
larly in construction, finance, and other ser-
vices where output measurement is notori-
ously difficult. Third, the decline in patent
grants in the 1970's was just a bureaucratic
mirage, an example of fluctuations induced
by changes in the data-generating process (a
budgetary crisis in the Patent Office) rather
than a reflection of the underlying activity
itself.3 The number of patent applications
did not decline significantly during this pe-
riod, but also it did not grow. The latter
fact, coupled with a continuous upward
growth in the absolute level of company-
financed R&D, resulted in a persistent de-


### ---Economics-1994-0-06.txt---
cline in the patents per R&D ratio in the
United States (and also in most of the other
countries for which we have data). This
raised the specter of diminishing returns to
R&D and offered the hypothesis of "ex-
haustion of inventive opportunities" as a
potential explanation for the productivity
slowdown.
This hypothesis has been examined re-
cently by various authors. There are basi-
cally two styles of analysis: one focuses di-
rectly on the link, if any, between R&D and
productivity growth (see e.g., Griliches,
1986a; Bronwyn Hall, 1993; Scherer, 1993),
while the other uses patents as indicators of
the output of the R&D effort and looks at
what has happened to the "knowledge-
production function" (see e.g., Griliches,
1990; Ricardo Caballero and Adam Jaffe,
1993; Robert Evenson, 1993; Samuel
Kortum, 1993). The bridge that is missing
between these two approaches would exam-
ine the units in which patents affect produc-
tivity growth and ask whether they have
stayed constant over time. Without such
constancy, no clear interpretation is possi-
ble.
II. Productivity Growth and the Role of R&D
In parallel to the aggregate "residual"
literature, a more micro-oriented approach
had developed. It took the study of techni-
cal change, diffusion, and the role of formal
R&D as its main challenge, with the hope
of bringing more of it within the realm of
economic analysis, helping thereby also to
explain some of this residual away. Using
modern language, one can interpret Edwin
Mansfield's and my own early work on dif-
fusion and on the role of R&D in agricul-
ture and manufacturing as trying to endoge-
nize as much of technical change as was
possible (Griliches, 1957, 1958, 1964;
Mansfield, 1961, 1965). Other important
contributors to this literature were Richard
Nelson, Scherer, Jacob Schmookler, and
Nestor Terleckyj. By expanding the notion
of capital to include also R&D capital and
estimating its effects, this literature docu-
mented the contribution of public and pri-
vate investments in R&D and their spillovers
to the growth of productivity.4 But the mag-
nitude of the estimated effects was modest,
not enough to account for the bulk of the
observed residual or the fluctuations in it
(Griliches, 1988). The experience here was
similar to other attempts to account for the
residual, such as using "embodiment" theo-
ries to magnify the potential effects of capi-
tal accumulation (Denison, 1962; Nelson,
1962) or looking for increasing returns to
scale (Griliches and Vidar Ringstad, 1972).
These various effects are real and nonnegli-
gible, but not large enough.
There is one other way of trying to make
something more out of the R&D story: the
possibility that the productivity impact of
R&D has declined over time-that the co-
efficients have changed. This hypothesis has
been investigated repeatedly by a number of
researchers with mixed results. Studies that
used data through the 1970's and early
1980's found no decline in the relevant co-
efficients. More recent studies that analyze
data through the late 1980's report more
mixed results, varying strongly with how the
computer industry and its deflator are han-
dled in the analysis.5 At the same time, the
stock market's valuation of R&D fell signif-
icantly, both in terms of ex post returns to



### ---Economics-1994-0-07.txt---
R&D in the 1980's (Michael Jensen, 1993)
and the market's view of current R&D in-
vestments (Bronwyn Hall and Robert Hall,
1993; B. Hall, 1993).
My own recent foray into this type of
analysis of industry data at the three-digit
SIC level is summarized in Table 1.6 It
reports estimates from regressions of growth
rates in total factor productivity (TFP)
on the rate of investment in R&D (the
R&D-sales ratio), where the estimated co-
efficient can be interpreted as the excess
gross rate of return to R&D (Griliches,
1979). The earlier 1958-1973 period yields
an estimate on the order of 0.33, while the
estimate for the later 1973-1989 period even
rises a bit, to 0.36. So far, so good! But
when one excludes the outlier computer
industry (see Fig. 2) the estimated coeffi-
cient falls from 0.36 to 0.13 for 1973-1989
and even lower for 1979-1989. Only one
observation out of 143 does this!7
These results raise a major data conun-
drum: is it right to treat the computer in-
dustry as an outlier and exclude it from
such calculations just because the productiv-
ity measure may be better there? It is quite
possible that if other technologically ad-
vanced industries (such as instruments,
communications equipment, and pharma-
ceuticals) had their price indexes adjusted
in a similar fashion, Figure 2 would look
much better, with the computer industry not
being as much of an outlier and with the
whole period showing much higher (social)
returns to R&D. That this is indeed the
case can be seen in Figure 3, where only
three such adjustments are made, but be-  


### ---Economics-1994-0-08.txt---
fore I discuss it, I need to digress briefly
and remind you about the developments in
computer price measurement.
Quality change is the bane of price and
output measurement. Until 1986, computer
prices were treated as unchanged in the
national income accounts. It took 25 years
for the recommendations of the Stigler
committee (Griliches, 1961; National Bu-
reau of Economic Research, 1961) to have a
noticeable effect on official practice, but
when they did, they did it with a bang! In
1986 the Bureau of Economic Analysis
(BEA) introduced a new computer price
index, based on hedonic regression meth-
ods, into the national accounts and revised
them back to 1972 (Rosanne Cole et al.,
1986).8 This index was falling by about 15
percent per year or more (as compared to
the assumed value of zero before), and that
had several major implications, including
the fact that it made the apparent recovery
in manufacturing productivity in the 1980's
much stronger, about one-third of the total
coming from the introduction of this price
index alone (Gordon, 1993b).
There was nothing wrong with the price
index itself. It was, indeed, a major advance,
and the BEA should be congratulated for
making it, but the way it was introduced
created some problems. First, it was a
unique adjustment. No other high-tech
product had received parallel treatment, and
thus it stuck out like a sore thumb. This had
the unfortunate consequence that the pro-
ductivity growth in the computer industry
itself was seriously overestimated, because
some of its major inputs, such as semicon-
ductors, were not similarly deflated. Second,
it was introduced into a framework with
fixed weights, wrecking havoc on it. Using
fixed 1982 weights and a sharply falling price
index implied the absence of a "real" com-
puter industry in the early 1970's and a very
rapid growth in its importance, leading to a
more than doubling of the share of machin-
ery in total manufacturing output by the

late 1980's. This last problem has largely
been solved recently with the introduction
of "benchmark-weighted" estimates of gross
domestic product (GDP) and the moving
away from fixed-weights national income ac-
counting (Allan Young, 1992). But the first
problem, the uniqueness of this adjustment
in the face of similar, though perhaps not as
extreme, problems elsewhere remains to
haunt us.
What I have done in Figure 3 (and in row
3b of Table 1) is to adjust the estimated
TFP growth in the computer industry down-
ward by deflating materials purchases in
this industry, which to a significant extent
consist of purchases of other computer com-
ponents and semiconductors, by the same
output price index. I have also substituted a
similar price index in the semiconductors
(electronic components) industry and also
adjusted the growth of TFP in the phar-
maceuticals industry upward to reflect the
exclusion of price declines due to the intro-
duction of generics in the current measure-
ment procedures. (I shall come back to
discuss this last adjustment later on.) So
adjusted, Figure 3 does not look all that

### ---Economics-1994-0-09.txt---

bad, and row 3b in Table 1 indicates no
decline in the R&D coefficient even without
the computer industry.
What is one to make of these conflicting
stories? It seems that the observed decline
in the R&D coefficients did not begin seri-
ously until the latter half of the 1970's, with
the second oil-price shock and the rise in
the dollar exchange rate. The abruptness of
the decline argues against a "supply-side"
explanation in terms of exhaustion of inven-
tive opportunities. It is more likely that the
peculiar aggregate shocks of that time went
against R&D-intensive industries: first, be-
cause they hit energy-intensive industries
such as chemicals and petroleum refining
more severely; and second, because the sub-
sequent rise in value of the dollar and the
expansion in imports that followed hit some
of the more high-tech R&D-intensive indus-
tries even harder, leading to declines in
"competitiveness," losses of rents, and the
appearance of excess capacity. The subse-
quent rise in the R&D coefficients (if it did
in fact occur), the rise in corporate R&D
investments through most of the 1980's, and
the rise in patenting in, the late 1980's (as
we shall see), all argue against interpreting
these coefficient movements as reflecting
"real" declines in the once and future
"potency" of R&D. What did happen,
though, was a sharp widening of the differ-
ential between social and private returns to
R&D. The internationalization of R&D, the
rise in the technical and entrepreneurial
skills of our competitors, and the sharp rise
in the dollar exchange rate in the mid-1980's,
all combined to erode, rather rapidly, the
rents accruing to the earlier accumulated
R&D capital and to the technical-expertise
positions of many of our enterprises. This
rise in the rate of private obsolescence and
the fall in the "appropriability" of R&D led
to sharp declines in both profitability and
real product prices. The latter, if they were
actually reflected in the appropriate price
indexes, would show up as an increase in
productivity, rather than a decline.
Before accepting this inconclusive verdict,
one still has to face the evidence of declin-
ing patent-to-R&D ratios. Figure 4 plots
domestic patent applications divided by to-
tal company-financed R&D expenditures in
U.S. industry (in 1972 dollars) and by the
total number of scientists and engineers in
industry. Looking at the right half of this


### ---Economics-1994-0-10.txt---
plot (the last couple of decades) we see a
more or less continuous decline with a small,
but possibly significant, turnaround in the
late 1980's. Similar trends can be seen also
in other countries, even in Japan (Evenson,
1991). But before one takes this as an indi-
cator of our recent problems, one should
glance also at the left side of this figure,
which goes back to the early 1920's. How
long has this been going on? This ratio
keeps falling, both through good times
(while productivity growth rates were rising)
and bad times. If this was not a cause for
worry earlier, why should one worry about it
now?9
III. Patents: A Shrinking Yardstick?
To decide whether we should be worried
by what is happening with the patent num-
bers we need to know what they measure.
Since I have discussed this at some length
elsewhere (Griliches, 1990), I will make only
two points here. First, the interpretation of
Figure 4 need not be pessimistic. Its mes-
sage may not be what meets the eye. And,
second, the meaning of both the numerator
and the denominators of the ratios plotted
in Figure 4 may have changed significantly
over time.
If patents can be taken as indicators of
invention, and if the value of an invention is
proportional to the size of its market (or
economy), then the fact that their total
numbers remained roughly constant over
long time periods is consistent with nonde-
clining growth rates of output and overall
productivity.10 If inventions are "produced"
by a combination of current R&D and the
existing state of knowledge (incorporating
the accumulated effects of science and
spillovers from the previous research activi-
ties of others), and if R&D is invested ap-
proximately "optimally," then under rea-
sonable assumptions, a rise (or fall) in the
underlying knowledge stock will affect them
both in parallel fashion and will leave their
ratio unchanged.1" There will be, therefore,
no evidence in this ratio on the underlying
state of the "stock of knowledge." More-
over, it will be declining with growth in the
size of the market, since a rise in the value
of inventions will push R&D up until pres-
ent costs equal again the present value of
future (private) returns.
The rate of growth of domestic patents
was close to zero during the last three
decades. That by itself should not be worri-
some. If their average value had been grow-
ing at the same rate as the economy as a
whole, there would be no reason for us to
worry about it. But there were long periods
when the actual numbers were worse than
that. During 1965-1985 the number of do-
mestic patent applications declined by - 0.6
percent per year while company-financed
R&D expenditures were growing by 4.8 per-
cent per year, in constant prices. But a
negative growth rate in the number of in-
ventions and a positive one in R&D are
inconsistent with an unchanging inventions
production function, unless the overall pool
of available knowledge is declining, or more


### ---Economics-1994-0-11.txt---
likely, unless the relationship between in-
ventions and the number of patents applied
for has been changing.
The suspicion that the relationship be-
tween the number of patents and the num-
ber of inventions (weighted by their relative
economic importance) has been changing is
not new. Schmookler (1966) stops most of
his analysis with pre-World War II data,
believing that the meaning of the patent
statistics changed at that time. What needs
to be reconciled in the data is the sharp
contrast between the rapidly growing R&D
series during 1953-1968 (and earlier) and
the essentially flat patent series. There are a
number of not mutually exclusive possibili-
ties here:
(i) The fast-growing R&D expenditures,
fueled by the new global opportunities
that opened up in the post-World War
II period, were being invested in face
of rapidly diminishing returns.
(ii) Some of the observed growth in R&D
could be spurious, the result of reclas-
sification of informal technological ac-
tivities into formal R&D under the
pressure of tax accountants, public-
relations experts, and R&D tax credits.
(iii) The rise of formal R&D-based inven-
tion crowded out smaller, less valuable
individual-inventor-based patents, while
the rise in the cost of patenting (in
terms of the time costs of dealing with
the patent system) and the more recent
sharp rise in fees may have selected out
a large number of potentially low-val-
ued patents. Given the evidence that
the value distribution of inventions and
patents is extremely skewed, with only
a small fraction having a high present
value, such a crowding out could raise
average values significantly, though the
required rate is rather on the high
side.12  It is also likely that the threshold for what
is patentable has risen, given the large in-
flux of foreign patent applications into the
U.S. system all impinging on a relatively
slow-growing and budget-constrained pat-
ent office.'3 On the other hand, the legal
status of patents in the United States has
improved significantly with the creation of a
special patents court, driving up the ex-
pected private value of a patent. Given the
presence of so many opposing forces, there
is no compelling need to reply on the
exhaustion-of-inventive-opportunities hy-
pothesis, especially since patents-to-R&D
ratios were falling much more drastically
during the "good times" of the past than
recently.14 Moreover, if we do take these
numbers seriously, then good news is just
around the corner: domestic patent applica-
tions have risen sharply in the last five years
(see Fig. 5), implying a potential resurgence
in the rate of technological change. This
leaves us, however, more or less where we
started, with the productivity slowdown
largely unexplained.

### ---Economics-1994-0-12.txt---

IV. Why Is the Glass Half-Empty?
Economists have not been very successful
in explaining what has happened to the
economy during the last two decades, nor
have they been able to agree on what should
be done about it. I will argue that data and
measurement difficulties may in fact be a
major source of this failure. This point will
be made not to provide us with an alibi, but
rather to temper the pretentiousness of
some of our pronouncements and to urge us
toward the more mundane task of observa-
tion and measurement.
Why don't we know more after all these
years? Our data have always been less than
perfect. What is it about the recent situa-
tion that has made matters worse?
The brief answer is that the economy has
changed and that our data-collection efforts
have not kept pace with it. "Real" national
income accounts were designed in an earlier
era, when the economy was simpler and had
a large agricultural sector and a growing
manufacturing sector. Even then, a number
of compromises had to be made to get mea-
surement off the ground. In large sectors of
the economy, such as construction and most
of the services, government, and other pub-
lic institutions, there were no real output
measures or relevant price deflators. Imag-
ine a "degrees of measurability" scale, with
wheat production at one end and lawyer
services at the other. One can draw a rough
dividing line on this scale between what I
shall call "reasonably measurable" sectors
and the rest, where the situation is not
much better today than it was at the begin-
ning of the national income accounts. Table
2 shows the distribution of nominal GDP by
major industrial sector. In the early post-
World War II period, the situation was not
all that bad: about half of the overall econ-
omy was "measurable" in this sense. By
1990, however, the fraction of the economy
for which the productivity numbers are half
reasonable had fallen to below one-third.
Figure 6 tells the same story with employ-
ment numbers. Measurement problems have
indeed become worse. Our ability to inter-
pret changes in aggregate total factor pro-
ductivity has declined, and major portions
of actual technical change have eluded our
measurement framework entirely.15

### ---Economics-1994-0-13.txt---
An example of the consequences of this
shift is what has come to be known as the
"computer paradox." We have made major
investments in computers and in other
information-processing equipment. The
share of "information" equipment in total
producer investment in durable equipment,
in current prices, has more than doubled,
from about 17 percent in 1960 to 36 percent
in 1992. Computers alone went up from less
than 1 percent to 11 percent of the total;
and that does not allow for improvements in
the quality of this equipment, which has
been happening at a very fast rate-on the
order of 15-30 percent per year (see Jack
Triplett, 1989; Berndt and Griliches, 1993).
Why has this not translated itself into visi-
ble productivity gains? The major answer to
this puzzle is very simple: over three-
quarters of this investment has gone into
our "unmeasurable" sectors (see Table 3),
and thus its productivity effects, which are
likely to be quite real, are largely invisible in
the data.
That there were gains is not really in
doubt. Just observing the changes in the
way banks and airlines operate, and in the
ways in which information is delivered to
firms and consumers, would lead one to
conclude that we are in the midst of a major
technical revolution. Effective distances are
declining rapidly in many parts of the world.
The rise of ATM networks in banking has
resulted in substantial though largely un-
measured time savings for consumers. It is
less clear, however, whether the large ex-
pansion of the securities industry has been
associated with a similar productivity in-
crease or was primarily a response to a real
decline in the cost of rent-seeking induced
by the falling price of information-
processing (see Timothy Bresnahan et al.,
1992).
There is also some scattered evidence for
the positive contribution of computers in
manufacturing, but given the needle-in-the
haystack aspect of this problem, it is not
particularly strong (see e.g., Alan Krueger,


### ---Economics-1994-0-14.txt---

1991; Donald Siegel and Griliches, 1992;
Erik Brynjolfson and Lorin Hitt, 1993; Igal
Hendel, 1993). Some of the gains from com-
puters have been reflected in higher wages
of their operators and in the more general
rise in the returns to education and "skill"
(Chinhui Juhn et al., 1993). More generally,
we may be just at the beginning of the
computer era, early in its diffusion and
learning stages, with most of the productiv-
ity contributions still to come, as we learn
how to use computers more effectively and


### ---Economics-1994-0-15.txt---
integrate them more efficiently into the ex-
isting production structures (Paul David,
1991).
Similar arguments, can be (and have been)
made about the difficulties in measuring the
contribution of R&D to productivity growth
(see Griliches, 1979). From one-third to over
half of all industrial R&D is "sold" to the
government, either in the form of research
contracts and prototypes or indirectly in the
form of weapons and space equipment, and
its direct productivity effects do not show up
in the data at all. Private R&D investment
is also likely to have followed the economy
and shifted its targets toward the faster-
growing sectors, with more invention and
technical change occurring exactly where we
have more trouble in measuring them.
Not only has the economy shifted into
uncharted waters, but even in the "mea-
surable" sectors accelerating rates of change
have destroyed the basis for some of the
older compromises. Currently, new goods
are introduced into the various official price
indexes rather slowly. While attempts are
being made to reduce the revision cycle in
the producer price index from five to two
years for some of the more high-tech goods,
this may still not be fast enough. In the
personal-computers market, for example,
the life of a model has recently fallen to a
year or less (Berndt et al., 1993).
Dealing with the quality-change problem
by treating every version of a product sold
to a different type of customer as a separate
commodity, as is currently the predominant
official practice, creates its own problems.
By linking out the decline in prices experi-
enced by consumers in their shift to super-
markets, discount stores, and mail-order
purchases, it underestimates significantly not
only the output of se;rvices, but also the
output of some of the more "standard"
manufacturing industries (Marshall Reins-
dorf, 1993). A prime example of that is the
treatment of generics in the pharmaceutical
price indexes. The stylized facts are as fol-
lows:
(i) Generics are introduced at roughly half
the price of the original brand.
(ii) The brand price, however, does not,
decline (it sometimes even goes up),
with the ex-monopolist depreciating
optimally her original position and with
generics gaining between half and
three-quarters of the market for the
particular drug.
(iii) But because generic versions are
treated as separate commodities, in
spite of what the FDA says, the price
index does not fall, and since the value
of shipments declines as the market
shifts to generics (and to hospital and
HMO formularies), so does measured
"output" in this industry and the asso-
ciated productivity measures (Griliches
and lain Cockburn, 1993).
This might explain the rather strange
fact that during the last decade pharma-
ceuticals, an industry with one of the high-
est R&D-sales ratios, had a rather dismal
productivity-growth performance. This was
the period with an increasing penetration of
generics, which should have reduced mea-
sured prices in this industry but did not.
The measurement environment has dete-
riorated also in other ways. There is less
willingness on the part of firms and con-
sumers to respond to detailed questions,
and our government has done little to em-
phasize the importance of good economic
data to its own functioning or the overall
understanding of our economy. The conse-
quence of such deterioration can be illus-
trated by the uncertainty about the level of
industrial investment in basic research, an
investment which many think is crucial to
our long-run economic performance
(Griliches, 1986a). Because the question that
asks about the allocation of total R&D ex-
penditures by the "character of work" is not
mandatory and is also not an easy one to
answer, less than half of all the firms sur-
veyed in 1988 answered it. As a result of
such nonresponse, the best that can be done
is to produce a "reasonable" range of esti-
mates, based on alternative imputation al-
gorithms, from $2.5 to $8.2 billion (and a
"central" guess of $3.9 billion), which leaves
us really in the dark as to what has hap-


### ---Economics-1994-0-16.txt---
pened to such investments recently (Eileen I.
Collins, 1990).
V. Data Woes
Why are the data not better? The facts
themselves are not in dispute. Every decade
or so a prestigious commission or commit-
tee produces a report describing in detail
various data difficulties and lacunae: the
Stigler committee report on government
price statistics (National Bureau of Eco-
nomic Research, 1961) is still a living docu-
ment, as are the related Ruggles report
(Richard Ruggles, 1977), the Rees produc-
tivity report (National Academy of Sciences,
1979), the Bonnen report (J. T. Bonnen,
1981), the Creamer GNP improvement re-
port (D. Creamer, 1977), the recent OTA
report (Office of Technology Assessment,
1989), and many others. But life goes on,
and change in this area is very slow. Why? I
don't really have good answers to this ques-
tion, and the topic itself is much larger than
can be handled in this address, but at least
three observations come to mind:
(i) The measurement problems are really
hard.
(ii) Economists have little clout in Wash-
ington, especially as far as data-collec-
tion activities are concerned. More-
over, the governmental agencies in
these areas are balkanized and under-
funded.
(iii) We ourselves do not put enough em-
phasis on the value of data and data
collection in our training of graduate
students and in the reward structure of
our profession. It is the preparation
skill of the econometric chef that
catches the professional eye, not the
quality of the raw materials in the meal,
or the effort that went into procuring
them (Griliches, 1986b).
In many cases the desired data are un-
available because their measurement is re-
ally difficult. After decades of discussion we
are not even close to a professional agree-
ment on how to define and measure the
output of banking, insutrance, or the stock
market (see Griliches, 1992). Similar diffi-
culties arise in conceptualizing the output
of health services, lawyers, and other con-
sultants, or the capital stock of R&D. While
the tasks are difficult, progress has been
made on such topics. The work of Jorgen-
son and Barbara Fraumeni (1992) on the
measurement of educational output is an
example both of what can be done and of
the difficulties that still remain. But it is not
reasonable for us to expect the government
to produce statistics in areas where the con-
cepts are mushy and where there is little
professional agreement on what is to be
measured and how. Much more could be
done, however, in an exploratory and re-
search mode.16 Unfortunately, the various
statistical agencies have been both starved
for funds and badly led, with the existing
bureaucratic structure downplaying the re-
search components of their enterprise when
not being outright hostile to them, research
being cut first when a budget crunch hap-
pens (Triplett, 1991).
Our current statistical structure is badly
split, there is no central direction, and the
funding is heavily politicized. How else can
one explain that the national income ac-
counts and the BEA as a whole receive only
one-third, and health and education statis-
tics each less than one-half of the funds
allocated to agricultural statistics?17 How
does one explain the failure of the most


### ---Economics-1994-0-17.txt---
recent attempt at getting more money for
economic statistics, the late "Boskin initia-
tive"? Central economic statistics do not
have a clear constituency that lobbies on
their behalf. Recent governments seem not
to care enough, or to have enough energy to
fight for something that has a more distant
horizon than the next election. One hopes
for some improvement in this situation from
the current administration. It has people
who know better in reasonably important
positions. Still, with the main focus on the
daily crisis and the continuing budget bat-
tles with Congress, I am not all that opti-
mistic. But if we want progress in this area,
if we care, we need to make our opinions
heard. We need to convince Congress (and
ourselves) that the requests for additional
funding of the statistical infrastructure are
justified as investments in general knowl-
edge and more informed policy formation;
that they are not just self-serving, intended
to allow us to publish more articles or run
thousands more regressions; that it is in-
deed important to know what is happening
and to understand where we might be going
or drifting.18
We need also to make observation, data
collection, and data analysis a more central
component of our graduate teaching. How
can we expect our community to fight for
the budgets of the BEA, BLS, or Census, if
the average student doesn't really know how
the data that they use are manufactured or
what the national accounts are made of.19
We also need to teach them to go out and
collect their own data on interesting aspects
of the economy and to rely less on "given"
data from distant agencies.'o There are en-
couraging signs that some of this is happen-
ing, especially in the micro area. One is
much more cheered by work such as that of
Robert Fogel (1986) on heights and nutri-
tion, Alan Krueger and Orley Ashenfelter
(1992) on twins, Richard Levin et al. (1987)
on the appropriability of technology,
Rebecca Henderson and Cockburn on phar-
maceutical R&D, Richard Freeman and
Harry Holtzer (1986) on inner-city youths,
Schankerman and Pakes (1986) on patent
renewal data, Manuel Trajtenberg (1990a)
on CT scanners, and Trajtenberg (199Gb)
and Adam Jaffe et al. (1993) on patent
citations, where researchers go out, collect,
and create new data sets, than by the
20,000th regression on the Robert Summers
and Alan Heston (1991) data set, illuminat-
ing as it may be. But unless we transmit this
message to our students, we will not be able
to convince others that this is a cause worth
supporting.
VI. Expanding the Framework
Is there something possibly wrong with
the way we ask the productivity question,
with the analytical framework into which we
force the available data? I think so. I would
focus on the treatment of disequilibria and
the measurement of knowledge and other
externalities. The current measurement
framework proceeds as if all investment
and employment decisions are made at
known and common factor and product
prices, throwing all of the heterogeneity
and uncertainty-the surprises and the dis-
appointments-into the residual category.
An alternative view would see measured
productivity growth as a summation of
above- (and below-) average returns to vari-
ous current investment decisions and capital
gains (or losses) on existing physical- and


### ---Economics-1994-0-18.txt---
human-capital stocks.2' The appearance of
such investment opportunities is the essence
of growth and change. They are largely dis-
equilibrium phenomena, resulting in a
lurching from one "steady state" to another
rather than something smooth and expo-
nential. The presence of locally increasing
returns, network externalities, asymmetric
information, and heterogeneous expecta-
tions, the appearance of new products and
technologies, and the changes in the politi-
cal and regulatory environments are all
sources of such "excess" returns, while the
ex post fixity of much of the investment in
both physical and human capital causes cap-
ital gains and losses and unanticipated "ob-
solescence" in the various stocks. We will
have to figure out how to take the residual
apart along such lines to make more
progress in understanding its proximate
sources.
Our theories tend to assume that we are,
indeed, at the frontier and that we can only
either move along it or try to shift it, the
latter being a difficult and chancy business.
In fact we may be far from our existing
"frontiers." Harvey Leibenstein's (1966)
ideas about X-efficiency, or more correctly
X-inefficiency, did not get much of a sympa-
thetic ear from us. They were inconsistent
with notions of equilibrium, the absence of
unexploited profit opportunities, and the
possibilities for economic arbitrage. But real
economic growth is the consequence of both
the appearance of such disequilibria and
the devising of ways of closing them. How
quickly they are eliminated depends on the
strength of incentive systems within enter-
prises, and on their organizational quality.
In spite of the large growth in the literature
on organizations, we have not yet developed
useful ways of quantifying their strengths
and weaknesses. Nor are we close to having
measures of such factors as the "work ethic"
or aspects of the property-rights system
which are likely to contribute much to the
observed differences in productivity across
nations.
The "new" growth theories have various
externalities as their centerpiece (see Solow
[1991] for a recent review). It is somewhat
ironic that they have come to the fore just
when growth started declining and notions
of eternal exponential growth began to lose
their luster. Knowledge externalities are ob-
viously very important in the growth pro-
cess, but they do not help us to explain what
has happened in the last two decades. There
is no reason to believe that they have de-
clined over time. If anything, the communi-
cation and transportation advances should
have expanded the availability of such exter-
nalities.22 But we have no good models for
the measurement of such processes.
Knowledge is not like a stock of ore,
sitting there waiting to be mined. It is an
extremely heterogenous assortment of infor-
mation in continuous flux. Only a small part
of it is of any use to someone at a particular
point of time, and it takes effort and re-
sources to access, retrieve, and adapt it to
one's own use. Thus models of externalities
must perforce be models of interaction be-
tween different actors in the economy. We
have, however, very few convincing models
of such interactions, and the identification
problems are severe (see e.g., Charles Man-
ski, 1993). Our measurement frameworks
are not set up to record detailed origin and
destination data for commodity flows, much
less so for information flows. We do have
now a new tool for studying some of this:
citations to patents and the scientific litera-
ture (see e.g., Jaffe et al., 1993), but anyone
currently active in the e-mail revolution and
participating in the conferences and work-
shops circuit knows how small this tip is
relative to the informal-communications
iceberg itself.


### ---Economics-1994-0-19.txt---
VII. The Glass Half-Full?
After a long detour I come back to the
original question: why don't we know more
about the sources of productivity growth
and the causes for its recent slowdown?
Why does it feel as if the glass is still
half-empty? First note that in a trivial sense
we are doing better: the residual is smaller.
But that is the bad news, not the good. It is
smaller not because we have succeeded in
providing a substantively fuller explanation
of output growth, but rather because mea-
sured output growth declined, leaving some
of these explanations in the dust. But we
are also doing better substantively. We know
much more about the components of growth
and where our measures are lacking. After
decades of work and contributions by Deni-
son, Jorgenson, Kendrick, and many others,
the conceptual and measurement underpin-
nings of the growth accounts are in much
better shape today. We now have extensive
micro data on firms, their productivity, their
R&D expenditures, and other variables. We
have more data on individual investments in
education and training, and we also have
more asset detail on capital formation. More
international data are now available, with
the OECD both collecting R&D data and
computing TFP numbers for many coun-
tries, and with Summers and Heston (1991)
providing comparable real GNP numbers
for many countries. Finally, we have much
more computing power and better econo-
metric techniques and frameworks for at-
tacking many of the problems that arise in
the analysis of such data. So what is still
missing?
We are caught up in a mixture of unmea-
surement, mismeasurement, and unrealistic
expectations. The productivity situation is
both better than we think and also worse. It
is likely that there have been significant
unmeasured productivity advances in many
of the service sectors (Bresnahan, 1986;
Baily and Gordon, 1988). Moreover, rising
R&D investment rates in the mid-1980's
and the recent rise in the number of patent
applications augur well for the future. Also,
productivity growth rates are probably un-
derestimated even in the "measurable" sec-
tors because they are based on "book value"
estimates of physical- and human-capital
stocks and do not reflect the capital losses
-the obsolescence that occurred, first as
the result of the various energy-price shocks,
and later as the result of increased interna-
tional competition and the melting away of
much of the previously existing monopoly
rents to both types of capital. That is actu-
ally bad news. We are not as wealthy as we
thought, but productivity growth, based on
the lower remaining levels of input, is prob-
ably higher than we have measured it.
A cautionary remark needs to be added
here: productivity growth contributes to the
potential for welfare, but it is not the same
thing. Welfare can move in the opposite
direction if the resources released by pro-
ductivity growth do not find adequate em-
ployment in other, economically valuable,
activities (including leisure). Also the physi-
cal, economic, and political environments
can change, both positively and negatively,
overwhelming the productivity story.23 So
even though I have been focusing on it here
tonight, it is not the be-all of economic
welfare. But as George Bernard Shaw used
to say when he was accused of money-grub-
bing: "Yes, I know that money is not happi-
ness, but it is a pretty good substitute."
Nevertheless, the issues I have been dis-
cussing here tonight are important. Much
depends on whether the "truth" is closer to
the upper ("measurable") line in Figure 1,
or the lower one. The country's mood is
affected by bad data and incorrect percep-
tions. Are we really not much better off
than we were in the 1960's? Would we
really like to exchange the commodity as-
sortment we have today for that of
yesteryear? Our health system, warts and
all? The air pollution? The civil-rights situa-
tion? The fear of nuclear war? These are

### ---Economics-1994-0-20.txt---
not just idle intellectual curiosities. They
affect what we feel about ourselves and the
future.
Returning to the topic of technical
change, our expectations of what economics
can deliver here may also be excessive. It is
unlikely that we can have a fully "endoge-
nous" theory of technical change. Yes, both
the rate and direction of inventive activity
are subject to economic influences and anal-
ysis. So also is the diffusion of innovations.
But the outcome of inventive activity is not
really predictable. True "innovation" is an
innovation. If it were knowable in advance
it would not be one, and the innovators
would not be able to collect any rents. In
that sense it is futile to expect that we could
control it fully or predict it well.24 Given the
fundamental uncertainties entailed in the
creative act, in invention, and in innovation,
there is no reason to expect the fit of our
models to be high or for the true residual to
disappear. We should, however, be able to
"explain" it better ex post even if we cannot
predict it.
The metaphor of the glass half-empty is
also misleading. As we fill it, the glass keeps
growing. A major aspect of learning is that
the unknown keeps expanding as we learn.
This should be looked at positively. It is
much better this way-especially for those
of us who are engaged in research!
## Economics-1995-0


### ---Economics-1995-0-02.txt---
While Aristotle agreed with Agathon that
even God could not change the past, he did
think that the future was ours to make-by
basing our choices on reasoning. The idea
of using reason to identify and promote
better-or more acceptable-societies, and
to eliminate intolerable deprivations of dif-
ferent kinds, has powerfully moved people
in the past and continues to do so now. In
this lecture I would like to discuss some
aspects of this question which have received
attention in the recent literature in social-
choice and public-choice theories. The con-
temporary world suffers from many new as
well as old economic problems, including,
among others, the persistence of poverty
and deprivation despite general economic
progress, the occurrence of famines and
more widespread hunger, and threats to our
environment and to the sustainability of the
world in which we live. Rational use of the
opportunities offered by modern science and
technology, in line with our values and ends,
is a powerful challenge today.
I. Problems and Difficulties
How are we to view the demands of ratio-
nality in social decisions? How much guid-
ance do we get from Aristotle's general
recommendation that choice should be gov-
erned by "desire and reasoning directed to
some end"? There are several deep-seated
difficulties here.
The first problem relates to the question:
whose desires, whose ends? Different per-
sons have disparate objects and interests,
and as Horace put it, "there are as many
preferences as there are people." Kenneth
Arrow (1951) has shown, through his fa-
mous "General Possibility Theorem" (an
oddly optimistic name for what is more
commonly-and more revealingly-called
Arrow's "impossibility theorem"), that in
trying to obtain an integrated social prefer-
ence from diverse individual preferences, it
is not in general possible to satisfy even
some mild-looking conditions that would
seem to reflect elementary demands of rea-
sonableness.1 Other impossibility results
have also emerged, even without using some
of Arrow's conditions, but involving other
elementary criteria, such as the priority of
individual liberty.2 We have to discuss why
these difficulties arise, and how we can deal
with them. Are the pessimistic conclusions
that some have drawn from them justified?
Can we sensibly make aggregative social-
welfare judgments? Do procedures for so-
cial decision-making exist that reasonably
respect individual values and preferences?


### ---Economics-1995-0-03.txt---
Second, another set of problems relates
to questions raised by James Buchanan
(1954a,b), which were partly a response to
Arrow's results, but they are momentous in
their own right.3 Pointing to "the funda-
mental philosophical issues" involved in
"the idea of social rationality," Buchanan
(1954a) argued that "rationality or irra-
tionality as an attribute of the social group
implies the imputation to that group of an
organic existence apart from that of its indi-
vidual components" (p. 116). Buchanan was
perhaps "the first commentator to interpret
Arrow's impossibility theorem as the result
of a mistaken attempt to impose the logic of
welfare maximization on the procedures of
collective choice" (Robert Sugden, 1993 p.
1948). But in addition, he was arguing that
there was a deep "confusion surrounding
the Arrow analysis" (not just the impossibil-
ity theorem but the entire framework used
by Arrow and his followers) which ensued
from the mistaken idea of "social or collec-
tive rationality in terms of producing results
indicated by a social ordering" (Buchanan,
1960 pp. 88-89). We certainly have to exam-
ine whether Buchanan's critique negates the
impossibility results, but we must also inves-
tigate the more general issues raised by
Buchanan.4
Third, Buchanan's reasoned questioning
of the idea of "social preference" suggests,
at the very least, a need for caution in
imposing strong "consistency properties" in
social choice, but his emphasis on proce-
dural judgments may be taken to suggest,
much more ambitiously, that we should
abandon altogether consequence-based
evaluation of social happenings, opting in-
stead for a procedural approach. In its pure
form, such an approach would look for
"right" institutions rather than "good" out-
comes and would demand the priority of
appropriate procedures (including the ac-
ceptance of what follows from these proce-
dures). This approach, which is the polar
opposite of the welfare-economic tradition
based on classical utilitarianism of founding
every decision on an ordering of different
states of affairs (treating procedures just as
instruments to generate good states), has
not been fully endorsed by Buchanan him-
self, but significant work in that direction
has occurred in public choice theory and in
other writings influenced by Buchanan's
work (most notably, in the important contri-
butions of Robert Sugden [1981, 1986]).
This contrast is particularly important in
characterizing rights in general and liberties
in particular. In the social choice literature,
these characterizations have typically been
in terms of states of affairs, concentrating
on what happens vis-a-vis what the per-
son wanted or chose to do. In contrast, in
the libertarian literature, inspired by the
pioneering work of Robert Nozick (1974),
and in related contributions using "game-
form" formulations (most notably, by Wulf
Gaertner, Pattanaik, and Suzumura [1992]),
rights have been characterized in procedu-
ral terms, without referring to states of af-
fairs. We have to examine how deep the
differences between the disparate formula-
tions are, and we must also scrutinize their
respective adequacies.
Fourth, the prospects of rationality in so-
cial decisions must be fundamentally condi-
tional on the nature of individual rational-
ity. There are many different conceptions of
rational behavior of the individual. There is,
for example, the view of rationality as canny
maximization of self-interest (the presump-
tion of human beings as "homo economicus,"
used in public choice theory, fits into this
framework). Arrow's (1951) formulation is
more permissive; it allows social considera-
tions to influence the choices people make.
Individual preferences, in this interpreta-
tion reflect "values" in general, rather than
being based only on what Arrow calls
"tastes" (p. 23). How adequate are the re-
spective characterizations of individual ra-
tionality, and through the presumption of
rational behavior (shared by most economic

### ---Economics-1995-0-04.txt---
models), the depiction of actual conduct
and choices?
Another issue, related to individual be-
havior and rationality, concerns the role of
social interactions in the development of
values, and also the connection between
value formation and the decision-making
processes. Social choice theory has tended
to avoid this issue, following Arrow's own
abstinence: "we will also assume in the pre-
sent study that individual values are taken
as data and are not capable of being altered
by the nature of the decision process itself"
(Arrow, 1951 p. 7).5 On this subject,
Buchanan has taken a more permissive po-
sition-indeed emphatically so: "The defi-
nition of democracy as 'government by dis-
cussion' implies that individual values can
and do change in the process of decision-
making" (Buchanan, 1954a p. 120).6 We
have to scrutinize the importance of this
difference as well.
This is a long and somewhat exacting list,
but the different issues relate to each other,
and I shall try to examine them briefly and
also comment on some of their practical
implications.
II. Social Welfare Judgments and Arrow's
Impossibility Theorem
The subject of welfare economics was
dominated for a long time by the utilitarian
tradition, which performs interpersonal ag-
gregation through the device of looking at
the sum-total of the utilities of all the peo-
ple involved. By the 1930's, however,
economists came to be persuaded by argu-
ments presented by Lionel Robbins (1938)
and others (influenced by the philosophy of
"logical positivism") that interpersonal
comparisons of utility had no scientific
basis.7 Thus, the epistemic foundations of
utilitarian welfare economics were seen as
incurably defective.
Because of the eschewal of interpersonal
comparability of individual utilities, the
"new welfare economics" that emerged tried
to rely only on one basic criterion of social
improvement, the Pareto criterion. Since
this confines the recognition of a social im-
provement only to the case in which every-
one's utility goes up (or someone's goes up
and no one's goes down), it does not require
any interpersonal comparison, nor for that
matter, any cardinality of individual utili-
ties. However, Pareto efficiency can scarcely
be an adequate condition for a good society.
It is quite insensitive to the distribution of
utilities (including inequalities of happiness
and miseries), and it takes no direct note of
anything other than utilities (such as rights
or freedoms) beyond their indirect role in
generating utilities. There is a need, cer-
tainly, for further criteria for social welfare
judgments.
The demands of orderly, overall judg-
ments of "social welfare" (or the general
goodness of states of affairs) were clarified
by Abram Bergson (1938, 1966) and exten-
sively explored by Paul Samuelson (1947).
The concentration was on the need for a
real-valued function W of "social welfare"
defined over all the alternative social states,
or at least an aggregate ordering R over
them, the so-called "social preference." In
the reexamination that followed the Berg-
son-Samuelson initiative (including the de-
velopment of social choice theory as a disci-
pline), the search for principles underlying a
social welfare function played a prominent
part.
Arrow (1951) defined a "social welfare
function" as a functional relation that speci-
fies a social ordering R over all the social
states for every set of individual preference
orderings. In addition to assuming-not es-
pecially controversially-that there are at



### ---Economics-1995-0-05.txt---
least three distinct social states and at least
two (but not infinitely many) individuals,
Arrow also wanted a social welfare function
to yield a social ordering for every possible
combination of individual preferences; that
is, it must have a universal domain. A sec-
ond condition is called the independence of
irrelevant alternatives. This can be defined in
different ways, and I shall choose an ex-
tremely simple form. The way a society ranks
a pair of alternative social states x and y
should depend on the individual prefer-
ences only over that pair-in particular,
not on how the other ("irrelevant") alterna-
tives are ranked.
Now consider the idea of some people
being "decisive": a set G of people-I shall
call them a group G-having their way no
matter what others prefer. In ranking a pair
x and y, if it turns out that x gets socially
ranked above y whenever everyone in group
G prefers x to y (no matter what prefer-
ences those not in G have), then G is deci-
sive over that ordered pair (x, y). When a
group G is decisive over all ordered pairs, it
is simply "decisive."
Arrow required that no individual (for-
mally, no single-member group) should be
decisive (nondictatorship), but-following
the Paretian tradition-also demanded that
the group of all individuals taken together
should be decisive (the Pareto principle).
The "impossibility theorem," in this version
(presented in Arrow [1963]), shows that it is
impossible to have a social welfare function
with universal domain, satisfying indepen-
dence, the Pareto principle, and nondictator-
ship.
The theorem can be proved in three sim-
ple steps.8 The first two steps are the fol-
lowing (with the second lemma drawing on
the first).
FIELD-EXPANSION LEMMA: If a group
is decisive over any pair of states, it is deci-
sive.9
GROUP-CONTRACTION LEMMA: If a
group (of more than one person) is decisive,
then so is some smaller group contained in
it.
The final step uses the Group-Contraction
Lemma to prove the theorem. By the Pareto
principle, the group of all individuals is de-
cisive. Since it is finite, by successive parti-
tioning (and each time picking the decisive
part), we arrive at a decisive individual, who
must, thus, be a dictator. Hence the impos-
sibility.


### ---Economics-1995-0-06.txt---
III. Social Preference, Social Choice,
and Impossibility
The preceding discussion makes abun-
dant use of the idea of "social preference."
Should it be dropped, as suggested by
Buchanan? And if so, what would remain of
Arrow's impossibility theorem?
We have to distinguish between two quite
different uses of the notion of "social pref-
erence," related respectively to (i) the oper-
ation of decision mechanisms, and (ii) the
making of social welfare judgments. The first
notion of "social preference" is something
like the "underlying preference" on which
choices actually made for the society by
prevailing mechanisms are implicitly based
-a kind of "revealed preference" of the
society.11 This "derivative" view of social
preference would be, formally, a binary rep-
resentation of the choices emerging from
decision mechanisms.
The second idea of "social preference"
as social welfare judgments-reflects a view
of the social good: some ranking of what
would be better or worse for the society.
Such judgments would be typically made by
a given person or agency. Here too an ag-
gregation is involved, since an individual
who is making judgments about social wel-
fare, or about the relative goodness of dis-
tinct social states, must somehow combine
the diverse interests and preferences of dif-
ferent people.
Buchanan's objection is quite persuasive
for the first interpretation (involving deci-
sion mechanisms), especially since there is
no a priori presumption that the mecha-
nisms used must -or even should -neces-
sarily lead to choices that satisfy the re-
quirements of binary representation (not to
mention the more exacting demands of an
ordering representation).12 On the other
hand, the second interpretation does not
involve this problem, and even an individual
when expressing a view about social welfare
needs a concept of this kind.13 When ap-
plied to the making of social welfare judg-
ments by an individual or an agency, Arrow's
impossibility theorem thus cannot be dis-
puted on the ground that some organic exis-
tence is being imputed to the society. The
amelioration of impossibility must be sought
elsewhere (see Section IV). However,
Buchanan's critique of Arrow's theorem
would apply to mechanisms of social deci-
sion (such as voting procedures).
Would the dropping of the requirement
that social choices be based on a binary
relation-in particular a transitive ordering
-negate the result in the case of social
decision mechanisms? A large literature has
already established that the arbitrariness of
power, of which Arrow's case of dictator-
ship is an extreme example, lingers in one
form or another even when transitivity is
dropped, so long as some regularity is de-
manded (such as the absence of cycles).'4
There is, however, cause for going further,
precisely for the reasons identified by
Buchanan, and to eschew not just the tran-
sitivity of social preference, but the idea of
social preference itself. All that is needed
from the point of view of choice is that the
decision mechanisms determine a "choice
function" for the society, which identifies



### ---Economics-1995-0-07.txt---
what is picked from each alternative "menu"
(or opportunity set).'5
However, provided some conditions are
imposed on the "internal consistency" of
the choice function (relating decisions over
one menu in a "consistent" way to decisions
over other-related-menus), it can be
shown that some arbitrariness of power
would still survive.16 But the methodological
critique of James Buchanan would still
apply forcefully, as reformulated in the fol-
lowing way: why should any restriction
whatever be placed a priori on the choice
function for the society? Why should not
the decisions emerging from agreed social
mechanisms be acceptable without having
to check them against some preconceived
idea of how choices made in different situa-
tions should relate to each other?
What happens, then, to Arrow's impossi-
bility problem if no restrictions whatever
are placed on the so-called "internal consis-
tency" of the choice function for the soci-
ety? Would the conditions relating individ-
ual preferences to social choice (i.e., the
Pareto principle, nondictatorship, and inde-
pendence) then be consistent with each
other? The answer, in fact, is no, not so. If
the Pareto principle and the conditions of
nondictatorship and independence are re-
defined to take full note of the fact that
they must relate to social choices, not to any
prior notion of social preference, then a very
similar impossibility reemerges (see Theo-
rem 3 in Sen [1993]).
How does this "general choice-functional
impossibility theorem" work? The underly-
ing intuition is this. Each of the conditions
relating individual preferences to social de-
cisions eliminates-either on its own or in
the presence of the other conditions-the
possibility of choosing some alternatives.
And the conjunction of these conditions can
lead to an empty choice set, making it "im-
possible" to choose anything.
For example, the Pareto principle is just
such a condition, and the object of this
condition in a choice context, surely, is to
avoid the selection of a Pareto-inferior al-
ternative. Therefore this condition can be
sensibly redefined to demand that if every-
one prefers x to y, then the social decision
mechanism should be such that y should
not get chosen if x is available.17 Indeed, to
eliminate any possibility that we are implic-
itly or indirectly using any intermenu consis-
tency condition for social choice, we can
define all the conditions for only one given
menu (or opportunity set) S; that is, we can
consider the choice problem exclusively over
a given set of alternative states. The Pareto
principle for that set S then only demands
that if everyone prefers some x to some y
in that set, then y must not be chosen from
that set.
Similarly, nondictatorship would demand
that there be no person such that whenever
she prefers any x to any y in that set S,
then y cannot be chosen from that set.
What about independence? We have to
modify the idea of decisiveness of a group
in this choice context, related to choices
over this given set S. A group would be
decisive for x against y if and only if,
whenever all members of this group prefer
any x to any y in this set S, then y is not to
be chosen from S. Independence would now
demand that any group's power of decisive-
ness over a pair (x, y) be completely inde-
pendent of individual preferences over pairs
other than (x, y). It can be shown that there
is no way of going from individual prefer-
ences to social choice satisfying these


### ---Economics-1995-0-08.txt---
choice-oriented conditions of indepen-
dence, the Pareto principle, nondictator-
ship, and unrestricted domain, even without
invoking any "social preference," and with-
out imposing any demand of "collective ra-
tionality," or any intermenu consistency
condition on social choice.18
The morals to be drawn from all this for
Buchanan's questioning of "social prefer-
ence" would appear to be the following.
The "impossibility" result identified in a
particular form by Arrow can be extended
and shown to hold even when the idea of
"social preference" is totally dropped and
even when no conditions are imposed on
"internal consistency" of social choice. This
does not, however, annul the importance of
Buchanan's criticism of the idea of social
preference (in the context of choices emerg-
ing from decision mechanisms for the soci-
ety), since it is a valid criticism on its own
right. But the "impossibility" problem iden-
tified by Arrow cannot be escaped by this
move.
IV. On Reasoned Social Welfare Judgments
How might we then avoid that impossibil-
ity? It is important to distinguish the
bearing of the problem in the making of
aggregative social welfare judgments, as op-
posed to the operation of social decision
mechanisms. I start with the former.
It may be recalled that the Bergson-
Samuelson analysis and Arrow's impossibil-
ity theorem followed a turn in welfare eco-
nomics that had involved the dropping of
interpersonal comparisons of utility. As it
happens, because of its utilitarian form, tra-
ditional welfare economics had informa-
tional exclusions of its own, and it had been
opposed to any basic use of nonutility infor-
mation, since everything had to be judged
ultimately by utility sum-totals in conse-
quent states of affairs. To this was now
added the exclusion of interpersonal com-
parisons of utilities, without removing the
exclusion of nonutility information. This
barren informational landscape makes it
hard to arrive at systematic judgments of
social welfare. Arrow's theorem can be in-
terpreted, in this context, as a demonstra-
tion that even some very weak conditions
relating individual preferences to social wel-
fare judgments cannot be simultaneously
satisfied given this informational privation.19
The problem is not just one of impossibil-
ity. Consider the Field-Expansion Lemma:
decisiveness over any pair of alternatives en-
tails decisiveness over every pair of alterna-
tives, irrespective of the nature of the states
involved. Consider three divisions of a given
cake between two persons: (99,1), (50,50),
and (1, 99). Let us begin with the assumption
that each person-as homo economicus -
prefers a larger personal share of the cake. So
they happen to have opposite preferences.
Consider now the ranking of (99,1) and
(50, 50). If it is decided that (50, 50) is better
for the society than (99,1), then in terms of
preference-based information, person 2's
preference is getting priority over person l's.
A variant of the Field-Expansion Lemma
would then claim that person 2's preference
must get priority over all other pairs as well,
so that even (1,99) must be preferred to
(50, 50).20 Indeed, it is not possible, given
the assumptions, to regard (50, 50) as best of
the three; we could either have (99,1), giv-
ing priority to person l's preference, or
(1,99), giving priority to 2's preference. But
not (50, 50). I am not arguing here that
(50,50) must necessarily be taken to be the
best, but it is absurd that we are not even
permitted to consider (50,50) as a claimant


### ---Economics-1995-0-09.txt---
to being the best element in this cake-
division problem.
It is useful to consider what arguments
there might be for considering (50,50) as a
good possibility, and why we cannot use any
of these arguments in the information
framework resulting from Arrow's condi-
tions. First, it might seem good to divide the
cake equally on some general non-welfarist
ground, without even going into preferences
or utilities. This is not permitted because of
-the exclusion of evaluative use of nonutility
information, and this is what the Field-
Expansion Lemma is formalizing. Second,
presuming that everyone has the same
strictly concave utility function, we might
think that the sum-total of utilities would be
maximized by an equal division of the cake.
But this utilitarian argument involves com-
parability of cardinal utilities, which is ruled
out. Third, we might think that equal divi-
sion of the cake will equate utilities, and
there are arguments for utility-centered
egalitarianism (see James Meade, 1976). But
that involves interpersonal comparison of
ordinal utilities, which too is ruled out. None
of the standard ways of discriminating be-
tween the alternative states is viable in this
informational framework, and the only way
to choose between them is to go by the
preference of one person or another (since
they have opposite preferences).
To try to make social welfare judgments
without using any interpersonal comparison
of utilities, and without using any nonutility
information, is not a fruitful enterprise. We
do care about the size and distribution of
the overall achievements; we have reasons
to want to reduce deprivation, poverty, and
inequality; and all these call for interper-
sonal comparisons-either of utilities or of
other indicators of individual advantages,
such as real incomes, opportunities, primary
goods, or capabilities.21 Once interpersonal
comparisons are introduced, the impossibil-
ity problem, in the appropriately redefined
framework, vanishes.22 The comparisons
may have to be rough and ready and often
open to disputation, but such comparisons
are staple elements of systematic social wel-
fare judgments. Even without any cardinal-
ity, ordinal interpersonal comparisons per-
mit the use of such rules of social judgment
as maximin, or lexicographic maximin.23 This
satisfies all of Arrow's conditions (and many
others), though the class of permissible so-
cial welfare rules that do this is quite lim-
ited, unless cardinality is also admitted,
along with interpersonal comparisons (see
Louis Gevers, 1979; Kevin Roberts, 1980a).
With the possibility of using interpersonal
comparisons, other classes of possible rules
for social welfare judgments (including
inter alia, utilitarianism) become usable.24
While the axiomatic derivations of dif-
ferent social-welfare rules in this literature
are based on applying interpersonal com-
parisons to utilities only, the analytical
problems are, in many respects, rather simi-
lar when people are compared in terms of
some other feature, such as real income,
holdings of primary goods, or capabilities to
function. There are, thus, whole varieties of

### ---Economics-1995-0-10.txt---
ways in which social welfare judgments can
be made using richer information than in
the Arrow framework.
This applies also to procedures specifi-
cally aimed at making social welfare judg-
ments and other aggregative evaluations,
based on institutionally accepted ways of
making interpersonal comparisons: for ex-
ample, in using indexes of income inequality
(see Serge Kolm's [1969] and Anthony
Atkinson's [1970] pioneering work on this),
or in aggregate measures of distribution-
corrected real national income (Sen, 1976a),
or of aggregate poverty (Sen, 1976b).5 This
links the theory of social choice to some of
the most intensely practical debates on eco-
nomic policy.26 While Arrow's impossibility
theorem is a negative result, the challenge it
provided has led, dialectically, to a great
many constructive developments.
V. On Social Decision Mechanisms
Moving from the exercise of making so-
cial judgments to that of choosing social
decision mechanisms, there are other dif-
ficulties to be faced. While systematic inter-
personal comparisons of utilities (and other
ways of seeing individual advantage) can be
used by a person making social welfare
judgment, or in agreed procedures for social
judgments (based on interpreting available
statistics to arrive at, say, orderings of ag-
gregate poverty or inequality or distribu-
tion-corrected real national income), this is
not an easy thing to do in social-decision
mechanisms which must rely on some stan-
dard expressions of individual preference
(such as voting), which do not readily lend
themselves to interpersonal comparisons.
The impossibility problem, thus, has
greater resilience here. While it is also the
case that the critique of James Buchanan
(and others) of the idea of "social rational-
ity" and the concept of "social preference"
applies particularly in this case (that of
judging social decision mechanisms), the im-
possibility problem does indeed survive, as
we have seen, even when the concept of
social preference is eschewed and the idea
of social rationality in the Arrovian form is
dropped altogether (Section III). How, then,
can we respond to the challenge in this
case?
We may begin by noting that the condi-
tions formulated and used by Arrow, while
appealing enough, are not beyond criticism.
First, not every conceivable combination of
individual preferences need be considered
in devising a social decision procedure, since
only some would come up in practice. As
Arrow had himself noted, if the condition of
unrestricted domain is relaxed, we can find
decision rules that satisfy all the other con-
ditions (and many other demands) over sub-
stantial domains of individual preference
profiles. Arrow (1951), along with Duncan
Black, had particularly explored the case of
"single-peaked preferences," but it can be
shown (Sen, 1966) that this condition can be
far extended and generalized to a much less
demanding restriction called "value restric-
tion."27


### ---Economics-1995-0-11.txt---
The plausibility of different profiles of
individual preferences depends on the na-
ture of the problem and on the characteris-
tics of individual motivations. It is readily
checked that with three or more people, if
everyone acts as homo economicus in a
cake-division problem (always preferring
more cake to oneself over all else), then
value restriction and the related conditions
would all be violated, and majority rule
would standardly lead to intransitivities. 'It
is also easy to show that in the commodity
space, with each concentrating on her own
commodity basket, the Arrow conditions
could not be all satisfied by any decision
mechanism over that domain. Majority rule
and other voting procedures of this kind do
cause cycles in general in what is called
"the economic domain" (of interpersonal
commodity space), if everyone votes in a
narrowly self-interested way.
However, majority rule would be a terri-
ble decision procedure in this case, and its
intransitivity is hardly the main problem
here. For example, taking the most deprived
person in a community and passing on half
her share of the cake divided between two
richer persons would be a majority improve-
ment, but scarcely a great welfare-economic
triumph. In view of this, it is perhaps just as
well that the majority rule is not only nasty
and brutish, but also short in consistency.28
The tension between social welfare judg-
ments (of different kinds explored, for ex-
ample, by Meade [1976], Arrow [1977],
Mirrlees (1982), William J. Baumol [1986],
or John Broome [1991]) and mechanical de-
cision rules (like majority decision) with
inward-looking, self-centered individuals is
most obvious here. Also, as Buchanan
(1994a, b) has argued, the acceptability of
majority rule is, in fact, related to its ten-
dency to generate cycles, and the endemic
cyclicity of majority decisions is inescapable,
given the endogeneity of alternative propos-
als that can be presented for consideration.
In practice, in facing political decisions,
the choices may not come in these stark
forms (there are many issues that are mixed
together in political programs and propos-
als), and also individuals do not necessarily
only look at their "own share of the cake"
in taking up political positions and atti-
tudes.29 The "public choice" school has
tended to emphasize the role of logrolling
in political compromises and social deci-
sions. While that school has also been rather
wedded to the presumption of each person
being homo economicus even in these exer-
cises (see Buchanan and Tullock, 1962),
there is a more general social process here
(involving a variety of motivations) that can
be fruitfully considered in examining deci-
sion mechanisms. Central to this is the role
of public discussion in the formation of
preferences and values, which has been em-
phasized by Buchanan (1954a,b).
The condition of independence of irrele-
vant alternatives is also not beyond dispu-
tation and, indeed, has led to debates-ex-
plicitly or by implication-for a very long
time. It was one of the issues that divided
J. C. Borda (1781) and Marquis de Con-
dorcet (1785), the two French mathemati-
cians, who had pioneered the systematic
theory of voting and group decision proce-
dures in the 18th century. One version of
the rule proposed by Borda, based on adding
the rank-order numbers of candidates in
each voter's preference list, violates the in-
dependence condition rather robustly, but it
is not devoid of other merits (and is fre-
quently used in practice).30 Other types of
voting rules have also been shown to have
different desirable properties.3'


### ---Economics-1995-0-12.txt---
In examining social decision mechanisms,
we have to take the Arrow conditions seri-
ously, but not as inescapable command-
ments. Our intuitions vary on these matters,
and Arrow's own theorem shows that not
everything that appeals to us initially would
really be simultaneously sustainable. There
is a need for some de-escalation in the grim
"fight for basic principles." The issue is not
the likely absence of rationally defendable
procedures for social decisions, but the rela-
tive importance of disparate considerations
that pull us in different directions in evalu-
ating diverse procedures. We are not at the
edge of a precipice, trying to determine
whether it is at all "possible" for us to hang
on.
VI. Procedures and Consequences
I turn now to the general issue, identified
earlier, of the contrast between relying re-
spectively on (i) the "rightness" of proce-
dures, and (ii) the "goodness" of outcomes.
Social choice theory, in its traditional
form, would seem to belong to the latter
part of the dichotomy, with the states of
affairs judged first (the subject matter of
"social preference" or "social welfare
judgements"), followed by identification of
procedures that generate the "best" or
"maximal" or "satisficing" states. There are
two issues here. First, can consequences
really be judged adequately without any no-
tion of the process through which they are
brought about? I shall also presently ques-
tion whether this presumption of process-
independence is the right way of seeing the
claims of social choice theory. Second, can
we do the converse of this, and judge proce-
dures adequately in a consequence-indepen-
dent way? This issue I take up first.
Sugden (1981, 1986), who has extensively
analyzed this dichotomy (between procedu-
ral and consequence-based views), explains
that in the public choice approach, which he
supports, "the primary role of the govern-
ment is not to maximize the social good, but
rather to maintain a framework of rules
within which individuals are left free to
pursue their own ends" (Sugden, 1993
p. 1948). This is indeed so, but even in
judging a "framework of rules" in this way,
we do need some consequential analysis,
dealing with the effectiveness of these
frameworks in letting individuals be actually
"free to pursue their own ends." In an
interdependent world, examples of permis-
sive rules that fail to generate the freedom
to pursue the respective individual ends are
not hard to find (see Sen, 1982b).
Indeed, it is not easy to believe that the
public-choice approach is-or can be-
really consequence-independent. For exam-
ple, Buchanan's support of market systems
is based on a reading of the consequences
that the market mechanism tends to pro-
duce, and consequences certainly do enter
substantially in Buchanan's evaluation of
procedures: "To the extent that voluntary
exchange among persons is valued positively
while coercion is valued negatively, there
emerges the implication that substitution of
the former for the latter is desired, on the
presumption, of course, that such substitu-
tion is technologically feasible and is not
prohibitively costly in resources" (Buchanan,
1986 p. 22). While this is not in serious
conflict with Buchanan's rejection of any
"transcendental" evaluation of the out-
comes (p. 22), nevertheless the assessment
of outcomes must, in some form, enter this
evaluative exercise. 32
There are, however, other-more purely
procedural-systems to be found in this lit-
erature. If the utilitarian tradition of judg-
ing everything by the consequent utilities is
one extreme in the contrast (focusing only
on a limited class of consequences), Nozick's
(1974) elegant exploration of libertarian
"entitlement theory" comes close to the
other end (focusing on the right rules that
cover personal liberties as well as rights of
holding, using, exchanging, and bequeathing



### ---Economics-1995-0-13.txt---
legitimately owned property). But the possi-
bility of having unacceptable consequences
has to be addressed by any such procedural
system. What if the results are dreadful for
many, or even all?
Indeed, it can be shown that even gigan-
tic famines can actually take place in an
economy that fulfills all the libertarian rights
and entitlements specified in the Nozick
system.33 It is, thus, particularly appropriate
that Nozick (1974) makes exceptions to
consequence-independence in cases where
the exercise of these rights would lead to
"catastrophic moral horrors."34 Because of
this qualification, consequences are made to
matter after all, and underlying this conces-
sion is Nozick's good sense (similar to
Buchanan's) that a procedural system of
entitlements that happens to yield catas-
trophic moral horrors (we have to have some
consensus on what these are) would
be-and should be-ethically unaccept-
able. However, once- consequences are
brought into the story, not only is the purity
of a consequence-independent system lost,
but also the issue of deciding on the relative
importance of "right rules" and "good con-
sequences" is forcefully reestablished.
I turn now to the other side of the di-
chotomy: can we have sensible outcome
judgments in a totally procedure-indepen-
dent way? Classical utilitarianism does in-
deed propose such a system, but it is hard
to be convinced that we can plausibly judge
any given utility distribution ignoring alto-
gether the process that led to that distribu-
tion (attaching, for example, no intrinsic
importance whatever to whether a particu-
lar utility redistribution is caused by charity,
or taxation, or torture).35
This recognition of the role of processes
is not, in fact, hostile to social choice the-
ory, since there is nothing to prevent us
from seeing the description of processes as
a part of the consequent states generated
by them.36 If action A is performed, then
"action A has been done" must be one-
indeed, the most elementary-consequence
of that event. If Mr. John Major were to
wish not merely that he should be reelected
as Prime Minister, but that he should be
"reelected fairly" (I am not, of course, in-
sinuating that any such preference has been
expressed by Mr. Major), the consequence
that he would be seeking would have proce-
dural requirements incorporated within it.
This is not to claim that every process can
be comfortably placed within the descrip-
tion of states of affairs without changing
anything in social choice theory. Parts of the
literature that deal with comparisons of de-
cision mechanisms in arriving at given states
would need modification. If, in general, pro-
cesses leading to the emergence of a social
state were standardly included in the char-
acterization of that state, then we have to
construct "equivalence classes" to ignore
some differences (in this case, between some
antecedent processes) to be able to discuss
cogently the "same state" being brought
about by different decision mechanisms. To
make sense of such ideas as, say, "path
independence" (on which see Plott [1973]),
so that they are not rendered vacuous,
equivalence classes of this type would cer-
tainly have to be constructed (on the con-
cepts of equivalence classes and invariance
conditions, see Sen [1986b]).
The contrast between the procedural and
consequential approaches is, thus, some-
what overdrawn, and it may be possible to
combine them, to a considerable extent, in
an adequately rich characterization of states
of affairs. The dichotomy is far from pure,
and it is mainly a question of relative con-
centration.


### ---Economics-1995-0-14.txt---
VII. Liberties, Rights, and Preferences
The need to integrate procedural consid-
erations in consequential analysis is espe-
cially important in the field of rights and
liberties. The violation or fulfillment of ba-
sic liberties or rights tends to be ignored in
traditional utilitarian welfare economics not
just because of its consequentialist focus,
but particularly because of its "welfarism,"
whereby consequent states of affairs are
judged exclusively by the utilities generated
in the respective states.37 While processes
may end up getting some indirect attention
insofar as they influence people's utilities,
nevertheless no direct and basic importance
is attached in the utililtarian framework to
rights and liberties in the evaluation of states
of affairs.
The initial formulation of social choice
did not depart in this respect from the utili-
tarian heritage, but it is possible to change
this within a broadly Arrovian framework
(see Sen, 1970, 1982a), and a good deal of
work has been done in later social choice
theory to accommodate the basic relevance
of rights and liberties in assessing states of
affairs, and thus to evaluate economic, polit-
ical, and social arrangements. If a person is
prevented from doing some preferred thing
even though that choice is sensibly seen to
be in her "personal domain," then the state
of affairs can be seen to have been wors-
ened by this failure. The extent of worsen-
ing is not to be judged only by the magni-
tude of the utility loss resulting from this (to
be compared with utility gains of others, if
any), since something more is also at stake.
As John Stuart Mill (1859 p. 140) noted,
"there is no parity between the feeling of a
person for his own opinion, and the feeling
of another who is offended at his holding
it."38 The need to guarantee some "minimal
liberties" on a priority basis can be incorpo-
rated in social choice formulations.
It turns out, however, that such uncondi-
tional priority being given even to minimal
liberty can conflict with other principles of
social choice, including the redoubtable
Pareto principle. The "impossibility of the
Paretian liberal" captures the conflict be-
tween (i) the special importance of a per-
son's preferences over her own personal
sphere, and (ii) the general importance of
people's preferences over any choice, irre-
spective of field. This impossibility theorem
has led to a large literature extending, ex-
plaining, disputing, and ameliorating the re-
sult.39 The "ways out" that have been sought
have varied between (i) weakening the pri-
ority of liberties (thereby qualifying the min-
imal liberty condition), (ii) constraining the
field-independent general force of prefer-
ences (thereby qualifying the Pareto princi-
ple), and (iii) restricting the domain of per-
missible individual-preference profiles. As
in the case of the Arrow impossibility prob-
lem, the different ways of resolving this con-
flict have variable relevance depending on
the exact nature of the social choice exer-
cise involved.
There have also been attempts to rede-
fine liberty in purely procedural terms. The
last is an important subject on its own (quite
independently of any use it might have
as an attempt to resolve the impossibility),
and I shall presently consider it. But as has


### ---Economics-1995-0-15.txt---
been noted by Gaertner, Pattanaik, and
Suzumura (1992), who have recently pro-
vided the most extensive recharacterization
of liberty (in terms of "game forms"), the
impossibility problem "persists under virtu-
ally every plausible concept of individual
rights" (p. 161).40
The decisive move in the direction of a
purely procedural view of liberty was made
by Nozick (1974), responding to my social
choice formulation and to the impossibility
of the Paretian liberal (Sen, 1970). This has
been followed by important constructive
contributions by Gardenfors (1981) and
Sugden (1981), and the approach has been
extended and developed into game-form
formulations by Gaertner et al. (1992). In
the game-form view, each of the players has
a set of permissible strategies, and the out-
come is a function of the combination of
strategies chosen by each of the players
(perhaps qualified by an additional "move"
by "nature"). The liberties and rights of the
different persons are defined by specifying a
permissible subset from the product of the
strategy sets of the different individuals. A
person can exercise his rights as he likes,
subject to the strategy combination belong-
ing to the permissible set.
In defining what rights a person has, or in
checking whether his rights were respected,
there is, on this account, no need to exam-
ine or evaluate the resulting state of affairs,
and no necessity to examine what states the
individuals involved prefer. In contrasting
this characterization of preference-indepen-
dent, consequence-detached rights with the
social choice approach to rights, perhaps
the central question that is raised is the
plausibility of making people's putative
rights, in general, so dissociated from the
effects of exercising them. This is a general
issue that was already discussed at a broader
level (Section VI).
In some contexts, the idea of seeing rights
in the form of permission to act can be
quite inadequate, particularly because of
"choice inhibition" that might arise from a
variety of causes. The long British discus-
sion on the failure of millions of potential
welfare recipients from making legitimate
claims (apparently due to the shame and
stigma of having one's penury publicized
and recorded) illustrates a kind of nonreal-
ization of rights in which permission is not
the main issue at all.4' Similarly, the inabil-
ity of women in traditionally sexist societies
to use even those rights that have not been
formally denied to them also illustrates a
type of rights failure that is not helpfully
seen in terms of game forms (see Sen, 1992b
pp. 148-50). Even the questions that stan-
dardly come up in this country in determin-
ing whether a rape has occurred have to go
well beyond checking whether the victim in
question was "free" to defy.
Leaving out such cases, it might well be
plausible to argue that rights can be nicely
characterized by game forms in many situa-
tions. However, even when that is the case,
in deciding on what rights to protect and
codify, and in determining how the underly-
ing purpose might be most effectively
achieved, there is a need to look at the
likely consequences of different game-form
specifications and to relate them to what
people value and desire. If, for example, it
appears that not banning smoking in certain
gatherings (leaving the matter to the discre-
tion of the people involved) would actually
lead to unwilling victims having to inhale



### ---Economics-1995-0-16.txt---
other people's smoke, then there would be
a case for considering that the game-form
be so modified that smoking is simply
banned in those gatherings. Whether or not
to make this move must depend crucially on
consequential analysis. The object, in this
case, is the prevention of the state of affairs
in which nonsmokers have to inhale unwill-
ingly other people's smoke: a situation they
resent and which-it is assumed-they
have a right to avoid. We proceed from
there, through consequential analysis (in an
"inverse" form: from consequences to
antecedents), to the particular game-form
formulation that would not achieve an
acceptable result. The fact that the arti-
culation of the game-form would be
consequence-independent and preference-
independent is not a terribly profound as-
sertion and is quite consistent with the fun-
damental relevance of consequences and
preferences.
The contrast between game-form formu-
lations and social-choice conceptions of
rights is, thus, less deep than it might first
appear (see Sen, 1992b).42 As in other fields
considered earlier (Section VI), in this area
too, the need to combine procedural con-
cerns with those of actual events and out-
comes is quite strong.
VIII. Values and Individual Choices
I have so far postponed discussing indi-
vidual behavior and rationality, though the
issue has indirectly figured in the preceding
discussions (for example, in dealing with
norms for social choice, individual interest
in social welfare judgments, and determina-
tion of voting behavior). The public choice
tradition has tended to rely a good deal on
the presumption that people behave in a
rather narrowly self-centered way-as homo
economicus in particular, even though
Buchanan (1986 p. 26) himself notes some
"tension" on this issue (see also Geoffrey
Brennan and Loren Lomarsky, 1993). Public
servants inter alia are to be seen as working
for their own well-being and success.
Adam Smith is sometimes described as
the original proponent of the ubiquity and
ethical adequacy of "the economic man,"
but that would be fairly sloppy history. In
fact, Smith (1776, 1790) had examined the
distinct disciplines of "self-love," "pru-
dence," "sympathy," "generosity," and
"public spirit," among others, and had dis-
cussed not only their intrinsic importance,
but also their instrumental roles in the suc-
cess of a society, and also their practical
influence on actual behavior. The demands
of rationality need not be geared entirely to
the use of only one of these motivations
(such as self-love), and there is plenty of
empirical evidence to indicate that the pre-
sumption of uncompromising pursuit of nar-
rowly defined self-interest is as mistaken
today as it was in Smith's time.43 Just as it is
necessary to avoid the high-minded senti-
mentalism of assuming that all human be-
ings (and public servants, in particular) try
constantly to promote some selfless "social
good," it is also important to escape what
may be called the "low-minded sentimental-
ism" of assuming that everyone is constantly
motivated entirely by personal self-
interest.44



### ---Economics-1995-0-17.txt---
This does not, however, negate an impor-
tant implication of the question raised by
Buchanan and others that public servants
would tend to have their own objective
functions; I would dissociate that point from
the further claim, with which it has come
mixed, that these objective functions are
narrowly confined to the officials' own self-
interest. The important issue to emerge is
that there is something missing in a large
part of the resource-allocation literature (for
example, in proposals of algorithms for de-
centralized resource allocation, from Oscar
Lange and Abba Lerner onward) which
make do without any independent objective
function of the agents of public action. The
additional assumption of homo economicus
is not needed to point to this general
lacuna.
While this has been a somewhat ne-
glected question in social choice theory
(though partially dealt with in the related
literature on implementation), there is no
particular reason why such plurality of moti-
vations cannot be accommodated within a
social choice framework with more richly
described social states and more articulated
characterization of individual choices and
behavior. In the formulation of individual
preference used by Arrow (1951) and in
traditional social choice theory, the nature
of the objective function of each individual
is left unspecified. While there is need for
supplementary work here, this is a helpfully
permissive framework-not tied either to
ceaseless do-gooding, or to uncompromising
self-centeredness.
Even with this extended framework, tak-
ing us well beyond the homo economicus,
there remain some difficulties with the no-
tion of individual rationality used here.
There is a problem of "insufficiency" shared
by this approach to rationality with other
"instrumental" approaches to rationality,
since it does not have any condition of criti-
cal scrutiny of the objectives themselves.
Socrates might have overstated matters a bit
when he proclaimed that "the unexamined
life is not worth living," but an examination
of what kind of life one should sensibly
choose cannot really be completely irrele-
vant to rational choice.45 An "instrumental
rationalist" is a decision expert whose re-
sponse to seeing a man engaged in slicing
his toes with a blunt knife is to rush to
advise him that he should use a sharper
knife to better serve his evident objective.
This is perhaps more of a limitation in
the normative context than in using the
presumption of rationality as a device for
predicting behavior, since such critical
scrutiny might not be very widely practiced.
However, the last is not altogether clear,
since discussions and exchange, and even
political arguments, contribute to the for-
mation and revision of values. As Frank
Knight (1947 p. 280) noted, "Values are
established or validated and recognized
through discussion, an activity which is at
once social, intellectual, and creative."
There is, in fact, much force in Buchanan's
(1954a p. 120) assertion that this is a central
component of democracy ("government by
discussion") and that "individual values can
and do change in the process of decision-
making."
This issue has some real practical impor-
tance. To illustrate, in studying the fact that
famines occur in some countries but not in
others, I have tried to point to the phe-
nomenon that no major famine has ever
taken place in any country with a multiparty
democracy with regular elections and with a
reasonably free press (Sen, 1984).46 This
applies as much to the poorer democratic
countries (such as India, Zimbabwe, or
Botswana) as to the richer ones.47 This is
largely because famines, while killing mil-



### ---Economics-1995-0-18.txt---
lions, do not much affect the direct well-
being of the ruling classes and dictators,
who have little political incentive to prevent
famines unless their rule is threatened by
them. The economic analysis of famines
across the world indicates that only a small
proportion of the population tends to be
stricken-rarely more than 5 percent or so.
Since the shares of income and food of
these poor groups tend normally to be no
more than 3 percent-of the total for the
nation, it is not hard to rebuild their lost
share of income and food, even in very poor
countries, if a serious effort is made in that
direction (see Sen, 1981; Dreze and Sen,
1989). Famines are thus easily preventable,
and the need to face public criticism and to
encounter the electorate provides the gov-
ernment with the political incentive to take
preventive action with some urgency.
The question that remains is this. Since
only a very small proportion of the popula-
tion is struck by a famine (typically 5 per-
cent or less), how does it become such a
potent force in elections and in public criti-
cism? This is in some tension with the as-
sumption of universal self-centeredness, and
presumably we do have the capacity-and
often the inclination-to understand and
respond to the predicament of others.48
There is a particular need in this context to
examine value formation that results from
public discussion of miserable events, in
generating sympathy and commitment on
the part of citizens to do something to pre-
vent their occurrence.
Even the idea of "basic needs," fruitfully
used in the development literature, has to
be related to the fact that what is taken as a
"need" is not determined only by biological
and uninfluencible factors. For example, in
those parts of the so-called Third World in
which there has been increased and exten-
sive public discussion of the consequences
of frequent childbearing on the well-being
and freedom of mothers, the perception that
a smaller family is a "basic need" of women
(and men too) has grown, and in this value
formation a combination of democracy, free
public media, and basic education (espe-
cially female education) has been very po-
tent. The implications of this finding are
particularly important for rational consider-
ation of the so-called "world population
problem."49
Similar issues arise in dealing with envi-
ronmental problems. The threats that we
face call for organized international action
as well as changes in national policies, par-
ticularly for better reflecting social costs in
prices and incentives. But they are also de-
pendent on value formation, related to pub-
lic discussions, both for their influence on
individual behavior and for bringing about
policy changes through the political process.
There are plenty of "social choice problems"
in all this, but in analyzing them, we have to
go beyond looking only for the best reflec-
tion of given individual preferences, or the
most acceptable procedures for choices
based on those preferences. We need to
depart both from the assumption of given
preferences (as in traditional social choice
theory) and from the presumption that peo-
ple are narrowly self-interested homo eco-



### ---Economics-1995-0-19.txt---
nomicus (as in traditional public choice the-
ory).
IX. Concluding Remarks
Perhaps I could end by briefly returning
to the questions with which I began. Arrow's
impossibility theorem does indeed identify a
profound difficulty in combining individual
preference orderings into aggregative
social welfare judgments (Section II). But
the result must not be seen as mainly a
negative one, since it directly leads on to
questions about how to overcome these
problems. In the context of social welfare
judgments, the natural resolution of these
problems lies in enriching the informational
base, and there are several distinct ways of
doing this (Section IV). These approaches
are used in practice for aggregative judg-
ments made by individuals, but they can
also be used for organized procedures for
arriving at social measures of poverty, in-
equality, distribution-adjusted real national
incomes, and other such aggregative indica-
tors.
Second, Buchanan's questioning of the
concept of social preference (and of its use
as an ordering to make-or explain-social
choices) is indeed appropriate in the case of
social decision mechanisms, though less so
for social welfare judgments (Section III).
The Arrow theorem, in its original form,
does not apply once social decision-making
is characterized in terms of choice func-
tions without any imposed requirement of
intermenu consistency. However, when the
natural implications of taking a .choice-
functional view of social decisions are
worked out, Arrow's conditions have to be
correspondingly restated, and then the im-
possibility result returns in its entirety once
again (Section III). The idea of social pref-
erence or internal consistency of social
choice is basically redundant for this impos-
sibility result. So Buchanan's move does not
negate Arrow's impossibility. On the other
hand, it is an important departure in its own
right.
Coming to terms with the impossibility
problem in the case of social decision mech-
anisms is largely a matter of give and take
between different principles with respective
appeals. This calls for a less rigid interpre-
tation of the role of axiomatic demands on
permissible social decision rules (Section V).
Third, Buchanan's argument for a more
procedural view of social decisions has much
merit. Nevertheless, there are good reasons
to doubt the adequacy of a purely procedu-
ral view (independent of consequences), just
as there are serious defects in narrowly con-
sequentialist views (independent of proce-
dures). Procedural concerns can, however,
be amalgamated with consequential ones by
recharacterizing states of affairs appropri-
ately, and the evaluation of states can then
take note of the two aspects together (Sec-
tion VI). This combination is especially im-
portant in accommodating liberty and rights
in social judgments as well as social decision
mechanisms (Section VII).
Finally, there is room for paying more
attention to the rationality of individual be-
havior as an integral component of rational
social decisions. In particular, the practical
reach of social choice theory, in its tradi-
tional form, is considerably reduced by its
tendency to ignore value formation through
social interactions. Buchanan is right to em-
phasize the role of public discussion in the
development of preferences (as an impor-
tant part of democracy). However, tradi-
tional public choice theory is made unduly
narrow by the insistence that individu-
als invariably behave as homo economicus
(a subject on which social choice theory
is much more permissive). This uncompro-
mising restriction can significantly misrep-
resent the nature of social concerns and
values. But aside from this descriptive limi-
tation, there is also an important issue of
"practical reason" here. Many of the more
exacting problems of the contemporary
world-varying from famine prevention to
environmental preservation-actually call
for value formation through public discus-
sion (Section VIII).
On the rationality of social decisions,
many important lessons have emerged from
the discipline of social choice theory as well
as the public choice approach. In fact, we
can get quite a bit more by combining these
lessons. As a social choice theorist, I had


### ---Economics-1995-0-20.txt---
not, in fact, planned to be particularly even-
handed in this paper, but need not, I sup-
pose, apologize for ending up with rather
even hands.
## Economics-1996-0


### ---Economics-1996-0-02.txt---
Interest in health economics has soared over
the past three decades, stimulated by intellec-
tual innovations, greater availability of data,
and, most importantly, a surge in health care
spending from 6 to 14 percent of GDP.' An
11 -fold increase2 in the number of Ph.D.s has
enabled many professional schools, govern-
ment agencies,3 and research institutes to add
health economists to their staffs. Nevertheless,
the health care debate of 1993-1994 benefited
much less than it could have from the results
of their research.
In this lecture I identify the primary sources
of modern health economics and describe in-
teractions between the discipline and the field
of health, drawing heavily on my personal ex-
perience. I then turn to the question of why
economists did not have more impact on
health care reform. I report and analyze the
answers of health economists, economic the-
orists, and practicing physicians to a survey I
conducted in 1995. My principal conclusion is
that value differences among economists, as
well as among all Americans, are a major bar-
rier to effective policy-making. I discuss the
implications of the importance of values for
economics and conclude the lecture with my
recommendations for health care reform-
recommendations based on my values as well
as my understanding of health economics.
I. The Past
In 1963 a seminal paper by Kenneth Arrow
discussed risk aversion, moral hazard, asym-
metrical information, philanthropic externali-
ties, and numerous other topics that have since
played major roles in health economics re-
search.4 He saw that uncertainty about health
status and about the consequences of care was
the key to understanding the health sector from
both positive and normative perspectives. As
Arrow wrote, "Recovery from disease is as
unpredictable as its incidence" ( 1963 p. 951 ).
At the same time that Arrow was depicting
the theoretical landscape, Martin Feldstein
was pioneering in the application of quantita-
tive methods such as 2-stage least squares,
principal component analysis, and linear pro-
gramming to the estimation of production
functions and other important economic as-
pects of medical care. His numerous papers
analyzing the British National Health Service
formed the basis for his Ph.D. thesis at Oxford
University (Feldstein, 1967).
A third line of work that has had a signif-
icant influence on health economics also be-
gan in the early 1960's with the National
Bureau of Economic Research Conference
on Investment in Human Beings (1962) and
Gary S. Becker's treatise on human capital


### ---Economics-1996-0-03.txt---
(1964). The NBER conference volume in-
cluded Selma Mushkin's (1962) paper,
"Health As an Investment," and a few years
later the application of the human capital
model to health was given its fullest develop-
ment by Michael Grossman (1972).
Predating and postdating the theoretical and
econometric innovations of the 1960's is a
stream of research that focuses on health care
institutions, technology, and policy. As early
as 1932, Michael M. Davis and C. Rufus
Rorem (1932) were writing about the crisis in
hospital finance. Significant contributions to
this genre have been made by Henry Aaron,
Alain Enthoven, Rashi Fein, Eli Ginzberg,
Herbert Klarman, Dorothy Rice, Anne Scitovsky,
Anne and Herman Somers, Burton Weisbrod,
and many others. Although they are all econ-
omists, much of their work does not appear in
economics journals, but rather in books and in
publications such as the New England Journal
of Medicine, Journal of the American Medical
Association, Milbank Memorial Fund Quar-
terly, and Health Affairs.
In recent decades several leading health
economists have addressed theoretical, empir-
ical, and policy questions in various aspects of
their research (e.g., Joseph Newhouse, Mark
Pauly). Health economics has also been enliv-
ened and enriched by contributions from econ-
omists who are primarily specialists in other
fields such as industrial organization, labor, fi-
nance, and public economics (e.g., Sherwin
Rosen, Richard Zeckhauser). There has also
been a welcome infusion from another direc-
tion, namely physicians who have earned
Ph.D.s in economics and who now contribute
to the economics literature (e.g., Alan Garber,
Mark McClellan).
Parenthetically, all this name-dropping has
a point. I want to underscore the varied intellec-
tual, methodological, and ideological sources
that have contributed to the health economics
enterprise. Research has often been described
as lonely work, and in one sense it is. But in
another sense it is the most collective of all
human activities. The philosopher Susan Haack
(1995) sees scientific research as analogous to
an attempt by many participants to fill out a
huge crossword puzzle. We have clues; we try
out possible answers; we check to see whether
they fit together. Occasionally, an Arrow or a
Becker comes up with one of the really big
answers that runs across the puzzle and makes
it easier to discover the smaller words that in-
tersect it. If several of the small answers don't
fit, however, we may have to modify or even
reject the larger one. It is good to remember
that all answers are provisional until the puzzle
is completed-and it never will be.5
Although I have mentioned only American
economists, note should be taken of many fine
health economists in England, Canada, and
other high-income countries. There is, how-
ever, less of a global intellectual community
in this field than in some other branches of
economics'-or in other fields of health7-
because most health economics research is
applied and is (or is perceived to be) coun-
try specific. More than 60 years ago Walton
Hamilton (1932) noted that "The organiza-
tion of medicine is not a thing apart which can
be subjected to study in isolation. It is an
aspect of culture whose arrangements are
inseparable from the general organization of
society" (p. 190). On the whole I agree
with Hamilton; there are, however, important
economic questions concerning technology
assessment and disease prevention that are
common to all high-income countries. This
type of research does not receive support com-
mensurate with its importance because fund-
ing sources, both public and private, tend to
focus on national problems.
My involvement in health economics grew
out of my research on the service industries
(Fuchs, 1968, 1969). It was motivated in part
by a desire to gain a better understanding of
the postindustrial society that was emerging in
the United States and other developed coun-



### ---Economics-1996-0-04.txt---
tries (Fuchs, 1966, 1978a). The growth of the
service economy and improved methods of
contraception were bringing women into paid
employment and dramatically changing gen-
der roles and relationships. Lower fertility and
longer life expectancy were transforming the
age distribution of the population, and this
transformation, along with the fragmentation
of the family and the declining influence of
traditional religion, were creating new social
and economic conditions. The health sector,
with its nonprofit institutions, professional
dominance, sharply skewed distribution of de-
mand, and the critical importance of the con-
sumer in the production process, seemed like
a fruitful area for investigation. I was partic-
ularly interested in trying to understand the de-
terminants of health and the determinants of
health care expenditures.
With regard to health, my research has led
me to emphasize the importance of nonmedi-
cal factors such as genetic endowment, the
physical and psychosocial environment, and
personal behaviors such as cigarette smoking,
diet, and exercise. Over time, advances in
medical science contribute significantly to re-
ductions in morbidity and mortality; at any
given point in time, however, differences in
health levels within or between developed
countries are not primarily related to differ-
ences in the quantity or quality of medical
care.8
With respect to expenditures on medical
care, my research has led me to emphasize the
importance of supply factors, especially tech-
nology and the number and specialty mix of
physicians.9 To be sure, conventional demand
factors such as price, income, and insurance
play significant roles, but in my judgment con-
centration on them to the exclusion of (partly
exogenous) supply factors misses a big part of
the expenditures story. Despite many attempts
to discredit it,'? the hypothesis that fee-for-
service physicians can and do induce demand
for their services is alive and well.11
My views about health and health care ex-
penditures have been formed not only through
research but also through close interaction
with medical scientists, practicing physicians,
and other health professionals. Since 1968 I
have maintained a regular medical school fac-
ulty appointment in addition to my appoint-
ment in economics, and have participated
every year in a wide variety of health-related
activities. This dual life would have gained ap-
proval from John Stuart Mill who, in The Prin-
ciples of Political Economy (1848, reprinted
1987), wrote, "It is hardly possible to overrate
the value ... of placing human beings in contact
with persons dissimilar to themselves, and
with modes of thought and action unlike those
with which they are familiar ... Such commu-
nication has always been ... one of the primary
sources of progress" (p. 581).
The proposition that the discipline of eco-
nomics has a great deal to contribute to health
and medical care is not one likely to require
elaborate defense before this audience. (I have
had audiences that were less receptive to this
notion.) It might, however, be useful to report
briefly just what it was in economics that I
found to be most relevant in the invasion of
alien turf. (To avoid undue suspense, let me
say at once that it was not game theory.)
In my experience, the most important con-
tribution we make is the economic point of
view, which may be summed up in three
words: scarcity, substitutability, and hetero-
geneity. This economic point of view stands
in stark contrast to the romantic and mono-
technic points of view that I found prevalent
among health professionals and health policy-
makers. The romantic point of view refuses to
accept the notion that resources are inherently
scarce; any apparent scarcity is attributed to
some manmade problem, such as capitalism or
socialism, market failure or excessive govern-
ment interference. In the 1960's and 1970's,
many physicians said that there was no need
to limit expenditures for medical care if only

### ---Economics-1996-0-05.txt---
we would cut defense spending. In 1996, when
health care expenditures are almost four times
as large as the defense budget, this argument
is not heard as often. Because it denies the
inevitability of choice, the romantic point of
view is increasingly seen as impotent to deal
with the problems of health care."2
To be sure, it is not clear whether economic
research or the force of circumstances is bring-
ing about the change in point of view. I suspect
that there is a synergistic relationship in which
the former provides the language to give
expression to the latter. Or, as Max Weber
(1915; reprinted 1946) wrote, material and
ideal interests are the tracks on which society
rides, but ideas throw the switches (p. 280).
The monotechnic point of view, found fre-
quently among physicians, engineers, and oth-
ers trained in the application of a particular
technology fails to recognize the diversity of
human wants, or acknowledge the difference
between what is technically best and what is
socially desirable." "Optimal" care is defined
as the point where the marginal benefit is zero,
ignoring the fact that resources used for health
care have alternative uses that might yield
greater benefit. The "production" of health is
viewed narrowly as a function of inputs of
medical care, and the appropriate input mix
is assumed to be determined by technology
without regard to relative prices, explicit or
implicit. For example, Feldstein found that av-
erage lengths of stay in British hospitals were
uniform across regions despite large regional
differences in the pressures for admission.'4
The monotechnic view often fails to con-
sider the heterogeneity of preferences, even
though for many health problems there are al-
ternative interventions: one drug versus an-
other, drugs versus surgery, or even "watchful
waiting" versus any intervention. Under the
influence of economists and other behavioral
scientists, physicians are now making such
choices with more attention to patient differ-
ences in time preference, attitudes toward risk,
tolerance of pain, functional needs, and other
characteristics.
Among our specific tools, one of the most
useful is the idea of the margin. The key to
gaining acceptance for this principle is to have
people realize that most decisions involve a
little more or a little less, and that they will
make better decisions if they look at the costs
and benefits associated with having a little
more or a little less. This formulation is more
effective than postulating "maximization,"
which economists find useful for classroom or
research purposes, but sounds unreal to most
noneconomists.
David M. Eddy's research on the frequency
with which women should get Pap smears pro-
vides a fine example of the use of marginal (or
incremental) analysis to assist in medical
decision-making. This screening test for cer-
vical cancer is of proven safety and effective-
ness, and before Eddy's work appeared most
experts recommended that women obtain this
test annually. Using mathematical models and
clinical studies of the natural history of the dis-
ease, Eddy (a physician with extensive train-
ing in operations research and economics)
calculated the incremental cost of 1 additional
year of life expectancy with screening regimes
ranging from once every 6 months to once
every 5 years. The results were striking. Some
screening has a high yield at low incremental
cost, but as the frequency of screening is in-
creased from once every 2 years to once a year
the incremental cost rises to close to $1 million
per additional year of life expectancy (Eddy,
1980, 1987, 1990).15
The impact of Eddy's research on health
policy is worth noting. The American Cancer
Society accepted his conclusions and the So-
ciety's recommendation to screen once every
3 years made the front page of the New York


### ---Economics-1996-0-06.txt---
Times. The U.S. Surgeon General, the U.S. Pre-
ventive Services Task Force, and the American
College of Physicians supported this position,
and many individual physicians changed their
practice accordingly. Intense opposition came
from the American College of Obstetricians and
Gynecologists and the American Society of Cy-
tology. The contending groups finally negotiated
a compromise along the following lines: "Pap
smears should be done annually; after two or
more negative examinations the frequency can
be decreased." 16
The economist's distinction between move-
ment along a function and a shift in the function
is a very useful one. It is particularly applicable
in discussing the relationship between medical
care and health. At any given time in developed
countries the effects of additional medical care
on health are usually small, but over time ad-
vances in medical science have had significant
effects on health."7 Or consider the relationship
between infant mortality and per capita income.
At any given time income is a good predictor of
infant mortality, especially post-neonatal mor-
tality (28 days to one year). In log-log regres-
sions across the 48 states in 1937 and 1965, the
income elasticity of post-neonatal mortality was
-0.53 (0.11) and -0.49 (0.12) respectively.18
The decline in post-neonatal mortality between
1937 and 1965, however, was consistent with an
elasticity of -2.00. There was undoubtedly a
shift in the function associated with the intro-
duction of antibiotics and other advances in
medical science (Fuchs, 1974b). In 1991 the
elasticity was -0.73 (0.12) but the change from
1965 to 1991 was consistent with an elasticity
of -1.08, suggesting a further shift in the func-
tion, but not nearly so large as the shift between
1937 and 1965.
Economists have much to contribute to the
health field. What can they expect in exchange?
The most immediate benefit to me was the pres-
sure to make my lectures and research results
accessible, relevant, and credible to intelligent
but untutored and often unsympathetic audi-
ences. I was obliged to write clearly and simply
and to reconsider assumptions and conclusions
in economics that I might otherwise have ac-
cepted too readily. My experience was in accord
with that of Thomas Henry Huxley (1863) who
wrote, "Some experience with popular lecturing
has convinced me that the necessity of making
things plain to uninstructed people was one of
the very best means of clearing up the obscure
corners in one's own mind."
For example, one of the questions that trou-
bled me for a long time is why there is such
a strong correlation between health and years
of schooling. I originally believed that this
was another manifestation of the productivity-
enhancing effect of education. Schooling could
increase an individual's knowledge about the
health effects of personal behavior and medical
care options or could enable a person to better
process and act upon information about health
(Grossman, 1975). Or schooling could in-
crease an individual's ability to develop strat-
egies of self control (Richard A. Thaler and
H. M. Shefrin, 1981). I began to doubt the
schooling-causes-health hypothesis, however,
when it was observed that the favorable effect
of an additional year of schooling on health
does not diminish with increased years of
schooling. It is just as strong for those with
more than a high school education as for those
with less and continues right through graduate
school on up to the doctoral level (Grossman,
1975).19 I began to suspect that perhaps the cor-
relation was the result of some underlying dif-
ference among individuals that affects both
schooling and health.
To explore this question I examined sur-
vey data on smoking behavior collected
by colleagues in the Stanford Heart Dis-
ease Prevention Program as part of a health


### ---Economics-1996-0-07.txt---
education experiment designed to alter smok-
ing and other risks for heart disease (Nathan
Maccoby and Douglas S. Solomon, 1981).
Identical regressions of smoking on school-
ing were estimated at age 17 and at age 24,
with schooling measured in both cases as the
number of years the individual would even-
tually complete. The most striking result was
the absence of any increase in the size of the
schooling coefficient between the ages of 17
and 24. The additional schooling could not
be the cause of the differential smoking be-
havior (and by extension the differential
health associated with smoking) at age 24
because the differences in smoking were al-
ready evident at age 17, before the dif-
ferences in schooling had emerged (Philip
Farrell and Fuchs, 1982) .20
In my judgment, the most likely explanation
for the high correlation between health and
schooling is that both reflect differences in
time preference (Fuchs, 1982). Both health
and schooling are aspects of investment in hu-
man capital; differences among individuals in
time preference that are established at an early
age could result in different amounts of in-
vestment in health and education.21
Although I believe there have been many
fruitful interactions between economics and
health, the political debate over health care
reform in 1993-1994 benefited much less
than it could have from the insights of econ-
omists. Possible explanations for the failure
of health economics research to have more
impact on policy are explored in the next
section.
II. The Present
George Stigler's Presidential Address to the
American Economic Association in December
1964 was distinctive in its emphasis on proph-
ecy over preaching. To be specific, Stigler pre-
dicted that economics was "at the threshold of
its golden age" (Stigler, 1965 p. 17) because
"the age of quantification is now full upon us"
(p. 16). The growth of empirical estimation
was, for Stigler, "a scientific revolution of the
very first magnitude" (p. 17). He believed
that empirical research would have an impact
on policy far beyond anything possible from
theory alone because "a theory can usually be
made to support diverse policy positions. The-
ories present general relationships, and which
part of a theory is decisive in a particular con-
text is a matter of empirical evidence" (p. 13).
With regard to health care, Stigler's predic-
tion of a vast expansion in empirical research
has been amply fulfilled. During the past 30
years economists have published thousands of
empirical articles on various aspects of health
and medical care. But the shallow and incon-
clusive debate over health policy in 1993-
1994 contradicts his expectation that this
research would narrow the range of partisan
disputes and make a significant contribution to
the reconciliation of policy differences.22 What
went wrong?
One possibility is that the research was in-
conclusive. If health economists cannot agree
among themselves, why should their research
have a salutary effect on public policy? Sec-
ond, even if the research were conclusive, it
would not be of much help to policy if the
results were not adequately disseminated to a
wider audience. A third possible explanation
is that the policy debate foundered on differ-
ences in values, differences which could not
be reconciled by empirical research, however
conclusive and however well disseminated.
To gain some insight into these matters,
I prepared a 20-question survey concerning
health economics and health policy and sent it
to health economists, economic theorists, and
practicing physicians. The health economists
were those whom I considered to be the lead-

### ---Economics-1996-0-08.txt---
ing people in the field, plus some of the more
promising recent Ph.D.s. There were 46 re-
spondents (response rate 88 percent). The the-
orists were also leaders in the field; I was
assisted in selecting them by two eminent the-
orists." There were 44 respondents (response
rate 63 percent). The practicing physicians
were reached through my personal contacts,
and include colleagues and friends of those
contacts. Nearly all are in private practice, not
teaching, research, or administration. They are
located on both the east and west coasts in
small towns and large cities. The practice set-
tings vary from solo to a group of over 100
physicians, and in organizational form from
traditional fee-for-service to capitation. They
include generalists, surgical specialists, and
nonsurgical specialists. There were 42 physi-
cian respondents (response rate 89 percent).
The participants were asked to indicate
whether they agree or disagree with each of 20
relatively short statements; they were also
given the option of answering "no opinion."
Ten percent of the health economists' replies
were "no opinion"; the theorists used that op-
tion 19 percent of the time, and the physicians
11 percent. Participants were also invited to
qualify any of their replies by jotting com-
ments on the back of the survey. The percent-
age of replies that were qualified was 8, 5, and
3 for the health economists, theorists, and phy-
sicians, respectively. Participants were told to
assume that the statements refer to the United
States in 1995, other things held constant. For
statements with more than one part, "agree"
would indicate that the respondent agreed with
all parts of the statement. The order of the
questions was determined randomly, and re-
spondents were guaranteed anonymity.
Three experts24 from three different univer-
sities who were not participants in the survey
were asked to identify which of the 20 ques-
tions were relatively value-free ("positive"
questions) and which had substantial value as-
pects ("policy-value" questions). Their in-
dependent replies were almost unanimous in
identifying seven of the questions as "posi-
tive," and thirteen as "policy-value." Table 1
shows the percent agreeing for each question,
with the two types of questions grouped sep-
arately. Question numbers refer to the ordering
of the questions in the survey. The policy-
value questions are presented in three groups:
four that pertain directly to national health in-
surance, three that pertain directly to health
insurance company underwriting, and all oth-
ers. Questions for which the percentage agree-
ing differs significantly from a 50-50 split (by
a chi-square test) are identified with asterisks.
We see in Table 1 that the degree of con-
sensus on positive questions among health
economists is extremely high.25 In six of the
seven cases the hypothesis that the observed
split differs from a 50-50 split simply by
chance is rejected with p < 0.01 and the sev-
enth with p < 0.05. There is also a high degree
of consensus among economic theorists, but
for two of the questions (12 and 13) the ma-
jority of theorists gave replies opposite to
the majority of health economists. Consensus
among the physicians on the positive questions
was more rare. In no case did the split differ
from 50-50 with p < 0.01, and in only three
cases was the split significant at p < 0.05. For
one question (4) the majority of physicians
gave replies opposite to the majority of health
economists.26
When we turn to the policy-value questions,
agreement among the health economists drops
sharply. For example, in replies to the four ques-
tions dealing with support for national health in-
surance, the health economists never depart
significantly from a 50-50 split. On question 8,



### ---Economics-1996-0-09.txt---



### ---Economics-1996-0-10.txt---

which would require insurance companies to
cover all applicants regardless of health condi-
tion with no premium surcharge for the sick, the
health economists are evenly divided: 51 percent
agree and 49 percent disagree. Among economic
theorists there is slightly more agreement on
policy, but not as much as among practicing
physicians who, contrary to both groups of econ-
omists, show more agreement on policy-value
than on positive questions.
The contrasts between the replies by group
and type of question are brought more sharply
into focus in Table 2, which shows the ave-
rage absolute difference between the percent-
age agreeing and the percentage disagreeing.
Among health economists the extent of con-
sensus for the positive questions is sig-
nificantly larger than for the policy-value
questions regardless of whether the compari-
son is between means or medians. Although
the sample sizes are very small (7 and 13 ), the
differences by type of question are so large we
can reject the null hypothesis with consider-
able confidence.27
It is also worth noting that the extent of
agreement among health economists on the
positive questions is much higher than is usu-
ally found in surveys of economists covering
a wide variety of fields. For example, in a
survey conducted by Richard M. Alston et al.
(1992) the authors identify ten questions as
"micro-positive" and seven as "micro-
normative."28 In order to achieve compar-
ability between their survey and mine, I
combined their "agree, with provisos" with
their "agree," and then calculated the mean
absolute difference between percentage agree-
ing and percentage disagreeing.29 This differ-
ence (22 percentage points) was much smaller
(and less statistically significant) than the dif-
ference I found for the health economists.


### ---Economics-1996-0-11.txt---
Why is there so little agreement among econ-
omists regarding policy-value questions when
there is so much agreement on the positive
questions? One possible explanation is differ-
ences in values. Most health policy decisions
have significant implications for freedom, effi-
ciency, justice, and security. Health economists
(like other Americans) probably desire all these
goals, but (again like other Americans) they
probably differ in the values they attach to
them, or in the way they define them,3' and
these differences could lead to sharply different
views about policy.
Another possible explanation is that there
are positive questions embedded in the policy-
value questions and that health economists dis-
agree with respect to those positive questions.
This is the view taken by Milton Friedman in
195332 although he subsequently modified his
position in 1966 and 1995.33 In order to gain
some insights concerning the roles of values
and embedded positive issues in policy differ-
ences I take a closer look at the policy-value
questions bearing on national health insurance
(3, 7, 14, 15) and on insurance company un-
derwriting (8, 17, 20).
Consider, for instance, question 3 which
calls for some national plan to cover the entire
population. The 62-38 percent split among
health economists may well reflect differences
in values, with those who agree placing a high
value on providing all Americans with the
right to have access to health care. On the other
hand, it is readily apparent that there are many
positive questions embedded in this policy-
value question. For instance, most economists
see a loss in efficiency from requiring every-
one to have the same health insurance, but they
probably differ in their estimates of the extent
of the loss. Some may even believe there is a
net gain in efficiency because of imperfections
in the private market for health insurance.
Strongly held differences about this positive
question could produce different answers to
question 3 even among respondents with sim-
ilar values.
Some of the positive questions embedded in
question 3 may be beyond the scope of con-
ventional economics. For instance, Professor
A may favor national health insurance in part
because she believes it will contribute to a
more stable and harmonious society.34 Profes-
sor B may disagree with that prediction, and
is therefore less inclined to support national
health insurance.
The role of embedded positive questions
can also be easily discerned in the three ques-
tions (8, 17, 20) dealing with insurance com-
pany underwriting. Health economists strongly
support charging higher premiums for smokers
than for nonsmokers, but are strongly opposed
to charging higher premiums to individuals
born with genetic defects. On question 8, deal-
ing with requiring insurance companies to in-
sure the sick with no premium surcharge, the
health economists are evenly split. One of the
positive questions embedded in question 8 is
the reason for people's illness. If a respondent
thought that most illness was the result of ge-
netic differences, the reply would presumably
be consistent with the answer to question 20.
On the other hand, if most illness was assumed
to be the result of personal behaviors like cig-
arette smoking, the reply would probably be
consistent with the one given to question 17.
Inasmuch as leading medical scientists have
strongly divergent views about the importance
of genetic factors in disease, it is hardly
surprising that health economists are unable
to reach agreement. The state of knowledge
about the links between genes and disease is


### ---Economics-1996-0-12.txt---
constantly changing. Thus, if cigarette smok-
ing were found to be determined primarily by
genetic factors, the answers to question 17
would probably change even in the absence of
any change in values.
Positive economic questions are also em-
bedded in the insurance company underwriting
issues. Most economists realize that requiring
health insurance companies to charge healthy
people the same premium as those with a ge-
netic disease will deter healthy individuals
from purchasing insurance. But economists
may well differ as to how large that effect will
be and how large a welfare loss it implies.
It is easy to see that there are positive ques-
tions embedded in the policy-value questions,
but it is more difficult to believe that disagree-
ment over them, rather than differences in
values, explains the low level of consensus
among health economists with respect to the
policy-value questions. Note that the physi-
cians have a higher level of consensus about
the policy-value questions than do the health
economists. This probably reflects more ho-
mogeneous values among physicians rather
than agreement about the embedded positive
questions. (Note the low level of agreement
among physicians on the explicit positive
questions.)
It may be that it is not so much disagreement
among health economists about the embedded
positive questions as it is uncertainty about
them that make differences in values the
driving force in replies to the policy-value
questions. Many psychologists and economists
have observed that uncertainty about a datum
causes most individuals to give it less weight
when making choices.:
Uncertainty among health economists con-
cerning the positive questions that are embed-
ded in the policy-value questions is suggested
by their use of the "no opinion" option. Un-
like the theorists, who chose "no opinion"
twice as often for the positive questions as for
the policy-value questions (28 percent versus
15 percent), the health economists chose "no
opinion" less often for the positive questions
than for the policy-value questions (8 percent
versus 11 percent).36 The role of uncertainty
was mentioned by Milton Friedman in 1966 as
a reason for qualifying his position about the
relative imeportance of scientific judgment and
value differences (Friedman, 1966 p. 6).
In order to investigate further the relation-
ship between policy-value and positive ques-
tions, I developed two indexes based on the
answers to the national health insurance and
insurance underwriting questions. The first in-
dex measures each respondent's support for
national health insurance. It is constructed by
assigning a value of 1 to agreement with each
of questions 3, 7, 14, and 15, a value of 0 for
disagreement with those questions, and a value
of 0.5 for no opinion. The sum of the values
was divided by 4, giving a range for the index
of 1 (indicating agreement with all four ques-
tions) to 0 (indicating disagreement with all
four questions). The "actuarial" 37 model in-
dex was based on answers to questions 8, 17,
and 20. In the case of question 8, "disagree"
was given a value of 1, and for questions 17
and 20 "agree" was given a value of 1. The
total score for each individual is divided by 3,
again yielding a range for the index from 1 to
0 (indicating complete support or complete re-
jection of the actuarial approach).
The results are presented in Table 3. We
see that with respect to national health insurance
the support among the three groups is virtually
identical. There is considerable variation around
the mean for each group, and the amount of vari-
ation is similar across thOe groups. Thirteen per-
cent of all respondents had an index value of 1,
while 15 percent completely rejected the notion
of national health insurance with an index value
of 0. Not surprisingly, there is a negative cor-
relation between the national health insurance
index and the actuarial model index. But there


### ---Economics-1996-0-13.txt---

is a significant difference between the groups in
the extent of support for the actuariai model in-
dex. The economic theorists have a value of
0.61, compared with 0.46 for the health econo-
mists and 0.44 for the practicing physicians. The
theorists are as supportive of national health in-
surance as are the other groups, but if insurance
is to be provided through the private market, the
theorists are more inclined than the other two
groups to have premiums reflect expected loss.
One reasonable interpretation of this result is that
the theorists give more weight to the efficiency
aspects of the actuarial model, whereas the
health economists and the practicing physicians
give more weight to the distributional aspects.
Is there a close relationship between the re-
spondents' scores on the indexes and their
responses to the positive questions? The corre-
lation coefficients presented in Table 4 show
that the answer is overwhelmingly in the nega-
tive. For the national health insurance index
there is only one positive question (10) for one
group (the health economists) that reaches sta-
tistical significance with p < 0.05. For the ac-
tuarial model index, only questions 9 and 10
show a significant relationship for the health
economists, and questions 10 and 12 for all
groups taken together. Whatever it is that is de-
termining the respondents' positions with regard
to national health insurance or the actuarial ap-
proach, it is not their views on the seven positive
questions.
Correlations between the indexes and the six
policy-value questions not utilized in their
construction also are typically low, with one
striking exception. Respondents agreeing with
question 5, which calls for national standard-
ized health insurance benefit packages, also
support national health insurance and just as
clearly reject the actuarial approach for private
insurance underwriting. The actuarial model
index is also negatively correlated with agree-
ment with question 1.
The weak relationship between the positive
questions and the two indexes is also revealed
in Table 5, which presents the results of re-
gressing the indexes on the positive ques-
tions.38 In the national health insurance

### ---Economics-1996-0-14.txt---

regression the only statistically significant co-
efficient is for question 10 for health econo-
mists. Other things being equal, those who
agree with the induced-demand hypothesis are
more supportive of national health insurance
than those who disagree, but the effect on the
index (0.239) is less than changing one of the
four answers from disagree to agree. The ac-
tuarial model regressions result in a few ad-
ditional significant coefficients but, in general,
the respondents' replies to the explicit positive
questions do not explain their position with re-
spect to such major policy issues as national
health insurance or insurance company under-
writing changes. It seems unlikely, then, that
their position on these policy issues can be ex-
plained by differences in the embedded posi-
tive questions.
Although I believe that differences in values
lie at the heart of the disagreement about
policy-value questions, I recognize that there
is scope for work on the embedded positive
questions and this work could contribute to a
narrowing of policy differences. One indica-
tion of where research is needed is the percent
of health economists answering "no opinion"
on the individual policy-value questions. This
option was chosen most frequently (35 percent
of the time) for question 11 concerning the
optimality of expenditures on medical R&D.39
Given the importance of technologic change
in medicine both from the point of view of
health outcomes and of expenditures, this is
clearly a high-priority area for research. Two
other questions elicited a "no opinion" re-
sponse from one fifth of the health economists.
They are question 1 concerning the subsidies
for health insurance by size of firm (a key part
of the Clinton plan) and question 20 (about
differential premiums for persons born with
genetic defects). In the latter case the high per-
centage responding "no opinion" may reflect
uncertainty regarding the magnitudes of the
efficiency and distributional implications of


### ---Economics-1996-0-15.txt---



### ---Economics-1996-0-16.txt---
eliminating premium differentials. Or, it may
reflect a reluctance to choose between conflict-
ing values.
Before leaving the survey it is worth con-
sidering what it reveals about the ability of
health economists to disseminate their conclu-
sions about the positive questions to a wider
audience. Overall, one must conclude that they
have not been very successful, as revealed by
the political debate of 1993- 1994 and the me-
dia coverage of policy issues. Consider, for
example, question 19 concerning whether in
the long run employers bear the primary bur-
den of their contributions to their employees'
health insurance. Although 87 percent of the
health economists disagreed with that state-
ment, politicians on both sides of the debate
assumed, erroneously, that it was correct.
Moreover, nearly all of the media made the
same error. Most of the politicians and most
of the media also showed little understanding
of questions 4, 12, 13, and 18.
I am as ready as the next economist to
criticize politicians and journalists, but the
survey results suggest that their poor under-
standing of health economics is not entirely
their fault. First, the economic theorists
and the practicing physicians, two groups with
above-average ability and opportunity to ab-
sorb the conclusions of the health economists,
did not show good command of the positive
questions. In my judgment the health econo-
mists answered 80 percent correctly, but the
average theorist answered only 52 percent cor-
rectly and the mean score for the physicians
was only 53 percent. The differences in the
distributions of scores is striking: 45 of the
46 health economists had more correct an-
swers than the average theorist or the average
physician.
A second possible reason for the poor un-
derstanding of health economics displayed by
the politicians and the media in 1993-1994 is
the wide disagreement among health econo-
mists over the policy-value questions. When
health economists interact with politicians and
journalists, their discussions probably focus on
the policy-value questions; in the absence of a
professional consensus on many of these ques-
tions, it is not surprising that politicians and
journalists fall back on their own values to
shape their positions.
Returning to the question posed at the be-
ginning of this section about why economic
research failed to result in a more informed
and productive health care policy debate, the
survey results provide some provisional an-
swers. First, although health economists are
in substantial agreement about the positive
questions, they have major disagreements
about policy-value questions. Second, health
economists were not successful in getting
their conclusions on positive questions ac-
cepted by the politicians or the media, and
even had difficulty in communicating their
results to economic theorists and practicing
physicians. Third, the health economists'
disagreements over policy probably reflect
differences in values, although it is clear that
there are many positive questions embedded
in the policy-value questions. In my judg-
ment the problem is not so much that the
health economists disagree about the embed-
ded questions as that they are uncertain
about them. In the face of such uncertainty,
they tend to let their values drive their policy
recommendations.
III. The Future
If values play such an important role in pol-
icy disputes, what are the implications for
economics and economists? First, we should
endeavor to make explicit the differences in
values, and seek ways to resolve them. Value
differences can take many different forms.
Economists are most familiar with the distinc-
tion between efficiency and distributional is-
sues, especially greater equality of income
versus greater total income.40 But comprehen-
sive changes in health policy can have other
important distributional effects. Even for in-
dividuals at the same income level, the costs
and the benefits of care could change along
many dimensions: rural areas versus central
cities, the elderly versus the young, smokers
versus nonsmokers, savers versus nonsavers,
men versus women, and so on. Health econ-
omists who are unanimous in approving gains
in efficiency might have very different views


### ---Economics-1996-0-17.txt---
regarding the desirability of the distributional
changes and might also differ in the weights
they give to the changes in efficiency versus
the distributional consequences.
Second, greater openness about value dif-
ferences should force economists to make ex-
plicit the positive questions that are embedded
in most policy-value questions. This would
point the way to productive research. If the
embedded questions are identified and studied,
it should be possible to reduce the uncertainty
about them and thus provide a basis for nar-
rowing differences on policy-value questions.
A third agenda item for economists is to un-
dertake research on the formation of values,
especially insofar as they are the consequences
of policy. Economists are understandably re-
luctant to prescribe values or to make nor-
mative judgments about them. But when
economic policies affect values and prefer-
ences, and these in turn affect behavior, it is
incumbent on economists to analyze the links
between policies and values, and to examine
the economic and social consequences of al-
ternative value systems. I believe there is an
analogy between the economics of values and
the economics of technology. Over the past
several decades some economists have begun
to treat technology as at least partly endoge-
nous.4" Now, a similar effort must be un-
dertaken for values (Henry J. Aaron, 1994;
Becker, 1996; Albert 0. Hirschman, 1986;
Assar Lindbeck, 1994).
Finally, economists must develop more self-
awareness of how our values color our judg-
ment about policy, and more candor in making
clear to others the respective roles of positive
research and of values in our policy recom-
mendations. Alice M. Rivlin, in her AEA pres-
idential address in December 1986, warned
economists against letting "their ideological
position cloud their judgment about the likely
effects of particular policies" (p. 4). She
urged us "... to be more careful to sort out, for
ourselves and others, what we really know
from our ideological biases" (p. 9). In my
view, there is a vast difference between a re-
searcher and a reformer, between an analyst
and a player in the policy arena. They are all
socially valuable occupations, and the same
individual may successfully wear different
hats at different times. What is not likely to
work well, either for economics or for policy,
is trying to wear two hats at the same time.
In the remainder of this paper I present a
summary of my policy recommendations for
health system reform. The use of the bully pul-
pit by an AEA president to push personal pol-
icy choices has ample precedent, but I also
want to use this opportunity to show how those
choices are shaped by the interaction between
my values and my understanding of health
economics. Finally, I identify aspects of my
policy recommendations that are problematic
and which would clearly benefit from addi-
tional research.
My three major recommendations are:
(i) a broad-based tax earmarked for health
care to provide every American with a
voucher for participation in a basic plan;
(ii) provision of care through integrated health
systems that include hospitals, physician
services, and prescription drugs. These
systems would be led by physicians, would
be reimbursed by capitation plus modest
co-payment from patients at the time of
use, and would be required to offer a wide
variety of point-of-service options to be
paid for by patients with after-tax dollars;
(iii) a large private center for technology as-
sessment financed by a small industry-
wide levy on all health care spending.
My desire to see all Americans insured for
a basic health plan is clearly driven in part by
values. Although medical care is often not a
crucial factor in health outcomes, it is nearly
always a source of utility through its caring
and validation functions. In my judgment, it
fully meets Adam Smith's 1776 definition of
a necessary: "By necessaries I understand not
only the commodities which are indispensably
necessary for the support of life but whatever
the custom of the country renders it indecent
for creditable people, even of the lowest order,
to be without" (1776; republished 1937 p.
821). To achieve universal coverage there
must be subsidization for those who are too



### ---Economics-1996-0-18.txt---
poor or too sick to acquire insurance, and there
must be compulsion for the "free riders" 42 to
pay their share.
There are only two ways to achieve system-
atic universal coverage: a broad-based general
tax with implicit subsidies for the poor and the
sick, or a system of mandates with explicit
subsidies based on income. I prefer the former
because the latter are extremely expensive to
administer and seriously distort incentives;
they result in the near-poor facing marginal tax
rates that would be regarded as confiscatory if
levied on the affluent.43
Both theory and experience show that inte-
grated health care systems are usually the best
way to deliver cost-effective care. The primary
reason is the physician's central role in medi-
cal decision-making. Under any approach to
care, it is the physician who admits patients to
hospitals, orders tests and other procedures,
and decides when to discharge. It is the phy-
sician who prescribes drugs and who refers
patients to other physicians for consultation
and treatment. Thus physicians' decisions
are the major determinant of the cost of care.
Only in an integrated system, however, do
physicians have the incentive, the informa-
tion, and the infrastructure needed to make
these decisions in a cost-effective way. In-
tegrated systems also have an advantage in
avoiding excess capacity of high-cost equip-
ment and personnel.
Given the central importance of physicians
to medical care, I believe the integrated sys-
tems should be led by them and other health
care professionals. At a minimum, health care
professionals should have a prominent place
in the govermance of the systems. One of the
greatest errors of health policy-makers today
is their assumption that market competition or
government regulation are the only instru-
ments available to control health care. There
is room for, indeed need for, a revitalization
of professional norms as a third instrument of
control.' The patient-physician relationship
often is highly personal and intimate, similar
in many ways to relationships within families
or between teachers and pupils or ministers
and congregants. This relationship is, in part,
what economist Kenneth Boulding (1968)
called an integrative system, one that depends
on mutual recognition and acceptance of rights
and responsibilities, enforced by traditional
norms as well as market pressures and govern-
ment regulations. As long as physicians con-
trol the use of complex technology in life and
death situations, and as long as we expect them
to perform priestly functions, they must be en-
dowed with certain privileges and held to cer-
tain standards of behavior different from those
assumed by models of market competition or
government regulation.45
Comprehensive government control of medi-
cal care has not worked well in any setting.
The essence of good care is an informed pa-
tient working cooperatively with a health pro-
fessional who provides personalized attention
and concern. The rules, regulations, and bu-
reaucratic controls that almost always accom-
pany governmental activities are inimical to
high-quality cost-effective care. It is revealing
that countries such as England and Sweden
with deep government involvement in the
financing of medical care have bent over back-
wards to leave physicians with a great deal of
professional autonomy-indeed more auton-
omy than is possessed by many American phy-
sicians working in a "private" system.
Market competition also has its problems. It
assumes a preoccupation with the bottom line
and governance by a corporate mentality that
judges the success of each division by its profit
growth. Physician-led systems will also have 

### ---Economics-1996-0-19.txt---
to pay attention to costs, and physicians will
also be interested in making a good income,
but there is a vast difference between a profit-
maximizing corporation and physicians who
strive to balance their obligations to patients,
the organization, and themselves.46
Reimbursement of these integrated systems
should be primarily by capitation, adjusted
for patient characteristics. In addition, pa-
tients should be required to make modest co-
payments at the time of use (e.g., $15 for each
visit and $5 for each prescription). Such pay-
ments will generate some income but, more
important, will help to discourage wasteful use
of health care. The payments could be waived
for patients living below the poverty level,
and for essential preventive services such as
vaccination.
The earmarked tax would provide every
American with a voucher for a basic health
care plan. Each integrated system would be
required to offer the basic plan, plus a variety
of options. These options are not alternative
insurance plans; they are services to be paid
for at time of use with after-tax dollars.47 The
options could take many forms: a private room
in the hospital; a wider choice of physicians
and hospitals than is available through the ba-
sic plan; or access to new experimental tech-
nologies or older technologies not included in
the basic plan because they have a low benefit-
to-cost ratio.48
These options would accommodate the de-
mands of patients with higher incomes or
those who choose to spend more of their in-
come on medical care. The options would not
constitute establishment of different plans. Ev-
eryone would be in the same plan and most
persons would stick to the basic plan most of
the time. An option would be exercised only
when the patient desired and was willing to
pay for it. This is the quintessential American
approach to balancing equality and freedom.
On the one hand, this approach avoids the
egalitarianism of the English and Canadian
systems in which only a small elite have an
escape valve. On the other hand, it does not
create a separate plan for the poor while the
great majority of Americans obtain care from
a different system. The experience with Med-
icaid shows that a separate system limited to
the poor is not likely to function well.
Where feasible, the integrated health care
system would engage in managed competi-
tion.49 Having advocated policies similar to
such an approach to health care for more than
20 years (Fuchs, 1974a), I am not unmindful
of its virtues. We cannot, however, rely on
managed competition alone to contain costs.
In most rural areas, population density is too
low to support several health care systems.
Even in some urban areas, competition is im-
possible or undesirable because of economies
of scale. For instance, only one hospital is
needed to serve a population of 100,000 effi-
ciently. Similar constraints apply to competi-
tion in physician specialty care, especially if
the physicians work full time at their special-
ties. A population of 1 million would probably
not justify enough independent maternity ser-
vices or open-heart surgery teams to create
competitive conditions. Moreover, the public
interest is not best served by insisting that
health professionals always maintain rigorous
arm' s-length competition with one another.
Patients can benefit from cooperation among
physicians and hospitals, both in reduced costs
and better service. Managed competition alone
will not be enough to contain costs; it must be 


### ---Economics-1996-0-20.txt---
supplemented by constraints on the supply
side, especially with respect to technology and
the specialty mix of physicians.
In 1995 Americans spent about $1 trillion
for health care, broadly defined. If, during the
past 30 years, health care spending had grown
at the rate of the rest of the economy, the
health care bill in 1995 would have been only
a little more than $400 billion. What accounts
for this extraordinary excess of almost $600
billion in annual spending? There has been a
small increase in physician visits per capita,
but use of acute care hospitals has decreased
sharply. Patient-days per 1000 population are
less than three fifths the level of 30 years ago.
By far the most important factor accounting
for the increase in health care's share of the
GDP is the change in technology.50 Physician
visits and hospital-days cost more than they
used to because the content has changed-the
technologies used for diagnosis and treatment
are more expensive than in the past. Much of
this technological change is welcome; it con-
tributes to enhancing the length and quality of
life. Some of the change is less desirable be-
cause it adds more to cost than to patient ben-
efit. Unfortunately, there is great uncertainty
regarding the merits of many technologies.
Moreover, even when the advantages and dis-
advantages are known, there are often signif-
icant barriers facing physicians who would
like to practice in a cost-effective manner.
To deal with this problem, I propose the cre-
ation of a large, private center for technology
assessment. Financing for this center would
come from a small levy (less than one tenth of
1 percent) on all health care spending. A cen-
tralized approach is necessary, because health
care is highly fragmented. Individual physi-
cians and health plans lack the incentive and
ability to commit the resources needed to as-
sess -new technologies. Even the largest insur-
ance companies individually account for only
a small percentage of the health care market;
they are, therefore, understandably reluctant to
pay for large-scale assessments that would
benefit all.51 Government agencies try to fill
the void, but the scale of effort is too small,
and a private center would be able to avoid the
political interference that often intrudes on
government-run agencies.52 Health care pro-
viders would fund and set the agenda for the
center, much as the electric power companies
do for the Electric Power Research Institute.
This institute is financed by a small levy on
every public utility bill.
A health care technology assessment center
would have two primary functions. First, it
would help to develop and disseminate system-
atic knowledge about the cost-effectiveness of
medical technology through support of research
and through a comprehensive program of
publications and conferences. The center would
have some intramural research capability, but
most of the research would be conducted extra-
murally at medical schools, hospitals, and re-
search institutes throughout the country. It would
provide health professionals with essential in-
formation to evaluate and improve their clinical
practices and offer a rational basis for deciding
what services should be included in the basic
plan.
The second important function would be to
provide legitimacy for the cost-effective prac-
tice of medicine. Currently, many directors of
health plans and many individual physicians
know they could be practicing in a more cost-
effective way, but they are inhibited from do-
ing so because they do not practice in a
vacuum. Physicians are influenced by peers
who have been trained in settings that empha-
sized the use of the latest technologies regard-
less of cost. Patients come with particular sets
of expectations based on what they read or
hear in the media and what their relatives and
friends tell them has been their experience.
The threat of malpractice suits lurks in the
background. A major function of the center

### ---Economics-1996-0-21.txt---
would be to give legitimacy and a stamp of
authority to physicians who practice in a more
cost-effective way.
My policy recommendations seek to achieve
a balance among the diverse values of effi-
ciency, justice, freedom, and security. The link
between the earmarked tax and the basic plan
would create a healthy tension between the de-
sire to increase benefits and the need to pay
for the increase in a responsible and equitable
manner. Competition among health care sys-
tems in highly populated areas would widen
choice and foster cost-effective practice. The
private technology assessment center would
help to contain costs without the imposition of
controls or caps that might stifle innovation
and progress.
Are these recommendations politically sale-
able? In the short run, certainly not. But nei-
ther are any other proposals for comprehensive
reform. Indeed, for more than 20 years it has
been my view that the United States would not
enact comprehensive health care reform ex-
cept in the wake of a major war, a depression,
large-scale civil unrest, or some other event
that completely changed the political cli-
mate. Why is the United States the only major
industrialized nation without national health
insurance? Many observers focus on the op-
position of "special interests," and that cer-
tainly is a factor, but I do not find it a
completely satisfactory explanation. After all,
special interests are not unknown in Sweden,
England, Canada, and other countries that do
have national health insurance.
In 1976 I suggested four reasons for its ab-
sence in the United States: distrust of govern-
ment, heterogeneity of the population, a weak
sense of noblesse oblige, and strong private
voluntary organizations such as nonprofit hos-
pitals and Blue Cross and Blue Shield plans
that carry out quasi-governmental functions
with respect to the financing and delivery of
health care (Fuchs, 1976). Upon revisiting
this question (Fuchs, 1991), I concluded that
the first three reasons were stronger than ever,
but the fourth had weakened considerably. It
is ironic that "the competition revolution"
(Fuchs, 1988b), which erodes the ability of
not-for-profit health care institutions to pro-
vide a modicum of social insurance through
community rating and cost shifting, may in the
long run push the country toward national
health insurance.
My plan is certainly not a panacea; it would
be difficult to implement and others might
seek a different balance of values. Several as-
pects require additional research. For example,
what should be the content of the basic plans?
How should the content change over time?
How should the plans be reimbursed from the
funds raised by the earmarked tax, and espe-
cially how should reimbursement be risk ad-
justed to take account of differences in plan
populations? Another problem is how to en-
courage competition among plans where it is
feasible, while recognizing that a competitive
approach will not be desirable or possible in
areas of low population density. Considerable
research is needed on how the out-of-plan op-
tions should be priced53 and how the providers
of such care should be reimbursed. Finally,
much thought should be given to how to re-
invigorate professional norms as a third in-
strument of control, along with market com-
petition and government regulation.54
I conclude this tour of health economics-
past, present, and future-on a mildly opti-
mistic note. In the past three decades econom-
ics has made a positive contribution to health
and medical care, and I believe that future con-
tributions will be even greater. Now that the
basic ideas of economics are gaining accep-
tance, it will be more important than ever for
economists to master many of the intricacies
of health care institutions and technologies.
We will also have to consider the problems of
dissemination in order to insure that when we
agree on research results, these results are un-
derstood and accepted by all relevant audi-
ences including the media, politicians, and
health professionals. Moreover, we must pay
more attention to values than we have in the
past. Through skillful analysis of the interac-
tions between values and the conclusions of
positive research, we will be able to contribute
more effectively to public policy debates. And,



### ---Economics-1996-0-22.txt---
if health economists are successful in this de-
manding assignment, we can lead the way to-
ward progress in areas such as child care and
education that face similar problems of rec-
onciling multiple goals and heterogeneity in
values. To be useful to our society while de-
riving pleasure from our work-in the words
of the old Gershwin tune, "Who could ask for
anything more?"
## Economics-1997-0


### ---Economics-1997-0-02.txt---
The improvement in living standards, life
expectancy, and economic growth prospects in
developing countries ranks among the most
important economic success stories since the
Second World War. Growth in some has been
dramatic, and while progress has been far from
uniform, there are grounds for optimism that
future growth prospects can be even better
than performance to date.
One factor accounting for that success has
been improved understanding and adoption of
economic policies much more conducive to sat-
isfactory economic growth than was the case in
the 1950's and 1960's. That better understand-
ing, in turn, resulted from a combination and
interaction of research and experience with de-
velopment and development policy.
Ideas with regard to trade policy and eco-
nomic development are among those that have
changed radically. Then and now, it was rec-
ognized that trade policy was central to the over-
all design of policies for economic development.
But in the early days, there was a broad consen-
sus that trade policy for development should
be based on "import substitution." By this
was meant that domestic production of import-
competing goods should be started and increased
to satisfy the domestic market under incentives
provided through whatever level of protection
against imports, or even import prohibition, was
necessary to achieve it. It was thought that im-
port substitution in manufactures would be syn-
onymous with industrialization, which in turn
was seen as the key to development.
The contrast with views today is striking. It
is now widely accepted that growth prospects
for developing countries are greatly enhanced
through an outer-oriented trade regime and
fairly uniform incentives (primarily through
the exchange rate) for production across ex-
porting and import-competing goods.' Some
countries have achieved high rates of growth
with outer-oriented trade strategies. Policy re-
form efforts removing protection and shifting
to an outer-oriented trade strategy are under
way in a number of countries. It is generally
believed that import substitution at a minimum
outlived its usefulness and that liberalization
of trade and payments is crucial for both in-
dustrialization and economic development.
While other policy changes also are necessary,
changing trade policy is among the essential
ingredients if there is to be hope for improved
economic performance.
And, while there are still some disagree-
ments over particular aspects of trade policy
both among academic researchers and policy
makers,2 the current consensus represents a
distinct advance over the old one, in terms
both of knowledge and of the prospects it
offers for rapid economic growth. While it
will no doubt be further refined in light of


### ---Economics-1997-0-03.txt---
experience, a changing world economy, and
research, there is no question of "going back"
to the earlier thinking and understanding of the
process.
A number of interesting questions arise
about this change in thought and policy.
How could it happen that a profession, for
which the principle of comparative advan-
tage was one of its key tenets, embraced such
protectionist policies? What was the contri-
bution of economic research to the sea
change in thinking, policy prescriptions, and
politicians' acceptance of the need for policy
reform? What sorts of economic research
best informed the policy process? In a nut-
shell, how did we learn? And what was the
contribution of economists and their re-
search to the process?
Attempting to answer these questions is
the subject of this lecture. Even with a focus
limited to trade and development, analysis of
the role of research and its usefulness is at
least somewhat conjectural. The issue, how-
ever, of what types of research inform good
policy is an important one. I suspect that the
tentative conclusions I draw here may be rel-
evant for other areas of research-informing
policy, but leave that to others to demon-
strate or refute.3
In what follows, I first sketch the initial ap-
proach to trade policy in early development
research and thought. Next, consideration is
given to the evolution of thought, research,
and experience with respect to trade and de-
velopment over the next several decades, and
to the "conventional wisdom" of the 1990's.
Thereafter, I consider the role of research and
the sorts of research that proved most fruitful
in guiding policy and changing the consensus.
Before proceeding, two caveats are neces-
sary. First, it is very difficult to disentangle
views of the proper role for trade policy in
development from views about the appropriate
role for the state. Partly as a legacy of the
Great Depression, partly because of the belief
that the Soviet Union had succeeded in its de-
velopmental and industrial aspirations through
central planning, and partly because of the per-
ceived success of wartime controls, there was
widespread agreement- in developed and de-
veloping countries alike-that the state should
play a major role in economic activity, not
only in affecting aggregate demand, but also
in regulating private markets and indeed aug-
menting or supplanting them with state-owned
enterprise production of manufactured and
other goods. Quite clearly, early views about
the necessity for a leading role for the state in
guiding resource allocation were incompatible
with an open trade policy or outer-oriented
trade strategy. Yet to attempt to consider the
evolution of both views is well beyond the
scope of this paper, and focus here is confined
to trade policy.
Second, to focus on research that influenced
thinking about economic policy is not to deni-
grate the importance of research that does not
appear to have had immediate policy relevance.
First of all, basic research often informs more
applied research. Second, in some cases of re-
search that provided little of lasting value, that
outcome could not be known at the time. Per-
haps some of that research served to demonstrate
the infeasibility of certain policy paths,4 or to
demonstrate the futility of further explorations.
Nonetheless, ex post it is clear that some
lines of research served to hasten the day
when policy makers would accept the desir-
ability of removing high walls of protection,
while others were irrelevant or served largely
to reinforce prejudices and perpetuate the "old
wisdom." Perhaps that is inevitable in the
"marketplace of ideas" as new paradigms are
brought forth to replace old ones.

### ---Economics-1997-0-04.txt---
I. Evolution of Theory, Understanding,
and Policy
A. The Early Years
As developing countries gained indepen-
dence from their former colonial rulers, 5 their
leaders had a political mandate to achieve
higher living standards and rapid economic
growth.6 It is difficult in the 1990's to recall
the extent to which it was then plausible to
view the world economy as split into the in-
dustrialized countries and the underdeveloped
countries, or "first world" and "third world,"
as they were often called. Underdeveloped
countries had markedly lower average educa-
tional attainments (including a great deal of
illiteracy and a high fraction of the population
with no schooling), poor health conditions,
and very little infrastructure. They were heav-
ily specialized in the production and export of
primary commodities and imported most of
their manufactured goods. While differences
among the underdeveloped countries were ac-
knowledged, these seemed minor contrasted
with the overwhelming realities of their com-
mon attributes and widespread poverty.
The new field of development economics
was regarded by many as covering underdev-
elopment because "conventional economics"
did not apply (see Albert Hirschman, 1982).
Focus on how the developing countries should
shape policies for accelerating growth and
raising living standards was the central issue.7
B. Accepted Stylized Facts and Premises
Early trade and development theories and
policy prescriptions were based on some
widely accepted stylized facts and premises
about the underdeveloped countries. These
were a mixture of touristic impressions, half-
truths, and misapplied policy inferences. In
hindsight, it is surprising how some then-
accepted stylized "facts" were so uncritically
accepted and held sway for so long. However,
it is not possible to understand what thinking
about trade and development was except in
light of those premises. Indeed, it can be ar-
gued that improved understanding of trade and
development came about in large part through
research which effectively demonstrated the
falsity of these premises.
A first premise was based on the fact-then
certainly true-that developing economies'
production structures were heavily oriented to-
ward primary commodity production. The de-
pendence on foreign trade was believed to be
extreme, as there was virtually no production
capacity for manufactured goods outside a few
light mass-consumed commodities. However,
many observers went further and attributed the
low living standards in developing countries
to dependence on primary commodity produc-
tion and export.
A second "fact," or premise, was that if
developing countries adopted policies of free
trade, their comparative advantage would for-
ever lie in primary commodity production. It
followed that industrialization and, hence, de-
velopment would not take place if free trade
policies were adopted.
A third premise-termed "export pessi-
mism"-was that both the global income and
price elasticities of demand for primary com-
modities were low. Consequently, it was an-
ticipated that export earnings would not grow
very rapidly, if at all.8


### ---Economics-1997-0-06.txt---
It was stipulated that a low-cost producer or
producers were already in operation abroad;
then, the argument proceeded, a potential en-
trant in a developing country would be faced
with an initial period of high costs, but could
in the longer run compete. However, in the
presence of dynamic externalities (presum-
ably internal to the industry), it was believed
that no individual producer would find it prof-
itable to start production. In these circum-
stances, the infant industry argument could
justify temporary intervention to make entry
into the new industry privately profitable pro-
vided that, over the longer term, its costs
would decline below the imported cost by
enough to yield an economic return on the in-
tervening loss, which could be viewed as an
investment.
Although the infant industry argument was,
in a first-best world, an argument for a pro-
duction subsidy (which would presumably
equal the unit value of the externality and
might apply as well for production for exports
as for the domestic market), it was combined
with the appeal for import substitution14 to
yield a justification for protection of newly es-
tablished manufacturing industries in devel-
oping countries.
However, combining the assumptions that
industrialization would have to take place
through substituting for imports, that there
were infant industries requiring initial inter-
vention, and that export earnings were un-
likely to increase, the stage was set for trade
and industrialization policies.
The premises underlying import-substitution
policies were so widely accepted that devel-
oping country exceptions were even incorpo-
rated into the General Agreement on Tariffs
and Trade (GATT) articles. Article XVIII
explicitly protected the developing countries
from the "obligations" of industrialized coun-
tries and permitted them to adopt tariffs and
quantitative restrictions. They also were enti-
tled to "special and differential treatment" in
other regards under GATT. That the GATT,
the upholder of an open international trading
system, would accept an "exception" for
developing countries shows how deeply en-
trenched the views supporting import substi-
tution were. It is arguable that the very
existence of this exception not only legiti-
mized developing countries' inner-oriented
trade policies, but also removed pressures
that might otherwise have been brought to
bear earlier for them to adopt trade and pay-
ments regimes more conducive to economic
growth. "
D. Resulting Evolution of Policies
In one way or another, provision was made
in country after country that, once domestic
production became feasible, imports would be
restricted. In Brazil, a "Law of Similars" pro-
vided that firms importing goods that were
similar to those available domestically would
lose their government privileges, which in-
cluded not only access to credit and tax treat-
ment, but also eligibility to bid on government
contracts and a variety of other valuable rights.
In India, imports were licensed, and in the
event that there was domestic production, any
would-be importer was required to obtain let-
ters from any supplier government officials
thought might be capable of producing the
good to the effect that the supplier could not
meet the specifications. In Turkey, goods were
removed from the list of items for which im-
port licenses could be granted once domestic
production capacity was available. Similar
provisions, or very high tariffs, were used to
encourage import substitution in most devel-
oping countries."

### ---Economics-1997-0-07.txt---
In some countries and industries, the trade
regime was used as the key policy instrument
to provide incentives for import-substituting
investment and production by private firms. In
other circumstances, state-owned enterprises
were established, and investments were made
directly by the state sector in new manufac-
turing activities. In that case, the trade regime
provided protection to the state-owned enter-
prises, although their budget constraints were,
in any event, very soft. None of these policies,
as adopted, provided means of identifying
where dynamic externalities were largest, nor
was there any provision for reduction of pro-
tection after an initial period. Indeed, protec-
tion was virtually automatic for any new
import-substitution industry.
A final aspect of early policies also contrib-
uted to high and indiscriminate levels of pro-
tection. That is, as countries embarked on
ambitious development plans, inflation rates
rose to levels significantly above those in in-
dustrial countries (although far below inflation
rates prevailing in many developing countries
today). Demand for foreign exchange was ris-
ing rapidly in response to the development
plans, rising incomes, and domestic inflation.
Nonetheless, policy makers in most developing
countries chose to maintain their fixed nominal
exchange rates. In part, this reflected the per-
ception, noted above, that there was little re-
sponse to prices and that, indeed, maintaining
the nominal exchange rate "taxed" agriculture
while simultaneously subsidizing capital goods
imports. In part, exchange rates were held fixed
because it was believed that so doing made im-
ports of capital goods cheaper and thus in-
creased investment. The net result was, of
course, real appreciation of the exchange rate,
which further intensified ex ante payments
imbalances, reduced foreign exchange avail-
ability, and induced greater restrictiveness in
import licensing.
It will be recalled that the 1950's and
1960's were a time of unprecedented eco-
nomic growth for the industrial countries and
for world trade. Buoyed in part by interna-
tional markets, and in part by the stimuli of
increased investment and other aspects of de-
velopment programs, the rates of growth of per
capita incomes rose markedly relative to his-
torical levels in most developing countries,
although they remained below those in indus-
trial countries with few exceptions. Even the
growth of industry itself was fairly rapid, as
the "easy" import-substitution opportunities
were by and large undertaken first.'7
However, with real exchange rate appreci-
ation and the pull of resources into newly
profitable, import-competing industries, the
growth of foreign exchange earnings inevita-
bly slowed. It is not widely appreciated that
developing countries, which had a 44 percent
share of world exports of agricultural com-
modities in 1955, lost share to the point where
they had only 31 percent by 1970.18
With acceleration in the growth of demand
for foreign exchange, and deceleration in the
growth of supply, foreign exchange difficulties
were inevitable. The export pessimism prem-
ise had been self-fulfilling, given the policies
that were followed. The drop in primary com-
modity prices in the early 1950's accentuated
the phenomenon, but affected the timing more
than the actuality of the result. The initial
response by most policy makers was to im-
pose rationing of scarce foreign exchange
(and require the surrender of foreign exchange
from exports) on imports, and the resulting
system had little to do with encouraging infant
industries.
Although initial rationing of imports was
usually on a relatively uniform and across-the-
board procedure, controls over foreign trade
generally became more restrictive and com-
plex over the next two decades, both in



### ---Economics-1997-0-08.txt---
response to growing "foreign exchange short-
age," in reaction to the "unfairness" of the
undifferentiated controls, and in response to
evasion of the regimes."9 Periodic balance of
payments crises arose in reaction to overval-
uation of the real exchange rate, increased in-
debtedness, and the failure of export earnings
to grow.
International Monetary Fund (IMF) "sta-
bilization" programs were undertaken, under
which import regimes were simplified and ra-
tionalized (as import licensing was, in those
years, not abolished). The nominal exchange
rate was normally altered (but usually to a
new fixed exchange rate in the face of con-
tinuing inflation).20 Even in IMF programs,
however, it was seldom intended that the
underlying trade policies related to import
substitution be changed: the intent, rather,
was to rationalize the trade regime and find
ways to induce more foreign exchange earn-
ings to finance the capital goods that would
be imported to undertake additional import-
substitution investments. Growth proceeded
in "stop-go" fashion, as periods of foreign
exchange crisis were followed by tight(er)
monetary and fiscal policies, a consequent re-
duction in excess demand for imports, and an
increase in foreign exchange earnings. When
the trade regime was again relaxed, growth
resumed and the demand for imports again
mushroomed until the next crisis.21
E. Research Directions and Contributions
Most research in the 1950's and 1960's was
based on the premises outlined above, and sup-
ported the basic thrusts of policy. It needs only
brief mention here. Some focussed on the pos-
sible existence of externalities and the need for
"balanced growth," as it was assumed that
expansion of any one industry alone would not
be feasible because of the limited size of the
market.22 This prescription, of course, was
based on the premise that development of
manufactured exports was not feasible. An-
other line of supportive research focussed on
planning models, concentrating in large part
on interindustry flows and linkages.23 Empir-
ical research on pattems of development be-
gan, focussing on the structure of economies
and their growth performance. For more than
a decade, the growing disparity between the-
ory and practice was all but ignored.
There was also research providing a ration-
ale for protection of new industries and import
substitution. These results demonstrated that
domestic distortions could warrant trade inter-
vention24 in a number of situations. Everett E.
Hagen (1958), in perhaps the best known of
these, set up a model assuming that urban
wages exceeded rural wages exogenously, and
demonstrated that a tariff could improve wel-
fare by inducing resources into the (artifi-
cially) higher-cost urban industries.
Work also continued on structuralist mod-
els, as a number of authors found reasons
why developing countries' economic struc-
tures were "different" and why, therefore, the
usual economic analysis would not apply.25
Chenery and Michael Bruno (1962), Chenery
and Alan Strout (1966), and Chenery and
many other coauthors developed the "two-
gap" model, using the stylized fact that
foreign exchange was "scarce" in devel-
oping countries. In this model, export earnings
were exogenously given and growing more
slowly than the demand for foreign exchange.


### ---Economics-1997-0-09.txt---
Investment was limited by the more binding
of two linear constraints: the available savings
and the available foreign exchange. There
were thus two "gaps" -between savings and
investment, and between demand for, and
supply of, foreign exchange. Growth was
constrained either by savings or by foreign
exchange availability, and the model demon-
strated the high potential productivity of for-
eign aid (in providing foreign exchange),
enabling otherwise redundant domestic sav-
ings to be used in capital formation. The
model, reflecting the views of the day, had lit-
tle role for the price mechanism.26
An example of an analytical effort to clarify
circumstances under which one of the stylized
facts could be realized was Bhagwati's ( 1958)
and Harry G. Johnson's (1967) demonstration
of the possibility of "immiserizing growth,"
under which a country might increase its out-
put, only to find the price of exports falling so
much that the country was worse off. As
Bhagwati showed, the conditions under which
that might happen were fairly extreme.
An important development was the theory
of shadow pricing, which was an offshoot of
programming and planning models. It was ini-
tially used to demonstrate how reliance on
market prices might yield an inappropriate re-
source allocation. Quickly, however, analysts
pointed to the distortions between domestic
prices of import-competing and exportable
goods because of the trade regime. There is
little doubt that cost-benefit techniques im-
proved project selection and enabled improved
governmental decision-making with, inter alia,
the insistence on use of border prices. The
publication of the I. M. D. Little and James A.
Mirrlees (1969) volume marked a milestone,
after which there was almost no question about
the appropriateness of using border prices in
project evaluation.
In a related and important development, the
theory of effective protection was developed
by Johnson (1965a), W. M. Corden (1966),
Bela Balassa (1965), and others, providing a
framework for analyzing the protection ac-
corded to industries engaged in light process-
ing and much higher value-added activities on
a comparable basis. The notion of domestic
resource costs (Bruno, 1965; Krueger, 1966),
showing the uneven allocation of resources to
earning and saving a unit of foreign exchange
across activities, was developed to meet the
argument that market prices failed to reflect
opportunity cost. This research provided a tool
with which economists could measure the
wide disparities in protection accorded to dif-
ferent import-competing industries.
Recognizing that these estimates were based
in part on partial equilibrium analysis,27 a
number of researchers began work on devel-
oping techniques for computing general equi-
librium results. Based on newly developed
solution algorithms, techniques were devel-
oped for models which endogenized prices,
and thus moved away from the linear models
earlier used for analysis.28
By the late 1960's and 1970's, there were sig-
nificant contributions which undermined some
of the premises on which import-substitution
strategies were based. At an analytical level,
one line of research focussed on whether the
stylized facts of "market failure" in fact war-
ranted the imposition of trade restrictions.
Bhagwati and V. K. Ramaswami (1963),
Johnson (1965b), Bhagwati (1969), and oth-
ers demonstrated that a trade instrument (tariff
or quota) was usually not a first-best, nor often
even second-best, instrument for achieving the
objectives in the name of which protection had
been granted. The equivalence of tariffs and
quotas, an old result in international econom-
ics, was revised and refined, as quotas became
more frequently used.29
Research also began analyzing other aspects
of the ways in which protection actually
worked. Here, attention focussed on rent-
seeking (Krueger, 1974) as a by-product of
protection (and, indeed, as a user of resources



### ---Economics-1997-0-10.txt---
as lobbyists sought protection-see Bhagwati
and T. N. Srinivasan, 1980), as resources
were used to obtain valuable import licenses,
thereby incurring deadweight costs. This, in
turn, showed that protection was more costly
than earlier, area-under-the-triangle estimates
had indicated. It further enabled insights as to
the buildup of vested interests that is likely to
arise once any policy is undertaken. When pol-
icy reforms were attempted, it was clear that
those administering earlier policies were in
the forefront of those opposing change, along-
side the beneficiaries of protection (or other
policies).
Related to work on rent-seeking and the ten-
dency for vested interests to spring up around
the policies that were adopted, others worked
on the theory of overinvoicing and underin-
voicing (see Bhagwati, 1974) and smuggling
(see Munir A. Sheikh, 1974; Mark Pitt, 1981),
again focussing on some of the flaws of the
system of protection as practiced in most de-
veloping countries.
As trade regimes became more chaotic,
empirical work began to document these prob-
lems, bolstered by the development of the
measurement tools embodied in the concepts
of effective rates of protection and domestic
resource costs. Researchers focussing on Pak-
istan discovered that there was actually neg-
ative value added in some circumstances,
suggesting that it would have been cheaper to
pay workers to stay home and import the final
product.3"
The Organization for Economic Coopera-
tion and Development (OECD) sponsored a
series of country studies on industrialization
led by Little et al. The three synthesized
(1970) the results and provided estimates of
effective rates of protection in a number of de-
veloping countries. These showed how high
and indiscriminate protection levels were and
demonstrated the extent to which import sub-
stitution had failed to achieve many of the ob-
jectives set for it. A later series of country
studies undertaken under the auspices of the
National Bureau of Economic Research, syn-
thesized in works by Bhagwati (1978) and
Krueger (1978), provided further systematic
empirical evidence of the economic wasteful-
ness and irrationality of the inner-oriented
trade regimes.
F. East Asian Experience
At the same time as evidence of the high
costs of import-substitution regimes was ac-
cumulating, another important development
occurred. Starting first in Taiwan, several East
Asian economies began growing rapidly under
policies diametrically opposite those prevalent
under import substitution. Interestingly, the
Taiwanese government seems to have listened
carefully to the views of S. C. Tsiang,3 1a pro-
fessor at Cornell University specializing in in-
ternational economics. Following the precepts
of comparative advantage, Tsiang advocated
growth through industrialization, but with in-
dustrialization taking place through increased
capacity for exports, as well as for the domes-
tic market. Taiwan's transformation from a
high-inflation, inner-oriented, aid-dependent
economy to a major exporting economy is well
known.
Korea, whose initial conditions appeared, if
anything, even less conducive to growth than
those of Taiwan, followed the same pattern. In
the late 1950's, Korea's exports had averaged
only 3 percent of gross domestic product
(GDP) and were growing slowly, if at all,
while imports represented 13 percent of GDP.
The current account deficit was financed
largely by foreign aid, and the domestic sav-
ings rate was virtually zero. Major policy re-
forms took place in Korea in the early 1960's,
which greatly increased the return to export-
ers. There were fairly uniform incentives to
all exporters and assurances that the real
exchange rate would not appreciate to their
detriment. Reforms also reduced the protec-
tion to import-competing producers and per-
mitted exporters duty-free importation of needed
intermediate goods and raw materials.
The Korean economic performance was
transformed, as growth rates entered the
double-digit range and living standards


### ---Economics-1997-0-11.txt---
improved rapidly. Hong Kong and Singapore
also became part of the East Asian "miracle"
through policies designed to encourage ex-
porting. Growth rates exceeded those previ-
ously thought to represent an upper bound on
attainable performance.32
It was not until the 1980's, however, that
the importance of the differences became
unarguable. After the second oil price increase
of 1979, the worldwide recession of 1980-
1982, and the accompanying "debt crisis,"
the East Asian net importing countries (NICs)
rapidly resumed growth, whereas other heav-
ily indebted countries were unable to service
their debts and were hard hit by events in the
international economy. Research undertaken
in attempting to understand the impact of the
debt crisis on the developing countries made
it abundantly evident that the debt-GDP ratios
were not significantly different between the
two groups of countries. What was signifi-
cantly different was the debt-export ratios, as
the East Asian countries were able to maintain
debt servicing and resume growth because of
the greater flexibility of their economies.33 It
also emerged that, even prior to the debt crisis,
the rates of growth of inner-oriented devel-
oping countries had not increased despite sub-
stantial increases in their savings rates.:
This is not the place to enter into the debate
as to the factors contributing to the success of
the East Asian "tigers." For, while there is
debate about whether government intervention
in "picking the winners" was a key compo-
nent of the growth strategy, 35 all recognize that
the reversal from an import-substitution strat-
egy, the opening up of the economy, and the
relative uniformity of incentives across the
board were necessary, if not sufficient, for suc-
cess. Indeed, there is an irony in the fact that
the East Asian experience has stimulated some
to attempt to identify the "dynamic" factors
in exporting that are absent from production
for the domestic market. Thus, we have a com-
plete turnaround: in the 1950's and 1960's, the
neoclassical argument for an open trade re-
gime was rejected on the grounds that it was
"static" and ignored "dynamic considera-
tions"; in the 1990's, there appears to be wide-
spread agreement that the benefits of an open
trade regime are largely "dynamic" in nature,
and go well beyond the gains from trade under
"static" models of an open economy. Just as
was the case with the infant industry argument,
however, there is a question as to how to iden-
tify and measure these "dynamic" gains.
II. How Did Economists and Researchers
Go Wrong?
The "Washington consensus" is very dif-
ferent from the policy consensus that led to the
adoption of import-substitution policies in the
1950's and 1960's. While there will no doubt
be refinements in that consensus with further
experience and research, it is highly unlikely
that the ideas of the 1950's and 1960's will be
revived.
One can raise three questions about the
change in viewpoints. First, how could it be
that the economics profession, whose consen-
sus on the principle of comparative advantage
was at least as great as that on any other policy
issue, endorsed a highly protectionist policy
stance?36 Second, what factors contributed to

### ---Economics-1997-0-12.txt---
changing the entrenched views of the 1950's
and 1960's? Finally, what types of research
were most (and least) productive in bringing
about better understanding of the role of trade
and trade policy in development? I address
these questions in turn.
The first is the issue of how the principle of
comparative advantage could have been so
blithely abandoned. With hindsight, it is al-
most incredible that such a high fraction of
economists could have deviated so far from
the basic principles of international trade.
What led them to do so? Can any lessons be
drawn to avoid (or shorten the duration of)
similar mistakes in other applied fields when
new policy problems arise?
But, recall the stylized facts that were
widely accepted. People were thought not to
respond to incentives; exports earnings were
thought to be predetermined and slowly grow-
ing at best; industrialization was necessary for
development; supply response was lacking;
and so on. These stylized facts, which were at
best simplistic and in most instances simply
wrong, permitted economists to conclude that
developing economies were "different."
However, it took theory to support these
conclusions. Here, one can distinguish several
failures. First, there was misapplication of
good theory. Second, there was what I shall
call the "theory of negative results," which
essentially could be used to provide a rationale
for virtually any trade intervention. Third,
there was good theory harnessed to erroneous
stylized facts.
A. Misapplication of Good Theory
Misapplication of good theory was sig-
nificant.37 The identification of comparative
advantage with the two-factor, two-good
model, and the assumption that free trade
would imply that developing countries would
forever specialize in primary commodities,
was an important misapplication. One of the
puzzling aspects of the evolution of thinking
about policy is the degree to which proponents
of open trade regimes failed to refute the al-
legation that free trade would forever leave de-
veloping countries specialized in production
of agricultural commodities.38
It was not until the 1970's (see Ronald W.
Jones, 197 ib; Krueger, 1977) that models-
motivated in part by the East Asian experience-
were developed in which three factors of
production (land, labor, and capital) were al-
located among sectors, each of which could
produce many commodities. As the three-
factor models demonstrated, comparative ad-
vantage lies within manufacturing and within
agriculture, and not between them. Thus, poor
unskilled, labor-abundant countries have a
comparative advantage in labor-intensive ag-
ricultural and unskilled labor-intensive man-
ufactured commodities, while countries with
a much higher land-labor ratio have a com-
parative advantage in more land-using agri-
cultural commodities and their comparative
advantage in manufacturing lies more in goods
with higher capital-unskilled labor ratios. In
these models, the overall trade balance in man-
ufactures is a function of the size of the man-
ufacturing sector, itself a function of past
capital accumulation and the land-man ratio.
A second serious misapplication of good
theory arose because of the nonoperational
nature of the theory itself, and the failure to
identify circumstances under which policy im-
plementation might be incentive compatible
and potentially increase welfare. A key culprit
in this case was the interpretation of the infant
industry argument. As I already discussed, it
was widely touted as a basis for import sub-
stitution, and generally recognized as a "le-
gitimate" case for a departure from free trade.
One can hardly argue with the proposition
that the presence of a positive externality gives
rise to a basis for intervention; if the external-
ity is dynamic and temporary, then temporary


### ---Economics-1997-0-13.txt---
intervention, such as infant industry protec-
tion, can be called for.
The problem with the argument, as a basis
for policy, is that it fails to provide any guid-
ance as to how to distinguish between an infant
that will grow up and a would-be producer
seeking protection because it is privately prof-
itable. It is not even clear how one could begin,
empirically, to identify the domain of the
externality. Moreover, even if there were a
producer or producers whose increased pro-
duction would generate dynamic externalities,
it does not follow that any level of protection
is warranted. And there is nothing in the infant
industry argument to provide guidance for
quantifying or estimating the likely magnitude
of the externality.
Indiscriminate protection in developing
countries was defended on infant industry
grounds with arguments of capital market fail-
ure, labor market failure (as the costs of train-
ing, presumably, would be borne by first
entrants into industries and then not recouped
as others hired workers away), costs of in-
vestments in technology, and uncertainty all
used. It was not until Baldwin's (1969) sem-
inal article that it was demonstrated that, even
when the presumed imperfection existed, it
was unlikely that infant industry protection
would help correct it. As Baldwin cogently ar-
gued, later entrants to an industry might speed
up their investments if protection made do-
mestic production more profitable, and the first
entrant might even be worse off! It was only
after critical examination of these circum-
stances that the defenders of the infant indus-
try case for import substitution became less
vehement.
The infant industry argument also is an
excellent example of a theory that is nonoper-
ational because criteria for bureaucrats to iden-
tify cases have not been put forward. Quite
aside from the unpredictability and immeasur-
ability of the future time path of costs in new
factories and the moral hazard associated with
asking individual entrepreneurs to indicate
how much protection they need, there is noth-
ing to my knowledge in the literature speci-
fying how the policy maker might instruct a
bureaucrat to identify (much less measure) a
dynamic externality if it were present, how an
incentive-compatible mechanism might be de-
vised for improving welfare, how the bureau-
crat might measure the height of warranted
protection, nor how policy makers might cred-
ibly commit to temporary protection. Even ex
post, it is not entirely clear how one might
identify an industry as a successful infant: sim-
ply because a firm became profitable and ex-
ported does not prove that there was either an
externality or a dynamic process at work! 9
B. Negative Results
Much of the theorizing that took place was
concerned with what I call "negative results."
That is, analysts sought to find reasons why,
for example, an exception to free trade should
be made. Once the principle of comparative
advantage was laid down as a basis for policy,
there was little left for theorists to prove sup-
porting an open trading system, so the chal-
lenge to theorists was to find conditions under
which the free trade precept did not hold. As
theory, these findings were significant, but for
policy they were unhelpful, and probably
served to perpetuate inappropriate policies.
In most real-world circumstances, one
strongly suspects that protection exists where
theoretical exceptions do not justify it, and that
moves to first-best policies would on average
lower, and not raise, protection. Judged by that
metric, research output relevant for policy
would consist more of attempts to measure the
costs of these excess levels of protection. In
practice, it would be interesting to review the
literature and ascertain how many articles, or
pages, or other measures of research output
were devoted to finding exceptions to the
proposition that comparative advantage should
form the basis for trade policy, contrasted with
those focussing on circumstances where pro-
tection was too high! In undergraduate inter-



### ---Economics-1997-0-14.txt---
national economics courses, sections on trade
policy spend considerable time addressing na-
tional defense exceptions, the optimum tariff
argument, the infant industry argument, second-
best arguments, and other arguments for pro-
tection. While attention is paid to the reasons
why these arguments may not be correct, focus
nonetheless centers on the exceptions to the
case for free trade, rather than on the reasons
for it. While this may be inevitable as a way
of reasoning, the temptation to draw inappro-
priate inferences seems high.
An example will illuminate the argument.
Whereas theory suggests criteria for depar-
tures from laissez-faire free trade which nor-
mally would result in different levels of
protection for different industries, a widely
used prescription for policy makers is that, if
there is to be protection, a uniform tariff is
usually preferable to any alternative structVre.
This proposition rests on several considera-
tions. First, only a uniform tariff can generate
a uniform rate of effective protection in the
import-competing sectors and, if different
goods are subject to different rates of tariff,
the resulting differences in effective rates of
protection will lead to resource misallocation
even within the import-competing industries
and have no relation to underlying "dynamic"
or market-failure considerations. Second, a
uniform tariff simplifies customs administra-
tion, making evasion and/or bribery of cus-
toms officials more difficult than a varying rate
structure. Third, a uniform tariff greatly re-
duces the opportunities for resource losses in
rent-seeking and lobbying. Fourth, given in-
ternational prices, international value added is
more likely to be maximized under a uniform
tariff structure than under a variable one.
None of these arguments is sufficient to
prove that a uniform tariff is optimal. And, in-
deed, it is straightforward to develop models
in which a uniform tariff is nonoptimal, es-
pecially in the presence of income-distribution
considerations. In theory, the costs of pro-
tection can be minimized by imposing higher
tariffs or taxes on goods whose supply and de-
mand is relatively more price inelastic.
Those arguments, as put forward, are all
couched in terms of demonstrating the "falsity"
of the proposition that a uniform tariff is pref-
erable to variable tariff rates and that there is a
departure from uniformity that can potentially
improve welfare. But the difficulty with that for-
mulation is that it does not provide a criterion
for which departures from uniformity might
improve welfare, because a model considering,
for example, income-distribution considerations,
cannot simultaneously address issues of corrup-
tion and administration. And, the fact that
income-distribution considerations can warrant a
nonuniform tariff structure does not prove that
any nonuniform tariff structure is preferable to
a uniform one! As such, a negative result gives
little or no guide for policy. Nonetheless, it arms
lobbyists and others with ammunition to dis-
credit technocrats' efforts to maintain a less ir-
rational structure of protection.
Some good theoretical papers would have
done less damage, or at least given less aid and
comfort to policy positions that were clearly
not those intended in the analyses, if the au-
thors had taken greater pains to note the lim-
itations to their analyses, and the other factors
that would have to be taken into account, be-
fore their results were applied to policy.
In that regard, it is often overlooked that most
policy implementation is carried out by govern-
ment officials who cannot be expected to have
advanced degrees, and sometimes even under-
graduate degrees, in economics. In many in-
stances (including formulae for optimal tariff
differentiation), the degree of sophistication
needed to interpret research results is well be-
yond that which most bureaucrats will have. As
pointed out by Johnson (1970 p. 101):
...The fundamental problem is that, as
with all second-best arguments, determi-
nation of the conditions under which a
second-best policy actually leads to an
improvement in social welfare requires
detailed theoretical and empirical inves-
tigation by a first-best economist ... it is
therefore very unlikely that a second-best
welfare optimum will result based on
second-best arguments.
C. Good Theory Assuming
Counterfactual Situations
The final abuse of theory was primarily a
fault of inappropriate stylized facts. Nonethe-
less, in many instances, analysts assumed
signs of variables that were certainly question-


### ---Economics-1997-0-15.txt---
able, modelled the situation neatly, and then
drew policy conclusions that could hold only
if the posited signs were valid. Yet their claims
often went beyond the assertion that "if these
facts ... then" variety.
As an example to illustrate the point, I have
deliberately chosen a good, widely cited paper,
because the paper represents good theory, but
interprets it, for policy purposes, with dubious
"stylized facts." Sudhir Anand and Vijay Joshi
(1979) considered a world, such as that envis-
aged by Hagen ( 1958), in which workers in the
advanced sector receive a higher wage than in
the rest of the economy due to unions or other
(presumably unalterable) circumstances. They
then asked whether maximizing international
value added for given employment of domestic
resources is an appropriate criterion when
income-distribution considerations cannot be sep-
arated from productive-efficiency considerations.
In their setup, the clear answer is no, because
tradeables are produced by the advanced (pre-
sumably unionized) sector, and hence maxi-
mizing international value will pull more
resources into that sector at the cost of a dete-
riorating income distribution. Interestingly,
they do not address the question of whether the
advanced sector is labor or capital intensive. If,
as is true for outer-oriented developing coun-
tries, the exportables are labor intensive relative
to import-competing activity, removing protec-
tion to induce a move of more workers to the
"advanced" high-wage sector would presum-
ably increase wages of those workers and also
those in the rest of the economy: a more equal
income distribution would be obtained at the
expense of lower real wages for all. Without
regard to factor intensity, however, Anand and
Joshi (1979 p. 350) conclude that:
The motivation behind the theory of dis-
tortions has been to criticise and to guide
trade and industrialisation policies ...
Our analysis emphasises the need for
caution ... Departures from technical ef-
ficiency may be called for as part of the
rational response by governments to the
limitations they face in carrying out de-
sirable income distribution policies ...40
Anand and Joshi ( 1979) assumed that mov-
ing toward economic efficiency in tradeables
requires paying higher wages because of a dis-
tortion. Yet, in fact, the evidence suggests that
it has been the highly protected, import-
competing industries which have been able to
pay above-average wages; removing protec-
tion has led to rapid expansion of employment
in labor-intensive industries. If the latter stylized
fact is correct, and if income-distribution consid-
erations are important, it would suggest that
the policy implications of the Anand-Joshi
analysis are the opposite of what they sug-
gest-namely, that policy makers should en-
courage, even beyond the optimum, a shift of
resources out of protected industries (presum-
ably by removing protection) and into export-
able industries.4"
III. What Research Contributed
to Improved Policies
Policies that were not consistent with policy
makers' growth objectives were cloaked in re-
spectability in the 1950's and 1960's by theory
and stylized facts of the type I have already
described. I have so far discussed properties of
some theories that made them susceptible to
misapplication or misuse.
A second question is equally important,
however. That is, how did the change in econ-
omists' policy prescriptions come about? What
led to the reversal to recognition of the im-
portance of an open economy after the con-
version to advocacy of import substitution in
the 1950's and 1960's? I can address this ques-
tion more rapidly because much of the answer
was implicit in the description of the evolution
of developing countries' trade policies.



### ---Economics-1997-0-16.txt---
Three sets of research efforts can be singled
out as having been particularly useful in in-
forming changes in policy, although others,
no doubt, also contributed.42 First, there was
research analyzing how import-substitution
policies were actually working. Second, and
not unrelated to the first, there was the refine-
ment and more appropriate interpretation of
theory. Third, there was research demonstrat-
ing the feasibility of the alternative.
A. Challenging the Stylized Facts and
Understanding How Import-Substitution
Regimes Worked
Analyses of the evidence regarding the key
stylized facts were in hindsight important steps
in undermining the intellectual consensus.
Demonstration that there were significant re-
sponses to incentives undermined the policy
case for ignoring prices. Proof that the terms
of trade had deteriorated very little, if at all,
began to undermine export pessimism.
Empirical work on the ways in which
import-substitution regimes functioned was
crucial. Comparative analyses such as those
of Little et al. (1970), Bhagwati (1978),
Krueger ( 1978, 1983 ), and Michael Michaely
et al. ( 1991 ) clearly contributed signifi-
cantly to awareness that the effects of import-
substitution policies were not idiosyncratic to
individual countries. The comparative studies
provided a great deal of evidence as to the
shortcomings of reliance on import substitu-
tion. Evidence that protection was not tem-
porary, that protection levels were high and
idiosyncratic, that there was very great dis-
crimination against exports, and that "foreign
exchange shortage" was a function of policies
and not an exogenously given datum, were all
important in challenging the protectionist trade
policies still prevailing in most developing
countries in the 1980's.
If one considered the evidence regarding the
workings of trade policies in any one country
taken alone, there were ample grounds for crit-
icism of inner-oriented trade policies, with the
monopoly positions they conferred on domes-
tic producers, the high costs of doing business,
rent-seeking low quality of products, and so
on. It was possible, however, to recognize that
and nonetheless conclude that policy makers
in that particular country had been inept, or
had simply failed to implement policies appro-
priately. As evidence mounted across coun-
tries, the similarity in the evolution of regimes
and their consequences was striking. It was in-
creasingly difficult to dismiss the evidence
from a particular country as being sui generis
or the failing only of the particulars of policy
execution in that country.
But, underpinning the analyses of indivi-
dual country situations, either in the compar-
ative studies or individually, were agreed-upon
measurement tools. The empirical studies
could not have had their impact without the
development and use of measurement tools.
As cost-benefit techniques were used, it be-
came increasingly difficult to justify some
highly uneconomic projects. And, as measure-
ment of effective rates of protection was un-
dertaken in country after country, the high and
erratic nature of protection became evident.
Techniques for cost-benefit analysis and mea-
surement of effective rates of protection were
important, first of all, in providing analysts
with tools with which to demonstrate the cha-
otic nature of import-substitution policies. In
addition, even before the policy consensus
changed, there is little doubt that some of the
earlier extreme irrationalities of policy were
curbed through use of these tools. It became
extremely difficult to defend the high average
of, and wide variance in, effective rates of
protection.
At an empirical level, it seems clear that early
demonstrations of the great range of variation in
rates of effective protection were useful both in
demonstrating some of the problems with trade
regimes and also in preventing at least a few of
the worst excesses that might otherwise have oc-
cuffed. More generally, recognition and rein-
troduction of the proposition that there is a 

### ---Economics-1997-0-17.txt---
response to incentives that cannot be overlooked
in policy formulation, combined with the evi-
dence on the erratic and arbitrary nature of in-
centives provided by trade regimes, forced a
reexamination of the premises on which import-
substitution policies were based.
Yet another contribution of empirical re-
search was to focus upon the actual workings
of policy implementation. In early policy pre-
scriptions, there had been something of a naive
tendency to assume that enunciating a desired
outcome was itself sufficient to achieve it.
This naivete was dispelled, as the theories re-
garding bureaucratic behavior, rent-seeking,
smuggling, and overinvoicing and underin-
voicing all enabled observers to examine more
critically the ways in which alternative policy
prescriptions might have side effects that had
earlier been unanticipated.
B. Refinement and More Appropriate
Interpretation of Theory
As already seen, some of the intellectual un-
derpinning of import-substitution policies was
provided by inappropriate interpretation of
theory, or the failure of theory to take into ac-
count key institutional or behavioral variables.
Analytical developments focussing on condi-
tions under which these interpretations were
valid, or examining the ways in which results
had to be modified to take into account these
institutional and behaviorial aspects, were
clearly important in improving understanding.
The entire literature on optimal interven-
tions in the presence of domestic distortions is
one important example of a demonstration that
earlier interpretations of theory had failed to
examine the relevant alternatives. It was in-
valuable in demonstrating clearly that in most
circumstances, the presence of a distortion
warranted a first-best policy intervention other
than a tariff.43 For example, in the case of
Hagen's (1958) employment-generating case
for protection, the optimal intervention litera-
ture demonstrated clearly that a first-best in-
tervention would be in the labor market, and
that a tariff or quota could not achieve a first-
best outcome.
Similarly, developments showing that the
comparative advantage results were not the
simple "specialize forever in primary prod-
ucts" precept proved significant in enabling
policy makers to contemplate alteration in
trade strategy. Baldwin's (1969) critical ex-
amination of the infant industry argument pro-
vides yet another example of an analytical
contribution that was important in making
those concerned with policy consider carefully
the effectiveness of the policies they had
adopted in achieving their desired goals.
Finally, there was theory that was developed
in response to the functioning of import-
substitution regimes. Here again, the theory of
rent-seeking, as it pointed to the ways in which
bureaucrats and others made protection very
costly, was important. Further, when it was
recognized that bureaucrats, businessmen, and
others attempted to capture or thwart policy
initiatives not in their self-interest and that
they acquired an interest in maintaining the
system, once established, and that resources
were expended in operating the system, it had
to be recognized that changing the system
would be politically difficult.
Development of a better understanding of
the incentives for underinvoicing and overin-
voicing of exports and imports and for smug-
gling under exchange-control regimes worked
in the same direction: not only could these ac-
tivities prove costly to the exchequer and in
terms of resource drains, but the very recog-
nition of their presence served to remind
policy makers of the limitations of their
instruments.
Finally, good analyses demonstrating how
individual import controls actually worked
contributed to understanding and made em-
pirical work more effective. The further
refinement of theory showing tariff-quota
equivalence has already been mentioned.
Rent-seeking again comes to mind. But, in
addition, individual mechanisms for encour-
aging import substitution each had their
own, often idiosyncratic, incentive effects. A
good example is Gene Grossman's (1981)
classic analysis of domestic content regula-
tions and their effects.



### ---Economics-1997-0-18.txt---
C. Demonstration of the Viability of
Alternative Trade Policies
Research on the contrast between East
Asian and other developing countries and rea-
sons for it obviously turned out to be a major
contributing factor in influencing thinking
about policy. In a way, research on East Asian
experience provided a final blow to the earlier
uncritical acceptance of the stylized facts. For,
the East Asian experiences demonstrated, as
nothing else could have, the feasibility and vi-
ability of alternative trade policies: it was no
longer possible to associate comparative ad-
vantage with reliance on primary commodity
exports, and the East Asian experience cer-
tainly put an end to the belief that developing
countries could not develop rapidly when re-
lying on integration with the international
economy.'
The experience of the East Asian exporters
did several things. Most important, it provided
concrete evidence that a developing country
could achieve industrialization without relying
on domestic markets to absorb almost all
additional output. That demonstrated the fal-
lacy of the earlier view that industrialization
could take place only through import substi-
tution.45 Also, the East Asian trade regimes of-
fered significant opportunities for empirical
research, and the evidence mounted that prop-
erties formerly thought to be those of all de-
veloping countries were, in fact, properties
resulting from inner-oriented trade and pay-
ments regimes.
It cannot be said that either research results
or the contrast in economic performance alone
led to the change in policies in other devel-
oping countries.46 Both research (especially
that which brought the sharply contrasting ex-
periences of the East Asian exporters and the
import-substituting countries into focus) and
experience contributed.
Whether one should regard the East Asian
experience as entirely separate from economic
theory, however, is an interesting question. As
already mentioned, Tsiang (1985) was him-
self an international economist, and it was in
significant part his efforts that led the Tai-
wanese authorities to abandon inner-oriented
policies and attempt to develop through ex-
ports. The theory of comparative advantage
was, at least in that instance, a pillar on which
policy was built. And, while a variety of fac-
tors no doubt contributed to the Korean adop-
tion of outer-oriented trade policies after 1960,
the favorable experience of Taiwan undoubt-
edly facilitated the willingness of decision
makers to try the new approach.
The East Asian exporters put to rest the
mistaken belief that developing countries re-
lying on the international market would forever
be specialized in the production of primary
commodities. They also showed that rates
of growth well above those realized even in
the most rapidly growing import-substitution
countries such as Brazil and Turkey could be
realized.
IV. What Lessons Can Be Learned for Research
in New Applied Fields?
It is difficult to draw generalizations based
on the evolution of analysis, empirical re-
search, and policy in one applied field. None-
theless, in the hope that insights from other
applied areas may reinforce or amend the list,
the effort seems worthwhile.
Perhaps the most obvious generalization
from the various factors that have been dis-
cussed is that empirical research which tests
for the presence and order of magnitude of
stylized facts which are used in modelling and 


### ---Economics-1997-0-19.txt---
policy formulation can be invaluable. If the
right stylized facts can be used as a basis for
theory, and theorists have good indications of
the relative quantitative importance of various
phenomena, it is clearly far more likely that
the theory itself can make a useful contribution.
In the case of trade policy and development,
the demonstrations that there were responses
to incentives and that developing countries
could expand export earnings and did have
comparative advantage in other than primary
commodities, were clearly crucial to improved
understanding of the relationship of trade to
development.
For that reason, high marks must go to the
analytical research that pointed to measure-
ment techniques such as effective protection
and cost benefit, which enabled policy makers
and their analysts to obtain empirical quan-
tification, however rough, of the relevant
magnitudes.47
In like manner, the empirical demonstration
of the similarity of policy responses across de-
veloping countries, and of the wide and largely
irrational variation in incentives for import-
competing industries, increased understanding
of what was wrong with existing policies.
Overturning, or more accurately interpret-
ing, the accepted stylized facts, therefore, was
a first prerequisite for developing a better the-
ory of trade policy for development. But the-
ory was important in many ways, in addition
to pointing to appropriate measurement tools.
First of all, good policy-relevant theory pro-
vided blueprints for those windows of oppor-
tunity in which governments genuinely sought
to improve economic performance, as was the
case in Taiwan and Korea in the early 1960's,
and in Chile, Mexico, and India in later de-
cades, to name just a few.48 Having the "blue-
prints" on hand from good theory is obviously
a major contribution. As already noted, how-
ever, that theory is often relatively dull -such
as comparative advantage-rather than the
more exciting and refined results of complex
models.
Second, theory was invaluable when it
showed why simple interpretations of received
doctrine were in fact wrong. This was the case
with the theory of first-best intervention in the
case of domestic distortions, and in the case
with comparative advantage as interpreted to
mean developing countries would specialize in
the production of primary commodities, and
with the infant industry argument.
These considerations suggest that research
results, in order to be most likely to be ame-
nable to policy relevance, should be interpret-
able into phenomena that are observable,
hopefully quantifiable, and recognizable by
the policy maker. A negative result, such as
that theory does not always tell us, can be
counterproductive precisely because the pol-
icy maker is informed only that a certain gen-
eralization (such as comparative advantage
and the value of free trade) is not without
exception; the generalization can then be
ignored.
A more general statement of the problems
inherent in theorems which show that major
propositions are "not generally true" would
encompass all of that theory which is cast in
terms of "anything can happen." While it is
certainly true that there are conditions under
which a wide range of outcomes (Pareto-
inferior, a bad equilibrium, Pareto-superior,
etc.) are possible from the same policy instru-
ment, it would have challenged the skills of
even the most superb theorist to attempt to de-
velop a case for the sorts of chaotic policies
prevalent in Turkey in 1957, in Ghana in 1983,
and in Argentina in the late 1980's. It is far
too easy for analysts to ignore the fact that "an
exception" does not rationalize all possible
policy alternatives to free trade.
There is a criterion for efficient resource al-
location, equating domestic and international
marginal rates of transformation. Even if there
are "dynamic" factors which contravene part
of the static efficiency criterion, they too are
measurable. Yet the "anything can happen"
theories do not provide guides as to how the


### ---Economics-1997-0-20.txt---
phenomena under examination may be quan-
tified, and thus provide rationalizations (ad-
mittedly for those who want them) for policies
that cannot by any realistic test pass muster.
Perhaps the lesson is that there is a signifi-
cant danger that economic theory will be mis-
interpreted in the policy arena, and researchers
could productively take more pains to distance
themselves from policy conclusions that are
not warranted by their analysis. Theoretical
papers which end with "it has been shown
that, under conditions x and y, policy z may
no longer represent an optimum ... Therefore
policy should ..." are obviously overstepping
their bounds when the empirical relevance of
x and y are not yet established, and even more
so when conditions other than x and y also may
be important (as, for example, with rent-
seeking).
But many good theory papers are written
where the authors assume that their audience
will consist entirely of other theorists. In such
instances, good theory may be misused, and it
certainly will be in the self-interest of some to
harness it to their own ends. It behooves ap-
plied economists, as well as the theorists, to
be careful to interpret the policy relevance of
results in ways which minimize the scope for
misinterpretation. This is as true for those
seeking to find "dynamic" aspects of export-
ing, or endogenous aspects of a "big push,"
as it should have been for those developing the
infant industry or optimum tariff arguments.
Complex results, such as those noted by
Johnson (1970), are particularly suspect in
that they can be interpreted in whatever ways
suit the decision maker or lobbyist.
Finally, there is theory which provides no
guidance as to when or how to observe the
phenomenon. In such instances, it is difficult
to find policy implications that will not be cap-
tured. One possible challenge for theorists
might well be to ask for at least one plausible
incentive-compatible mechanism under which
the inefficiencies they identify might be im-
proved upon by policy makers and bureau-
crats. The existence of infant industries, of
cases in which there are rents that might be
captured by appropriate strategic trade policy,
and of informational asymmetries and other
market imperfections cannot be doubted. But
until the magnitude of these phenomena can
somehow be measured, or incentive-compatible
mechanisms for correcting them can be de-
vised, theorists asserting their presence are
simply providing a carte blanche for policy
makers and bureaucrats to intervene in what-
ever ways they like, and this will simulta-
neously be seized upon by special interests to
bolster their causes.
No matter how careful economists are,
special interests always will seize their re-
search results in supporting their own objec-
tives. And, no matter how sophisticated and
careful research findings are, there always
will be politicians formulating, and non-
economists administering, policies. Recog-
nition of these propositions could do much
to increase the degree to which economists'
research results can contribute (positively)
to policy formulation.
I
## Economics-1998-0


### ---Economics-1998-0-01.txt---
One of the great pleasures of belonging to
my generation of economists is that we were
able to witness the birth and the subsequent
evolution of the modern approach to the
analysis of economic growth. The center-
piece of that approach is probably growth
accounting, but we should never forget that
growth accounting is firmly rooted in eco-
nomic theory.
My way of telling the story goes like this:
Many, maybe even most, economists expected
that increments of output would be explained
by increments of inputs, but when we took our
best shot we found that traditional inputs typ-
ically fell far short of explaining the observed
output growth. Our best shot consisted in at-
tributing to each factor a marginal product
measured by its economic reward. Thus:
(1) ffAy = WAL + (p + 6)AK + R.
Here:
Ay = change in output (GDP);
AL = change in labor input;
p = initial general price level;
w = initial real wage;
T = initial real rate of return to capital;  8 = rate of real depreciation of capital;
AK = change in capital stock; and
R = "the residual" of growth unexplained
by increases in traditional inputs.
Many economists are probably more famil-
iar with a variant of (1)
(1') (Ay/y)-= (wL/py)(LL/L)
+ [(+ 6)Klfy ] (AK/K)
+ (Rly) = se(AL/L)
+ Sk(AK/K) + (Rly).
In whichever form, the measured residual
typically accounted for an important fraction
of the observed output growth, quite often half
or more.


### ---Economics-1998-0-02.txt---


### ---Economics-1998-0-03.txt---
This result came as a surprise to the profes-
sion, though perhaps less so to those who
reached it, or something very like it, by an al-
temative route. They were the people who
came at the problemn out of a tradition of mea-
suring labor productivity, and at some point
complemented output per worker with a mea-
sure of output per unit of capital, and finally
joined the two to create a measure of total fac-
tor productivity (TFP). The idea of total factor
productivity increasing through time was less
a shock to these people than the "growth re-
sidual" was to those who approached its mea-
surement along the lines of equation ( 1) or
(1'). See Moses Abramovitz (1952, 1956)
and Solomon Fabricant (1954).
In any case, as the newly discovered residual
loomed large in our professional thinking, our
discussion centered on two potential explana-
tions: "human capital" and "technical ad-
vance." (See Robert M. Solow, 1957.) These
can be thought of as complementary explana-
tions, at least up to a point, with technical ad-
vance representing truly new ways of doing
things, and the accumulation of "human capi-
tal" representing increases in the "quality" of
the typical human agent. It was not long before
attempts were made to quantify the contribution
of improved labor quality. These came as part
of a general move toward disaggregation of the
two factors, which can be represented by:
(2) ffAy=ZiwViLi
+ z9(Pj + 6j)AKJ + R'.
Here the index i can vary over all sorts of ed-
ucation and skill groups as well as categories
like gender, age, occupation, region, etc. All
these are items that may signal a different mar-
ket wage. In a similar vein, the index j would
appropriately vary over categories like the cor-
porate, noncorporate, and housing sectors
where, for tax if for no other reasons, different
(gross-of-tax) rates of return would presum-
ably prevail, even in a full equilibrium.
In an equation like (2), the presumed mar-
ginal product of each category of labor is mea-
sured by the wage wi . Average quality can be
measured by Q, = iwi Lil i L,, and the con-
tribution of change in quality to Ay, between
t and t + 1 can be calculated as Liw( i(A Q, + I /
Qt). Thus, the contribution of quality change  is already built into the first summation in (2),
but can be separately identified if we so
choose.
A focus on human capital could lead us to
a slightly different way of breaking down
1wiALi. Here we could choose some "basic
wage" w*, ideally the wage of some well-
defined category of relatively unskilled labor.
Then we could divide the remuneration wi of
any given category into a part w* which was
a reward for "raw labor" and another part
(wi - w *) which we would identify as the
reward to the human capital of a typical
worker of type i.
Using a framework like (2) has long been
the standard for careful professionals. Pio-
neered by Zvi Griliches (1960, 1963), it was
utilized by Edward F. Denison (1967) and
John W. Kendrick (1973, 1976, 1977), among
others. This approach has been further devel-
oped and carried to a high art by Dale W.
Jorgenson and Griliches ( 1967), Jorgenson et
al. (1987), and Jorgenson (1995).
The main point to be made here is that once
the residual is measured using a framework
like (2) or its equivalent, the direct, measured
contribution of human capital is captured in
the labor term 1wiALi. By direct contribution
I mean what people are paid for. Doctors earn
more than nurses, and engineers more than
draftsmen. These and similar differences are
captured in D;FiALi, which can be positive
even if XALi is zero, just from an upward re-
shuffling of the same labor force. A truly ac-
curate measurement of type (2) would capture
all the subtle differences of quality that exist
in a modem labor force and would give each
a weight corresponding to the (gross-of-tax)
earnings that demanders are observed to pay.
We may do this imperfectly, but, in concept at
least, the residual R' as measured by (2) does
not contain any elements of quality change or
any direct contributions of human capital to
growth. This is a quite important point for it
permits us to zero in on the residual as repre-
senting "technical change," "TFP improve-
ment," and "real cost reduction."
There is no analytical reason to prefer one
of the above three terms over another, in re-
ferring to the residual R'. But I am going a bit
out on a limb to say that a term like "technical
change" leads most economists to think of in-
ventions, of the products of research and de-


### ---Economics-1998-0-04.txt---
velopment (R&D), and of what we might call
technical innovations. On the other hand, TFP
improvement, once purged of the changes in
the quality of labor and/or the direct contri-
butions of human capital, makes one think of
externalities of different kinds -economies of
scale, spillovers, and systematic complemen-
tarities. And finally, real cost reduction, to my
mind, makes one think like an entrepreneur or
a CEO, or a production manager.
I think it would be perfectly fair to char-
acterize my presentation today as a paean in
praise of "real cost reduction" as a standard
label for R'. Labels do not change the un-
derlying reality, but they may change the
way we look at it and the way we think about
it. They also can lead us to understand it bet-
ter. Thinking in terms of real cost reduction
has certainly done all this for me, as I have
tried to sort out the many puzzles and com-
plexities that surround the process of eco-
nomic growth.
Let me try to take you down the path I trav-
eled. In the first place, real cost reduction
(RCR) is probably on the mind of most busi-
ness executives, production managers, etc., at
some point or another in any given week, let
alone in any given month or year. It is a major
path to profit in good times, and a major de-
fense against adversity in bad times. Most U.S.
firms that have downsized in recent years did
so with RCR in mind. So, too, did the firms
that computerized their payrolls and other ac-
counts. And so also did those who shifted to
what they considered more modern manage-
ment techniques. I recall going through a
clothing plant in Central America, where the
owner informed me of a 20-percent reduction
in real costs, following upon his installation of
background music that played as the seam-
stresses worked. And then there is the story of
two Chilean refrigerator firms that ended up as
parts of a single conglomerate at one point.
The new management reduced the number of
models from something like 24 to two, making
agreements to import other models while ex-
porting these two. The end result was that out-
put more than doubled, while the labor force
was cut to less than half, and even the capital
stock (at replacement cost) was significantly
reduced. This sounds like (alnd is really) econ-
omies of scale, but they would not be detected
by our usual measures, as both labor force and
capital stock went down. And we all have seen
cases where, say, an office's real costs were
reduced when a martinet of a manager was re-
placed by someone more reasonable. But we
have also seen cases where real costs were re-
duced when a very lax manager was replaced
by someone more strict.
It has long been my song that there are at
least 1001 ways to reduce real costs and that
most of them are actually followed in one part
or other of any modem complex economy,
over any plausible period (say, a decade).
Once one accepts this proposition as true, the
question then arises: Why would anybody try
to settle on just one underlying cause of real
cost reduction? The answer, I think, is mind-
set-the framework in which one is thinking
at the moment. The pioneer writings of the re-
cent endogenous growth literature can, I think,
be said to reflect a kind of annoyance at some-
thing like R or R' being considered exogenous.
There was an urge to surmount that inelegance
by somehow making the residual endogenous.
And in a simple growth model that meant gen-
erating a feedback from the rest of the model
to the residual. A 1001 feedbacks would be out
of the question, but one feedback would work
just fine. Thus Paul Romer (1986) focused on
a feedback through "knowledge," with the
stock of knowledge shifting production func-
tions all over the economy; Robert E. Lucas,
Jr. (1988) focused on "human capital," not
on its direct and remunerated productivity, but
on the externalities that each increase in the
stock of human capital were presumed to gen-
erate. These single feedbacks achieved the
limited purpose of endogenizing R or R'
within a specified model, but they did not rep-
resent very well the multifaceted nature of real
cost reduction as we observe it in actuality.
And, in point of fact, both the cited authors in
their more recent writings display a deep rec-
ognition of the subtlety and complexity of the
growth process, not really capable of being
captured through a simple feedback mecha-
nism. (See Romer, 1990, 1994a, b; Lucas,
1993.)
So, real cost reduction is multifaceted and
everywhere around us. Where does that get us?
Or how can we get anywhere in the face of
such complexity? The next step is to recognize
that in spite of its complexity, real cost reduc-
tion can be reduced to a single metric, and can


### ---Economics-1998-0-05.txt---

be made additive. For a quick appreciation of
this, assume that total factor productivity grew
by 80 percent in one industry over a decade,
by 60 percent in another industry, and by 50
percent in a third. If their initial value added
amounted to $100 billion, $200 billion, and
$300 billion, respectively, then the real cost
reduction of the first was $80 billion, that of
the second was $120 billion, and that of the
third $150 billion. So we can say that, mea-
sured at initial prices, the real cost reduction
of the three together was $350 billion over the
decade in question. I truly think that the notion
of real cost reduction being additive in this
way came to my mind, and is easily seen by
others, just as a consequence of the label. The
idea of additivity does not follow nearly so
easily from the labels "technical advance"
and "total factor productivity."
Anyway, this vision of the growth process
opens up many new vistas and gives us many
new challenges. To me, it gives life to the re-
sidual, viewed as real cost reduction, in a way
that remote macroeconomic externalities
never did. It gives the residual body, in the
sense that the number of dollars saved by real
cost reduction is a tangible and measurable
quantity. It gives the residual a name (real cost
reduction), an address (the firm), and a face
(the face of the entrepreneur, the CEO, the
production manager, etc.) And, finally, we
shall see that there can be vastly different ex-
pressions on that face, even as we move from
firm to firm in a given industry, as the TFP
experience of a period moves from sharply
positive to devastatingly negative.
I. Yeast versus Mushrooms: Part I
Table 1 is based on the numerical example
just given, plus the information that the re-
maining industries (say, in the economy) to-
gether had an initial value added of $1,400
billion and experienced real cost reduction of
$150 billion over the period. Setting out data
in the format of Table 1 allows us to make
statements like "15 percent ($300 b./$2,000
b.) of the industries (measured by initial value
added) accounted for 40 percent ($200 b./
$500 b.) of the real cost reduction (RCR) of
the period" and "30 percent ($600 b./$2,000
b.) of the industries accounted for 70 percent
($350 b./$500 b.) of the period's RCR."
I stumbled on this way of presenting data on
real cost reduction in the course of writing a
background paper (Harberger, 1990) for the
World Bank's World Development Report of
1991. Once I saw it, I immediately embraced
it, because it helped me communicate to others
what I call the "yeast versus mushrooms" is-
sue. The analogy with yeast and mushrooms
comes from the fact that yeast causes bread to
expand very evenly, like a balloon being filled
with air, while mushrooms have the habit of
popping up, almost overnight, in a fashion that
is not easy to predict. I believe that a "yeast"
process fits best with very broad and general
externalities, like externalities linked to the
growth of the total stock of knowledge or of
human capital, or brought about by economies
of scale tied to the scale of the economy as a
whole. A "mushroom" process fits more
readily with a vision such as ours, of real cost


### ---Economics-1998-0-06.txt---

reductions stemming from 1001 different
causes, though I recognize that one can build
scenarios in which even 1001 causes could
work rather evenly over the whole economy.
Personally, I have always gravitated toward
the "mushrooms" side of this dichotomy. I
remember being impressed, when I first saw
some early industry estimates of TFP improve-
ment, by their tendency to industry concentra-
tion. For years I told my students that the
1920's were the decade of cars and rubber
tires, the 1930's the decade of refrigerators,
the 1940's that of pharmaceuticals (especially
antibiotics), and the 1950's that of television,
with telecommunications anid computers tak-
ing over in recent decades. But these were just
impressions, not based on any systematic ap-
proach. My real turnaround came in the course
of writing my 1990 paper, where I presented
a series of tables based on Kendrick and Elliot
S. Grossman's (1980) work. Table 2 is an
example.
Table 2 has the same format as Table 1. Col-
umn (1) presents the familiar measure of the
percentage by which TFP grew, or real costs
were reduced, during the period in question
(note that the percentages apply to the period
1958-1967 as a whole; they are not annual


### ---Economics-1998-0-07.txt---
rates). To turn these percentages into dollar
amounts of real cost saving over the period,
one multiplies them by base-period real GDP
[col. (4)]. The results are shown in colunm
(2). Columns (3) and (5) are the cumulative
sums of columns (2) and (4), respectively.
Working with these figures one can make
statements like those at the bottom of the
table-i.e., the top 10 percent of industries
accounted for 30 percent of total real cost re-
duction; the top 22 percent of industries (mea-
sured by initial value added) accounted for
more than half of total real cost reduction.
Readers will notice that at the foot of each
column in the table is an entry refering to 18
additional industries, which together accounted
for only 10 percent of the total TFP contribuition,
while their combined share of initial output was
almost 60 percent of the total.
Using the analogy with yeast and mushrooms,
the results of my calculations using the
Kendrick-Grossman data pointed very clearly to
a "nmushrooms" interpretation. Not only were
the contributions to RCR highly conicentrated in
a relatively few industries, these industries also
were very different as one shifted from decade
span to decade span. The top four branches in
percentage of real cost reduction during 1948-
1958 were Communications, Public Utilities,
Farming, and Miscellaneous Manufacturing. In
1958-1967 they were Lumber, Railroad Trans-
port, Textile Mills, and Electrical Machinery. In
1967-1976 they were Finance, Insurance &
Real Estate, Apparel, Communications, and
Chemicals. Only Communications appears twice
among these 12 listings.
Now to my mind, this already brings
evidence to bear on a number of possible hy-
potheses concerning the nature of TFP
improvement. Certainly some ways of inter-
preting a generalized externality due to im-
proved education would be hard to justify
using evidence like this. Strong links of the
residual term to R&D expenditures' would
suggest a high degree of persistence among the
leaders in TFP improvement. So also (proba-
bly) would economies of scale associated with
the scale either of the firm or of the industry.
Such economies are not likely to jump wildly
around from one industry to the next, from pe-
riod to period. One would expect them to em-
body characteristics of the productive process
that would be relatively stable over time;
hence they should show a reasonably high de-
gree of persistence, over time, in terms of the
TFP experience of particular industries.
No economist can look at Table 2 without
thinking of its close analogy with a Lorenz
curve. That, indeed, was the next step I took
in trying to represent the degree of concentra-
tion of real cost reduction. Figure 1 (drawn
from Edgar Robles, 1997), shows the quasi-
Lorenz curves for a 20-industry breakdown of
the U.S. manufacturing sector over four suc-
cessive five-year periods.
What strikes one immediately about Figure
1 is the characteristic "overshooting." I have
marked withi the first vertical line the point
where the rising curve crosses 100 percent on
the vertical axis. The interpretation is that in
1970-1975 the cumulative real cost reduction
of just 25 percent of manufacturing industries
(measured by initial value added) was equal
to the total RCR for manufacturing as a whole.
After that there are other industries producing
another 40 percent of the total, but their con-
tribution is offset by still other industries with
negative RCR during the period.
Corresponding to the 25-percent figure for
1975, we have around 12 percent for 1975-
1980, 48 percent for 1980-1985, and 40 per-
cent for 1985-1991. These are the fractions of
manufacturing industry which by themselves
were able to account for the full amount of real
cost reduction during the respective period, in
manufacturing industry as a whole.
The second vertical line in each panel of
Figure 1 marks the maximum point of the
curve. The interpretation is that about 64 per-
cent of industries enjoyed real cost reduction
during 1970-1975, with the remaining 36 per-
cent suffering real cost increases (declining
TFP). For the subsequent periods, the corre-
sponding figures are 65(35) percent, 78(22)
percent, and 82 ( 18 ) percent. Here the first fig-
ure is the percent of industries enjoying real
cost reductions; the figures in parentheses rep-
resent those experiencing declining TFP.
Some interest attaches to the ordinate of the
maximum point on each curve. In the first pe-
riod, TFP growth ended up accounting for close



### ---Economics-1998-0-08.txt---

to 170 percent of the RCR for total manufactur-
ing. In 1975-1980 this figure was about 240
percent, in 1980-1985 only about half that, and
in 1985-1991 a little more than 125 percent.
The trouble is that when the aggregate TFP con-
tribution is relatively small, the cumulative total
of the positive contributions is a large multiple
of that aggregate, while when the aggregate is
large, this multiple tends to be smaller. Thus, for
1970-1975 and for 1975-1980, the total RCR
in manufacturing as a whole was only about 2.3
percent of initial manufacturing value added. In
contrast, the total RCR for all manufacturing was
almost 10 percent of initial manufacturing value
added in 1980-1985, and about 7.5 percent in
1985-1991.
The problem obviously becomes greatly com-
pounded if the real cost reduction for the aggre-
gate (in this case total manufacturing) turns out
to be negative. Special conventions would have
to be established to make clear the interpretation
of Loreinz-like diagrams in such cases.
I believe I have hit on a felicitous way of
solving all these problems, and at the same
time creating an even better, clearer visual rep-
resentation of the degree of concentration or
dispersion of real cost reduction among the
components of an aggregate. The idea is sim-
ply to relabel the vertical axis of the Lorenz-
like diagram, making it represent an annual
growth rate. For simplicity, think of a 30-
degree line as representing 1 percent per an-
num of TFP growth. The rest of the vertical
axis would be calibrated accordingly. Thus, by
looking at the slope of a simple chord, we
could visually assess how rapid was the TFP
growth of the aggregate in question.
Figure 2 is presented simply for didactic
purposes. Here we have a hypothetical indus-
trial branch made up of four industries, A, B,


### ---Economics-1998-0-09.txt---

C, and D. First, we order the industries in de-
scending order, according to their rates of TFP
increase in the period. Then we calculate cu-
mulative real cost reduction (a real dollar
amount) and plot it against cumulative initial
real value added. Then we scale the vertical
axis so as to comply with whatever metric we
have decided upon for the TFP growth rate (in
the example, a 30-degree line representing a
1-percent annual TFP growth rate), and the
horizontal axis so as to add up to 100 percent.
In the lower panel of Figure 2 1 give ex-
amples to show how these diagrams cope with
the problems of a low TFP growth rate (the
overshoot for the case of 0.25-percent growth
would show up peaking at over 400 percent in


### ---Economics-1998-0-10.txt---

### ---Economics-1998-0-11.txt---
a Lorenz-type diagram) and of negative TFP
growth (where it is hard to even conceptualize
a Lorenz-type picture).
I first presented these diagrams before a
large audience at the Western Economic As-
sociation meetings in Seattle (July 1997), and
for that presentation coined the label of "sun-
rise diagrams" on their analogy with the sun
rising over a hill. That same evening Yoram
Barzel suggested that where the aggregate
slope is negative, we apply the term "sunset
diagrams," which I immediately accepted.
Figure 3 presents a set of sunrise-sunset
diagrams based on Jorgenson et al. (1987 pp.
188-90). These cover 32 industrial sectors
(their 35 minus Agriculture, Trade, and
Government Enterprises). I think the utility
of sunrise-sunset diagrams needs no further
championing once these pictures are exam-
ined and digested. Practically all variants are
represented in these real-world cases: low
TFP growth with a huge overshoot (1953-
1957 and 1969-1973); negative growth
with large and moderate overshoots (1966-
1969 and 1973-1979); moderate growth
with small (1979-1985), medium (1960-
1966), and large (1948-1953) overshoots.
One striking fact that emerges from this set
of pictures is how variable across periods is
the negative contribution of the losers. If the
losers had only contributed zero change in
TFP, we would have had cumulative TFP con-
tributions of about 0.8 percent per annum in
1948-1953, in 1957-1960, and in 1960-
1966. And the other periods would not have
been much different: about 0.7 percent in
1953-1957 and in 1969-1973, 0.6 percent in
1966-1969, and 0.5 percent in 1973-1979
and 1979-1985. Instead of this narrow range
of cumulative contributions, we have an actual
distribution that goes from -0.9 percent in
1973- 1979 through around 0.1 percent in
1953-1957 and 1969-1973 to over 0.5
percent in 1960-1966 and 1979-1985.
Does this not suggest that we make a major
research push trying to improve our under-
standing of the phenomenon of negative TFP
growth? What syndromes characterize the firms
and industries experiencing it? How much of it
stems from external shocks like international
prices? How much of it from competition
within the industry? How much of it represents
firms struggling to survive, yet experiencing
output levels well below their previous peaks
(and presumably below installed capacity)?
How much of it represents things like "labor
hoarding" as firms go through periods of
adversity?
IL. Yeast versus Mushrooms: Part II
I hope that in the previous section I have
made a convincing case concerning: (a) the
usefulness of sunrise-sunset diagrams, (b) the
aptness of the "yeast versus mushrooms" di-
chotomy, and (c) the pervasiveness with
which the mushroom side of that dichotomy
seems to come out ahead when the GDP is
broken down into industries or industrial
branches for TFP analysis. The grand design
that emerges from the studies reported here,
and from just about all the other industry
breakdowns that I recall having seen, is that:
(i) a small-to-modest fraction of industries
can account for 100 percent of aggregate real
cost reduction in a period; (ii) the comple-
mentary fraction of industries contains win-
ners and losers, the TFP contributions of
which cancel each other; (iii) the losers are
a very important part of the picture most of
the time, and contribute greatly to the varia-
tions we observe in aggregate TFP perfor-
mance; and (iv) there is little evidence of
persistence from period to period of the lead-
ers in TFP performance.
The above results are, I think, very in-
teresting (in the sense of piquing our curi-
osity), very strong (in terms of their impli-
cations about the nature of the growth
process), and very robust (in the sense that
they have wide applicability over different
data sets analyzed by different authors using
at least somewhat different methods). But
these results, so far, are quite compatible
with what I might call an "industry view"
of the TFP story. This is the way I, myself,
looked at the growth process until quite
recently-a vision that was reflected in my
stories about rubber tires and autos in the
1920's, refrigerators and other household
appliances in the 1930's, pharmaceuticals in
the 1940's, etc. The image that I had in
mind was one of yeast within each industry
and mushrooms between industries-a
commonality of TFP experience by firms within'
an industry, depending on that industry's


### ---Economics-1998-0-12.txt---

luck in the technological draw, side by side
with highly diverse experience between indus-
tries because the distribution of technical ad-
vances had wide dispersion, even for periods
as long as a decade.
Getting access to data at the firm level per-
mits one to explore whether this view is com-
patible with the actual experiences of firms and
industries. We are just in the early stages of this
exploration, but I think the result is quite clear
already; namely, the "mushrooms" story pre-
vails just as much among firms within an in-
dustry as it does among industries within a
sector or broader aggregate. I will present here
only a taste of the evidence from the United
States (on which our systematic work just re-
cently got started). Our massive evidence
comes from the Mexican manufacturing sector,
for which Leonardo Torre ( 1997) has analyzed
data from a sample of over 2,000 firms. A small
fraction of these firms were lost owing to miss-
ing data, but some 1,900 firms remained in the
sample that Torre finally worked with. These
firms were divided into 44 branches of industry,
so that on average we have about 43 firms per
branch.
There are really too many ways to present
such a mass of information as is contained in
Torre's study. What I will do here is give the
aggregate picture in Figure 4, and then show
in Figures 5A-C three fast-growing branches,
three of around median growth, and three from
among the slowest-growing branches.
To complement these figures, I finally pres-
ent, in Figures 6A-D, certain summary statis-
tics from the sunrise-sunset diagrams of the 44
branches that Torre studied. Here Figure 6A
gives the distribution of average rates of TFP
growth among the 44 industries. Figure 6B
shows the distribution of peak cumulative con-
tributions, i.e., what the TFP contribution
would have been had all the negatives been
zeros. Figure 6C displays the percentile of
firms (by initial value added) marking the bor-
derline between positive and negative TFP
growth. And finally, Figure 6D shows, for
branches with positive TFP growth, the per-
centile of firms which, by themselves, account
for 100 percent of the industry's TFP growth.
This evidence almost seems to replicate, for
firms within an industry, what was found in
the previous section for industries within the


### ---Economics-1998-0-13.txt---

economy-rampant overshooting of sunrise-
sunset diagrams, great influence of firms with
negative TFP growth in determining the TFP
outcome for an industry, and a small or mod-
erate fraction of firms accounting for 100 per-
cent of the TFP growth of an industry (when
that growth is positive), with the complemen-
tary fraction being winners and losers whose
efforts end up just offsetting each other. It re-
mains to try to give some interpretation to
those results.
III. "Just Errors" or "It's a Jungle
Out There?"
The first question that will enter the mind
of many economists on looking at the evi-
dence presented so far is: how much of what


### ---Economics-1998-0-14.txt---

we have seen and emphasized might simply
be the result of errors of observations? This
is by no means a frivolous question. For one
can actually create frequency distributions
of rates of TFP increase which contain ex-
actly the same information as the sunrise-
sunset diagrams previously presented. The
only trick is to count as the unit of frequency
not one firm (out of an industry aggregate)
or one industry (out of some larger aggre-
gate) but, instead, say, 1 percent of the total
value added of the aggregate. Thus a firm
with 20 percent of the value added of an in-
dustry would appear with 10 times the
weight of a firm accounting for 2 percent of
the value added of that industry. In such a
chart, the cumulative frequency (say, 68 per-
cent) above ATFP = 0 would represent the
projection on the horizontal axis of the
maximum point on a sunrise diagram. Its


### ---Economics-1998-0-15.txt---

complement (32 percent) would represent
the initial value added associated with neg-
ative TFP performance during the period.
If, then, all the information could be gen-
erated by a properly designed frequency dis-
tribution of rates of TFP growth, could it not
all be the result of chance alone-more spe-
cifically, of errors of measurements? I really
think not-my favorite quip on this is that
"white noise does not sing a tune." That is, if
we can rationalize what we see in terms of an
analytical framework which embodies well-
established economic principles and sensible
presumptions about underlying relationships
and facts, this is itself strong evidence against
the white noise hypothesis.
Nonetheless, we have to face the fact that
errors of observation of some magnitude cer-
tainly do exist, and we must recognize that
they can cloud our perceptions and bias our
results. What I am going to do here is consider
frequency distributions of firms. TFP is mea-


### ---Economics-1998-0-16.txt---

sured in two ways-one using value added by
a set of firms on the one hand, and the other
using "output" by those same firms, mea-
sured through dividing value added by sepa-
rate estimated firm-by-firm price (of value
added) indexes pj. For these purposes we can
conveniently think in terms of logarithms, so
let:
V = observed value added of firm;
pj = estimated firm-level price index;
y, = v, - p, = estimated output;  Vj = Tj + ej [Tj =true value added];
p= = 7rj + Uj [7r, = true price index]; and
qj = T- 7r, [true output of firm].
We would like to have data on cj and its
variance
2 2 +
If we simply work with observed value added
as our quantity variable, we get
a?2 = a2 + a? (assuming at0 = ?)
If we worked with the measured yj, we get
2= ao + a? + a2 + u2- 2at
(assuming a and e to be strictly random).
My presumptions are as follows:
(i) We can estimate value added quite ac-
curately at the firm level. Hence the pre-
sumption that ao is small.
(ii) In most industries, there is considerable
variety among the firms and their prod-
ucts. Hence, except in cases of industries
with very homogeneous products, we
should not expect a2 to be small. Hence,
I expect a > a?
(iii) Finally, we have the presumption that, at
least at the level of firms within an in-
dustry, o7 < 0. We know that firms
choose to operate in regions of the de-
mand curve where they consider the elas-
ticity facing them to be greater than one.
But also, in an analysis of the growth
process, one would expect the big gains
in value added to accrue to those firms
in an industry which were passing along
to consumers some of the fruits of cur-
rent or past real cost reductions.
These three presumptions lead me to the con-
clusion that ao is likely to understate the true
variance of output ao (because - 2JT > 0 and
ao2 > sa?), and that ao is likely to overstate
0o2 (only the covariance terms with e and u,
which were assumed to be zero, could make it
otherwise). And since Torre worked with real


### ---Economics-1998-0-17.txt---

value added as his quantity variable, this sug-
gests that, if anything, the substitution of the
"true quantity variable" q for observed value
added v would have given results with
greater dispersion of TFP, and consequently
greater overshooting in his sunrise-sunset
diagrams.
The above demonstration should be taken as
merely suggestive. It is not important to me
that Torre' s results underestimate the variabil-
ity of the different firms' TFP experience. It is
only important that measurement error should
not be the principle determinant of those re-
sults. On this I feel very confident. In my view,
it really is "a jungle out there," with winners
and losers in every period-good as well as
bad.
As I have noted earlier, we are only just be-
ginning a systematic study of TFP among U.S.
firms, so I can offer no display comparable to
Torre' s.
However, Robles (1997) did examine the
experience of 12 firms in the U.S. oil industry.
His results are summarized in Figure 7. But
Robles tells basically the same story as Torre.
Three firms out of the 12 were more than suf-
ficient to generate the real cost reduction ex-
perienced by the total group. Half (or almost
half) of the firms had negative TFP growth in
each period. And the cumulated amount of this
negative TFP growth was sizeable when mea-
sured against the total TFP performance of the
industry.
What I see in TFP performance is quite anal-
ogous to what I see in the stock market pages of
the newspaper. There are winners and losers
eveiy day, every month, and every year. The
gains and losses come from all sorts of causes.
World price shocks can drive firms into negative
TFP performance if the consequent output re-
ductions are greater than the reductions of in-
puts. So, too, can cyclical or secular declines in
demand, including those caused by the success-
ful actions of competitors.
When firms are under stress, they typically
fight to stay alive. Maybe they fight for too
long in some cases, in the sense that less of
society's resources would be wasted if they


### ---Economics-1998-0-18.txt---
12 -
10 -
8
C-)
CT
U-
4
2
0
0 12.5 25 37.5 50 62.5 75 87.5 iQO
Percentiles
FIGURE 6C. PERCENTAGE WITH POSITIVE TFP GROWTH: MEXICAN MANUFACTURING 1984-1994
FREQUENCY DISTRIBUTION OF PERCENTILES, 44 INDUSTRIAL BRANCHES
were to quit earlier in response to a challenge
that turns out to be deadly. But they do not
recognize the challenge as deadly, so they
keep struggling to survive. I believe this is part
of the nature of entrepreneurs, CEOs, and
business leaders in general. They would not be
where they are, doing what they are doing, if
they were ready to quit at the first sign of a
challenge. They are fighters by nature, and
they probably would not have achieved suc-
cess if they were not.
Firms with negative TFP growth may even
be innovators. New challenges come and dif-
ferent firms think of different ways to respond
to them. Some (like Intel and Microsoft) end
up winners; others (Montgomery Ward and
Apple?) end up losing. But it may not be that
they just waited passively and tried to fight to
survive in the face of negative shocks. They
may have had quite innovative ideas, with de-
cent prior probabilities of success, but in the
end success did not come. Thus, negative TFP
performance can, and I believe often does,
come simply from "backing the wrong horse."
To me, Joseph A. Schlumpeter's vision
(1934) of "creative destruction" captures
much of the story. What he is saying is, yes,
it's a jungle out there, but the processes of that
jungle are at the core of the dynamics of a
market-oriented economy. They are what got
us to where we are, and they hold the best
promise for further progress in the future.2
In my opinion, Schumpeter saw through to
the essence of the problerrm, but it is not wise
for us to be fatalistic in accepting his vision.
We cannot lose by making a major effort to
understand the process of TFP improvement
where it happens-at the level of the firm.
This is all the more true because of the


### ---Economics-1998-0-19.txt---

pervasiveness of negative as well as positive
TFP performance among the components of
almost any aggregate. By learning more about
this aspect of the aggregate picture, we may
stumble upon ways to "accentuate the positive
and eliminate the negative" parts of the TFP
story. But that is too quixotic a goal to take as
the point of focus right now. To me, the pres-
ent task is simply to get hold of the huge mass
of information that is available at the firm
level and squeeze it hard enough to wring out
as much understanding and as much insight as
we can.
IV. Some Observations on Methods
and Research
What I am about to say in this section is not
meant to consist of direct implications of what
has gone before. Instead, I think of the earlier
parts of this paper as building a case for a cer-
tain vision of the economy, and of how the
forces of growth work within it. This vision in
turn leads one to think in different ways not
only about the growth process itself but about
how we, as economists, might best advance
our study and understanding of it, and how
policies might be molded so as better to pro-
mote it.
(a) It is always wise to study the compo-
nents of growth separately. The rate of in-
vestment, the rate of return on capital, the rate
of growth of the labor force in numbers or in
hours worked, the contribution of human cap-
ital or of the increment in average quality of
labor, and the residual representing real cost
reduction-all these are sufficiently different,
and potentially sufficiently disjoint from each
other, to merit their being treated separately. I
would give special emphasis to the following
three points.
(i) The worthwhileness of measuring the
rate of return and emphasizing its role in
the growth process.
(ii) The importance of focusing on invest-
ment rather than saving in studying the


### ---Economics-1998-0-20.txt---


### ---Economics-1998-0-21.txt---
process of growth. Saving is an interest-
ing topic in its own right, but the more
''open economy" is the situation being
studied, the less saving has to do with
investment. Saving takes on great im-
portance in closed-economy models fo-
cused on aggregate growth, in which
case it is equal to investment. It gets to
be almost meaningless as one focuses on
the growth of cities and regions, or on
firms and industries.
(iii) The importance of viewing the residual
as an umbrella covering real cost reduc-
tions of all kinds, and of recognizing that
we are closer to home thinking that RCR
takes 1001 forms than that it can be well
represented by one or two or three
aggregate-style variables.
(b) In principle, the accumulation of hu-
man capital by the laborforce should be rep-
resented in the labor contribution of the
growth equation, or in a bifurcation of this
contribution into one due to raw labor, the
other to human capital. It is in a term like
iwiALi that one captures the shifting skill
composition of the labor force. In particular,
we capture here the higher wages that are the
fruits of investment in education and training,
which are the benefits that the workers them-
selves perceive. These should be kept sepa-
rate from any externalities education might
have.
It is important to try to keep this internalized
part of the story out of the residual, so that we
can straightforwardly interpret the residual as
real cost reduction.
(c) To study externalities due to education,
training, or human capital, we should not be
content with broad generalizations such as
"TFP growth is higher in entities with lots of
human capital per worker." We should try to
figure out how this externality works. Is it
higher forfirms with high incidence of human
capital? Is it higher for industries or sectors?
Or are human capital externalities more spatial
in nature, making more efficient the economic
life of the cities, provinces, states, or nations
which have high concentrations of human cap-
ital? And if this is a fruitful trail to pursue, at
what type and size of geographical units do
these externalities typically work?
(d) The same goes for economies of scale.
We should not be satisfied with vague attri-
butions of economies of scale, say, at the level
of the national economy. Instead, we should
pursue the matter. If the economies of scale
are national, through what channels do they
work, and what evidence do we have to look
at to see them in operation? In particular, what
is their connection to real cost reductions
where they really happen-i.e., at the level of
the firm? Economies of scale at the levels of
the firm and the industiy are easier to visual-
ize. Here, too, however, the task is to check
them out-to see if the real cost reductions of
firms are linked to the initial sizes of those
firrns themselves, or of the industries in which
they operate, and of the direction (up or down)
in which output is moving.
(e) Perhaps most important of all, we
should really try to take full advantage of ev-
idence at the firm level. I think particularly of
identifying considerable numbers of outstand-
ing cases of TFP improvements and TFP de-
cline, and studying them one by one to try to
ferret out the sources of their big real cost re-
ductions and real cost increases. You can be
pretty sure, if there have been big real cost
reductions in a firm, some people in that firm
have a pretty good idea of where those reduc-
tions came from and how they were accom-
plished. By capturing this grassroots evidence,
we can put some added discipline into our ru-
minations about the nature of TFP at the ag-
gregate level. We must follow up on the sort
of work pioneered by Jacob Schmookler
(1966) and Edwin Mansfield (1995). In gen-
eral, our aggregate story should be compatible
with, and comfortably contain, what we see at
the grassroots level. In particular our overall
picture of TFP improvement should comfort-
ably accept the overwhelming evidence of the
"'mushroomss" rather than "yeast" nature of
the process.
(f ) Special urgency applies to the study of
declining total factor productivity at both the
firm and the industry levels. The pervasiveness
of declining TFP is perhaps the most profound
conclusion to emerge from the empirical links
that I have reported here. As a profession, we
obviously have been aware of its existence at
the industry level for virtually all studies that


### ---Economics-1998-0-22.txt---
give a breakdown by industry reveal it. Yet to
my knowledge, we have barely scratched the
surface in studying it. I find it hard to think of
more fertile soil for future research on the pro-
cess of economic growth.
(g) I do not think that we gain much by
trying to express the relation between policies
and economic growth by a series of regres-
sions. Cross-country growth regressions seem
hopelessly naive to longtime observers of the
growth process like myself. To us, there is too
mutch to question in regression lines that draw
much of their slope from the differences be-
tween Sudan and Switzerland, between Bang-
ladesh and Brazil, or between Ceylon and
Canada. In contrast, it seems much more sen-
sible to look at episodes within individual
countries and to search for common elements
that characterize the passage from bad to good
growth experiences within each of the number
of countries, and for those elements that seem
to describe the good growth experiences on the
one hand and the bad ones on the other. I think
we can reach in this way a good appreciation
of the nature of the growth process, without
resorting to the straitjacket of regression lines
that seem to draw from comparisons among
very disparate countries, lessons that are sup-
posed to be meaningful for countries like
Bangladesh, Ceylon, and the Sudan-as well
as others at different levels-as each strives
to take the next upward step in the climb to-
ward modernization.
My view of cross-country growth regres-
sions is somewhat less negative to the extent
that they focus on the components of growth
(rate of investment, rate of return, and real
cost reduction in particular) rather than on the
overall growth rate. There is also a subtle dis-
tinction to be drawn between two ways of
presenting cross-country regressions- (i) as
"explaining" why and how some countries
grow faster than others (not recommended),
and (ii) as simply summarizing a series of
"stylized facts" describing the experience we
observe (far preferable, and not just for its be-
ing more modest in its claims).
V. Some Policy Implications
In approaching the question of the influence
of policy on real cost reduction in particular,
and, to a degree even on economic growth in
general, I believe that the key words are "ob-
structing" and "enabling." We know from
sad experience how easy it is for governments
to adopt policies that get in the way of eco-
nomic growth and even turn it negative. We
know, too, that there is no "silver bullet," no
single magic key that by itself opens the door
to a paradise of prosperity and growth.
Broadly speaking, the easiest starting point for
a successful growth experience is a once-
prosperous economy that has suffered from
bad policies. Releasing that economy from its
trammels, correcting an accumulation of past
mistakes, can sometimes set in motion a pro-
longed episode of astounding growth. A shift
from policies that obstruct to policies that en-
able growth seems to lie at the heart of growth
"miracles" like those of Taiwan, Spain, Ko-
rea, Brazil, Indonesia, Malaysia, and China
(among others).
The springboard for the following listing of
policy implications is the interpretation of the
growth residual as representing real cost re-
duction and the ready acceptance that in the
real world RCR comes in 1001 different
forms.
(a) The first key observation is that people
must perceive real costs in order to reduce
them. Hence, policies that impede the accurate
perception of real costs are ipso facto inimical
to growth. Inflation is the most obvious, prob-
ably the most pervasive, and almost certainly
the most noxious of such policies. If I have any
expertise based on experience in economics, it
has to be in the first-hand observation of pro-
cesses of serious inflation. So I ask you to
take my word for it: the most serious cost of
inflation is not a triangle or a trapezoid under
the demand curve for real cash balances, nor
is it the inflation tax. The most serious cost
of inflation is the blurring of economic
agents' perceptions of relative prices. This
happens because individual prices adjust in
different ways and at very different rates. A
high product price and a low input cost nor-
mally is an invitation clamoring for new in-
vestments to be made. This is not so during a
serious inflation, when such a signal can eas-
ily turn out to be "here today, gone next
month" as both product and input prices con-
tinue on their separate paths of adjustment to


### ---Economics-1998-0-23.txt---
the ongoing inflation. Without exception, in
my own observations, the higher the rate of
inflation, the worse is its effect in blurring
agents' perceptions of relative prices. In an
inflation at, say, 20 percent to 50 percent per
year, people see prices as in a morning haze;
in one of 20 percent to 50 percent per month,
they see them as in a London fog. Many em-
pirical studies exist showing that serious in-
flations are seriously inimical to growth. (See
William Easterly, 1996.) The clouding of
perceptions of relative prices is an important
reason why-for it gets in the way of suc-
cessful real cost reductions at the level of the
individual firm.
Inflation also inhibits growth in other, per-
haps more obvious ways:
(i) by diverting energies from more produc-
tive activities to the search for mecha-
nisms of inflation protection;
(ii) by reducing (often very drastically) peo-
ple's real monetary balances, thus im-
pacting negatively on the real amount of
credit the banking system provides to the
productive sector; and
(iii) somewhat related to both (a) and (b),
by causing people (both "here"' and
abroad) to invest abroad some of the
funds they would otherwise have in-
vested "here," or (what is very close
to the same thing) by accumulating
hoards of hard currencies as an inflation
hedge.
(b) A second policy implication is, in the
words of my friend and longtime collabora-
tor Ernesto Fontaine, avoid "prices that lie"
(precios mentirosos). Talking about infla-
tion, we focus on the blurring of the signals
that the price system gives; here we focus on
its giving wrong signals due to distortions
that have been introduced, usually as a direct
consequence of government policies. No
good can or did come, in terms of economic
efficiency, from tariffs of 50 percent and 100
percent and more, giving effective protec-
tion often of 200 percent and 300 percent
and more. Nor can growth be fostered by
heavy-handed price controls and interven-
tions in credit markets.
I am not being a religious purist here-just
as big distortions have big costs, small distor-
tions typically have small costs, and all econ-
omies are distorted to some degree. The
message here is that economies have to pay
the price for the level of distortions they
choose to have, and that one of the important
components of that price is that distortions
create situations where what is truly a saving
of private costs is not a genuine saving of costs
from the point of view of the economy as a
whole.
(c) Just as bad, and often even worse than
direct distortions, are the excess costs imposed
on an economy by ill-conceived regulations
and bureaucratic hurdles. Hermando DeSoto
(1989) has made the exposure of these tram-
mels in Peru into what has become virtually
his life's work. Clear rules of the game are
an essential and integral part of a well-
functioning market economy, but all too easily
these get supplemented by others that make
investment, production, marketing, sales, new
product development, etc., more costly. Labor
laws have been particularly troublesome, often
adding artificially to the cost of labor and giv-
ing firms a strong incentive to avoid hiring
new workers, simply because of the high costs
associated with any later dismissal of them.
But there are loads of other items-the need
for approvals, sometimes a dozen or more,
before undertaking some investment or some
new venture; regulations that one way or an-
other impede new entry, so as to protect strong
vested interests ( small retailers being pro-
tected against supermarkets in many coun-
tries); and the complexity of tax codes and
their enforcement, which imposes large com-
pliance costs on business firms and indi-
viduals. Somehow, countries interested in
promoting growth should find ways of paring
their regulatory frameworks down to those
rules and requirements that are really justifi-
able in terms of their costs and benefits to the
economy and society at large.
(d) Although international trade distor-
tions (tariffs, quotas, licenses, prohibitions,
etc.) might be subsumed under points (b) and
(c), their importance merits a separate head-
ing. The move to openness (from a protec-
tionism that sometimes bordered on autarchy)
has been one of the main hallmarks of the
growth miracles of the past half-century [see


### ---Economics-1998-0-24.txt---
Sebastian Edwards (1993) and Anne 0.
Krueger (1985, 1997)]. Just as inflation has
costs beyond the area under the demand curve
for real cash balances, so protectionism seems
to have burdens that go beyond the standard
triangle-trapezoid-rectangle measures of the
costs of trade distortions. There are at least two
quite natural explanations: first, that openness
helps grease the wheels of the international
transfer of more modern technologies, and
second, that firms that may once have relaxed
in ease and comfort behind high protective
barriers end up having to sink or swim once
forced to compete in a much more open-
economy setting. Under either explanation,
trade liberalization opens up new paths of real
cost reduction, thus providing additional im-
petus to economic growth.
(e) The recent wave of privatizations
among both developed and developing econ-
omies may have important effects in enabling
real cost reductions that otherwise might have
been delayed, or not have happened at all. It
is, I believe, fair to say that in most countries
state-owned enterprises operate under a series
of constraints that seriously get in the way of
real cost minimization in a comparative-static
sense and of real cost reduction in a dynamic
sense. These constraints sometimes limit the
salaries of executives, sometimes impose
onerous conditions on the firm as it employs
lower-skilled workers, often limit the capacity
of the firm to shut down inefficient lines of
production, and almost always make it diffi-
cult to fire workers, etc. To my mind, however,
perhaps the worst attribute of state-owned en-
terprises is the ethos that often evolves inside
of them-an ethos where middle managers
are well advised to "leave well enough
alone," "not rock the boat," and "not invite
trouble." This ethos flies in the face of a vision
of the growth process that gives a huge role to
the search for real cost reductions at the grass-
roots level, and that recognizes the tumult that
accompanies "creative destruction" in all its
forms. I thus must applaud the contemporary
trend toward privatization. If I harbor any
qualms in this connection, they concern the
degree to which many privatizations have been
carried out in too much haste and with too little
care, often motivated by purely fiscal consid-
erations rather than by a general search for
economic efficiency. This nlay have led to gra-
tuitous transfers of wealth in some instances
and to the planting of newly private enterprises
in soil that was not properly prepared (e.g.,
still lacking a sound regulatory framework for
electricity rates, or intelligent rules promoting
competitiveness in at least some aspects of
telecommunications, etc.)
(f) One cannot complete a list like this
without mentioning something that most of us
simply take for granted-a sound legal and
institutional framework in which individuals
are protected against arbitrary incursions on
their property and other economic rights. This
very basic point-recently much emphasized
by Douglass C. North ( 1990), Robert J.
Barrow and Xavier Sala-i-Martin (1994),
Mancuir Olson, Jr. ( 1996), and Barro ( 1997 )
is at least potentially a vital element for a sus-
tained process of successful economic growth.
If it is true that spurts of growth have some-
times occurred in the absence of such a frame-
work, it is also true that most cases of
sustained growth over long periods of time
have benefitted from a sound institutional and
legal environment.
(g) Somewhat related to the above is the
element of political consensus concerning the
broad outlines of economic policy. We have
learned from experience that very admirable
policy reforms can take place, yet end up hav-
ing little effect. This can happen because a
new government comes in and reverses the re-
form. But it can also happen because people
fear that a new government will come in and
reverse the reforms later on. At the moment,
the Chilean economy is one of the jewels of
economic growth (and general economic suc-
cess) in Latin America. Many people point to
the thoroughness and pervasiveness of Chile's
economic reforms over the last two decades or
so. But not so many point to the fact that the
reform package has remained essentially intact
through several changes of ministers, and even
more i-mportant, through two presidential elec-
tions in which the winners came from the op-
posite side of the political fence from the
government that initiated the reforms. The
confidence in the economic order of things in-
stilled by this sequential endorsement of the
basic framework of economic policy has to be


### ---Economics-1998-0-25.txt---
one of the important reasons for Chile's con-
tinued, very impressive economic perfor-
mance. And it is important, also, in the context
of this paper. Living in a world in which real
cost reductions are a key dynamic force pro-
ducing economic growth, we must look to the
motivations and preoccupations of those who
take the critical decisions at the level of the
firm. For these decisions, it is not only impor-
tant that the policy framework be good now;
the expectation that it will stay good in the
future is also important. Otherwise, invest-
ments will tend to be limited to those with
short horizons and payment periods, and much
soil, fertile with longer-term economic oppor-
tunities, will go unplowed.
VI. A Vision of the Growth Process
Let me now try to summarize my own vi-
sion of the growth process-the major ele-
ments of which have been presented here. In
the first place we have the five standard pillars
of growth-the rate of increase in the labor
force, the rate of increase in the stock of hu-
man capital, the increase in the capital stock
(net investment as a fraction of value added),
the rate of return which that investment will
yield (or can be expected to yield) and, last
but not least, real cost reductions stemming
from 1001 different sources.
Commenting on these in turn, I would note
that increases in the labor force have taken on
new meaning in many countries as labor force
participation rates (particularly those of
women) have increased. Whereas with a con-
stant participation rate, the growth rate of the
labor force is just a proxy for the growth rate
of population, important increases in labor
force participation can lead, just by them-
selves, to significant increases in measured
real income per head.
Concerning increases in the stock of human
capital, my conviction is that most of their
contribution to growth is, on the whole, well
measured by market wages, as in the expres-
sion XiwiALi. This does not deny the exis-
tence of externalities due to an increased
human capital stock; it simply judges their in-
fluence on the growth rate to be modest in
comparison with the effects of education,
training, learning-by-doing, etc., that can be
(and typically are) internalized by those who
receive them. We therefore look for the effects
of human capital accumulation mainly in the
term YjwjALj, and only (via externalities) as
one of many elements underlying the growth
residual R'.
The rate of investment is a veteran on the
stage of growth analysis. What I would em-
phasize here is the importance of maintaining
a clear separation between the rate of invest-
ment and the rate of saving. Models (like
those of the representative consumer) in
which saving and investment are always
equal are not much use even for analysis at
the national level in our modern, interde-
pendent world. They are even less useful as
one goes down to smaller geographical
regions, and simply cease to make sense as
one studies the growth process at the levels
of the industry and the firm.
The rate of return to investment has in
many ways been the orphan of our growth
analysis, having been masked from view by
our typical representation of capital's contri-
bution to the growth rate as Sk (AK/K). Here
the rate of return (p + 6) is totally hidden
from view. I deeply urge that more of us get
into the habit of representing this same term
as (p + 6)(AKIy). I want to see more atten-
tion paid to the rate of return because it plays
such a central role in the motivation of eco-
nomic agents, and also because changes in it
are such an important element in understand-
ing and explaining the growth residual, R'.
Table 3 helps explain why I feel this way.
This table is adapted from Harald Beyer's
(1996) work. He carried out an analysis of
the growth experiences of 32 countries rang-
ing from Sri Lanka to the United States on
the income scale, and from Iceland to Austra-
lia on the geographic scale. In Table 3 we
present results for his ten countries with the
highest and for his ten countries with the low-
est GDP growth rates from 1971-1991. In the
second column the calculated average annual
rate of return is shown. In the third column
we have capital's contribution to the growth
rate [z (p + 6) (AKly) ], and in the final col-
umn the estimated average annual rate of TFP
growth, all over the same time period.
Table 3 shows an unequivocal tendency for
fast-growing countnes to be experiencing high
rates of return as well as high capital contri-
butions and high rates of TFP improvement.


### ---Economics-1998-0-26.txt---

This is all the more interesting because in the
calculation of TFP a higher level of the rate of
return operates to reduce the calculated TFP
(i.e., Ap is a positive component of R' and
should presumably be positively correlated
with it,3 but R' is found by subtracting p AK
from Ay; hence, in a sense, the level of p
should presumably be negatively correlated
with R'). What we are seeing here, in my
opinion, is a genuine syndrome in which all
sorts of good things go together. Strong real


### ---Economics-1998-0-27.txt---
cost reductions and high rates of return create
attractive investment opportunities which,
when acted upon, bring about a high capital
contribution to growth. It should be no surprise
that under such circumstances the GDP growth
rate itself tends to be high. It should likewise
be no surprise that the opposite syndrome
with weak real cost reductions and low rates
of return producing fewer interesting invest-
ment opportunities-should end up being as-
sociated with a low capital contribution and a
low GDP growth rate.
Finally, we come to the residual R' itself.
To me, the biggest message here is to recog-
nize the multiplicity of sources from which it
can (and I believe does) come, and the addi-
tivity that nevertheless is its attribute. I think
that the term real cost reduction very neatly
captures both these aspects in a way that ren-
ders it preferable to terms like TFP improve-
ment and technical advance-preferable not
in the sense of a mechanical definition (for
which all three are equally good), but in the
sense of better conveying the underlying na-
ture of the process to one's listeners or readers.
The next step is to recognize that of the five
main pillars, at least three (the rate of invest-
ment, the rate of return, and real cost re-
duction) are key foci of decision-making
processes at the level of the firm. I cannot es-
cape the conclusion that the great bulk of the
action associated with the growth process
takes place at the level of the firm. Hence, I
feel we should focus much more study than
we have in the past on what happens at this
level. And when we are not working at the firm
level, we should pay a lot of attention to what
happens at lesser levels of disaggregation like
industries and industrial branches.
Key insights flow from taking this kind of
focus. Few economists are aware of the per-
vasiveness with which sunrise-sunset dia-
grams are characterized by overshooting, or of
the importance that firms or industries with
real cost increases (i.e., reductions in TFP)
play in determining the aggregate rates of real
cost reduction that we see in such diagrams.
Here we have only scratched the surface in
digesting the evidence. But I find impressive
the degree to which the data of Table 3 seem
to point to a growth syndrome in which high
rates of return, high rates of investment, high
rates of real cost reduction, and high rates of
output growth all go together. I see in this re-
sult the likelihood that real cost reductions are
the big driving force, generating high rates of
return and calling forth high rates of invest-
ment and high output growth. This interpre-
tation is compatible with many exercises that
I have perforned over the years in which I
have tried to contrast high-growth with low-
growth experiences. In such exercises, as in
Table 3, the difference in rates of real cost re-
duction has typically been a major "source"
of the difference in growth rates.
Also impressive in the analysis of the
Jorgenson data is the degree to which the vary-
ing experiences of U.S. manufacturing in dif-
ferent decades derives from different degrees
of bad experience (real cost increases) rather
than different degrees of good experience (real
cost reduction). It is as if the creative part of
Schumpeter's "creative destruction" was
more steady (for these decades in U.S. man-
ufacturing) than the destructive part, whetting
our (or at least my) appetite to look deeper,
inquiring into why this was so.
The Mexican data at the firm level were
somewhat more recalcitrant than the Jorgenson
data by industrial branch, but they nonetheless
give us a clear picture of lots of winners and
lots of losers, with the losers being strongly
characterized by falling real value added and/
or by falling real rates of return.4


### ---Economics-1998-0-28.txt---
The role of policy in this vision of the
growth process is an "enabling" one. By cre-
ating the circumstances where firms can
quickly and accurately predict opportunities
for real cost reduction and act on them, gov-
ernments can guide the economy toward an
enhanced contribution of RCR to growth. By
rationalizing and/or eliminating barriers and
controls, they may also lead to an increased
pace of investment and increased rates of re-
turn. In this view, the connection between
good policy and growth is not mechanical, and
thus cannot easily be captured in regression-
type analysis, but that does not stop it from
being of vital importance.
I want to give special weight to another role
of "growth-enabling" policy actions, which
has to do with how policies, the effects of
which might typically be considered to be
comparative static, can nonetheless turn out to
influence economic growth rates over ex-
tended periods of time.
This story begins with a recognition that
most developing countries have typically used
production techniques that were "backward"
in relation to those used by the advanced econ-
omies. One way to verify this is to imagine
integrally replicating, say, a U.S. factory in In-
dia, and manning it there with Indian workers
equivalent in skill to their U.S. counterparts.
The combination of lower construction costs
and much lower operating costs (mainly
wages) would permit this hypothetical new In-
dian firm to undercut the prices of both the
U.S. firm of which it was a copy and the typ-
ical Indian firm currently active in the same
industry. This says that the typical Indian firm
is operating on an "inferior" production func-
tion. If, as I believe, the difference in effi-
ciency between U.S. and developing-country
firms is typically large, there is much room for
quite rapid improvements in the developing
countries as they learn how to "adopt and
adapt" already-known techniques from the
advanced countries.
I would assume that the incentives for "con-
vergence" are always present, but that they
have typically run into barriers and trammels
of many kinds in the poor countries of the
world. Reducing the barrfers and loosening the
trammels permits the more rapid convergence
to techniques that are closer to the frontier of
knowledge.
The way I see the influence of policy in
growth, it is simply not true that implementing
enabling policies typically permits a quantum
jump from the old to the truly modem. It is
more accurate to describe it as speeding up
what will in any case be a very lengthy pro-
cess. Personally, I like the analogy to a hy-
draulic system in which a large vessel with a
high water level and lots of water is connected
to a much smaller and narrower vessel with a
much lower level of water. Physical laws dic-
tate a tendency for the water levels to equalize
in the end. But this can take a very long time
if the tube connecting the two vessels is tiny,
or is clogged by extraneous matter.
The policies that we consider good for
growth have the attribute, in this analogy, of
removing the extraneous matter and/or enlarg-
ing the connecting tube. But even with the best
modernizing policies, the tube remains small
enough so that it takes many decades for a
country to pass from poor to middle income or
from middle income to rich. If somehow the
hydraulic connection could be made so large
as to bring about an almost instantaneous full
adjustment of the water level, then we would
say that good policies mainly represent level
adjustments. But observing even the best of
real-world growth experiences, I think we
have to conclude that the adjustment is going
to be extended over a lengthy period in any
event, thus causing the big observable result
of better policies to be a higher growth rate
over an extended period rather than a discrete
jump to a totally different level.
This way of looking at the world also leads
to some observations on the current literature
dealing with convergence. I have long been
mystified by allusions to an ultimate conver-
gence of growth rates among countries, or an
ultimate convergence of levels of output per
head. To me, the natural convergence is prod-
uct by product, not country by country. And


### ---Economics-1998-0-29.txt---
among products there may be some where
current techniques will never be further
improved. Those products will have no real
cost reductions or TFP improvements in the
future, while others will enjoy huge advances
of productivity. My guess is that unlucky
countries (Bhutan, Nepal, Mongolia?) may
always lag way behind the pack, while luckier
ones (Taiwan, Argentina, Brazil?) may one
day hope to be among the world's leaders. So
convergence comes through as a general ten-
dency, and quite surely a general possibility,
for the production techniques used in making
any given product to improve as enterprises
using "backward" techniques learn of better
ones, and even more important, learn about
how to put them into practice. I do not believe
that much more than this can be said of con-
vergence as a real-world force. Wage rates for
given types of labor tend toward a rough
equality across regions in a country because
of the ease of migration in response to per-
ceived wage differences. The forces at work
internationally are both weaker and more
complex, but the big message here is that
the improvement of technique in any one in-
dustry does nothing to improve the wages of
labor in just that industry. After an improve-
ment, the industry may end up hiring more or
less labor, but will presumably choose the
amount of labor so as to bring marginal pro-
ductivity into correspondence with market
wages. So technological improvement has an
effect on wages via supply and demand in the
national labor market, not through any direct
link from technical improvement to wages
(for given skills, etc.) at the level of the in-
dustry or the firm.
As my final point, let me return to the
thought that the justification for perfecting the
functioning of the market system does not lie
only in reducing the efficiency costs associated
with each period's operation of the economy.
Perfecting a country's economic policy does
not only cause it to move from a path at
around, say, 90 percent of its potential output
to another equal to 95 percent of potential,
with the time path of potential output being
somehow given in advance. That gain would
certainly be a worthwhile gain, and it would
amply justify a lot of hard work involved in
achieving it. But that gain is still fundamen-
tally comparative static in nature.
What I hope to have evoked in this paper is
a sense that the perfecting of economic pro-
cesses can also in nearly all cases be justified
as greasing the wheels of the constant search
for new avenues of real cost reduction. To the
extent that economic reforms do so, they be-
come vehicles for bringing an economy to a
point where, year after year, new, cheaper, and
better ways are found of doing things, not just
in so-called "production" but also in such
mundane areas as merchandising, sales, fi-
nance, insurance, and many more.
Some years ago, in a book that I edited called
World Economic Growth (1984), I wrote an
essay called "Economic Policy and Economic
Growth," in which I listed "13 lessons" that
I thought followed from the papers presented
in the volume, recounting the growth experi-
ences of countries as disparate as Ghana and
Taiwan, or Japan and Sweden. These lessons-
basically focused on thinking about policies in
terms of their economic costs and benefits-
could easily be read as a reprise of the old
comparative-static story. But they were not
meanit as such-it is quite relevant that they
appeared in an essay concerned with world eco-
nomic growth. The point was that these sensible
policies emerged as part of a consensus of se-
rious economists, each an expert in his partic-
ular country's history, focusing attention on the
process of economic growth.
A few years later, and as the theme of a
different concept, John Williamson (1990)
coined the term, the "Washington consen-
sus." Williamson listed ten points, covering
territory very similar to my 13 lessons. He also
produced a pithy summary that captures the
essential thrust of both his and my listings:
"Macroeconomic prudence, outward orienta-
tion, and domestic liberalization." He, too,
and the members of the Washington profes-
sional establishment whose apparent consen-
sus led to Williamson's list, were not just
thinking of comparative-static gains as they
reached their conclusions about policy. They
were thinking about ways to move economies
from slow growth, stagnation, and even in
some cases negative growth, to a healthy,
prosperous flowering of economic progress.
Similar views were more recently affirmed by
Stanley Fischer (1993).
To me, the dynamics of real cost reduction
are at the very least an important piece of what


### ---Economics-1998-0-30.txt---
people have in mind when they list efficiency-
oriented policies as essential ingredients of a
program promoting economic growth. It is
policies of this type that give the right signals
to the CEOs and the managers down the line,
that take away trammels that impede their
quest for real cost reductions, and that create
an environment in which Schumpeter's pro-
cess of "creative destruction" can work its
wonders.
APPENDIX ON METHODOLOGY
The vision of the growth process presented
in this paper leads one almost inevitably to
some methodological twists-twists which, if
they are not new, at least differ in significant
ways from what I take to be the most common
practice in breaking economic growth down
into components.
(a) To measure the real rate of return to
capital, one must express the numerator (real
dollars of retum) and the denomiinator (the
capital stock) in the same units. The most ef-
ficient way to do this is to measure both output
(value added) and the capital stock in units of
the GDP deflator. That way one is sure that the
outputs of all the subaggregates in the econ-
omy add up to the GDP, and one also satisfies
the requirement that the capital and return be
measured in the same units. This is also the
way cash flows would be deflated in a stan-
dard, ex post project evaluation. When this is
done at the aggregate level the contribution of
capital to growth is (p + 5) AK where p is an
aggregate rate of return to capital, 6 the depre-
ciation rate (including obsolescence), and AK
the net increment to the capital stock in the
period in question. At a subaggregate level, the
contribution of capital to growth in activity j
is (pj + bj) AKj. At both levels, we find that
high rates of return are an important compo-
nent of most successful growth episodes.
(b) To capture the great diversity of the la-
bor factor, we would like to have a very fine
breakdown of labor into categories (indexed
by i). The labor contribution is then liwiALi,
where wi represents the real wage of category
i and ALi the change in hours worked by cat-
egory i. Since the number of relevant catego-
ries of labor is huge, any such breakdown is
difficult, and gets more difficult as one disag-
gregates from economy to sector to branch to
industry and to firm. This Gordian knot can be
cut by a simple assumption, similar to what is
done in most countries to convert residential
construction to real terms. There, one builds a
price index of a "standard house" p*, and
then obtains a quantum of construction C* by
dividing total construction outlays by the price
of the standard house. In the resulting aggre-
gate, each individual residence (i) gets attrib-
uted a quantum of housing equal to Pi Ip */ In
this work I define a standard wage w*, which
I assign to "standard labor" or "raw labor."
The excess of anybody's actual wage over w *
is attributed to human capital. The returns to
natural ability, as well as to formal education,
training, and experience belong there, under
this interpretation. High returns due to a dis-
torted wage structure are not appropriately
attributable to human capital, but the meth-
odology would nonetheless be correct in at-
tributing to the affected labor a marginal
productivity that is measured by the distorted
high wage.
The "labor contribution" as measured by
w*AL* is equal to w* (Q S(wi /w *) AL1 +
iLi A(w /w*). The second term will be zero
if the structure of relative wages remains con-
stant, or even if the weighted average premium
does not change. Any changes in the weighted
average premium will cause the calculated re-
sidual to be different from those calculated by
other methods.
The "two-deflator method" is characterized
by the use of a single numeraire-deflator (say,
the GDP deflator), by the treatment of the
quantum of output as value added divided by
the numeraire-deflator, and by the use of a
standard wage w * and a quantum of labor L *
equal to the wages bill divided by w *. This is
the method used by Beyer (1996), Robles
(1997), and Torre (1997) in their work re-
ported in this paper.
It goes without saying that the two-deflator
method is rough. But it is also tremendously
robust and easily applied. I think of it as being
really designed for use at the firm level, where
very commonly we can get data in value
added, on gross investment, and on the wages
bill, but know nothing (from standard sources)
about the quantum of output or about the num-
ber of total hours worked (or even the total
number of employees used). This opening of
wide new vistas, of huge new data sets, is what


### ---Economics-1998-0-31.txt---
I consider the strongest argumnent for the two-
deflator approach.
But there are other pluses as well. First, at
the aggregate economy level, the two-deflator
approach comes very close to the traditional
approach. In rate-of-growth terms, we have
(R */y) = gy S- skgk * SL gL *, compared with
(Rly) =g - Skgk -SLgN, where g refers to
growth rate, and y to GDP. K* differs from K
in being built up from gross investment de-
flated by the GDP deflator, while K is built up
from gross investment deflated by the invest-
ment deflator of GDP. L * is in principle much
more refined than N (number of workers), but
its measurement can be influenced by a wid-
ening or narrowing skill premium. (R */y)
likewise differs from Jorgenson's residual
(R'/y) = gy - Yjskjgkj - 1ise gf mainly in his
use of different capital deflators for different
categories of capital. (The implicit labor
breakdown in L * is much finer even than
Jorgenson's, but Jorgenson does not have to
contend with the possibilities of widening or
narrowing skill premiums -at least not
among the labor categories he works with,
which are typically broken down by gender,
age, education, occupation, industry, and em-
ploymnent status.)
The bottom line is that when Beyer com-
pares his two-deflator results, at the national
aggregate level, with those of others using dif-
ferent methods, he finds on the whole only
modest differences. [See Beyer (1996);
Harberger (1998).]
When one uses the two-deflator method at
the industry level, one often has the possibility
to adjust the quantity variable so as to make it
correspond with that of the more traditional
approach. Thus, we may start by using dy)e (=
pjdyj + yjdpj) as the quantity variable, and cal-
culate a residual Rj* using that concept. Then
we may get an adjusted residual by taking
R yjdpj. This is easy to do so long as we
have decent data on dpj, the relative price of
j, which we often do at the branch or industry
level. When Jorgenson's residuals are com-
pared with the two-deflator residuals, with and
without price adjustment, I find the differences
without adjustment to be small enough to be
quite acceptable. With adjustment, the degree
of agreement between the two approaches is
quite notable (85 percent of differences less
than one percentage point of per annium
growth). [See Robles ( 1997); Ilarberger
(1998).]
When one gets down to the firm level, the
two-deflator method is in its element. Rarely
do we have decent time series on the price in-
dex of a firm' s output. Treating many firrns in
one industry, one might then give all of them
the same price index-that of the industry. At
that point the distribution of adjusted TFP re-
siduals among the firms would end up differ-
ing from the original two-deflator distribution
only by a constant. When expressed in percent-
age terms we vould have (R)' ly)) = g4i -
*kj j ge*, for each fim j without adjust-
ment, while with adjustment we would have
R]*Iy1 = the same expression minus go, the
rate of growth of the industry's relative ptice
index (the same for all firms).
So in the great bulk of cases one ends up
with something quite like the two-deflator
method when working at the individual firm
level. The consolation is that the residual
terms of individual firms, calculated for the
whole economy, add up to a residual term
for the aggregate-in the sense that outputs
sum to GDP, the L]* sum to L * for the econ-
omy, the Kj* to K* for the economy, etc. For
more details on methodology, see Harberger
(1998).
## Economics-1999-0


### ---Economics-1999-0-01.txt---
In his Presidential Address five years ago,
Zvi Griliches ( 1994) called attention to the se-
vere difficulties that beset current attempts to
measure the growth of labor productivity in
the American economy. Because of these dif-
ficulties, it is likely that the true rate of eco-
nomic growth is substantially underestimated.
The root of the problem is the difficulty in
measuring output in the service sector which
now represents two-thirds of the economy. In
such sectors as health care and information
services, the contribution to gross domestic
product (GDP) is measured by inputs rather
than outputs, a procedure that makes it impos-
sible to gauge accurately improvements in the
quality of output. Thus, in the case of com-
puters, which are transforming American so-
ciety, economists have been unable, so far, to
find a measurable contribution of computers to
the rise in labor productivity-an astonishing
paradox.
I want to follow up on this problem of mis-
measurements. My thesis is that the profession
is lagging behind the economy more than it
has to. We are, to some extent, entangled in
concepts of the economy and in analytical
techniques that were developed during the first
third or so of the century, when economics
emerged as a modem discipline. The range of
the discipline did not expand greatly during
the middle decades of the century, due partly
to a concentration on the reformulation of the
previous analytical concepts and techniques in
more sophisticated and more general mathe-
matical models. Although the dividends from
these efforts were high and have contributed
to the flexibility and capacity of economics,
they did not encourage a reconsideration of
some of the received assumptions about the
scope and focus of economic analysis. There
has been a significant broadening of the scope
of economics during recent decades, with the
emergence of such fields as the new household
economics, the new institutional economics,
the economics of aging, and medical econom-
ics, but much remains to be done.
The balance of this address is divided into
four sections. I begin with the inadequate
attention to the accelerating rate of techno-
logical change, the implications of this accel-
eration for the restructuring of the economy,
and its transforming effect on human beings.
I then consider the neglect of the nonmarket
sector of the economy, the implication of that
neglect for the measurement of consumption,
and for the analysis of economic growth. The
third section deals with the need to shift the
focus of economic analysis from cross-
sectional to life-cycle and intergenerational
data sets, especially in connection with fore-
casting. The final section points to the impact
of cultural lag in the treatment of material in-
equality, and the neglect of the more severe
problem of spiritual inequality. I use the word
spiritual not in its religious sense but as a ref-
erence to commodities that lack material form.
Spiritual or immaterial commodities make up
most of consumption in the United States and
other rich countries today.


### ---Economics-1999-0-03.txt---
I. Some Implications of Technophysio Evolution
The rapid acceleration in technological
change is apparent in the decline in mortality
rates during the twentieth century. Study of the
causes of this decline point to the existence of
a synergism between technological and phys-
iological improvements that has produced a
form of human evolution that is biological but
not genetic, rapid, culturally transmitted, and
not necessarily stable. This process, which is
still ongoing in both rich and developing
countries, has been called "technophysio
evolution."
Unlike the genetic theory of evolution
through natural selection, which applies to the
whole history of life on earth, technophysio
evolution applies only to the last 300 years of
human history, and particularly to the last cen-
tury. Despite its limited scope, technophysio
evolution appears to be relevant to forecasting
likely trends over the next century or so in lon-
gevity, the age of onset of chronic diseases,
body size, and the efficiency and durability of
vital organ systems. It also has a bearing on
such pressing issues of public policy as the
growth in population, in pension costs, and in
health-care costs (Fogel and Dora L. Costa,
1997).
Technophysio evolution implies that human
beings now have so great a degree of control
over their environment that they are set apart
not only from all other species, but also from
all previous generations of Homo sapiens.


### ---Economics-1999-0-04.txt---
This new degree of control has enabled Homo
sapiens to increase its average body size by
over 50 percent, to increase its average lon-
gevity by more than 100 percent, and to im-
prove greatly the robustness and capacity of
vital organ systems.'
Figure 1 helps to point out how dramatic the
change in the control of environment after
1700 has been, and it highlights the astounding
acceleration of technological change over the
past two centuries. The advances in the tech-
nology of food production after the Second
Agricultural. Revolution (which began about
1.700 A.D.) were far more dramatic than those
associated with the First Agricultural Revolu-
tion since they permitted population to in-
crease at so high a rate that the line of
population appears to explode, rising almnost
vertically. The new technological break-
throughs in manufacturing, transportation,
trade, communication, energy production,
leisure-time services, and medical services
were in many respects even. more striking than
those in agriculture. Figure 1. emphasizes that
prior to 1600, centuries elapsed between major
technological advances and the process of dif-
fusion was even more extended, continuing
over several millennia. Studies of the origin
and diffusion of the plow, for example, show
how little improvement there was in its design
between its original development in the Me-
sopotamian valley around 4000 B.C. and its
diffusion across the Mediterranean Sea and
northward in Europe down to the beginning of
the second millennium (Bishop, 1936; E.
Cecil Curwen, 1953).
To my mind nothing better illustrates this
amazing acceleration in technological change
than the realization in the twentieth century of
humankind's ancient desire to fly. The first
successful motor-driven flight took place in
1903, but the fragile aircraft of Wilbur and
Orville Wright traveled only a few hundred
feet. Just 66 years later, an astronaut was
standing on the moon, talking to another as-
tronaut on earth, and hundreds of millions of
people around the world overheard and
watched that conversation.
Worldwide, the most important aspect of
technophysio evolution is the continuing con-
quest of chronic malnutrition, which was vir-
tually universal three centuries ago.2 Table 1
shows that in rich countries today some 1,800
to 2,000 or more kilocalories (kcal) of energy
are available for work daily per equivalent
adult male, aged 20-39.3 At the beginning of
the eighteenth century, however, France pro-
duced less than one-fifth of the current U.S.
amount of energy available for work. And En-
gland was not much better off. Only the United
States provided potential energy for work
equal to or greater than late-twentieth-century
levels during the eighteenth and early nine-
teenth centuries, although some of that energy


### ---Economics-1999-0-05.txt---
was wasted due to the prevalence of diarrhea
and other conditions that undermined the
body's capacity to utilize nutrients (Fogel and
Floud, 1999).
One implication of these estimates of caloric
availability is that mature adults of the eigh-
teenth and much of the nineteenth century
must have been very small by current stan-
dards and less physically active. Today the av-
erage American male in his early thirties is
about 177 cm (70 inches) tall and weighs
about 78 kg (172 pounds). Such a male re-
quires daily about 1,800 kcal for basal metab-
olism and a total of 2,300 kcal for baseline
maintenance. If either the British or the French
had been that large during the eighteenth cen-
tury, virtually all of the energy produced by
their food supplies would have been required
for personal maintenance, with little available
to sustain work. To have the energy necessary
to produce the national products of these two
countries circa, 1700, the typical adult male
must have been quite short and very light
(Fogel, 1997).
Recent studies have established the predic
tive power of height and weight at early ages
with respect to onset of chronic diseases and
premature mortality at middle and late ages.
Variations in height and weight appear to be
associated with variations in the chemical
composition of the tissues that make uip vital
organs, in the quality of the electrical trans-
mission across membranes, and in the func-
tioning of the endocrine system and other vital
systems. Nutnitional status thus appears to be
a critical link connecting improvements in
technology to improvements in human physi-
ology (Fogel and Costa, 1997).
So far I have focused on the contribution of
technological change to physiol-ogical im-
provements. The process has been synergistic,
however, with improvement in. nutrition and
physiology contributi-ng significantly to eco-
nomic growth and technological progress in a
manner described elsewhere (Fogel., 2000).
Here I merely want to point out the main con-
clusion. Technophysio evolution appears to
account for about half of British economic
growth over the past two centuries. Much of
this gain was due to the improvement in hu-
man thermodynamic efficiency. The rate of
converting human energy input into work out-
put appears to have increased by about 50 per-
cent since 1790 (cf., Partha Dasgupta, 1993).
Technophysio evolution calls into question
a number of easy and frequent assu-mptions in
economic analyses such as: tastes are fixed;
needs are fixed or exogenously determined;
existing life tables are adequate to forecast fu-
ture pension costs in. 2030 or 2075; and the
rate of aging is genetically controlled and un-
changing from one generation to another.
Technophysio evolution also calls into
question such frequently used theoretical as-
sumptions as fixed utility functions, fixed rates
of time preference over the life cycle, and the
related assumption that, except for risk differ-
entials, economic phenoomena should gener-
ally be subject to the same rate of discount.
Yet the rate of discount varies over the life
cycle; children, after all, have much higher
time preferences than adults. It may also vary
by religion. Some individuals are prepared to
wait for their reward in heaven while others
want it here and now. Moreover, these differ-
ences may be evolving and multiplying more
rapidly than is now presunmed, as is indicated
by the debates over the impact of greenhoiuse
gases. Rethinking of the issue is now under-
way (see William D. Nordhaus, 1997; cf.,
Peter Koslowski, 1992; Nazli Choucri, 1.993;
Marc Fleurbaey and Philippe Michel, 1994;
Michael Toman, 1994) but the profession can
benefit from an increased allocation of re-
sources to this problem.
Technophysio evolution requires not just
marginal adjustments, but majtor leaps in eco-
nomic theory. We are slow in pondering such
grand questions as the inmplications of the Hu-
man Genome Project, which is now nearing
completion, and the emergence of molecular
medicine for the future of economic life. We
have entered an era in which p-urposeful inter-
vention in evolutionary processes is passing
beyond plant and animal breeding. The new
growth economics needs to incorporate at least
some aspects of directed, rapid human evolu-
tion. Endogenous technological change needs
to extend to the fundamentals of human be-
havior. Theorists also need to grapple with the
ethical implications of technological changes
that, whatever their positive aspects, threaten
to undermine the mystery of human life by
transforming people into "material" that is


### ---Economics-1999-0-06.txt---
transplanted, cloned, arbitrarily altered in ex-
ternal appearance, artificially changed in per-
sonality and intelligence, and otherwise
manufactured in ways that challenge the defi-
nition of a human being (cf., Zbigniew Brze-
zinski, 1996).
It. The Growth of the Nonmarket Sector'
One aspect of technophysio evolution has
been a change in the structure of consumption
and in the division of discretionary time be-
tween work and leisure. Perhaps the best index
of the growth of the nonmarket sector is the
change in the use of time. Changes in hours of
work and in the average division of the day
have paralleled the changes in the structure of
consumption. Table 2 shows the remarkable
reduction in the workyear that has occurred for
males in the U.S. labor force over the past cen-
tury. Sleep, meals, and essential hygienie,
which are biologically determined, required
about 10 hours of the day in 1880, as they do
today. The remaining 14 hours represent "dis-
cretionary" time.
The most notable feature of Table 2 is the
large increase in leisure available to the typical
male worker. His leisure time has tripled over
the past century, as his workyear declined
from about 3,100 hours to about 1,730 hours
today. Table 2 also forecasts the division of
the average day in 2040, indicating that by that
date more than half of the discretionary day
will be devoted to leisure activities. The fore-
cast is for a reduction of the workyear from
the current average of about 1,730 hours to just
1,400 hours, with the average workweek down
to 30 hours.
The pattern of chainge anmong women was
similar to that among men (cf., Claudia
Goldin, 1990; Stanley Lebergott, 1993). Th'e
workday of wotnen in 1.880 was somnewhat
longer, and in some respects may have bexen
more arduous, than that of men. In households
of working farmners, artisans, and manual la-
borers, wives rose before their husbainds and
continued working until bedtimle at 10 or I1
P.M. That routine suggests a workday that
may have run about 15 niinutes longer than
that of males, implying an annual workyear of
perhaps 3,200 hours.
As a result of the mechanization of the
household, smaller families per household,
and the marketing of prepared foods, the typ-
ical nofiemployed mnarried woman today
spends about 3.4 hours per day engaged in
housework; and if she is enmployed the figure
for housework drops to 2.2 hours. However,
women in the labor force average about 4.4
hours per day as emnployees. Hence comlbining
"4work" with " chores," men and women
work roughly equal amounts per day, and both
enjoy much miore leisure than they used to.
The principal difference is that the gains of
women have comrie exclusively from the re-
duction in hours of housework, while the gains
of men have come from the reduction in the
hours of employed work (cf., John P.
Robinson and Geoffrey Godbey, 1997).
I have so far retained the common distinc-
tion between work and leisure, although these
terms are already inaccurate and may soon be
obsolete. The distinction was invented when
most people were eingaged in manual labor for
60 or 70 hours per week and was intended to
conitrast with the highly regarded activities of
the English gentry or their American equiva-
lent, Thorsten Veblen's (l1899) "leisure
class." However, it should not be assumed
that members of the leisure class were indo-
lent. In their youth they were students and ath-
letes. In young adult years they were warriors.
In middle and later ages they were judges,


### ---Economics-1999-0-07.txt---

bishops, merchant princes, and patrons of the
arts. Whatever they did was for the pleasure it
gave them since they were so rich that earning
money was not their concern.
Hence, leisure is not a synonym for indo-
lence, but a reference to desirable forms of ef-
fort or work. As George Bernard Shaw (1928)
put it, "labor is doing what we must; leisure
is doing what we like; and rest is doing nothing
whilst our bodies and our minds are recovering
from their fatigue." In order to avoid confu-
sion, in the balance of this address I reserve
the word "work" for use in its physiological
sense, an activity that requires energy, over
and above the basal metabolic rate (BMR).
Activity aimed primarily at earning a living I
will call " earnwork. " Purely voluntary activ-
ity, even if it incidentally carries some pay-
ment with it, I will call "volwork "
Why have hours of earnwork declined so
much in recent years? The answer to that ques-
tion is suggested by the fact that it is not just
daily and weekly hours of earnwork that have
declined. The share of lifetime discretionary
hours spent in earnwork has declined even
more rapidly. Table 2 only dealt with the hours
of earnwork of persons in the labor force. It
did not reflect the fact that the average age of
entering the labor force is about five years later
today than it was in 1880, or that the average
period of retirement for those who live to age
50 is about 11 years longer today than it was
in 1880 (cf., Lee, 1996). A century ago only
one out of five males aged 65 and older were
retired. Today, six out of seven are retired.
All in all the lifetime discretionary hours
spent earning a living have declined by about
one-third over the past century (see Table 3)
despite the large increase in the total of life-
time discretionary time. In 1880, four-fifths of
discretionary time was spent eamning a living.
Today, the lion's share (59 percent) is spent
doing what we like. Moreover, it appears prob-
able that by 2040 over three-quarters of dis-
cretionary time will be spent doing what we
like, despite a fuLrther substantial increase in
discretionary time due to the continuing exten-
sion of the life span (cf., Jesse H. Ausubel and
A. Griibler, 1995).
Why this deep desire for volwork? Why do
so many people want to forgo earnwork which
would allow them to buy more food, clothing,
housing, and other goods'? The answer tumrs
partly on the extraordinary technological
change of the past century, which has not only
greatly reduced the nunmber of hours of labor
the average individual needs to obtain his or
her -food supply, but has also made housing,
clothing, and a vast array of consurner dura-
bles so cheap in real terms that the totality of
material consumption requires miuch fewer
hours of labor today than was required over a
lifetine for food alone in 1880.
Indeed, we have become so rich that we are
approaching saturation' in the consumption
not only of necessities, but of goods recently
thought to be luxuries, or which were only
dreams or science fiction during the first third
of the twentieth century. T'oday there is an av-
erage of two cars per household in the United
States. Nearly every household with a person
competent to drive a car has one. On some
items such as radios, we seem to have reachied
supersaturation, since there is now more than
one radio per ear (5.6 per household). The
point is not merely that we are reaching satu-
ration in commodities that once defined a high
standard of living aiid quality of life but also
that the hours of labor required to obtain those
comnmodities have drastically declined. The
typical household in 1875 required 1,800
hours of labor in the marketplace to acquire
the annual food supply, but today it takes jus.t
260 hours. All in all, the comfrmodities that
used to account for over 80 percent of house-
hold consumption can now be obtained in
greater abundance than previously, with less



### ---Economics-1999-0-08.txt---
than a third of either the market or the house-
hold labor once required (Fogel, 2000).
Table 4 shows how sharply the U.S. distri-
bution of consumption has changed over the
past 120 years. Food, clothing, and shelter,
which accounted for about three-quarters of
consumption in 1875, accounted for just 12
percent in 1995. Leisure, on the other hand,
has risen from 18 percent of consumption to
67 percent.6 As Table 4 shows, the long-term
income elasticities of the demand for food and
clothing are below 0.5 and the elasticity of the
demand for shelter is closer to, but still below,
1.0. On the other hand, the long-term income
elasticities for leisure, education, and for med-
ical services are over 1.O.7
Table 4 differs from current official tabula-
tions of household consumption in two prin-
cipal respects. Official tabulations, with minor
exceptions, are limited to the out-of-pocket ex-
penditures of households. Table 4, however,
adds expenditures for education and health
care consumed by households but paid by gov-
ernment, employers, and other third parties.
My procedure does little to change the distri-
bution of consumption in 1875 but signifi-
cantly increases the education and health-care
shares of consumption in 1995.8
Table 4 also differs from official tabulations
by adding to the value of out-of-pocket expen-
ditures on leisure, the value of the time de-
voted to leisure (volwork). That time is priced
at the average hourly rate of compensation of
labor. The procedure increases the share of lei-
sure in consumption in both 1875 and 1995.
While leisure (volwork) remains a relatively
small share of expanded consumption in 1875,

it accounts for two-thirds of expanded con-
sumption in 1995.'
The failure to include the value of volwork
in the national income and product accounts is
perhaps the most glaring example of the cul-
tural lag to which I referred at the beginning
of this address. That omission also leads to a
significant underestimate of the long-term
growth rate of per capita income. Before ad-
justments for the increased quality of volwork,
the growth rate is increased by eight-tenths of
a point (from 1.8 to 2.6 percent per annum).
But adjustments for improvements in the qual-
ity of volwork might substantially increase
that figure, since leisure-time activities in 1875
were limited largely to church on Sundays and
carousing in bars during the rest of the week
(cf., Fogel, 2000). Despite some important
contributions to the development of an eco-
nomics of leisure (cf., Gary S. Becker, 1991;
Costa, 1998a, c; Daniel S. Hamermesh, 1998;
John Pencavel, 1998), the profession has far
to go before it catches up with the economy.
I1I. Shifting to Life-Cycle Data Sets for
Successive Cohorts and to Intergenerational
Data Sets
It is no secret that cross-sectional data sets
are cheaper to construct and more abundant


### ---Economics-1999-0-09.txt---
than longitudinal data sets. But whatever their
usefulness for other problems, cross-sectional
data are often highly misleading guides to
trends on such critical economic issues of the
new millennium as the prevalence rates of
chronic disabilities, expenditures on health
care, and pension costs.
Research initiated during the past decade
and a half has called into question previous
views on the length and fixity of the life span,
on the shape of the Gompertz curve (which
relates the log of the age-specific probability
of dying to age), on the theory of the epide-
miological transition, 10 and on the related
proposition that longer life expectancy implies
worse health among the survivors. It appears
that some of the earlier propositions were the
consequence of attempts to infer life-cycle be-
havior from cross-sectional data sets. Such ef-
forts were thwarted by changes in the
sampling design of successive cross sections
and by changes in technology that led to earlier
diagnosis of preexisting conditions (Timothy
Waidmann et al., 1995).
The new research also accumulated evi-
dence on the outward movement of the sur-
vivorship curve. Vaino Kannisto ( 1994) (cf.,
Kannisto, 1996) has shown that, in 14 coun-
tries for which the data are adequate, mortality
over age 80 has been declining by about 1 per-
cent per annum for about half a century with
a significant acceleration in recent decades.
John R. Wilmoth (1995, 1997), who exam-
ined extreme longevity in five countries,
concluded that the right-hand end of the sur-
vivorship curve has been shifting outward for
two centuries. Moreover, there is additional
evidence that the Gompertz curve either levels
off or declines at old old ages (James W.
Vaupel, 1997; cf., S. Jay Olshansky and Bruce
A. Cames, 1997).
Another development is the continued ac-
cumulation of evidence linking events early in
life, and reflected in height, weight, and body
mass index (BMI), to the onset of chronic con-  ditions. " A number of longitudinal studies that
were launched in the 1950's and 1960's have
recently been extended to cover the entire pe-
riod of human growth and early adulthood,
through follow-up studies. These have con-
firined the persistence of central nervous sys-
temr defects induced by malnutrition in early
childhood (Nevin S. Scrimshaw, 1995). Nu-
merous other follow-up studies have shown
that malnutrition and smoking in adolescence
and in middle ages are risk factors for the early
onset of chronic conditions and premature
mortality, especially due to coronary heart dis-
ease, non-insulin-dependent diabetes, and re-
spiratory diseases (Avita Must et al., 1992;
Vincent J. Carey et al., 1997; N. K. Chin et
al., 1997; Joan M. Dom et al., 1997; K. Kotani
et al., 1997; Dan S. Sharp et al., 1997; Ralf
Bender et al., 1998). These relationships have
been established in American, Asian, Austra-
lian, European, and Latin American popula-
tions-rich and poor. Economists have also
discovered a close link between later produc-
tivity and height, BMI, and protein consump-
tion (after controlling for caloric intake)
(John Strauss and Duncan Thomas, 1995;
Thomas and Strauss, 1997).
There has also been an expansion of re-
search into the connection between intrauter-
ine and infant growth and the onset of chronic
diseases (or premature mortality). The strong-
est evidence for such a link that has emerged
thus far is with respect to hypertension, coro-
nary heart disease (CHD), and non-insulin-
dependent diabetes. A review of 32 papers
dealing with the relationship between birth
weight and hypertension by Catherine M. Law
and Alistair W. Shiell (1996) showed a ten-
dency for middle-aged blood pressure to in-
crease as birth weight declined. Evidence of a
connection between birth size and later coro-
nary heart disease has been found in England,
Wales, Sweden, India, and Finland.12


### ---Economics-1999-0-10.txt---
The accumulation of historical and current
biomedical studies on the trends in health, lon-
gevity, and human physiology, combined with
controlled studies of animal populations, are
leading some evolutionary biologists to place
increasing emphasis on plasticity in human ag-
ing (Michael R. Rose, 1991; Caleb E. Finch,
1997; Hillard Kaplan, 1997). The term "plas-
ticity" refers to the widely varying pattern of
aging within species and the ability of the
length of the life span to be affected by envi-
ronmental factors, some of which may operate
over several generations (cf., Kenneth W.
Wachter and Finch, 1997).
The search for better ways to forecast long-
term trends in health-care costs and in pension
costs has made it essential for economists to
understand the underlying physiological, nu-
tritional, and epidemiological factors that af-
fect the changing demand for health care and
retirement. Forecasts about health-care costs
are obviously related to assumptions about
changes in both life expectancy and age-
specific morbidity rates. If current morbidity
rates at older ages are presumed to remain con-
stant or to increase over the next 30 to 50
years, and if life expectancy is also presumed
to increase, then national health-care costs be-
come astronomic. However, if one takes ac-
count of the recent declines in age-specific
disability rates, then the share of health-care
costs in GDP might remain constant (Kenneth
G. Manton et al., 1997b; Manton et al., 1998),
provided the demand for health services
(given disability rates) does not increase. If,
however, the income elasticity of the demand
for health is greater than one, then as income
increases, the share of income that is spent on
health care could increase even if disability
rates decline (see Fogel, 1997). It is quite pos-
sible for the demand for medical interventions
to increase, even though age-specific morbid-
ity rates decline, for one or more of the fol-
lowing reasons: shifts in the age structure of
the population toward ages with high morbid-
ity rates; improvements in inedical interven-
tions for a wide range of chronic conditions
which alleviate symptoms but do not cure; the
replacement of current disease-specific standards
of care by new ones based on improved tech-
nologies that are much more expensive than
those replaced; the elimination of current age re-
strictions on such expensive procedures as organ
replacements (cf., David M. Cutler and Ellen
Meara, 1998; Alan M. Garber et al., 1998).
The complexity of the underlying issues in
the economics and biodemography of aging
has led to a significant shift away from cross-
sectional data sets and to a concentration on
longitudinal data sets. The earliest of the major
longitudinal studies sponsored by the National
Institutes of Health (NIH), the Framingham
Heart Study, began in 1950 and was focused
on the causes and treatment of coronary heart
disease rather than on the economics and bio-
demography of aging. The Retirement History
Survey (RHS) followed a cohort of men and
women aged 58 to 63 from 1969 to 1979 and
then was suspended. Although not initially
planned as a longitudinal study, it became the
mainstay of retirement research during the
1980's. Linked to the social security file on
covered earnings, it provided important in-
sights into the labor-force and retirement be-
havior of older workers.
In 1990, the National Institute of Aging
launched a new Health and Retirement Survey
(HRS) focused on the cohort born between
1931 and 1941, and aimed at collecting a much
wider set of variables than covered by the
older RHS. The new HRS collected numerous
measures of health (including cognitive abil-
ity), taxable earnings, job characteristics,
hours of work, job turnover, family character-
istics, pensions, health insurance, and owner-
ship of an array of assets including real estate,


### ---Economics-1999-0-11.txt---
consumer durables, and financial securities.
The most ambitious social science project ever
undertaken, the first wave of HRS cost
$14,000,000 and the second wave was budg-
eted for $17,000,000. A third wave is currently
under way collecting information on the birth
cohorts of 1942-1947 (F. Thomas Juster and
Richard Suzman, 1995).
NIA launched a second longitudinal survey
aimed at cohorts born in 1924 or earlier years.
This sample, which is called Asset and Health
Dynamics. Among the Oldest Old (AHEAD),
consists of persons aged 70 years and older in
1994, when the first wave was undertaken. Al-
though the questions in AHEAD overlap with
HRS, functional ability is investigated inten-
sively and labor-market activity is covered
lightly.
Both HRS and AHEAD have made it pos-
sible to examne a wide range of issues with
more reliable and more detailed evidence than
previously available. James P. Smith and
Raynard Kington (1997), for example, have
used AHEAD to examine disparities in func-
tional status and to relate them to socio-
economic status (SES variables). They
discovered strong feedback effects not only
from health to SES variables but from SES
variables to health. To disentangle these ef-
fects they broke household income and wealth
into various categories made possible by the
data and examined the effects by age. They
were also able to make use of a range of vari-
ables bearing on the health and socioeconomnic
status of relatives in three generations (par-
ents, siblings, and children). Their analysis in-
dicated that cuffent-period health and income
are attributes of past, concurent, and future
generations. Measuring the full extent of these
influences, the direction of causation, and
complex interactions requires the study of life-
cycle histories from birth to very old age. It
would be inappropriate, they concluded, to use
SES variables to explain variations in late-age
health without taking account of the feedback
mechanisms or identifying within-period in-
novations in the stock of health (cf. John
Bound et al., 1998).
Such findings point to the usefulness of cre-
ating a prospective life-cycle sanple for an ex-
tinct cohort (the veteratns of the Union Army)  by utilizing military, pension, and census records
in archives. This procedure not only creates a
longitudinal data base in a small fraction of the
time required to trace a living cohor, but cm be
done at less than a tenth of the normnal cost. Such
a project was launched by NIA in 1996 (cf,
Clayne L. Pope and Larry T. Wimmer, 1998).
Based on 11 different data sets, the fully
linked life histories contain over 10,000 vari-
ables on each recruit, including socioeconomic,
ecological, and health variables. Called "Early
Idicators of Later Work Levels, Disease, d
Death," this project provides a conmprehensive
data set on the life course of over 39,000 Union
Amy veterans. Bor mainly between 1835 and
1845, these men represented the first cohor to
reach age 65 in the twentieth cent , d can
be compared with the veterans of World Wa IL1.
The preliminary comparisons revealed that at
the same ages the prevalence of chronic diseases
was much higher among elderly Uniion Any
veterans tha among veteras of World War IL
Musculoskeletal and respiratoy diseases were
16 times as prevalent, heart diseases were 2.9
times as prevyent, and digestive diseases were
4.7 times as prevalent among elderly veterans in
1910 than in the niid-1980's (cf., Sven E.
Wilson and Louis L. Nguyen, 1998). Moreover,
young adults bom during the second quaer of
the nineteenth centr who survived the deadly
contagious diseases of childhood and early ad-
olescence were not freer of degenerative dis-
eases than persons of the samne ages today, as
propounded by the theory of epidemiological
transition, but were more afflicted. Heria rates
at ages 35-39, for exanmple, were more than
three times as prevalent in the 1860's as in the
1980's.
Although the analysis of the data in the Un
ion Army sample is still in progress, some of
the initial findings have a bearing on forecasts
of long-term trends in health status. Costa
( 1998b) has reported that early-age socioeco-
nomiic and biomedical stress had a substantial
impact on the likelihood that Union Army vet
erans would have disabling chronic health
conditions by age 60. Thus, veterans raised in
a county with high mortality rates were, half a
century later, at elevated risks of suffering
from disabling respiratory disease, circulatory
disease, and musculoskeletal problems (cf.,
Lee, 1997). Episodes of acute diseases expe-
rienced as youtng adults, such as respiratory


### ---Economics-1999-0-12.txt---
infections, work-related injuries, and extended
bouts of diarrhea, also increased the odds of
suffering from chronic disabilities by age 60.
Costa concludes that about 15 percent of the
decline in the prevalence of joint problems and
75 percent of the prevalence of back problems
between 1910 and 1980 was due to shifts in
the occupational structure from manual to
white-collar jobs. Moreover, a comparison of
rates of decline in disabilities before and after
1980 indicates that disabilities are declining at
an accelerating rate (cf., Manton et al., 1997a;
Cutler and Elizabeth Richardson, 1998).
The mounting evidence of substantial inter-
actions over the life cycle that influence the
process of aging, the acceleration of techno-
logical change which has profoundly affected
the context in which aging occurs, and the in-
creasing evidence that environmental influ-
ences on the aging process begin in utero, has
led to the initiation of a new life-cycle project
called "Fetal, Infant, and Later Aging Mark-
ers, Cohort b. 1910-35." The acronym for
this project is FILAM.
The central objective of FILAM is the cre-
ation of a life-cycle sample of persons born
between 1910 and 1935 that would make it
possible to compare changes in the aging pro-
cess over the period of 70 years that separate
this new sample from the aging experiences of
the Union Army cohort. The FILAM cohort is
important not only because it studies individ-
uals currently between ages 63 and 89, but also
because of the dramatic environmental and
early life-style changes they experienced.
These changes include the rise and partial de-
cline of smoking, the decline and the new rise
of alcohol consumption, the replacement of
horses by internal combustion engines as the
main source of urban vehicular power, the
cleaning up of the water and milk supplies, and
the emergence of a wide range of effective
medical interventions.
The sample will be drawn from the birth
records of 10,000 men and women of differing
ethnicities and races who were born in Boston,
New York City, Baltimore, Chicago, Iowa
City, and San Francisco. Approximately half
of the neonates will not have survived to the
present day and these men and women will be
linked to their death certificates. The survivors
will be traced and interviewed to determine the
presence of chronic conditions, socioeco-
nomic status, and family and own health his-
tory. Survivors will be linked to social
security, census, military, and tax records, sub-
ject to their written consent.
FILAM will make it possible to investigate
the predictive power of fetal, neonatal, and
early childhood measures of retarded growth
such as weight for gestational age, ratio of pla-
cental weight to birth weight, infant weight
gain, thinness at birth, arid shortness at birth
relative to head size, on the risk of developing
specific chronic conditions at mid-adult and
late ages. Among the chronic conditions that
will be examined are coronary heart disease,
hypertension, stroke, obstructive lung disease,
non-insulin-dependent diabetes, and autoim-
mune thyroiditis. FILAM will also make it
possible to investigate how the interaction of
fetal and infant developments with various risk
factors at later childhood, young adult, and
middle ages may intensify or moderate risks
of chronic conditions and early death after age
65. Another objective is the analysis of differ-
ences in the health histories, occupational his-
tories, and retirement pattern between FILAM
and the Union Army sanmple, with special em-
phasis on the similarities and differences of
predictors of later work levels, morbidity, and
waiting time until death.
The HRS, AHEAD, Union Army sample,
and FILAM all contain information on the
parents and children of the individuals under
study. Hence, they make it possible to ad-
dress some factors that may be transmitted
intergenerationally. An effort to utilize ar-
chival data to study intergenerational pro-
cesses is also under way. Pope (1992) is
linking a large sample of genealogies to the
life-cycle sample of Union Army recruits.
There are at least 60,000 published family
histories that contain information on over
100,000,000 people who ever lived in North
America. Pope is drawing a subsample of
these histories containing 10,000 men of
military age at the time of the Civil War. It
is estimated that 40 percent of these men
served in the Union Army. This new sample
(called ILAS, for intergenerationally linked
aging sample) will be linked to the military,
pension, medical, and census data sets pre-
viously discussed.


### ---Economics-1999-0-13.txt---
WlAS will make it possible to control for the
effect of wartime stress by comparing subse-
quent morbidity and mortality among those who
served in the Union Arny with relatives who
did not. It will also be possible to measure family
effects on aging and mortality experience. This
will be done by including parents' occupation,
wealth, residential history, number of children,
place or region of birth, and migration histoiy.
Brothers in ILAS share a common prewar en-
vironment as well as a common genetic heritage.
They may also share a common war experience
(see D. S. Lauderdale and P. J. Rathouz, 1998).
This common genetic heritage and environment
is not fully captured by the aforementioned in-
tergenerational variables because heritability is
composed of the many different dimensions in-
cluded in genetics and environment. However,
conmmon family effects may be measured by us-
ing independent variables to "sweep out" the
effects of observed variables on death age. The
covariance of the errors in that regression with
brothers' estimated death ages is then a measure
of the common family effect on death age. As
an alternative to the residual-covariance ap-
proach, a kiindred-frallty model (Vaupel, 1990)
could be used where brothers share a level of
frailty. Then, with assumptions about the struc-
ture of the frailty distribution, the parameters of
a hazard function and a frailty distribution could
be estimated (cf., James J. Heckman and
Christopher R. Taber, 1994).
IV. The Production and Distribution
of Spiritual Assets
There is, finally, the issue of spiritual or im-
material assets. A good place to begin is with
Socrates' question: What is the good life? That
was a critical question not only for the sons of
rich Athenians but for sons of the landed rich
throughout history. Freed of the need to work
in order to satisfy their material needs, they
sought self-realization in public service, mili-
tary adventures, philanthropy, the arts, theol-
ogy, ethics, and moral philosophy. Their
preoccupation with immaterial commodities
led Adam Smith to argue that the landed ar-
istocracy ignored their property and lacked in-
terest in advancing methods of cultivation.
"The situation of such a person," he wrote,
"naturally disposes him to attend rather to or-
namenit which please his fancy, than to profit
for which he has so little occasion" (Smith,
1937 pp. 364, 891-892).
In a world in which all but a small percenit-
age are lacking in adequate nutrition and other
necessities of life, self-realization may indeed
seem like a mere ornanent, but not in a coun-
try where even the poor are rich by past or
Third World standards. That is the case in
America today since the poverty line is at a
level of real income that was attained by only
those in the top 10 percent of the income dis-
tribution a century ago'3 (Fogel, 2000). Tech-
nophysio evolution has made it possible to
extend the quest for self-realization from a
minute fraction of the population to almost the
whole of it. Although those who are retired
will have more time to pursue self-realization,
even those still in the labor force will have
sufficient leisure to seek it either within their
professional occupations or outside of them
(Peter Laslett, 1991; Hans Lenk, 1994),
Some proponents of egalitarianism insist
on characterizing the material level of the
poor today as being harsh. They confound
current and past conditions of living. Failure
to recognize the enormous material gains
over the last century, even for the poor, im-
pedes rather than advances the struggle
against chronic poverty in rich nations, the
principal characteristic of which is spiritual
estrangement from the mainstream society.
Although material assistance is an important
element in the struggle to overcome spiritual
estrangement, such assistance will not be
properly targeted if one assumes that iin-
provement in material conditions naturally
leads to spiritual improvement.
That proposition, so widely emnbraced by the
nore secular of the economic reformers of the
twentieth century, did more to promote the
consumerism of the 1920's and 1930's than to
produce spiritual regeneration. The middle and
working classes became preoccupied with the
acquisition of automobiles and those house-
hold appliances made possible by electricity:

### ---Economics-1999-0-14.txt---
irons, lamps, telephones, toasters, refrigera-
tors, radios, and washing machines. It was this
consumerism that led such progressive critics
of the era as Vernon Louis Parrington, pioneer
in the development of intellectual history, to
decry the "cash-register" mentality of modern
urban life (Parrington, 1930 p. 81).
The economist's traditional measures of in-
come inequality are inadequate measures of
both egalitarian gains and egalitarian failures
(cf., Amartya K. Sen, 1996). They focus on a
variable- money income-that currently ac-
counts for less than half of real consumption
and which in a generation may slip to just a
quarter of real consumption. The most serious
threats to egalitarian progress-certainly the
most intractable forms of poverty-are related
to the unequal distribution of spiritual (im-
material) resources (cf., William Julius
Wilson, 1996).
Realization of the potential of an individual
is not something that can be legislated by the
state, nor can it be provided to the weak by the
strong. It is something that has to develop
within each individual. Moreover, which as-
pect of one's potential an individual chooses
to develop most fully, such as choosing a pro-
fession, is purely an aesthetic consideration.
John Dewey and one of his chief disciples,
Richard Rorty of the University of Virginia,
contend that in a democracy self-realization is
"4a particularized creative project of individual
growth" (Richard Shusterman, 1994 pp. 396-
97). The emphasis on individual choice does
not mean that other individuals and institutions
play no role in shaping those choices. Quite
the contrary, the quality of the choices and the
range of opportunity depends critically on how
well endowed an individual is with spiritual
resources. But the spiritual resources needed
for personal development are unequally dis-
tributed among young and old, among men
and women, among various ethnic groups, and
among rich and poor. Those rich who are con-
tinuously preoccupied with sensual gratifica-
tions are as likely to fail in self-realization as
the poor who share that preoccupation. Al-
though the rich may have the wealth to buy
the treatment needed from highly trained pro-
fessionals, inexpensive character and religious
counseling may serve as well, if not better, for
the addicts of all classes.
The full list of maldistributed spiritual re-
sources is too long to discuss adequately here
but I have in mind such vital assets as a vision
of opportunity and a work ethic. A common
characteristic of such assets is that they are
transferred from one individual to another
mainly very early in the life of the recipient.
Self-esteem and a sense of family solidarity
begin to be transferred to children along with
mother's milk and with pabulum. Other spir-
itual resources begin to be transferred during
the toddler and toilet-training stages, including
a sense of discipline, a capacity to resist or
control impulses, and a sense of community.
Telling nursery rhymes such as "TThis little
piggy went to market," recounting the auto-
biographies of the mother and father, and fam-
ily histories going back two or three
generations convey such spiritual resources as
a work ethic, a sense of the mainstream of
work and life, an ethic of benevolence, a vision
of opportunity, and a thirst for knowledge.
Although these early transfers of spiritual
resources are enriched and expanded by pri-
mary, secondary, and college education, and
by occupational and other later-life experi-
ences, the salience of these later transfers de-
pends in no small measure on what happens at
home before formnal education begins. It is,
therefore, necessary to remedy the maldistri-
bution of spiritual resources early in life, be-
cause the most spiritually deprived infants will
often be born to single, teenaged mothers who
are themselves spiritually deprived.
Some young mothers are too deprived, or
too young, to call on their own life experiences
to transmit a sense of discipline and of oppor-
tunity, a work ethic, a family ethic, a sense of
self-esteem, and a knowledge of the main-
stream of work and life. The deprivation can
be addressed by promoting a system of men-
toring, taking advantage of the increasingly
large number of retired men and women who
have abundant -spiritual resources. Such men-
toring programs would be useful, not only for
the toddlers and their mothers and fathers, but
also for the elderly who are looking for ways
to enrich their retirement years.
Despite the improvements in their material
conditions of life, including comfortable
stocks of consumer durables, the elderly today
suffer from a maldistribution of immaterial


### ---Economics-1999-0-15.txt---
resources that traces back to the conditions of
their youth. Persons aged 80 today were borm
in 1918 or 1919. Only 43 percent of that cohort
graduated from high school and less than 15
percent entered college. Even among the
youngest cohort of the elderly, those born in
1933 and 1934, only half graduated from high
school and about 20 percent entered college
(U.S. Bureau of the Census, 1975 p. 379).
These cohorts also suffered from high infant
death rates, poor nutrition in early infancy, and
early onset of chronic diseases, as compared
with cohorts born since World War II.
Hence, despite their relatively high levels of
income and stocks of consumer durables, the
maldistribution of spiritual resources is sub-
stantial. Depression, alienation, and substance
abuse are common (S. C. Samuels, 1997).
Those who are most afflicted are lonely, have
few communal contacts, live in retirement
homes rather than in their own households,
and sense a loss of control over their personal
lives (W. L. Fletcher and R. 0. Hansson,
1991; K. Pahkala et al. 1992; K. Yamashita
et al., 1993). Recent studies also indicate that
those who lacked immaterial resources early
in life have difficulty in attaining self-
realization after retirement (J. C. HIenretta,
1997; J. E. Mutchler et al., 1997).
I have emphasized the level of education be-
cause recent studies indicate that the capacity
of the elderly to engage effectively in physical
activity was strongly correlated with education
early in life. Education also affects cognitive
ability and the rate of illness (J. W. Rowe and
R. L. Kahn, 1997). Consequently, individuals
who were deprived of adequate education in
youth are, for that reason among others, rela-
tively deprived of both physiological and spir-
itual resources in late life.
Despite the long reach of youthful depri-
vation, there are enough other factors affecting
the quality of elderly life to pennit redistri-
butions that compensate for previous deficits.
On the physiological side, for example, there
are effective medical interventions that can in-
crease the quality of life and longevity. Al-
though the elderly are eligible for Medicare to
pay for treatment, the quality of treatment is
variable, and many individuals may be
shunted to low-quality care. Moreover, some
interventions are denied, or are more reluc-  tantly ordered, for the elderly than for the mid-
dle aged.
Because spiritual resources are so un-
equally distributed among the elderly, dif-
ferent programs are needed for different
strata. The mninority of the current elderly
who are well educated, the 14 percent with
at least bachelor's degrees, most of whom
had professional careers, have developed
some innovative programs (U.S. Bureau of
the Census, 1997 p. 160). In Great Britain
one of these is called the "University of the
Third Age." This educational program is not
aimed at providing credentials for those
about to embark upon new careers, but at
satisfying the thirst for knowledge. It is
based on the proposition that education, and
the acquired knowledge and skills, are a
source of self-satisfaction, even if they do
not enhance an individual's employability.
As Laslett (1991 pp. 171-71) put it:
Reading in a literature, mastering a lan-
guage, unraveling a point in logic or phi-
losophy, understanding the objectives
set for themselves by poets, painters,
novelists or architects, these things ex-
tend your appreciation and your miastery
of your world, your objective and your
subjective world as well. They are ful-
filling, and adding to other people's
knowledge is the most fulfilling of all.
Programs su'h as the University of the
Third Age will become increasingly important
as the baby boomers and others of the more
highly educated cohorts of the post-World
War :I era begin to retire. However, today and
for the next decade, the bulk of the elderly
lacks the skills to create and participate in such
high-level programs as the University of the
Third Age. A recent survey of adult literacy
revealed that more than half of the elderly pop-
ulation suffers from functional illiteracy.
These individuals may be able to sign their
name or read very simple material, but they
cannot follow instructions for taking medi-
cines or cope with a variety of documents en-
countered in daily living (R. Boling, 1,998).
Those who suffer from low levels of literacy
are educable. Engaging them in intellectual ac-
tivities has a significant influence on their
physiological perormance. Recent studies re-


### ---Economics-1999-0-16.txt---
veal more physiological plasticity than was
previously suspected. The capacity for self-
improvement continues into old age and ap-
propriately designed programs can return
diminished individuals to earlier levels of
functioning (Rowe and Kahn, 1997; cf.,
Wachter and Finch, 1997).
Peer tutoring has a two-way effect, since
it is beneficial both to the learner and to the
tutor. Both gain from involvement in social
networks that enhance mood, combat de-
pression, and reduce the risk of suicide. For
widowed men, the benefits are physiological
as well as psychological. Men in situations
that provide higher social support have sig-
nificantly lower losses of cortisol, epineph-
rine, and norepinephrine (hormones that
reduce pain, stimulate the functioning of the
heart, and improve electrical transmission
across cells). Statistical analysis indicates a
positive relationship for both men and
women between social support and physical
performance. For the tutors, being active in
such productive and emotionally rewarding
activities serves to retain a sense of relative
youthfulness. Thus volwork, because it is ef-
fective, because it is emotionally rewarding,
and because it is what the tutors want to do,
adds significantly to national product.
Use of fiscal policy to correct the maldis-
tribution of income is based, explicitly or
implicitly, on the ethical proposition that
those households at the top of the income
distribution have more income than they
ought to have. What about the case of spir-
itual redistributions? Are spiritual resources
maldistributed because virtue is too heavily
concentrated? Government cannot legislate
the transfer of virtue as it does with money
income. Even if they desired to do so, those
rich in virtue or in the family ethic, or in
benevolence, could not transfer spiritual re-
sources by writing out checks denominated
in virtue, benevolence, or family solidarity.
Those poor in these spiritual resources ac-
quire more of them only through the process
of self-realization, through a concerted ef-
fort to develop as fully as possible the vir-
tuous aspects of their nature.
Those rich in spiritual resources can help
those who are spiritually deprived by counsel-
ing them, by providing spiritual companion-
ship and moral support, by informing and
teaching those who are deprived about existing
opportunities and procedures, and by helping
to raise their self-esteem. But this process of
correcting the maldistribution of spiritual re-
sources not only leaves those who are deprived
better off, it also increases the spiritual re-
sources of those who have virtue in abun-
dance. In contrast to income redistribution,
spiritual redistribution is not a fixed-sum game
in which some people can become better off
only if other people are made worse off. It is
a game in which total resources increase and
the share of the deprived in this larger total
may also increase without in any way dimin-
ishing those who have a superabundance of
spiritual resources.
Some economists may be astonished by my
claim that in some respects the discipline has
fallen seriously behind the economy. After all,
if it were so, who would know about it before
them? The answer lies in the subtext of this
address. To understand where the economy is
and how it is evolving one needs to study not
only the present but the past. In the 1940's,
Kuznets ( 1941 ), musing about some of the an-
alytical mistakes made in the aftermath of the
Great Depression said: "A broader historical
background might have prevented some econ-
omists from ignoring the dependence of their
generalizations upon transient historical con-
ditions."' That advice is as good today as it
was a half century ago.
## Economics-2000-0


### ---Economics-2000-0-01.txt---
People today have more adequate nutrition
than ever before and acquire that nutrition at the
lowest cost in all human history, while the
world has more people than ever before-not by
a little but by a lot. This is an achievement that
many have argued could not be realized.
Throughout history there have been those who
believed that food shortages and famine were
the fate of humanity and that the world's pop-
ulation was restricted not by human decisions
on fertility but by limitations imposed by na-
ture. Unfortunately for nearly all of human his-
tory and for the vast majority of the world's
people, this pessimism was justified. In the last
two centuries, and especially in the twentieth
century, all has changed to a remarkable degree.
The twentieth century can be remembered as the
century in which hunger could have been elim-
inated and, to a significant extent, has been.
I. Food and Population Growth
Thomas Robert Malthus, publishing the first
edition of his famous An Essay on the Princi-
ples of Population in 1798, is usually credited
with the pessimistic view that population had a
tendency to outrun the available food supply
and was held in check by vice and misery--war,
disease, or starvation-but he was not the orig-
inator of the idea. At least two millennia earlier
it was written in the Bible: "When goods in-
crease, those who eat them increase." (Ecclesi-
astes 5.)
Quintus Septimus Florence Tertillianus wrote:
Indeed it is certain, it is clear to see, that
the earth itself is currently more culti-
vated and developed than in earlier times.
Now all places are accessible, all are doc-
urnented, all are full of business. The
most charming farms obliterate empty
places, ploughed fields vanquish forests,
herds drive out wild beasts, sandy places
are planted with crops, stones are fixed,
swamps drained, and there are such great
cities where formerly hardly a hut ... ev-
erywhere there is a dwelling, everywhere
a multitude, everywhere a government,
everywhere there is life. The greatest ev-
idence of the large number of people: we
are burdensome to the world, the re-
sources are scarcely adequate to us; and
our needs straiten us and complaints are
everywhere while already nature does not
sustain us. Truly, pestilence and hunger
and war and flood must be consider as a
remedy for nations, like a pruning back of
the human race becoming excessive in
numbers. (Bart K. Holland, 1993 pp.
328-29.)
This was written about 200 A.D. when the
world's population was approximately 200 mil-
lion. Note that the quotation includes nearly all
the modern complaints about the effects of ex-
cessive population on the environment-defor-
estation, loss of biological diversity, farming
unsuitable land, drainage of the natural refuges
for wildlife-as well as the massing of people in
cities.
While Malthus was neither the first, nor the
last, to claim population growth carried with it
the seeds of disaster for humanity, he may have
been the first to significantly modify his view
that population growth would inevitably press
against the food supply. Five years after the
gloomy first edition, in the second edition of An
Essay on the Principles of Population he sig-
nificantly modified his major conclusion. After
noting the recent growth of European popula-
tion, he wrote:
.. fewer famines and fewer diseases aris-
ing from want have prevailed in the last
century than in those that preceded it. On
the whole, therefore, though our future
prospects respecting the mitigation of the


### ---Economics-2000-0-03.txt---
evils arising from the principle of popu-
lation may not be so bright as we could
wish, yet they are far from entirely dis-
heartening and by no means preclude
gradual and progressive improvement in
human society which, before the late wild
speculations on the subject, was the object
of rational expectations. (Malthus, 1992
pp. 330-31.)
Unfortunately, the Malthus of the first edition
provided a model of population growth that
accurately depicted the experience of nearly all
of human history and was generally valid up to
the time he wrote. But he was also correct in his
view that during the century following the pub-
lication of the essay that there would be gradual
improvement in the well-being of people in the
part of the world where he lived, namely Eu-
rope. However, the progress was neither uni-
form nor without interruption, as witness the
Irish famine of the 1840's and other famines
and food shortages that occurred in several Eu-
ropean countries during the nineteenth century.
In the second edition he recognized a third
factor that affected population growth in addi-
tion to vice and misery-namely, the desire for
self-improvement. In other words, families
were willing and capable of influencing the
number of children by changing the age of
marriage, for example.
What made it possible for the world to escape
from what could be called the Malthusian trap?
The answer is simple: the creation of knowl-
edge.1 While there had been improvements in
agriculture for many millennia through knowl-
edge gained from practical experience-learn-
ing by doing-there was an explosion of
knowledge over the past two centuries that
made possible an unparalleled increase in per
capita well-being, not just in terms of food but
in all aspects of life. Fundamentally, new tech-
nologies have been developed at a rate unprec-
edented by historical standards.
Consider the following (Angus Maddison,
1995):
1. The increase in the world's population in the
decade of the 1980's of 844 million was
nearly as large as the world's total popula-
tion in 1800 of 900 million.
2. During the decade of the 1980's the increase
in the world's gross domestic product per
capita equaled the estimated per capita gross
domestic product in 1820 (Maddison, 1995
p. 228).
Measured in 1990$, in the 1980's the per
capita GDP increased by $661; the per capita
figure for 1820 was $651.
3. The physical world-the land, the water, the
air, the sun-was basically the same in the
1980's as it was in 1820 or 1020 or 109000
years ago. Some might argue that the phys-
ical world was less valuable than in the past.
The magnitude of the increase in the world's
output since 1820 is much greater than is di-
rectly implied by the comparability of the in-
crease in GDP during the 1980's and in all
history up to 1820. The increase in real world
output during the 1980's was more than 10
times the output in 1820 and the world output in
1990 was 40 times that of 1820. How could
these enormous changes have occurred? They
occurred because we have found ways to offset
the limitations that natural resources imposed
on the world's output in times past as well as
improving greatly the amount and productivity
of human capital. We have not found how to
repeal the principle of diminishing marginal
returns. But we have found low cost and abun-
dant substitutes for natural resources important
in the production process.
As I will show later, the improvement in
well-being of the world's population goes far
beyond the enormous increase in the value of
the world's output. The improvements are evi-
dent in fewer famines, increased caloric intakes,
reduced child and infant mortality, increased
life expectancy, great reductions in time
worked, and greatly increased percentage of the
population that is literate.

### ---Economics-2000-0-04.txt---
This lecture proceeds in the following way. I
show that for most of human history, life was
both short and difficult for the vast majority of
the world's people, that food supply was a ma-
jor factor affecting population size, and that
consumption-nonfood as well as food-was
very limited. I shall then turn to the question of
how the developed world escaped from the
Malthusian trap during the nineteenth century
and how the developing world did so more than
a century later.
I emphasize three major factors that I con-
sider responsible for the remarkable period of
economic growth that has occurred over the past
two or three centuries that permitted breaking
free from the limits imposed by the food supply.
The first factor is the significant advances in
agricultural productivity in the eighteenth and
nineteenth centuries. The increase in agricul-
tural productivity made possible the develop-
ment of cities as the major focus of further
economic development and growth. The second
factor is the enormous increase in knowledge
over the past two centuries made possible by
increasing population and rising real per capita
incomes resulting from the economic growth
from the mid-eighteenth century. The increase
in real incomes permitted the allocation of sub-
stantial resources to the creation of knowledge.
This reallocation was associated with the rapid
development of two institutions- universities
and research institutes. The third factor, con-
trary to what is often assumed, is that the re-
sponse of families to the removal of restraints
on their well-being imposed by limited food
supplies was not significantly increased fertil-
ity; population growth resulted primarily from
mortality declines. Population growth was not
limited by the supply of food but by the deci-
sions of families.
The three reasons do not fully explain why
population growth did not spoil everything for
the developed world in the nineteenth century
and for the developing world more recently.
One reason the growth of food output in the
nineteenth century may not have been over-
whelmed by population growth was that knowl-
edge and technology required for the rapid
reduction of mortality did not become generally
available until near the end of the nineteenth
century and, further, the rapid increase in the
population of cities limited the decline in mor-
tality. The decline in mortality in the developing
world in the twentieth century was far more
rapid and resulted in a much higher rate of
population growth than the experience of the
nineteenth century even though fertility de-
clined significantly.
II. Agriculture and Food Before the
Nineteenth Century
Agriculture is a relatively recent invention-
the transformation from hunting and gathering
to planting and growing crops and domesticat-
ing animals probably occurred about 10 millen-
nia ago. At that time the world's population was
about 4 million and a large fraction of all re-
sources were devoted to obtaining food, and a
very poor lot it was.
As of 1800 it is estimated that '75 to 80
percent of the working population in the devel-
oped world was engaged in agriculture (Bai-
roch, 1988 p. 287). In the rest of the world, with
nearly 80 percent of the world's population, the
percentage of workers engaged in agriculture
was certainly higher-of the order of 85 to 90
percent. In 1891, 90 percent of the population of
India was rural (Adna Ferrin Weber, 1899 p.
124) and as late as 1949, 89 percent of China's
population was rural.2 Unfortunately we do not
have evidence that permits -us to directly deter-
mine the amount of food available in ancient
times. But if life expectancy in Roman times
were 25 years (Donald J. Bogue, 1969 p. 566),
it is highly probable that the available food per
capita was very limited. Fogel has estimated the



### ---Economics-2000-0-05.txt---
daily caloric supplies at the beginning of the
eighteenth century of 2,095 for Great Britain
and 1,657 for France (Fogel, 1996 p. 10). Life
expectancy for England in 1725 is estimated to
be 32 years and in France in 1750, 26 years.
Over the next century per capita calories in-
creased by approximately 10 percent-to 2,237
in Great Britain and to 1,846 in France and by
1800 life expectancy in England was 36 years
and in France 32 years (Fogel, 1996 p. 2).
Obviously other factors had a role in the in-
crease in life expectancy, but it is unlikely that
these increases and those that followed would
have occurred in the absence of improved nu-
tritional intake.
A life expectancy of between 25 and 30 years
was probably the fate of most of humanity
throughout recorded history until about 1650
(Bogue, 1969 p. 566). It was not until the sev-
enteenth century that there is evidence that life
expectancy increased significantly beyond what
it was in Roman or earlier times. As noted,
England and France, two of the wealthiest na-
tions of the world, had life expectancies at the
beginning of the eighteenth century that were
not much above what had prevailed throughout
human history.
It is probable that the per capita calorie sup-
plies for the world prior to the seventeenth
century were in the range found in England and
France at the beginning of the eighteenth cen-
tury-perhaps from 1,650 to less than 2,000.
These are in the range of calorie intakes in many
developing countries in 1934-1938, the earliest
date for which we have estimates for several
countries. Calorie intakes in India, the Philip-
pines, Peru, Colombia, and Mexico were in the
range of 1,800 to 2,000 calories (M. K. Bennett,
1976 p. 199). By 1934-1938 these countries
had significant population growth rates and at
earlier times consumption was probably rather
less.
Important evidence that the productivity of
agricultural resources in Europe remained rela-
tively constant and low was that in Europe,
excluding Russia, there was almost no change
in the percentage of the total urban population
between 1300 and 1800. Bairoch (1988 pp. 177,
216) estimates that in 1300 the urban population
of Europe was 10.4 percent of the total; five
centuries later in 1800 it was only 12.1 percent
and most of this increase occurred in England in
the eighteenth century. The nineteenth century
saw a major increase in urbanization; by the end
of the nineteenth century the urban population
was 37.9 percent of Europe's population, Rus-
sia excluded. The urban population increased
almost five times in the nineteenth century after
little more than doubling in the previous five
centuries (Bairoch, 1988 pp. 177, 216). The
development of cities as a significant share of
the total population became possible only after
farmers increased production relative to their
own consumption.
Further evidence that per capita output of
agriculture increased very little throughout his-
tory was the slow growth of world population
until nearly the beginning of the nineteenth cen-
tury. During the first millennium of the current
era, the annual rate of growth was 0.04 percent,
a doubling time of 1700 years. In the 700 years
ending in 1700, the rate of population growth
was 0.12 percent, a doubling time of about 580
years. The rate of population growth did in-
crease in the eighteenth century-to 0.41 per-
cent annually. But even at that rate it would take
179 years to double.
Europe's population during the eighteenth
century increased from 102 million to 154 mil-
lion and this increase was made possible by a
significant increase in food production oc-
curred. However, except in England, there was
no increase in urbanization so it is reasonable to
infer that in the rest of Europe the growth of
food production increased at approximately the
same rate as population during the eighteenth
century.
I[I. Agriculture and the Industrial Revolution
What was agriculture's contribution to the
Industrial Revolution? The Industrial Revolu-
tion is generally considered to have started



### ---Economics-2000-0-06.txt---
about 1750 in England and up to a century later
in the rest of Europe. As I have noted, the share
of cities in Europe's population had remained
nearly constant for the previous five centuries,
and that this meant that the available food sup-
ply had not increased significantly faster than
population and, equally important, that the pro-
ductivity of labor in agriculture also had not
increased enough to permit labor to transfer out
of agriculture and migrate to cities. The mid-
point of the eighteenth century marks a striking
dividing point in the demographic and agricul-
tural history of England. In the century up to
1750 England's population was static. It actu-
ally declined in some periods and increased at
an annual rate of only 0.1 percent or by 10
percent in the entire century (E. A. Wrigley and
R. S. Schofield, 1981 pp. 528-29). Life expect-
ancy may have actually declined. But between
1751 and 1801 its population grew at an annual
rate of 0.81 percent and the total increased by
50 percent. In the next half century the popula-
tion nearly doubled. Nearly all of the increase in
the United Kingdom's population in the nine-
teenth century was urban (Bairoch, 1988
p. 290).4
What increased productivity in agriculture so
strikingly after 1750? Exact causes are un-
known, but many changes were involved, in-
cluding the spread of two high-yielding crops
from the Americas-corn (maize) and potatoes,
the enclosure movement, the elimination of fal-
low, improved drainage, and increased avail-
ability of animal manure made possible by the
cultivation of turnips as feed for cattle (David S.
Landes, 1969 p. 76). There was a major increase
in England and the Netherlands in the grain-to-
seed ratio to more than ten in 1750-1820 com-
pared to seven in the two centuries prior to 1700
(B. H. Slicher van Bath, 1963).5 Such a large
increase in yield was almost certainly associated
with a significant increase in labor productivity.
While urbanization increased very little in En-
gland during the last half of the eighteenth cen-
tury, there was a significant expansion of
industrial activity in rural areas, especially in
the production of textiles.
Significant increases in per capita food pro-
duction and in labor productivity in agriculture
were necessary conditions for the Industrial
Revolution which was associated with, and may
well have been advanced by, rapid population
growth. The increase in food production was
necessary to sustain the rapid population
growth; the growth in agricultural labor produc-
tivity was required to permit a reduction in the
share of labor devoted to farming and to permit
the transfer of labor to the cities. I do not argue
that the improvements in food supply and labor
productivity were sufficient conditions for the
Industrial Revolution. It is quite probable that
the agricultural and industrial revolutions had
the same sources and each was affected by
developments in the other.
IV. The Mechanical Revolution
The improvements in labor productivity in
agriculture occurring in the eighteenth century
and the early years of the nineteenth century
were insignificant compared to the changes that
occurred in the rest of the century. Throughout
history for most of the world's population the


### ---Economics-2000-0-07.txt---
major source of calories has been grain-of the
order of 75 to 80 percent (Bennett, 1976 p. 206).
Until the early nineteenth century the serious
bottleneck in the production of grain was har-
vesting. The plow was introduced several mil-
lennia before, and it saved labor, but at a time of
the year when labor was not scarce. Plowing
could be done over an extended period of time,
but harvesting in most areas had to be done in a
brief period to prevent the crop being harmed or
destroyed by wind, rain, or frost.
At the beginning of the nineteenth century
grain was harvested by the same methods as in
the fourteenth century and probably much ear-
lier-the sickle, the scythe, and the cradle. T'he
invention and introduction of the reaper in
America in the second quarter of the nineteenth
century changed all that. The reaper was soon
followed by the binder, which was a reaper with
an attachment that brought the grain straw to-
gether in a bundle and tied it with twine. The
binder was complemented by the thresher that
saved a great deal of labor, though at a time less
critical than the savings made possible by the
reaper and binder. In turn the binder and
thresher were largely replaced by the combine,
but not until well into the twentieth century.
Many other machines and tools were part of
the mechanical revolution. Very important
was harnessing the internal combustion en-
gine to create the tractor. The labor savings of
the mechanical revolution were enormous. It
is estimated that the direct labor input used to
produce a ton of grain in the United States
declined by 70 percent in the nineteenth cen-
tury (Martin R. Cooper et al., 1947). Conse-
quently in the developed countries after the
mid-nineteenth century the transfer of labor
from agriculture to nonagricultural pursuits
was more likely limited by the rate of growth
of nonagricultural employment than by the
labor requirements of agriculture.
V. Land Was Not the Scarce Resource
While today many give emphasis to the lim-
ited supply of land of good quality as a major
impediment to further increases in food produc-
tion, throughout nearly all of human history
land has not been an important factor limiting
production. It had to have been something else
when the world's population was 500 million,
as it was in the sixteenth century, or perhaps
even when the population first reached one bil-
lion, early in the nineteenth century. Given the
state of knowledge that existed until quite re-
cently, the primary limiting factor was labor.
Labor limited the amount of food that could be
produced by a family and, as noted, for much of
human history, farm families were barely able
to produce enough for their own consumption
with little surplus for trade with others. Until
quite recently this surplus was hardly more than
a quarter or a fifth of what they produced. A
good indicator that land was not the limiting
factor is that until the beginning of the nine-
teenth century yields were calculated per unit of
seed, not per unit of land (Slicher van Bath,
1963).
Ester Boserup (1965) makes a convincing
case that labor and not land was the limiting
factor in agricultural output until quite recently.
She showed how farmers adapted to increasing
population by modifying the ways that land was
utilized, shifting from slash and burn and long
fallow to shorter periods of fallow and in West-
ern Europe eliminating fallow entirely. They
found ways other than fallow to maintain the
fertility of the soil-the use of manure and
legumes, for example. These changes were the
result of new knowledge, knowledge largely
derived from experience of the farmers them-
selves and were a response to the growing pop-
ulation and the need to expand food production.
VI. The Increased Role of Knowledge
As noted, the enormous increase in the
world's output over the past two centuries has
been due in large part to the advancement of
knowledge combined with the increase in hu-
man resources, both in number and capabilities,
and savings translated into physical capital. We
do not have more natural resources than existed
in the distant past, yet output has increased
many fold. What is the source of the increased
knowledge? Two factors have been important-
one is simply the growth of population and the
other is that rising real per capita incomes have
made it possible for specialization in the pro-
duction of knowledge and for devoting a signif-
icant share of our resources to that effort.
Michael Kremer (1993) makes a convincing
case for the conclusion that a larger population


### ---Economics-2000-0-08.txt---
leads to greater creation of knowledge. First, the
larger the population, the greater the benefit
from a given improvement in productivity re-
sulting from new knowledge. Second, with a
larger population, there are more individuals
capable of making a significant discovery or
adding to knowledge. It is not that today we are
smarter or more intelligent than populations a
century ago, two centuries ago, or a millennium
ago. Presumably the distribution of talents or
intelligence is the same today as at any past
time. But there are many, many more of us and
if the distribution of talents has not changed,
there are many more individuals capable of
advancing knowledge.
But it is not only that there are more of us
available to add to the world's knowledge, but
with the improvements in agricultural produc-
tivity, the expansion of the cities, and the very
large increases in real per capita incomes that
have occurred over the past two centuries, in-
stitutions have been created specifically to ad-
vance and transmit knowledge. I refer to
universities and research institutes, including
both public and private ones. It was not that
prior to the nineteenth and twentieth centuries
that there were no individuals who had the
intelligence, time, curiosity, and energy for the
creation of knowledge. But their numbers were
limited. Our lives, however, are greatly influ-
enced by those who developed the reaper and
the binder, the internal combustion engine, the
steam engine, the railroad, electricity, the tele-
phone, and by those who discovered the small
pox vaccine and the germ theory of disease. But
by the beginning of the twentieth century their
effects on the lives of individuals were limited
compared to the effects of the recent increases
in knowledge and their applications.
When as many as 80 to 85 percent of the
world's labor force was engaged in farming, a
small percentage of a much smaller world pop-
ulation had the time and resources to devote to
producing nonfood products, such as clothing,
tools, roads, and housing, let alone acquiring
new knowledge and technology. In 1990 in the
developed world no more than 10 percent of its
labor force was engaged in agriculture and in
the developing world approximately 60 percent
(World Bank, 1997 p. 220). Not only are there
about seven times as many people as there were
in 1800, but a significant percentage of this
much larger population specializes in the cre-
ation of knowledge compared to the very small
number who could do so just two centuries ago.
The modern university, with many faculty de-
voting their time to research in science and
graduate education, is a very recent creation-
such institutions hardly existed before the mid-
dle of the nineteenth century. German
universities dominated the world' s graduate ed-
ucation in the nineteenth century. Yet as of
1900 in all the German universities there were
only 38,000 students and 1,830 faculty
(Friedrich Paulsen, 1908 p. 193); these are totals
for all colleges and universities, not just those
engaged in graduate education.
In 1869-1970, only a single Ph.D. was
awarded in the United States (U.S. Bureau of
the Census, Department of Commerce, 1960).
The development of colleges and universities
after 1869-1970 was quite remarkable. In that
year there were 563 colleges and universities
with a total faculty of 5,553 and 52,000 stu-
dents. The contribution to new knowledge had
to be limited; there were approximately ten fac-
ulty members per institution, including, I as-
sume, the president who probably spent much
of the available time trying to find enough fi-
nancial resources to keep the institution open.
Sixty years later, for example, there were
82,000 faculty, 1.1 million students, and 2,299
doctorates awarded. Further rapid expansion of
higher education came after World War II and
by 1994/1995 there were an estimated 915,000
faculty, 14.3 million students, and 43,000 doc-
torates awarded (Thomas I). Snyder, 1993).
In part, as a result of World War II, the
governmental support of research in universities
and federal research laboratories was greatly
expanded and many private research institutes
were created and developed. Prior to World
War II federal support of research was largely
concentrated in agriculture and the military.6

### ---Economics-2000-0-09.txt---
As the twentieth century ends, both the share
and the absolute amount of the world's re-
sources devoted to the development of new
knowledge are vastly greater than at the begin-
ning of the century. Equally important is that
the share of resources devoted to the wide dis-
tribution of that knowledge has also increased
greatly.
VII. Population Growth-Roles of Fertility
and Mortality
My third point is that population growth in
the developed countries in the nineteenth cen-
tury and in the developing countries in the twen-
tieth century was due almost entirely to
mortality declines and not to fertility increases.
In other words, the response of men and women
to improved circumstances-improved nutri-
tion and higher incomes-was not to increase
fertility significantly. For the nineteenth century
the picture is clear. For the three European
countries, both fertility and mortality declined.
In England and Sweden there was an increase in
fertility during the latter half of the eighteenth
century but the increase was small (less than 10
percent) and lasted less than 50 years before
declining throughout the nineteenth century.
The increases in fertility had little or no effect
on population growth in Europe, with a modest
positive effect in Sweden and England from
perhaps 1750 to 1800, but with declines
throughout the nineteenth century.
The total fertility rate (average number of
children per woman) for Sweden increased from
4.21 in 1750 to 4.68 in 1800 but then declined
continuously throughout the nineteenth century,
reaching a level of 1.90 in 1990 (Massimo Livi-
Bacci, 1992 p. 122). Life expectancy in the last
20 years of the eighteenth century was 34 years,
increasing to 39 years by 1835 and to 54 years
in the first decade of the twentieth century
(Nathan Keyfitz and Wilhelm Flieger, 1968 pp.
36-37).
Total fertility rates for England increased
from 5.28 in 1750 to 5.87 in 1775 and then
declined to 1.96 in 1900 (Livi-Bacci, 1989 p.
122). In the early period of the Industrial Rev-
olution there seems to have been a small posi-
tive response in fertility to the improved
circumstances that lasted less than half a cen-
tury and had only a modest effect on the rate of
population growth. In England life expectancy
was 32 years in the last fifth of the seventeenth
century and remained at that level in the years
before 1750. It increased to 36 years by the end
of the eighteenth century and to 41 years by the
middle of the nineteenth century (Wrigley and
Schofield, 1981 pp. 528-29) and continued to
increase thereafter. In France the fertility and
mortality trends are very clear-the total fertil-
ity rate was low in 1825 at 3.42 and fell con-
tinuously reaching 2.14 in 1900 (Livi-Bacci,
1992 p. 122). Life expectancy increased from
about 28 years in 1760 to 40 years in 1840 and
to 46 years at the end of the century (Wrigley,
1987 pp. 274).
The data on fertility and mortality available
for the developing countries since 1960 prove
that the source of the rapid population growth in
these countries was the decline in mortality
rather than an increase in fertility. In fact, both
mortality and fertility fell much more rapidly in
the developing countries in the twentieth cen-
tury than in the developed countries in the nine-
teenth century prior to 1875.7 Excluding China,
which has had coercive restraints on fertility,
the decline in fertility in the 31 lowest-income
countries from 1960 to 1995 was 38 percent
(United Nations Development Program
[UNDP], 1998). Over the same period of time,
life expectancy increased from 42 years to 59
years for the same countries. But the fertility
decline lagged behind the mortality decline by a
decade or more and high rates of population
growth occurred in the 1960's and the 1970's.
For example, between 1960 and 1978, in the 38


### ---Economics-2000-0-10.txt---
low-income economies the crude death rate de-
clined 31.5 percent while the crude birth rate
declined 14.4 percent (China excluded) (World
Bank, 1980). The annual population growth rate
for the same countries was 2.5 percent for
1960-1970 and 2.2 percent for 1970-1978
(World Bank, 1980).
Why has fertility declined as real per capita
incomes have increased? At low levels of in-
come, with agriculture as the major occupation,
children have a positive benefit in increasing the
level of income of the parents as well as pro-
viding security against illness and old age. Chil-
dren, and their growth and development, enter
into the utility functions of parents positively.
Parents realize satisfaction both in terms of the
quantity and quality of their children (Becker,
1991). As real per capita incomes increase, the
structure of the benefits from children change.
The direct contribution of children to the in-
come and material welfare of their parents di-
minishes and in urban communities becomes
negative; even in agricultural communities
where incomes and the level of mechanization
are high, children make modest contributions to
current incomes and fertility in rural and urban
areas in the United States are now the same.
However, the utility that parents derive from
their children's growth and development in-
creases as their incomes increase and the em-
phasis on the quality is reflected in increased
investment in their children. Children have in-
creasingly become a consumption good as real
per capita incomes have increased. Thus the
desired number of children is negatively related
to real income and as contraceptive knowledge
and technology have improved, families now
have the ability to achieve the number of chil-
dren desired to a greater degree and at lower
cost than in decades past.
VIII. Why the Nineteenth Century Had Lower
Population Growth
The differences in the population growth
rates between Europe in the nineteenth century
and in the developing countries in the twentieth
century are very great. During the first half of
the nineteenth century, the annual growth rate
for Europe (excluding Russia) was 0.55 percent;
from 1850 to 1880, 0.60, and for the last two
decades, 0.80 percent. The annual rate of in-
crease for the developing regions for 1950 to
1995 was 2.0 percent. In 1900 Europe's popu-
lation (excluding Russia) was 285 million. If
Europe's population during the nineteenth cen-
tury had grown at the developing countries' rate
from 1950 to 1995, its population would have
exceeded a billion in 1900, more than three
times its actual population. Could Europe have
accommodated such a large population in 1900
without a significant reduction in its real per
capita income at the end of the century? Obvi-
ously we will never know, but it seems very
unlikely that it could have unless many of the
technological developments of the twentieth
century had occurred much, much earlier. While
it was true that the rate of economic growth, as
measured by changes in real GDP per capita,
was much slower in Europe in the nineteenth
century than in the developing countries in the
twentieth century (Maddison, 1995), it is worth
exploring why population growth was relatively
slow in Europe.
One factor responsible for the slow growth of
population in Europe was the significant in-
crease in the percentage of the population living
in cities-in 1800 the percentage was 12.1 and
in 1900 it was 37.9. Throughout the nineteenth
century, cities had much higher rates of mortal-
ity than rural areas. Migration from rural areas
was the source of the growth of cities. Not only
did death rates in cities exceed birth rates, but
their death rates were significantly higher than
in rural areas.
Bairoch (1988 p. 230) reports that in Western
Europe throughout the nineteenth century infant
mortality rates in urban areas exceeded the rates
in rural areas by 30 to 60 percent. In Sweden in
the early nineteenth century infant deaths ac-
counted for approximately 25 percent of all
deaths (Keyfitz and Flieger, 1968). But the dif-
ference in mortality was not confined to infants;
life expectancy at age 15 in Sweden was more
than four years higher in rural than in urban
areas in 1881-1890 (Bairoch, 1988 p. 235).8


### ---Economics-2000-0-11.txt---
The difference between population growth rates
in the nineteenth and twentieth centuries was
due primarily to the advancement of knowledge
and technology that permitted much more rapid
reductions in mortality in the twentieth century,
even in the world's poorest countries. There
was rather limited progress in reducing death
rates until the midpoint of the nineteenth cen-
tury in Sweden and significantly later for En-
gland. The basic environmental problems of
unclean water, inadequate sanitation, and child-
hood infectious diseases still took a major toll
until the early years of the twentieth century.
The infant mortality rate in New York City in
1890 was 264 per 1,000 births, more than dou-
ble the rate of 121 in rural areas (Weber, 1899).
The rates of decline in fertility in the devel-
oping world were greater than in the developed
world for the periods under consideration. How-
ever, the crude birth rates in the developing
world started their decline from a much higher
level than existed in the developed world in the
eighteenth and nineteenth centuries. The crude
birth rates in Sweden and England in the eigh-
teenth and early nineteenth centuries were in the
range of 35 to 37 per thousand population while
the averages for low-income countries in 1960
was 48 and the average for middle-income
countries was 40 (World Bank, 1980). Conse-
quently, the birth rate in the low-income coun-
tries needed to fall by a third just to reach the
level prevailing in Western Europe at the be-
ginning of the Industrial Revolution. The more
rapid growth of population in today's develop-
ing world was not due to increases in fertility
but to the combined effects of high initial rates
of fertility and rapid declines in mortality.
IX. Wide Distribution of Benefits of Knowledge
In recent years a great deal of concern has
been expressed about the lack of convergence of
per capita income among countries and increas-
ing inequality within countries. The emphasis
on increased income inequality has left the im-
pression that most measures of well-being have
become much more unequal as well. The use of
differences in per capita incomes as measures of
either satisfaction or well-being assumes that
these measures are proportional to income, a
conclusion that cannot be supported.
Contrary to views that are widely held, for
several important measures of well-being there
has been great improvement, both absolutely
and relatively, in the lives of the people of the
low-income developing countries.9 The benefits
of the growth of knowledge have not been re-
stricted to the countries responsible for the ad-
vances in knowledge but have spread
throughout most of the world. And they would
have spread more quickly and more widely if
the policies of many governments had been
more supportive of economic growth and
development.
Improvements in the conditions of life in
terms of nutrition, infant mortality, and life ex-
pectancy, have occurred at a much faster pace in
the developing countries in the twentieth cen-
tury than in the developed countries in the nine-
teenth century. These improvements have
occurred with much larger populations and
greater population densities. The population of
the developing countries at the end of the twen-
tieth century is 4.84 billion, an increase of 350
percent in a century. This compares to the in-
crease in Europe in the nineteenth century of 85
percent. But not only did the improvements in
well-being occur more rapidly during similar
periods of economic development, but with re-
spect to several very important variables the
gaps narrowed significantly during the twenti-
eth century and especially during the last half of
that century.


### ---Economics-2000-0-12.txt---
A striking difference between the developing
countries at the end of the twentieth century and
the developed countries at the end of the nine-
teenth century is that the lowest-income coun-
tries have achieved rates of infant mortality and
life expectancy that are significantly superior to
those attained at the end of the nineteenth cen-
tury in the developed countries.
The infant mortality rate for 30 low-income
developing countries, including China, in
1960 was 157 per thousand births and it de-
clined by 62 percent to 62 in 1996 (IJNDP,
1998). The infant mortality rate in 1900 in
nine European countries ranged from a low of
121 in Denmark to a high of 216 in Austria
(Bairoch, 1988 p. 231). The rate in the United
States was 160. The teeming cities of the
developing world are often viewed negatively
by observers from the developed world. A
recent publication has the title "The Poverty
of Cities in the Developing World" (Martin
Brockerhoff and Ellen Brennan, 1997). Yet
the study revealed that cities with a popula-
tion of a million or more included in their
sample had an infant mortality rate of 60 per
thousand births in the 1990's (Brockerhoff
and Brennan, 1997 p. 24). Two comparisons
are relevant. Estimates of infant mortality for
the first decade of the twentieth century were
500 to 600 for Bombay and 350 to 400 in
Singapore (Bairoch, 1988 p. 450). The infant
mortality rate in New York City at the begin-
ning of the twentieth century was 264 (We-
ber, 1899 p. 346).
While infant mortality rates in cities in the
developed world at the beginning of the twen-
tieth century were higher than in rural areas, in
the developing world the rates in the cities are
now below those in rural areas (Brockerhoff and
Brennan, 1997 p. 24). These data indicate both
the large magnitude of the declines and the
extent to which the improvements have been
widely shared, even among many of the lowest-
income families in the world.
Significant increases in life expectancy were
achieved between 1900 and mid-century in the
developing countries, though much greater ab-
solute increases came later. The best available
long-term data are for India, at least one benefit
of being a British colony. Life expectancy in
India in 1900 was 23 years, increasing to 32
years in the 1940's (Bogue, 1969 p. 572) and to
43 years in 1960 and 62 years in 1996.10 Life
expectancy increased by 170 percent in a cen-
tury--it is now almost three times what it was a
hundred years ago. Life expectancy in the
world's poorest countries has increased since
1940 at a far more rapid rate than achieved in
any country in the developed world in the nine-
teenth century. This is an area where there has
been convergence between the rich and the poor
countries over the past several decades. At the
end of the nineteenth century life expectancy in
seven industrial countries ranged from 46 to 51
(Bogue, 1969). In 33 low-income countries in
1996 life expectancy was 64 years, compared to
44 years in 1960, an absolute increase of 20
years (World Bank, 1998). Furthermore, the
improvements in infant mortality and life ex-
pectancy have been achieved at lower levels of
real per capita incomes than those prevailing in
the developed countries at the beginning of the
twentieth century (Maddison, 1995). The
knowledge about the benefits of clean water and
sanitation has been widely distributed and in-
vestments have been made to make those ben-
efits widely available."
Since the late 1940's there has been greater
improvement in the world's availability of food
than had occurred in all previous history. The
evidence is the increase in per capita food sup-
plies that occurred in the developing countries,
with nearly 80 percent of the world's popula-
tion. There are reasonably reliable estimates of
daily per capita supply of calories for 1961-


### ---Economics-2000-0-13.txt---
1963 when the daily per capita supply was
1,940 k/cals. In 1994-1996 the supply was
2,580 (Nikos Alexandratos, 1999 p. 5908)-a
remarkable increase of 33 percent, given that
population doubled during the period. Based on
the increase in per capita grain production from
1948-1952 to 1961-1963, it can be estimated
that the per capita calorie supply was about
1,700 in 1948-1952. The increase in calories
per capita available in the developing countries
from 1948-1952 to 1994-1996 was of the or-
der of 50 percent.12 Since developing countries
produce at least 90 percent of the food they
consume, this means that food production al-
most trebled in four decades! This could not
have happened prior to the last half of the twen-
tieth century; the knowledge that made it pos-
sible did not then exist.
Alexandratos (1999 p. 5908) provides a pic-
ture of the improvement in food supplies that
adds another dimension to the increase in the
per capita availability in the developing coun-
tries: " ... the part of the world population living
in countries where per capita food supplies are
still very low (under 2,200 k/cal/day) decreased
considerably to only 10% in the mid-1990s,
down from 56% 30 years earlier." Note that the
2,200 calories per day that is now defined as
very low is somewhat higher than was available
in England and significantly higher than in
France in 1800, just two centuries ago. True, the
average citizen of England and France as of
1800 was stunted and/or wasted-as short in
height and low in weight-just as the average
person in the developing countries with signif-
icantly less than 2,200 calories per day would
be similarly designated today. What is impor-
tant is that this level of consumption applies to
countries with only a tenth of the world's pop-
ulation while 200 years ago it applied to nearly
all of the world's population.
It is estimated that in 1990 approximately
780 million persons (19 percent of the develop-
ing-country population, down from 36 percent
in 1969-1971) were malnourished (Alexandra-
tos, 1995 p. 33). There is an adequate quantity
of food now produced to provide these people
with sufficient calories. However, as Adam
Smith taught us, policies are an important factor
determining how well a nation utilizes its re-
sources. The majority of the malnourished peo-
ple live in rural areas and most of them live in
countries that have had policies that discrimi-
nated against agriculture and rural people for all
or part of the last three decades. The most
effective means to eliminate such malnutrition
is to increase the incomes of farm people in
these countries, something that would occur
with more appropriate policies (Johnson, 1999
p. 52).
In my opening sentence I stated that not only
are people better fed than ever before, but they
acquire their food at the lowest cost in all his-
tory. There is no way to prove that the real cost
per calorie is the lowest in all history, but we do
know that nearly all people are now devoting a
smaller percentage of their consumption expen-
ditures to the acquisition of food than was true
at times past. As recently as 1955 families in the
United States allocated 23 percent of their con-
sumption expenditure to food; today it is about
10 percent. For Japan the reduction was from 54
to 20 percent and for South Korea from 50 to 36
percent. Between 1960 and 1990 the food share
in Thailand declined from 47 to 23 percent
(United Nations, National Account Statistics). It
is not unreasonable to assume that at the begin-
ning of the nineteenth century in the developed
countries that 70 percent or more of the con-
sumption expenditures went for food and that
the percentage was even higher at the beginning
of the twentieth century for the developing
countries. 13


### ---Economics-2000-0-14.txt---
X. Concluding Comments
During the last two centuries, and especially
in the twentieth century, there has been an enor-
mous increase in knowledge that has been trans-
formed into technology and ways of utilizing
resources more efficiently. It is not only that
knowledge has increased rapidly but the means
of communicating that knowledge in an effec-
tive way have been markedly improved and the
knowledge has become much more accessible
throughout the world.
The rapid growth of knowledge has re-
sulted both from the growth of the world's
population and the increase in the percentage
of that population that is now able to devote
time and energy to the creation of knowledge.
It was not so long ago that farmers accounted
for 80 percent of the world's labor force and
they barely produced enough for themselves
with little left for exchange. As productivity
in agriculture increased, the rapid growth of
cities occurred and the growth in real per
capita incomes exceeded what had ever been
achieved before. The fact that during the
1980's the increase in the world's output was
ten times what world output was in 1820
illustrates how great has been the growth of
output in a very brief period of time.
But perhaps the greatest achievement of the
twentieth century is that the majority of the
poor people of the world have shared in the
improvements in well-being made possible by
the advancement of knowledge. Three mea-
sures show how great these improvements
have been-infant mortality rates, life expect-
ancy, and per capita food supplies. The large
cities of the developing world now have in-
fant mortality rates about a quarter of those of
New York City in 1890. True, there is much
more that can be done to share more fully the
benefits of the knowledge base. And I am
confident that whoever speaks from this plat-
form just 25 years from now could point to
further dramatic reductions in worldwide in-
equalities in well-being.

## Economics-2001-0


### ---Economics-2001-0-03.txt---
The resurgence of the American economy
since 1995 has outrun all but the most optimistic
expectations. Economic forecasting models
have been seriously off track and growth pro-
jections have been revised to reflect a more
sanguine outlook only recently.! It is not sur-
prising that the unusual combination of more
rapid growth and slower inflation in the 1990's
has touched off a strenuous debate among econ-
omists about whether improvements in Ameri-
ca's economic performance can be sustained.
The starting point for the economic debate is
the thesis that the 1990's are a mirror image of
the 1970's, when an unfavorable series of "sup-
ply shocks" led to stagflation-slower growth
and higher inflation.2 In this view, the develop-
ment of information technology (IT) is one of a
series of positive, but temporary, shocks. The
competing perspective is that IT has produced a
fundamental change in the U.S. economy, lead-
ing to a permanent improvement in growth
prospects.
The relentless decline in the prices of informa-
tion technology equipment has steadily enhanced
the role of IT investment as a source of American
economic growth. Productivity growth in IT-
producing industries has gradually risen in impor-
tance and a productivity revival is now under way
in the rest of the economy. Despite differences in
methodology and data sources, a consensus is
building that the remarkable behavior of IT prices
provides the key to the surge in economic growth.
In the following section I show that the foun-
dation for the American growth resurgence is
the development and deployment of semicon-
ductors. The decline in IT prices is rooted in
developments in semiconductor technology that
are widely understood by technologists and
economists. This technology has found its
broadest applications in computing and commu-
nications equipment, but has reduced the cost of
a wide variety of other products.
A substantial acceleration in the IT price de-
cline occurred in 1995, triggered by a much
sharper acceleration in the price decline of
semiconductors in 1994. Although the decline
in semiconductor prices has been projected to
continue for at least another decade, the recent
acceleration could be temporary. This can be
traced to a shift in the product cycle for semi-
conductors from three years to two years that
took place in 1995 as the consequence of inten-
sifying competition in markets for semiconduc-
tor products.
In Section II I outline a framework for ana-
lyzing the role of information technology in the
American growth resurgence. Constant quality
price indexes separate the change in the perfor-
mance of IT equipment from the change in price
for a given level of performance. Accurate and
timely computer prices have been part of the
U.S. National Income and Product Accounts
(NIPA) since 1985. Unfortunately, important
information gaps remain, especially on trends in
prices for closely related investments, such as
software and communications equipment.
The cost of capital is an essential concept for
capturing the economic impact of information
technology prices. Swiftly falling prices provide
powerful economic incentives for the substitution
of IT equipment for other forms of capital and for
labor services. The rate of the IT price decline is a


### ---Economics-2001-0-04.txt---
key component of the cost of capital, required for
assessing the impacts of rapidly growing stocks
of computers, communications equipment, and
software.
In Section III I analyze the impact of the 1995
acceleration in the information technology price
decline on U.S. economic growth. I introduce a
production possibility frontier that encompasses
substitutions between outputs of consumption
and investment goods, as well as inputs of cap-
ital and labor services. This frontier treats IT
equipment as part of investment goods output
and the capital services from this equipment as
a component of capital input.
Capital input has been the most important
source of U.S. economic growth throughout the
postwar period. More rapid substitution toward
information technology has given much addi-
tional weight to components of capital input
with higher marginal products. The vaulting
contribution of capital input since 1995 has
boosted growth by nearly a full percentage
point. The contribution of IT accounts for more
than half of this increase. Computers have been
the predominant impetus to faster growth, but
communications equipment and software have
made important contributions as well.
The accelerated information technology price
decline signals faster productivity growth in
IT-producing industries. In fact, these industries
have been the source of most of aggregate pro-
ductivity growth throughout the 1990's. Before
1995 this was due to the decline of productiv-
ity growth elsewhere in the economy. The IT-
producing industries have accounted for about
half the surge in productivity growth since 1995,
but faster growth is not limited to these industries.
I conclude that the decline in IT prices will
continue for some time. This will provide in-
centives for the ongoing substitution of IT for
other productive inputs. Falling IT prices also
serve as an indicator of rapid productivity
growth in IT-producing industries. However, it
would be premature to extrapolate the recent
acceleration in productivity growth in these in-
dustries into the indefinite future, since this de-
pends on the persistence of a two-year product
cycle for semiconductors.
In Section IV I outline research opportunities
created by the development and diffusion of
information technology. A voluminous and rap-
idly expanding business literature is testimony
to the massive impact of IT on firms and prod-
uct markets. Highest priority must be given to a
better understanding of the markets for semi-
conductors. Although several models of the
market for semiconductors already exist, none
explains the shift from a three-year to a two-
year product cycle.
The dramatic effects of information technol-
ogy on capital and labor markets have already
generated a substantial and growing economic
literature, but many important issues remain to
be resolved. For capital markets the relationship
between equity valuations and growth prospects
merits much further study. For labor markets
more research is needed on investment in infor-
mation technology and substitution among dif-
ferent types of labor.
I. The Information Age
The development and deployment of infor-
mation technology is the foundation of the
American growth resurgence. A mantra of the
"new economy"-faster, better, cheaper-cap-
tures the speed of technological change and
product improvement in semiconductors and
the precipitous and continuing fall in semicon-
ductor prices. The price decline has been trans-
mitted to the prices of products that rely heavily
on semiconductor technology, like computers
and telecommunications equipment. This tech-
nology has also helped to reduce the cost of
aircraft, automobiles, scientific instruments, and
a host of other products.
Modem information technology begins with
the invention of the transistor, a semiconductor
device that acts as an electrical switch and en-
codes information in binary form. A binary digit
or bit takes the values zero and one, correspond-
ing to the off and on positions of a switch. The
first transistor, made of the semiconductor ger-
manium, was constructed at Bell Labs in 1947
and won the Nobel Prize in Physics in 1956 for
the inventors-John Bardeen, Walter Brattain,
and William Shockley.4
The next major milestone in information tech-
nology was the coinvention of the integrated cir-
cuit by Jack Kilby of Texas Instruments in 1958



### ---Economics-2001-0-05.txt---
and Robert Noyce of Fairchild Semiconductor in
1959. An integrated circuit consists of many, even
millions, of transistors that store and manipulate
data in binary form. Integrated circuits were orig-
inally developed for data storage and retrieval and
semiconductor storage devices became known as
memory chips.5
The first patent for the integrated circuit was
granted to Noyce. This resulted in a decade of
litigation over the intellectual property rights.
The litigation and its outcome demonstrate the
critical importance of intellectual property in
the development of information technology.
Kilby was awarded the Nobel Prize in Physics
in 2000 for discovery of the integrated circuit;
regrettably, Noyce died in 1990.6
A. Moore's Law
In 1965 Gordon E. Moore, then Research
Director at Fairchild Semiconductor, made a
prescient observation, later known as Moore's
Law.7 Plotting data on memory chips, he ob-
served that each new chip contained roughly
twice as many transistors as the previous chip
and was released within 18-24 months of its
predecessor. This implied exponential growth
of chip capacity at 35-45 percent per year!
Moore's prediction, made in the infancy of the
semiconductor industry, has tracked chip capac-
ity for 35 years. He recently extrapolated this
trend for at least another decade.8
In 1968 Moore and Noyce founded Intel Cor-
poration to speed the commercialization of
memory chips.9 Integrated circuits gave rise to
microprocessors with functions that can be pro-
grammed by software, known as logic chips.
Intel's first general purpose microprocessor was
developed for a calculator produced by Busi-
com, a Japanese firm. Intel retained the intellec-
tual property rights and released the device
commercially in 1971.
The rapidly rising trends in the capacity of
microprocessors and storage devices illustrate the
exponential growth predicted by Moore's Law.
The first logic chip in 1971 had 2,300 transistors,
while the Pentium 4 released on November 20,
2000, had 42 million! Over this 29-year period the
number of transistors increased by 34 percent per
year. The rate of productivity growth for the U.S.
economy during this period was slower by two
orders of magnitude.
B. Semiconductor Prices
Moore's Law captures the fact that successive
generations of semiconductors are faster and bet-
ter. The economics of semiconductors begins with
the closely related observation that semiconduc-
tors have become cheaper at a truly staggering
rate! Figure 1 gives semiconductor price indexes
constructed by Bruce T. Grimm (1998) of the U.S.
Bureau of Economic Analysis (BEA) and em-
ployed in the U.S. National Income and Product
Accounts since 1996. These are divided between
memory chips and logic chips. The underlying
detail includes seven types of memory chips and
two types of logic chips.
Between 1974 and 1996 prices of memory
chips decreased by a factor of 27,270 times or at
40.9 percent per year, while the implicit deflator
for the gross domestic product (GDP) increased
by almost 2.7 times or 4.6 percent per year! Prices
of logic chips, available for the shorter period
1985 to 1996, decreased by a factor of 1,938 or
54.1 percent per year, while the GDP deflator
increased by 1.3 times or 2.6 percent per year!
Semiconductor price declines closely parallel
Moore's Law on the growth of chip capacity,
setting semiconductors apart from other products.
Figure 1 also reveals a sharp acceleration in
the decline of semiconductor prices in 1994 and
1995. The microprocessor price decline leapt to
more than 90 percent per year as the semicon-
ductor industry shifted from a three-year prod-
uct cycle to a greatly accelerated two-year
cycle. This is reflected in the 2000 Update of
the International Technology Road Map for
Semiconductors,'0 prepared by a consortium of
industry associations.

### ---Economics-2001-0-06.txt---

C. Constant Quality Price Indexes
The behavior of semiconductor prices is a
severe test for the methods used in the official
price statistics. The challenge is to separate ob-
served price changes between changes in semi-
conductor performance and changes in price
that hold performance constant. Achieving this
objective has required a detailed understanding
of the technology, the development of sophisti-
cated measurement techniques, and the intro-
duction of novel methods for assembling the
requisite information.
Ellen R. Dulberger (1993) of IBM introduced
a "matched model" index for semiconductor
prices. A matched model index combines price
relatives for products with the same perfor-
mance at different points of time. Dulberger
presented constant quality price indexes based
on index number formulas, including the
[Irving] Fisher (1922) ideal index used in the
U.S. national accounts. 1 1 The Fisher index is the
geometric average of the familiar Laspeyres and
Paasche indexes.
W. Erwin Diewert (1976) defined a superla-
tive index number as an index that exactly
replicates aflexible representation of the under-
lying technology (or preferences). A flexible
representation provides a second-order approx-
imation to an arbitrary technology (or prefer-
ences). A. A. Konus and S. S. Byushgens
(1926) first showed that the Fisher ideal index is
superlative in this sense. Laspeyres and Paasche
indexes are not superlative and fail to capture
substitutions among products in response to
price changes accurately.
Grimm (1998) combined matched model
techniques with hedonic methods, based on an
econometric model of semiconductor prices at
different points of time. A hedonic model gives
the price of a semiconductor product as a func-
tion of the characteristics that determine perfor-
mance, such as speed of processing and storage
capacity. A constant quality price index isolates
the price change by holding these characteristics
of semiconductors fixed.
Beginning in 1997, the U.S. Bureau of Labor


### ---Economics-2001-0-07.txt---
Statistics (BLS) incorporated a matched model
price index for semiconductors into the Pro-
ducer Price Index (PPI) and since then the na-
tional accounts have relied on data from the
PPI. Reflecting long-standing BLS policy, his-
torical data were not revised backward. Semi-
conductor prices reported in the PPI prior to
1997 do not hold quality constant, failing to
capture the rapid semiconductor price decline
and the acceleration in 1994.
D. Computers
The introduction of the Personal Computer
(PC) by IBM in 1981 was a watershed event
in the deployment of information technology.
The sale of Intel's 8086-8088 microprocessor
to IBM in 1978 for incorporation into the PC
was a major business breakthrough for In-
tel. 12 In 1981 IBM licensed the MS-DOS
operating system from the Microsoft Corpo-
ration, founded by Bill Gates and Paul Allen
in 1975. The PC established an Intel/
Microsoft relationship that has continued up
to the present. In 1985 Microsoft released the
first version of Windows, its signature oper-
ating system for the PC, giving rise to the
Wintel (Windows-Intel) nomenclature for this
ongoing collaboration.
Mainframe computers, as well as PC's, have
come to rely heavily on logic chips for central
processing and memory chips for main mem-
ory. However, semiconductors account for less
than half of computer costs and computer prices
have fallen much less rapidly than semiconduc-
tor prices. Precise measures of computer prices
that hold product quality constant were intro-
duced into the NIPA in 1985 and the PPI during
the 1990's. The national accounts now rely on
PPI data, but historical data on computers from
the PPI, like the PPI data on semiconductors, do
not hold quality constant.
Gregory C. Chow (1967) pioneered the use of
hedonic techniques for constructing a constant
quality index of computer prices in research
conducted at IBM. Chow documented price de-
clines at more than 20 percent per year during
1960-1965, providing an initial glimpse of the
n'k ~~~~~~~~~13
remarkable behavior of computer prices. In
1985 the Bureau of Economic Analysis incor-
porated constant quality price indexes for com-
puters and peripheral equipment constructed by
Rosanne Cole et al. (1986) of IBM into the
NIPA. Triplett (1986) discussed the economic
interpretation of these indexes, bringing the
rapid decline of computer prices to the attention
of a very broad audience.
The BEA-IBM constant quality price index
for computers provoked a heated exchange be-
tween BEA and Edward F. Denison (1989), one
of the founders of national accounting method-
ology in the 1950's and head of the national
accounts at BEA from 1979 to 1982. Denison
sharply attacked the BEA-IBM methodology
and argued vigorously against the introduction
of constant quality price indexes into the na-
tional accounts.14 Allan Young (1989), then Di-
rector of BEA, reiterated BEA's rationale for
introducing constant quality price indexes.
Dulberger (1989) presented a more detailed
report on her research on the prices of computer
processors for the BEA-IBM project. Speed of
processing and main memory played central
roles in her model. Triplett (1989) provided an
exhaustive survey of research on hedonic price
indexes for computers. Robert J. Gordon (1989,
1990) gave an alternative model of computer
prices and identified computers and communi-
cations equipment, along with commercial air-
craft, as assets with the highest rates of price
decline.
Figure 2 gives BEA's constant quality index
of prices of computers and peripheral equip-
ment and its components, including main-
frames, PC's, storage devices, other peripheral
equipment, and terminals. The decline in com-
puter prices follows the behavior of semicon-
ductor prices presented in Figure 1, but in much
attenuated form. The 1995 acceleration in the
computer price decline parallels the accelera-
tion in the semiconductor price decline that
resulted from the changeover from a three-year
product cycle to a two-year cycle in 1995.


### ---Economics-2001-0-08.txt---

E. Communications Equipment and Software
Communications technology is crucial for the
rapid development and diffusion of the Internet,
perhaps the most striking manifestation of in-
formation technology in the American econ-
omy.15 Kenneth Flamm (1989) was the first to
compare the behavior of computer prices and
the prices of communications equipment. He
concluded that the communications equipment
prices fell only a little more slowly than com-
puter prices. Gordon (1990) compared Flamm's
results with the official price indexes, revealing
substantial bias in the official indexes.
Communications equipment is an important
market for semiconductors, but constant quality
price indexes cover only a portion of this equip-
ment. Switching and terminal equipment rely
heavily on semiconductor technology, so that
product development reflects improvements in
semiconductors. Grimm's (1997) constant qual-
ity price index for digital telephone switching
equipment, given in Figure 3, was incorporated
into the national accounts in 1996. The output
of communications services in the NIPA also
incorporates a constant quality price index for
cellular phones.
Much communications investment takes the
form of the transmission gear, connecting data,
voice, and video terminals to switching equip-
ment. Technologies such as fiber optics, micro-
wave broadcasting, and communications satellites
have progressed at rates that outrun even the dra-
matic pace of semiconductor development. An
example is dense wavelength division multiplex-
ing (DWDM), a technology that sends multiple
signals over an optical fiber simultaneously. In-
stallation of DWDM equipment, beginning in
1997, has doubled the transmission capacity of
fiber-optic cables every 6-12 months.'6


### ---Economics-2001-0-09.txt---

Both software and hardware are essential for
information technology and this is reflected in
the large volume of software expenditures. The
eleventh comprehensive revision of the national
accounts, released by BEA on October 27,
1999, reclassified computer software as invest-
ment.17 Before this important advance, business
expenditures on software were treated as current
outlays, while personal and government expen-
ditures were treated as purchases of nondurable
goods. Software investment is growing rapidly
and is now much more important than invest-
ment in computer hardware.
Robert P. Parker and Grimm (2000) describe
the new estimates of investment in software. BEA
distinguishes among three types of software-
prepackaged, custom, and own-account software.
Prepackaged software is sold or licensed in stan-
dardized form and is delivered in packages or
electronic files downloaded from the Internet.
Custom software is tailored to the specific appli-
cation of the user and is delivered along with
analysis, design, and programming services re-
quired for customization. Own-account software
consists of software created for a specific applica-
tion. However, only price indexes for prepackaged
software hold performance constant.
Parker and Grimm (2000) present a constant
quality price index for prepackaged software,
given in Figure 3. This combines a hedonic
model of prices for business applications soft-
ware and a matched model index for spread-
sheet and word-processing programs developed
by Steven D. Oliner and Daniel E. Sichel
(1994). Prepackaged software prices decline at
more than 10 percent per year over the period
1962-1998. Since 1998 the BEA has relied on a
matched model price index for all prepackaged
software from the PPI; prior to 1998 the PPI
data do not hold quality constant.
BEA's prices for own-account software are
based on programmer wage rates. This implic-
itly assumes no change in the productivity of
computer programmers, even with growing in-
vestment in hardware and software to support
the creation of new software. Custom software

### ---Economics-2001-0-10.txt---
prices are a weighted average of prepackaged
and own-account software prices with arbitrary
weights of 75 percent for own-account and 25
percent for prepackaged software. These price
indexes do not hold the software performance
constant and present a distorted picture of soft-
ware prices, as well as software output and
investment.
F. Research Opportunities
The official price indexes for computers and
semiconductors provide the paradigm for eco-
nomic measurement. These indexes capture the
steady decline in IT prices and the recent accel-
eration in this decline. The official price indexes
for central office switching equipment and pre-
packaged software also hold quality constant.
BEA and BLS, the leading statistical agencies
in price research, have carried out much of the
best work in this area. However, a critical role
has been played by price research at IBM, long
the dominant firm in information technology.'8
It is important to emphasize that information
technology is not limited to applications of
semiconductors. Switching and terminal equip-
ment for voice, data, and video communications
has come to rely on semiconductor technology
and the empirical evidence on prices of this
equipment reflects this fact. Transmission gear
employs technologies with rates of progress that
far outstrip those of semiconductors. This im-
portant gap in our official price statistics can
only be filled by constant quality price indexes
for all types of communications equipment.
Investment in software is more important
than investment in hardware. This was essen-
tially invisible until BEA introduced new mea-
sures of prepackaged, custom, and own-account
software investment into the national accounts
in 1999. This is a crucial step in understanding
the role of information technology in the Amer-
ican economy. Unfortunately, software prices
are another statistical blind spot, with only
prices of prepackaged software adequately rep-
resented in the official system of price statistics.
The daunting challenge that lies ahead is to
construct constant quality price indexes for cus-
tom and own-account software.
II. The Role of Information Technology
At the aggregate level IT is identified with the
outputs of computers, communications equip-
ment, and software. These products appear in
the GDP as investments by businesses, house-
holds, and governments along with net exports
to the rest of the world. The GDP also includes
the services of IT products consumed by house-
holds and governments. A methodology for an-
alyzing economic growth must capture the
substitution of IT outputs for other outputs of
goods and services.
While semiconductor technology is the driv-
ing force behind the spread of IT, the impact of
the relentless decline in semiconductor prices is
transmitted through falling IT prices. Only net
exports of semiconductors, defined as the dif-
ference between U.S. exports to the rest of the
world and U.S. imports, appear in the GDP.
Sales of semiconductors to domestic manufac-
turers of IT products are precisely offset by
purchases of semiconductors and are excluded
from the GDP.
Constant quality price indexes, like those re-
viewed in the previous section, are a key com-
ponent of the methodology for analyzing the
American growth resurgence. Computer prices
were incorporated into the NIPA in 1985 and
are now part of the PPI as well. Much more
recently, semiconductor prices have been in-
cluded in the NIPA and the PPI. Unfortunately,
evidence on the prices of communications
equipment and software is seriously incomplete,
so that the official price indexes are seriously
misleading.
A. Output
The output data in Table 1 are based on the
most recent benchmark revision of the national
accounts, updated through 1999.19 The output
concept is similar, but not identical, to the con-
cept of gross domestic product used by the
BEA. Both measures include final outputs pur-
chased by businesses, governments, house-
holds, and the rest of the world. Unlike the BEA
concept, the output measure in Table 1 also

### ---Economics-2001-0-11.txt---


### ---Economics-2001-0-12.txt---

includes imputations for the service flows from
durable goods, including IT products, employed
in the household and government sectors.
The imputations for services of IT equipment
are based on the cost of capital for IT described
in more detail below. The cost of capital is
multiplied by the nominal value of IT capital
stock to obtain the imputed service flow from IT
products. In the business sector this accrues as
capital income to the firms that employ these
products as inputs. In the household and gov-
ernment sectors the flow of capital income must
be imputed. This same type of imputation is
used for housing in the NIPA. The rental value
of renter-occupied housing accrues to real es-
tate firms as capital income, while the rental
value of owner-occupied housing is imputed to
households.
Current dollar GDP in Table 1 is $9.8 tril-
lions in 1999, including imputations, and real
output growth averaged 3.46 percent for the
period 1948-1999. These magnitudes can be
compared to the current dollar value of $9.3
trillions in 1999 and the average real growth
rate of 3.40 percent for the period 1948-1999
for the official GDP. Table 1 presents the cur-
rent dollar value and price indexes of the GDP
and IT output. This includes outputs of invest-
ment goods in the form of computers, software,
communications equipment, and non-IT invest-
ment goods. It also includes outputs of non-IT
consumption goods and services as well as im-
puted IT capital service flows from households
and governments.
The most striking feature of the data in Table
1 is the rapid price decline for computer invest-
ment, 17.1 percent per year from 1959 to 1995.
Since 1995 this decline has almost doubled to
32.1 percent per year. By contrast the relative
price of software has been flat for much of
the period and began to fall only in the late
1980's. The price of communications equip-
ment behaves similarly to the software price,
while the consumption of capital services from
computers and software by households and gov-
ernments shows price declines similar to com-
puter investment.
The top panel of Table 2 summarizes the
growth rates of prices and quantities for major
output categories for 1990-1995 and 1995-
1999. Business investments in computers,
software, and communications equipment are
the largest categories of IT spending. House-
holds and governments have also spent siz-
able amounts on computers, software,
communications equipment and the services
of information technology. Figure 4 shows
that the output of software is the largest IT


### ---Economics-2001-0-13.txt---

category as a share of GDP, followed by the
outputs of computers and communications
equipment.
B. Capital Services
This subsection presents capital estimates for
the U.S. economy for the period 1948 to 1999.20
These begin with BEA investment data; the
perpetual inventory method generates estimates
of capital stocks and these are aggregated, using
service prices as weights. This approach, origi-
nated by Jorgenson and Zvi Griliches (1996), is
based on the identification of service prices with
marginal products of different types of capital.
The service price estimates incorporate the cost
of capital.21
The cost of capital is an annualization factor
that transforms the price of an asset into the
price of the corresponding capital input.22 This
includes the nominal rate of return, the rate of
depreciation, and the rate of capital loss due to
declining prices. The cost of capital is an essen-
tial concept for the economics of information
technology,23 due to the astonishing decline of
IT prices given in Table 1.
The cost of capital is important in many areas
of economics, especially in modeling producer
behavior, productivity measurement, and the
economics of taxation.24 Many of the important
issues in measuring the cost of capital have been
debated for decades. The first of these is incor-
poration of the rate of decline of asset prices
into the cost of capital. The assumption of per-
fect foresight or rational expectations quickly
emerged as the most appropriate formulation

### ---Economics-2001-0-14.txt---
and has been used in almost all applications of
the cost of capital.25
The second empirical issue is the measure-
ment of economic depreciation. The stability of
patterns of depreciation in the face of changes in
tax policy and price shocks has been carefully
documented. The depreciation rates presented
by Jorgenson and Stiroh (2000b) summarize a
large body of empirical research on the behavior
of asset prices.2 A third empirical issue is the
description of the tax structure for capital in-
come. This depends on the tax laws prevailing
at each point of time. The resolution of these
issues has cleared the way for detailed measure-
ments of the cost of capital for all assets that
appear in the national accounts, including infor-
mation technology.27
The definition of capital includes all tangible
assets in the U.S. economy, equipment and
structures, as well as consumers' and govern-
ment durables, land, and inventories. The capi-
tal service flows from durable goods employed
by households and governments enter measures
of both output and input. A steadily rising pro-
portion of these service flows are associated
with investments in IT. Investments in IT by
business, household, and government sectors
must be included in the GDP, along with house-
hold and government IT capital services, in
order to capture the full impact of IT on the U.S.
economy.
Table 3 gives capital stocks from 1948 to
1999, as well as price indexes for total domestic
tangible assets and IT assets-computers, soft-
ware, and communications equipment. The es-
timate of domestic tangible capital stock in
Table 3 is $35.4 trillions in 1999, considerably
greater than the $27.9 trillions in fixed capital
estimated by Shelby W. Herman (2000) of
BEA. The most important differences reflect the
inclusion of inventories and land in Table 3.
Business IT investments, as well as purchases
of computers, software, and communications
equipment by households and governments,
have grown spectacularly in recent years, but
remain relatively small. The stocks of all IT
assets combined account for only 4.35 percent
of domestic tangible capital stock in 1999. Ta-
ble 4 presents estimates of the flow of capital
services and corresponding price indexes for
1948-1999.
The difference between growth in capital ser-
vices and capital stock is the improvement in
capital quality. This represents the substitution
towards assets with higher marginal products.
The shift toward IT increases the quality of
capital, since computers, software, and commu-
nications equipment have relatively high mar-
ginal products. Capital stock estimates fail to
account for this increase in quality and substan-
tially underestimate the impact of IT investment
on growth.
The growth of capital quality is slightly less
than 20 percent of capital input growth for the
period 1948-1995. However, improvements in
capital quality have increased steadily in rela-
tive importance. These improvements jumped
to 44.9 percent of total growth in capital input
during the period 1995-1999, reflecting very
rapid restructuring of capital to take advantage
of the sharp acceleration in the IT price decline.
Capital stock has become progressively less ac-
curate as a measure of capital input and is now
seriously deficient.
Figure 5 gives the IT capital service flows as
a share of gross domestic income. The second
panel of Table 2 summarizes the growth rates of
prices and quantities of capital inputs for 1990-
1995 and 1995-1999. Growth of IT capital ser-
vices jumps from 11.51 percent per year in
1990-1995 to 19.41 percent in 1995-1999,
while growth of non-IT capital services in-
creases from 1.72 percent to 2.94 percent. This
reverses the trend toward slower capital growth
through 1995.
C. Labor Services
This subsection presents estimates of labor
input for the U.S. economy from 1948 to 1999.
These incorporate individual data from the Cen-
suses of Population for 1970, 1980, and 1990,
as well as the annual Current Population Sur-
veys. Constant quality indexes for the price and


### ---Economics-2001-0-15.txt---


### ---Economics-2001-0-16.txt---

### ---Economics-2001-0-17.txt---

quantity of labor input account for the hetero-
geneity of the workforce across sex, employ-
ment class, age, and education levels. This
follows the approach of Jorgenson et al. (1987).
The estimates have been revised and updated by
Mun S. Ho and Jorgenson (2000).28
The distinction between labor input and labor
hours is analogous to the distinction between
capital services and capital stock. The growth in
labor quality is the difference between the
growth in labor input and hours worked. Labor
quality reflects the substitution of workers with
high marginal products for those with low mar-
ginal products. Table 5 presents estimates of
labor input, hours worked, and labor quality.
The value of labor expenditures in Table 5 is
$5.8 trillions in 1999, 59.3 percent of the value
of output. This share accurately reflects the con-
cept of gross domestic income, including impu-
tations for the value of capital services in
household and government sectors. As shown in
Table 2, the growth rate of labor input acceler-
ated to 2.18 percent for 1995-1999 from 1.70
percent for 1990-1995. This is primarily due to
the growth of hours worked, which rose from
1.17 percent for 1990-1995 to 1.98 percent for
1995-1999, as labor-force participation in-
creased and unemployment rates plummeted.
The growth of labor quality has declined con-
siderably in the late 1990's, dropping from 0.53
percent for 1990-1995 to 0.20 percent for
1995-1999. This slowdown captures well-
known demographic trends in the composition
of the workforce, as well as exhaustion of the
pool of available workers. Growth in hours
worked does not capture these changes in labor-
quality growth and is a seriously misleading
measure of labor input.
III. The American Growth Resurgence
The American economy has undergone a re-
markable resurgence since the mid-1990's with
accelerating growth in output, labor productiv-
ity, and total factor productivity. The purpose of
this section is to quantify the sources of growth
for 1948-1999 and various subperiods. An 

### ---Economics-2001-0-18.txt---


### ---Economics-2001-0-19.txt---
important objective is to account for the sharp
acceleration in the level of economic activity
since 1995 and, in particular, to document the
role of information technology.
The appropriate framework for analyzing
the impact of information technology is the
production possibility frontier, giving outputs
of IT investment goods as well as inputs of IT
capital services. An important advantage of
this framework is that prices of IT outputs and
inputs are linked through the price of IT cap-
ital services. This framework successfully
captures the substitutions among outputs and
inputs in response to the rapid deployment of
IT. It also encompasses costs of adjustment,
while allowing financial markets to be mod-
eled independently.
As a consequence of the swift advance of
information technology, a number of the most
familiar concepts in growth economics have
been superseded. The aggregate production
function heads this list. Capital stock as a mea-
sure of capital input is no longer adequate to
capture the rising importance of IT. This com-
pletely obscures the restructuring of capital in-
put that is such an important wellspring of the
growth resurgence. Finally, hours worked must
be replaced as a measure of labor input.
A. Production Possibility Frontier
The production possibility frontier describes
efficient combinations of outputs and inputs for
the economy as a whole.29 Aggregate output Y
consists of outputs of investment goods and
consumption goods. These outputs are pro-
duced from aggregate input X, consisting of
capital services and labor services. Productivity
is a "Hicks-neutral" augmentation of aggregate
input.
The production possibility frontier takes the
form:
(1) Y(In 9 IC , Is, It,9 Cn 9 Cc)
where the outputs include non-IT investment
goods I,, and investments in computers Ic, soft-
ware IS' and communications equipment It, as
well as non-IT consumption goods and services
Cn and IT capital services to households and
governments Cc. Inputs include non-IT capital
services Kn and the services of computers Kc,
software Ks, and telecommunications equip-
ment K, as well as labor input L.30 Totalfactor
productivity (TFP) is denoted by A.
The most important advantage of the produc-
tion possibility frontier is the explicit role that it
provides for constant quality prices of IT prod-
ucts. These are used as deflators for nominal
expenditures on IT investments to obtain the
quantities of IT outputs. Investments in IT are
cumulated into stocks of IT capital. The flow of
IT capital services is an aggregate of these
stocks with service prices as weights. Similarly,
constant quality prices of IT capital services are
used in deflating the nominal values of con-
sumption of these services.
Another important advantage of the production
possibility frontier is the incorporation of costs of
adjustment. For example, an increase in the output
of IT investment goods requires forgoing part of
the output of consumption goods and non-IT in-
vestment goods, so that adjusting the rate of in-
vestment in IT is costly. However, costs of
adjustment are external to the producing unit and
are fully reflected in If prices. These prices incor-
porate forward-looking expectations of the future
prices of If capital services.
B. Aggregate Production Function
The aggregate production function employed
by Robert M. Solow (1957, 1960) and, more re-
cently, by Jeremy Greenwood et al. (1997, 2000),
Arnold C. Harberger (1998), and Hercowitz
(1998) is a competing methodology. The produc-
tion function gives a single output as a function of
capital and labor inputs. There is no role for sep-
arate prices of investment and consumption goods
and, hence, no place for constant quality IF price
indexes for outputs of IF investment goods.
Greenwood et al. employ a price index for
consumption to deflate the output of all


### ---Economics-2001-0-20.txt---
investment goods, including information tech-
nology. Confronted by the fact that constant
quality prices of investment goods differ from
consumption goods prices, they borrow the con-
cept of embodiment from Solow (1960) in order
to convert investment goods output into an ap-
propriate form for measuring capital stock.31
Investment has two prices, one used in the mea-
suring output and the other used in measuring
capital stock. This inconsistency can be re-
moved by simply distinguishing between out-
puts of consumption and investment goods, as
in the national accounts and equation (1). The
concept of embodiment can then be dropped.
Perhaps inadvertently, Greenwood et al. have
revisited the controversy accompanying the in-
troduction of a constant quality price index for
computers into the national accounts. They have
revived Denison's (1993) proposal to use a con-
sumption price index to deflate investment in
the NIPA. Denison found this appealing as a
means of avoiding the introduction of constant
quality price indexes for computers. Denison's
approach leads to a serious underestimate of
GDP growth and an overestimate of inflation.
Another limitation of the aggregate produc-
tion function is that it fails to incorporate costs
of adjustment. Robert E. Lucas, Jr. (1967) pre-
sented a production model with internal costs of
adjustment. Fumio Hayashi (2000) shows how
to identify these adjustment costs from James
Tobin's (1969) Q-ratio, the ratio of the stock
market value of the producing unit to the market
value of the unit's assets. Implementation of
this approach requires simultaneous modeling
of production and asset valuation. If costs of
adjustment are external, as in the production
possibility frontier (1), asset valuation can be
modeled separately from production.32
C. Sources of Growth
Under the assumption that product and fac-
tor markets are competitive, producer equilib-
rium implies that the share-weighted growth
of outputs is the sum of the share-weighted
growth of inputs and growth in total factor
productivity:
(2) wi,,,,A In I,, + wi',cA In IC + WiP,sA In Is
+ wP,t/A In It + wc,A In C,,
+Wc,cAIn Cc
- VK,nA In K,, + VK,CA In KC
+ VK,sA In Ks + VK,tA In Kt
+ VLA In L + A In A
where wP and -v denote average value shares. The
shares of outputs and inputs add to one under
the additional assumption of constant returns,
WI,n + WI,c + WI's + WI,t + WC,1n + WC,c
VK,n + VK,c + VK,s + VK,t + VL 1.
Equation (2) makes it possible to identify the
contributions of outputs as well as inputs to U.S.
economic growth. The growth rate of output is
a weighted average of growth rates of invest-
ment and consumption goods outputs. The con-
tribution of each output is its weighted growth
rate. Similarly, the growth rate of input is a
weighted average of growth rates of capital and
labor services and the contribution of each input
is its weighted growth rate. The contribution of
TFP, the growth rate of the augmentation factor
A in equation (2), is the difference between
growth rates of output and input.
Table 6 presents results of a growth account-
ing decomposition, based on equation (2), for
the period 1948-1999 and various subperiods,
following Jorgenson and Stiroh (1999, 2000b).
Economic growth is broken down by output and
input categories, quantifying the contribution of
information technology to investment and con-
sumption outputs, as well as capital inputs.
These estimates identify computers, software,
and communications equipment as distinct
types of information technology.
Rearranging equation (2), the results can be
presented in terms of average labor productiv-
ity (ALP), defined as y = YIH, the ratio of
output Y to hours worked H, and k = KIH is
the ratio of capital services K to hours worked:
(3) A Iny== VKA Ink
+ VL(A InL - A In H) + A In A.



### ---Economics-2001-0-21.txt---

Equation (3) allocates ALP growth among three
sources. The first is capital deepening, the
growth in capital input per hour worked, and
reflects the capital-labor substitution. The sec-
ond is improvement in labor quality and cap-
tures the rising proportion of hours by workers
with higher marginal products. The third is TFP
growth, which contributes point-for-point to
ALP growth.
D. Contributions of IT Investment
Figure 5 depicts the rapid increase in the
importance of IT services, reflecting the accel-
erating pace of IT price declines. In 1995-1999
the capital service price for computers fell 24.81
percent per year, compared to an increase of
36.36 percent in capital input from computers.
As a consequence, the value of computer ser-
vices grew substantially. However, the current
dollar value of computers was only 1.6 percent
of gross domestic income in 1999.
The rapid accumulation of software appears
to have different sources. The price of software
services has declined only 2.04 percent per year
for 1995-1999. Nonetheless, firms have been
accumulating software very rapidly, with real
capital services growing 16.30 percent per year.
A possible explanation is that firms respond to
computer price declines by investing in comple-
mentary inputs like software. However, a more
plausible explanation is that the price indexes
used to deflate software investment fail to hold
quality constant. This leads to an overstatement
of inflation and an understatement of growth.
Although the price decline for communica-
tions equipment during the period 1995-1999 is
comparable to that of software, investment in
this equipment is more in line with prices. How-
ever, prices of communications equipment also
fail to hold quality constant. The technology of
switching equipment, for example, is similar to
that of computers; investment in this category is
deflated by a constant-quality price index devel-
oped by BEA. Conventional price deflators are
employed for transmission gear, such as fiber-
optic cables. This leads to an underestimate of
the growth rates of investment, capital stock,
capital services, and the GDP, as well as an
overestimate of the rate of inflation.
Figures 6 and 7 highlight the rising contribu-
tions IT outputs to U.S. economic growth. Fig-
ure 6 shows the breakdown between IT and
non-IT outputs for subperiods from 1948 to
1999, while Figure 7 decomposes the contribu-
tion of IT into its components. Although the


### ---Economics-2001-0-22.txt---

### ---Economics-2001-0-23.txt---


### ---Economics-2001-0-24.txt---
importance of IT has steadily increased, Figure
6 shows that the recent investment and con-
sumption surge nearly doubled the output con-
tribution of IT. Figure 7 shows that computer
investment is the largest single IT contributor in
the late 1990's, but that investments in software
and communications equipment are becoming
increasingly important.
Figures 8 and 9 present a similar decompo-
sition of IT inputs into production. The contri-
bution of these inputs is rising even more
dramatically. Figure 8 shows that the contribu-
tion of IT now accounts for more than 48.1
percent of the total contribution of capital input.
Figure 9 shows that computer hardware is the
largest IT contributor on the input side, reflect-
ing the growing share and accelerating growth
rate of computer investment in the late 1990's.
Private business investment predominates in
the output of IT, as shown by Jorgenson and
Stiroh (1999, 2000b).33 Household purchases of
IT equipment and services are next in impor-
tance. Government purchases of IT equipment
and services, as well as net exports of IT prod-
ucts, must be included in order to provide a
complete picture. Firms, consumers, govern-
ments, and purchasers of U.S. exports are re-
sponding to relative price changes, increasing
the contributions of computers, software, and
communications equipment.
Table 2 shows that the price of computer
investment fell by more than 32 percent per
year, the price of software 2.4 percent, the price
of communications equipment 2.9 percent, and
the price of IT services 11.8 percent during the
period 1995-1999, while non-IT prices rose 2.2
percent. In response to these price changes,
firms, households, and governments have accu-
mulated computers, software, and communica-
tions equipment much more rapidly than other
forms of capital.
E. Total Factor Productivity
The price or "dual" approach to productivity
measurement makes it possible to identify the
role of IT production as a source of productivity
growth at the industry level.34 The rate of pro-
ductivity growth is measured as the decline in
the price of output, plus a weighted average of
the growth rates of input prices with value
shares of the inputs as weights. For the com-
puter industry this expression is dominated by
two terms: the decline in the price of computers
and the contribution of the price of semiconduc-
tors. For the semiconductor industry the expres-
sion is dominated by the decline in the price of
semiconductors.35
Jorgenson et al. (1987) have employed
Domar's (1961) model to trace aggregate pro-
ductivity growth to its sources at the level of
individual industries.36 More recently, Har-
berger (1998), William Gullickson and Michael
J. Harper (1999), and Jorgenson and Stiroh
(2000a, 2000b) have used the model for similar
purposes. Productivity growth for each industry
is weighted by the ratio of the gross output of
the industry to GDP to estimate the industry
contribution to aggregate TFP growth.
If semiconductor output were only used to
produce computers, then its contribution to
computer-industry productivity growth, weighted
by computer-industry output, would precisely
cancel its independent contribution to aggregate
TFP growth. This is the ratio of the value of
semiconductor output to GDP, multiplied by the
rate of semiconductor price decline. In fact, semi-
conductors are used to produce telecommunica-
tions equipment and many other products.
However, the value of semiconductor output is
dominated by inputs into IT production.
The Domar aggregation folmula can be approx-
imated by expressing the declines in prices of
computers, communications equipment, and soft-
ware relative to the price of gross domestic in-
come, an aggregate of the prices of capital and
labor services. The rates of relative IT price de-
cline are weighted by ratios of the outputs of IT
products to the GDP. Table 7 reports details of this
TFP decomposition for 1948-1999; the IT and
non-IT contributions are presented in Figure


### ---Economics-2001-0-25.txt---

10. The IT products contribute 0.50 percentage
points to TFP growth for 1995-1999, compared to
0.25 percentage points for 1990-1995. This re-
flects the accelerating decline in relative price
changes resulting from shortening the product cy-
cle for semiconductors.
F. Output Growth
This subsection presents the sources of GDP
growth for the entire period 1948 to 1999. Cap-
ital services contribute 1.70 percentage points,
labor services 1.14 percentage points, and TFP
growth only 0.61 percentage points. Input
growth is the source of nearly 82.3 percent of
U.S. growth over the past half century, while
TFP has accounted for 17.7 percent. Figure
11 shows the relatively modest contributions of
TFP in all subperiods.
More than three-quarters of the contribution
of capital reflects the accumulation of capital
stock, while improvement in the quality of cap-
ital accounts for about one-quarter. Similarly,
increased labor hours account for 80 percent of
labor's contribution; the remainder is due to
improvements in labor quality. Substitutions
among capital and labor inputs in response to
price changes are essential components of the
sources of economic growth.
A look at the U.S. economy before and after
1973 reveals familiar features of the historical
record. After strong output and TFP growth in
the 1950's, 1960's, and early 1970's, the U.S.
economy slowed markedly through 1990, with
output growth falling from 3.99 percent to 2.86
percent and TFP growth declining from 0.92
percent to 0.25 percent. Growth in capital inputs
also slowed from 4.64 percent for 1948-1973 to
3.57 percent for 1973-1990. This contributed to
sluggish ALP growth-2.82 percent for 1948-
1973 and 1.26 percent for 1973-1990.
Relative to the early 1990's, output growth in-
creased by 1.72 percent in 1995-1999. The con-
tribution of IT production almost doubled, relative
to 1990-1995, but still accounted for only 28.9
percent of the increased growth of output. Al-
though the contribution of IT has increased
steadily throughout the period 1948-1999, there
has been a sharp response to the acceleration in the
IT price decline in 1995. Nonetheless, more than
70 percent of the increased output growth can be
attributed to non-IT products.
Between 1990-1995 and 1995-1999 the con-
tribution of capital input jumped by 0.95


### ---Economics-2001-0-26.txt---

percentage points, the contribution of labor input
rose by only 0.24 percent, and TFP accelerated by
0.51 percent. Growth in ALP rose 0.92 as more
rapid capital deepening and growth in TFP offset
slower improvement in labor quality. Growth in
hours worked accelerated as unemployment fell to
a 30-year low. Labor markets have tightened con-
siderably, even as labor-force participation rates
increased.37
The contribution of capital input reflects the
investment boom of the late 1990's as busi-
nesses, households, and governments poured
resources into plant and equipment, especially
computers, software, and communications
equipment. The contribution of capital, predom-
inantly IT, is considerably more important than
the contribution of labor. The contribution of IT
capital services has grown steadily throughout
the period 1948-1999, but Figure 9 reflects the
impact of the accelerating decline in IT prices.
After maintaining an average rate of 0.25 per-
cent for the period 1973-1990, TFP growth fell to
0.24 percent for 1990-1995 and then vaulted to
0.75 percent per year for 1995-1999. This is a
major source of growth in output and ALP for the
U.S. economy (Figures 11 and 12). While TFP
growth for 1995-1999 is lower than the rate of
1948-1973, the U.S. economy is recuperating
from the anemic productivity growth of the past
two decades. Although only half of the accelera-
tion in TFP from 1990-1995 to 1995-1999 can be
attributed to IT production, this is far greater than
the 4.26 percent share of IT in the GDP.
G. Average Labor Productivity
Output growth is the sum of growth in hours
and average labor productivity. Table 8 shows
the breakdown between growth in hours and
ALP for the same periods as in Table 6. For the
period 1948-1999, ALP growth predominated
in output growth, increasing just over 2 percent
per year for 1948-1999, while hours increased
about 1.4 percent per year. As shown in equa-
tion (3), ALP growth depends on capital deep-
ening, a labor-quality effect, and TFP growth.



### ---Economics-2001-0-27.txt---

Figure 12 reveals the well-known productivity
slowdown of the 1970's and 1980's, emphasizing
the acceleration in labor productivity growth in the
late 1990's. The slowdown through 1990 reflects
reduced capital deepening, declining labor-quality
growth, and decelerating growth in TFP. The
growth of ALP slipped further during the early
1990's with a slump in capital deepening only
partly offset by a revival in labor quality growth
and an up-tick in TFP growth. A slowdown in


### ---Economics-2001-0-28.txt---

hours combined with slowing ALP growth during
1990-1995 to produce a further slide in the
growth of output. In previous cyclical recoveries
during the postwar period, output growth acceler-
ated during the recovery, powered by more rapid
growth of hours and ALP.
Accelerating output growth during 1995-
1999 reflects growth in labor hours and ALP
almost equally.38 Comparing 1990-1995 to
1995-1999, the rate of output growth jumped
by 1.72 percent-due to an increase in hours
worked of 0.81 percent and another increase in
ALP growth of 0.92 percent. Figure 12 shows
the acceleration in ALP growth is due to capital
deepening as well as faster TFP growth. Capital
deepening contributed 0.60 percentage points,
offsetting a negative contribution of labor qual-
ity of 0.20 percent. The acceleration in TFP
added 0.51 percentage points.
H. Research Opportunities
The use of computers, software, and commu-
nications equipment must be carefully distin-
guished from the production of IT.39 Massive
increases in computing power, like those expe-
rienced by the U.S. economy, have two effects
on growth. First, as IT producers become more
efficient, more IT equipment and software is
produced from the same inputs. This raises pro-
ductivity in IT-producing industries and con-
tributes to TFP growth for the economy as a
whole. Labor productivity also grows at both
industry and aggregate levels.
Second, investment in information technol-
ogy leads to growth of productive capacity in
IT-using industries. Since labor is working with
more and better equipment, this increases ALP
through capital deepening. If the contributions
to aggregate output are captured by capital
deepening, aggregate TFP growth is unaf-
fected.40 Increasing deployment of IT affects
TFP growth only if there are spillovers from
IT-producing industries to IT-using industries.
Top priority must be given to identifying the
impact of investment in IT at the industry level.


### ---Economics-2001-0-29.txt---
trated in a small number of IT-using industries,
while Stiroh (2000) shows that aggregate ALP
growth can be attributed to productivity growth
in IT-producing and IT-using industries. The
next priority is to trace the increase in aggregate
TFP growth to its sources in individual indus-
tries. Jorgenson and Stiroh (2000a, 2000b)
present the appropriate methodology and pre-
liminary results.
IV. Economics on Internet Time
The steadily rising importance of information
technology has created new research opportuni-
ties in all areas of economics. Economic histo-
rians, led by Chandler (2000) and Paul A. David
(2000),41 have placed the information age in
historical context. The Solow (1987) Paradox,
that we see computers everywhere but in the
productivity statistics,42 has provided a point of
departure. Since computers have now left an
indelible imprint on the productivity statistics,
the remaining issue is: Does the breathtaking
speed of technological change in semiconduc-
tors differentiate this resurgence from previous
periods of rapid growth?
Capital and labor markets have been severely
impacted by information technology. Enormous
uncertainty surrounds the relationship between
equity valuations and future growth prospects
of the American economy.43 One theory at-
tributes rising valuations of equities since the
growth acceleration began in 1995 to the accu-
mulation of intangible assets, such as intellec-
tual property and organizational capital. An
alternative theory treats the high valuations of
technology stocks as a bubble that burst during
the year 2000.
The behavior of labor markets also poses
important puzzles. Widening wage differentials
between workers with more and less education
has been attributed to computerization of the
workplace. A possible explanation could be that
high-skilled workers are complementary to IT,
while low-skilled workers are substitutable. An
alternative explanation is that technical change
associated with IT is skill biased and increases
the wages of high-skilled workers relative to
low-skilled workers.44
Finally, information technology is altering
product markets and business organizations, as
attested by the large and growing business lit-
erature,45 but a fully satisfactory model of the
semiconductor industry remains to be devel-
oped.46 Such a model would derive the demand
for semiconductors from investment in informa-
tion technology in response to rapidly falling IT
prices. An important objective is to determine
the product cycle for successive generations of
new semiconductors endogenously.
The semiconductor industry and the informa-
tion technology industries are global in their
scope with an elaborate international division of
labor.47 This poses important questions about
the American growth resurgence. Where is the
evidence of a new economy in other leading
industrialized countries? An important explana-
tion is the absence of constant quality price
indexes for semiconductors and information
technology in national accounting systems out-
side the U.S.48 Another conundrum is that
several important participants-Korea, Malay-
sia, Singapore, and Taiwan-are "newly indus-
trializing" economies. What does this portend
for developing countries like China and India?
As policy makers attempt to fill the widening
gaps between the information required for
sound policy and the available data, the


### ---Economics-2001-0-30.txt---
traditional division of labor between statistical
agencies and policy-making bodies is breaking
down. In the mean time, monetary policy mak-
ers must set policies without accurate measures
of price change. Similarly, fiscal policy makers
confront ongoing revisions of growth projec-
tions that drastically affect the outlook for fu-
ture tax revenues and government spending.
The stagflation of the 1970's greatly under-
mined the Keynesian Revolution, leading to a
New Classical Counterrevolution led by Lucas
(1981) that has transformed macroeconomics.
The unanticipated American growth revival of
the 1990's has similar potential for altering eco-
nomic perspectives. In fact, this is already fore-
shadowed in a steady stream of excellent books
on the economics of information technology.49
We are the fortunate beneficiaries of a new
agenda for economic research that could refresh
our thinking and revitalize our discipline.
## Economics-2002-0


### ---Economics-2002-0-02.txt---
Diversity is the staff of economic life. Inter-
personal differences in tastes and talents,
whether naturally endowed or environmentally
produced, give us the unique "propensity to
truck, barter, and trade" that improves our stan-
dards of living. Every elementary economics
student knows how different endowments in an
exchange economy create potential gains from
trade, and how competitive markets efficiently
intermediate and exhaust those gains. In pro-
duction activities, work is organized in highly
specialized ways to use our human resources to
the fullest.
All this is so elementary that economists
largely take it for granted, yet much of the
complexity of modem economic life is built
upon these foundations. The variety of choices
that confront us is astonishing. No consumer
buys more than a tiny fraction of goods that are
available to be purchased. The average person is
unable to identify by name more than a handful
of goods because most are irrelevant to any-
one' s personal economic behavior. And in work
activities, each of us masters hardly any of the
immense varieties of skill required in a modem
economy. Out of the totality of what is known
by society at large, a single person knows prac-
tically nothing, no matter how well educated or
how brilliant! Work and production knowledge
are even more specialized than consumption
choices and activities.
How do decentralized markets accommodate
the diversity of choices, tastes, and productivi-
ties that are so important in economic affairs?
The choice of quantities (the intensive margin)
by a typical buyer or seller has dominated neo-
classical economics. Most of price theory fo-
cuses on the determination of price and
quantities of already-defined goods, but does
little to examine the extensive margin by which
the nature of the goods is chosen. Price theory
does not provide a rich enough structure to
analyze these issues, which require a framework
that takes heterogeneity and diversity as a fun-
damental, primitive construct. Location or spa-
tial theory is specifically designed for that task.
It is a theory of choice based on interpersonal
differences in willingness to pay for differenti-
ated objects perhaps best known from Adam
Smith's theory of equalizing differences.' Dif-
ferentiated products are valued according to
their various qualities and product characteris-
tics. Comparing reservation prices with market
prices determines specific choices of buyers and
sellers out of the vast varieties that are avail-
able. Many successful examples have clarified
how spatial models can be applied to the eco-
nomics of variety and diversity.
Much of my research reflects my attempts
over the years to work out some of the eco-
nomic issues associated with diversity and the
implications of heterogeneity for markets and
prices.2 There are three main themes: the deter-
mination of value in the presence of diversity,
the sorting or allocation of diverse buyers to
diverse sellers, and the effects of heterogeneity
and sorting on inequality.
I. Value, Assignment, and Inequality
How do markets accommodate inherent dif-
ferences in goods, jobs, and productive talents
of people? How are these things valued? Just as
the value of land depends on its location, it is
often possible to think of goods, jobs, and peo-
ple in terms of their addresses in a map of
productive attributes or characteristics. Some
addresses are more desirable than others and
market prices equate the supply and demand for


### ---Economics-2002-0-03.txt---
the latent characteristics of goods at each loca-
tion on the map. Thinking spatially proves es-
pecially useful when there are many more
varieties of goods than attributes that each con-
tains. Because there are fewer attributes than
goods, the dimensionality of the problem is
greatly reduced and analysis can proceed on
conventional cost-benefit terms.
Examples of applications include hedonic in-
dexes of quality change needed to correct price
indexes for changing product characteristics;
among such products as automobiles and com-
puters; regression analysis of housing prices on
house characteristics, used for real estate assess-
ments in urban economics; the capital asset
pricing model, where asset characteristics are
the means and covariances of their rate of return
distributions; studying how labor markets eval-
uate jobs of varying quality, useful for estimat-
ing the social value of safety and environmental
goods that are not directly traded; and how and
why labor markets sustain enormous differ-
ences in rewards and rents among people of
different talents. All are manifestations of al-
most exactly the same basic spatial problem:
valuing diversity.
Market values are an important part of the
story. The allocation of diversity in the econ-
omy is another. How are buyers and sellers
matched or assigned to each other in market
equilibrium? These marriage-type questions
bear importantly on the economic consequences
of diversity because stratification of agents is
inherent in spatial equilibrium. Certain kinds of
buyers come to be associated with certain kinds
of sellers, even when there are no externalities
and social influences in preferences. Rich peo-
ple tend to ride in a better class of automobiles
than poor people. They are more likely to live
on the lakeshore and in other high-rent districts,
to eat in fancy restaurants, wear designer
clothes, send their children to better schools,
and work in more pleasant environments. But
there are many other manifestations of the same
basic sorting or assignment issues in the pres-
ence of diversity. Widows and orphans tend to
hold their wealth in relatively safe assets. Peo-
ple from similar ethnic groups tend to live to-
gether in city enclaves, more talented students
are apt to be found in colleges and graduate
schools that have more talented teachers,
higher-quality lawyers work on the largest legal
claims, and people exposed to higher unem-
ployment risks tend to live in the same
neighborhoods.
The address analogy in spatial equilibrium
often extends to these kinds of matches or as-
signments: goods with special attributes appeal
to buyers with specific kinds of tastes. In prod-
uct markets, sellers design their goods to cater
to specific types of customers. And in labor
markets, each of us in our career choices and
work activities seeks a niche in the incredibly
complex machinery of modern production and
the division of labor. The number of people
seeking these slots and the nature of the tech-
nologies that affect the personal scale of oper-
ations affects the distribution of rewards in
society.
Markets accommodate diversity by establish-
ing prices that tend to make different things
relatively close substitutes at the margin. Adam
Smith's insight that market prices tend to equal-
ize their net advantages is fundamental to these
problems. If one good has more desirable char-
acteristics than another, the less preferred vari-
ety must compensate for its disadvantages by
selling at a lower price. Supply is inelastic and
exogenous in geographic spatial theory, but in
many applications both sides of the market must
be considered jointly. Sellers choose their vari-
eties by comparing prices with costs. Higher-
quality goods are more costly to produce and
must be offered at a higher price. In equilibrium
these extra costs can only be supported if their
incremental value to some customers is at least
as large as their incremental costs. Thus diver-
sity creates inequality in prices and values. The
reverse statement is also true. Certain kinds of
inequality are necessary to sustain diverse out-
comes. For example, if higher-quality goods
were not more expensive to produce than lower-
quality ones and if all consumers had the same
relative ranking on the quality of two different
goods, then only the higher-quality good would
survive in the market. The lower-quality good is
driven out by the existence of a superior one
that can be produced at equal cost.
What is less obvious is that there are social
incentives to create inequality, even when
agents are initially identical in every conceiv-
able way. This is a third theme of the essay. The
basic idea also derives from Smith, who argued
that personal investments in skill acquisition,


### ---Economics-2002-0-04.txt---
not inherited differences in natural abilities, are
the principal causes of wage inequality in soci-
ety. Since labor-market skills are costly to learn,
in market equilibrium their costs must be reim-
bursed by offering larger expected earnings to
potential entrants, otherwise students would not
have the proper economic incentives to study
them. Since much of the cost of education and
learning are in time and opportunities forgone,
the force of interest weighs heavily in these
decisions and can cause remarkably large dif-
ferences in observed earnings, as equilibrium
phenomena.
But once a skill has been acquired, its eco-
nomic return is greatest if it is used as inten-
sively as possible. That the costs of acquiring
most skills are to some extent independent of
how intensively they are utilized makes it effi-
cient for people to specialize their skills and
trade with each other. There are huge econo-
mies of scale in skills. Once acquired, a skill can
be used over and over again without diminish-
ing its stock. Indeed, the reverse may be true,
which provides incentives for students to ac-
quire skills early and to increase their work
hours after having become skilled.
Furthermore, individuals have different tal-
ents and are better suited to some productive
activities than others. The principle of compar-
ative advantage holds true for human-capital
production as well as for international trade. It
accounts for why work is so specialized and
why each person knows such a small amount of
what is known in total. It even holds if people
are identical ex ante. Similar ideas have re-
ceived lots of attention lately in the fields of
industrial organization and international trade,
but are just as important, if not more so, for the
organization of work.
The cost basis that supports induced or "vol-
untary" inequality has other interesting conse-
quences. Unequal rewards motivate people to
strive for superior performance and influence
their decisions to acquire skills. The two inter-
act because new generations of workers replace
older generations: the assignment of people to
jobs changes over the life cycle. A large share
of the growth in personal earnings over mana-
gerial and other careers occurs at discrete pro-
motion points to higher-ranking positions.
Competition for promotions, to acquire greater
skill, show one's stuff, and get more powerful
and higher-paying positions, plays an important
role both in the internal dynamics of organiza-
tions and in the overall economy. Uncertainty of
outcomes and the statistical aspects of promo-
tion and job assignments guarantee that compe-
tition for superior positions occurs in every
form of economic organization. The need to use
the record of past performance to assess pros-
pects for other positions automatically gives
people incentives to try to influence the mea-
sures that will put them in a superior category.
The strength of these incentives depends on
how much of a difference-in money, prestige
and perquisites-it makes to achieve a better
grade and a higher classification.
II. Valuing Diversity
Much of my research consists of applications
of the problem of analyzing markets for differ-
entiated products when the measure of differen-
tiation is naturally ordered from best to worst.
Market prices reflect both the costs and values
of the underlying attributes of goods. Agents
implicitly use cost-benefit analysis to choose
locations in the product spectrum, with buyers
comparing the market prices of alternative va-
rieties with their relative values in use and with
sellers comparing market prices with their rel-
ative costs. Equality between demand and sup-
ply for each variety sustains the market
equilibrium price-quality structure.
Consider a commodity that comes in two
different varieties. For example, there are high-
and low-quality cars, better and worse houses
(or schools or neighborhoods), good jobs and
bad ones, fast and slow computers, and so on.
Let c represent all other goods consumed and let
Zh and z1 measure the high- and low-quality
characteristics of the goods in question. The
relative prices of the two varieties in terms of
other goods are Ph and Pl In the situation con-
sidered, which is typical of many markets, in-
dividual buyers and sellers are small compared
to the overall market and individually have no
market power. Suppose that customers purchase
either one unit of the differentiated product or
none. This is a leading case. Most people live in
exactly one neighborhood, hold one job, and
drive one car. Preferences are given by a utility
function u(c,z) of the usual kind. The choice set
consists of three distinct points in the (p,z)


### ---Economics-2002-0-05.txt---

plane, as in Figure 1. A consumer lives at point
A, (0,0), if neither variety is purchased, at point
B, (pl,zl), if the low-quality variety is most
preferred, and at point C, (Ph,Zh), if high qual-
ity is chosen. High-quality goods must sell for
higher prices than low-quality goods, or else
low quality is dominated and disappears from
the market. Thus, higher z is always associated
with larger p if both Zh and z, are actually
traded. Given that some variety is purchased, a
consumer chooses Zh if the benefits of its addi-
tional quality exceed its additional cost. Once
having decided on the choice of variety, the
consumer decides whether to purchase it or do
without.
The first part of the problem is equivalent to
choosing the maximum between u(y - Ph, Zh)
and u(y - pl, zl), where y is income. The
added cost of high quality is l\p = Ph - Pl- Its
added benefit is how much more the buyer is
willing to pay for it, A\O, and is defined as a
compensating variation:
(1) U(y - pI - AO, Zh) = U(y - pi, Z1)-
AXO is the money premium a person would pay
for Zh when the lower-quality item z, is avail-
able at price p,. The optimal choice is Zh if
AXO > Ph - p, and z, otherwise. The second part of
the problem, whether or not to purchase the
good at all, is another cost-benefit comparison.
Define 0 as the compensating variation that
equates the utility of not purchasing anything to
that obtained from the best possible variety:
(2)
u(y,O)
= max{u(y - 0 - AO, Zh), U(y - 0, Z1)}.
The consumer does not purchase any z if both
0 < p, and 0 + AO < Ph-
This can be neatly described diagrammati-
cally with a spatial bidfunction 0 (z), defined as
the amount a person with income y will pay for
various varieties at some constant utility index:
(3) u(y - 0(z), z) = constant.
0(z) is an indifference curve between money
and the measure of quality z. From (3), its
derivative a 0/az = uzJuC, is the marginal rate
of substitution between z and c. This is pos-
itive and 0 (z) is upward sloping. Diminishing
marginal rate of substitution implies that
0"(z) < 0: the marginal willingness to pay
for additional quality is decreasing. The
curves labeled 0' in Figure 1 depict indif-
ference curves for three different kinds of
buyers. Consumers whose tastes look like 00 do
not purchase the differentiated product at all
because the indifference curve through (0,0) lies
above the available price-quality combinations
for z. Analogously, those whose tastes look like
01 purchase z, and those whose tastes are more
like 02 buy Zh- Choices of differentiated variet-
ies are nicely ordered by the intensity of pref-
erences for quality in this example.
Supply decisions of sellers are similar. The
benefit of selling a variety is its market price.
Production is profitable if price exceeds produc-
tion costs of at least some sellers. Parallel with
bid functions, these choices are depicted by a
spatial offer function p( z)-the locus of price-
quality pairs that result in the same profit. 'p( c)
is the supply price of quality z for that seller.
Since higher-quality goods are more costly to
produce, 'p'(z) > 0. Offer curves are increas-
ing and convex functions of z. Producers either
specialize their production in distinct varieties
or produce several of them in a product line.
Costs and production conditions, indivisibili-
ties, the nature of competition, and competitors'
costs factor into these outcomes. Figure 1 de-
picts a case of specialization. The offer function
labeled Sp1 refers to a seller with comparative


### ---Economics-2002-0-06.txt---
advantage at producing the lower-quality vari-
ety and the curve labeled 92 refers to a seller
whose production conditions are better suited to
high quality. Since (pl lies everywhere above
(Zh, Ph), seller 1 cannot offer the high-quality
variety at a profit level higher than that obtained
by offering the low-quality variety. Conversely,
since (P2 lies everywhere above (zl, Pl), seller 2
cannot offer the low-quality variety at a profit
level higher than that obtained by offering the
high-quality variety. Sellers whose minimum
acceptable profit-offer curve cover both prices
produce both objects. An example of such a
seller is one with offer function Sp*, who is
indifferent between selling the two varieties.
Some auto manufacturers produce a full
product line and others specialize in niche mar-
kets. Research universities cater to students
with superior high-school records and achieve-
ments, and would not be very cost effective as
junior colleges. Climatic and geographic en-
dowments give some California vineyards ad-
vantages in producing high-quality wine that is
much harder to produce in New York and Mich-
igan, yet some California vintners produce both
higher- and lower-quality brands. The presti-
gious law firms handling large legal claims are
careful about which cases they take on and
whom they admit as partners. Production activ-
ities in which workers directly interact require
personnel who complement each other's per-
sonal productivity and efficiency characteris-
tics. Because of direct complementarity in most
production settings, more interpersonal varia-
tion in efficiency within production units can be
tolerated by transacting through the market
rather than directly in teams. Impersonal
transactions are the equivalent of intermediate
product markets and reduce the adverse conse-
quences that occur when less efficient workers
pull down the productivity of more efficient
ones.
Figure 1 shows how the market sustains di-
versity as an equilibrium phenomenon. Differ-
ent kinds of buyers purchase different kinds of
goods. Consumers with tastes that correspond to
O'(z) buy z1 at price Pi and are supplied by
sellers with bid functions that correspond to
pl(z). Consumers with tastes that correspond
to 02( z) buy z, at price Ph and are supplied by
sellers with bid functions that correspond to
(p2( z). Neither seller has any incentive to try to
sell to consumers of the other type, nor does any
buyer have any incentive to purchase from the
other type of seller. All four types of agents can
do no better, given the opportunities available.
A. Interpreting the Implicit Value of
Characteristics
Empirical investigations of product and labor
differentiation use cross-section data to relate
prices p with attributes z. The hedonic regres-
sion method regresses product prices on product
characteristics. It was initially developed to
study real cost reductions in auto and other
durable goods manufacturing that were con-
cealed by product design changes and quality
improvements. In labor economics, wages of
workers are regressed on their personal produc-
tivity and job characteristics. In land and hous-
ing markets, site and structure prices are
regressed on house attributes (size, architectural
style, and age) and onsite characteristics (neigh-
borhood, location, and public services). Labor
and land market studies are useful for imputing
the social value of certain intangible goods, like
safety and clean environments. An important
use in goods markets is to construct price and
quantity indexes that control for changes in the
quality of goods over time.
B. Cross-Section Values
Environmental and safety concerns are at the
forefront of public policy today. The rhetoric
and passions they arouse make it easy to forget
that these goods are costly to produce and that
rational decisions require comparing their ben-
efits with their costs. Assessing the costs of
these kinds of public policies is like finding the
costs of any other investment. Assessing bene-
fits requires estimating the willingness of con-
sumers to pay for more safety and better
environments. Practice is tricky because there
exist no explicit markets where safety and clean
air are directly traded, and from which demand
values can be directly inferred. Instead, safety
and environmental quality often are by-products
of other transactions and their valuations must
be imputed from the observed packages in
which they play a part.
Exposure to risk and pollution are affected by
work and residential choices. Some jobs are


### ---Economics-2002-0-07.txt---
more hazardous than others and the social and
physical environment varies greatly among
neighborhoods. Private cost-benefit consider-
ations underlying such choices are the basis for
imputing the required values. Housing in crime-
free neighborhoods is expensive because people
are willing to pay more for greater personal
safety and protection of their property and be-
cause crime-free neighborhoods are scarce.
Wages on hazardous jobs must be higher in
order to induce workers to expose themselves to
greater risk of life and limb. Observed price
differences across jobs and locations are the
implicit prices of characteristics, as in Figure
1, with z interpreted as job safety or neighbor-
hood safety.
Valuations generally vary among agents.
People with different tastes and incomes have
different bid and offer functions, but more is
involved. In most types of economic exchange,
the Law of One Price implies that marginal
valuations across buyers are identical and that
differences in tastes manifest themselves only in
differences in quantities consumed. For exam-
ple, the "last" loaf of bread is worth about the
same-its market price-to a person who con-
sumes one loaf per week as to a person who
buys one loaf per day.
The Law of One Price always applies to the
specific houses, jobs, or goods markets that
embody intangible characteristics, but not nec-
essarily to the intangible characteristics them-
selves. Whether there is a unique market price
of a characteristic depends on whether or not the
characteristics embodied in existing varieties
can be recombined or remanufactured by buyers
into different varieties. The leading example of
such "combinability" is asset and portfolio
management. Risk and return of any single asset
are relevant only insofar as they affect the risk
and return on one's total portfolio. A portfolio is
a linear combination of various assets, so co-
variance of risk on one asset compared to others
is the key risk component. The implied linear
restrictions (or no-arbitrage conditions) imply a
unique market price for risk.
But the fact is that combinability of charac-
teristics across varieties is not possible for most
other goods. If it is expensive to untie bundles
after they have been manufactured, sellers must
design their goods for specific tastes and assem-
ble packages of characteristics that appeal to
specific market segments. This generally results
in differing attribute prices across packages.
One cannot buy another unit of comfort for a
sports car in an independent "comfort" market.
Instead, a larger car must be purchased. A
worker on a risky job cannot subcontract little
bits of the risk to others in a secondary market.
It is all-or-nothing. The only way less risk can
be chosen is by finding a safer job. Workers
come prepackaged with various combinations
of skills and traits, some productive and others
counterproductive. Employers cannot detach
the less desirable ones from any single worker.
Rather, an entirely different person has to be
hired. In these cases the market equilibrium
price function p( z) usually is nonlinear, and the
gradient p'(z) generally depends on z itself.
Since there is no single market price for z,
different people have different valuations of it at
the margin. Type 0' and 02 buyers in Figure
1 serve as an example. In principle an average
of the two slopes at z1 and Zh is appropriate for
assessing the (marginal) benefits of a small in-
dependent public project affecting z in some
application, with the average weighted by ben-
efit incidence of the project among different
types of people.
So many factors determine market prices of
goods in practice that the best chance empiri-
cally for isolating the implicit value of safety
and environment is to examine specific goods or
jobs where these aspects dominate other consid-
erations of choice. For instance, my labor-
market study with Richard Thaler (1 976) on the
value of life was one of the first to systemati-
cally examine wage premiums on very risky
jobs, where risk was measured as excess insur-
ance premiums charged by private companies
on worker compensation policies.
The revealed preference argument in Figure
1 applies directly to that problem. Here z rep-
resents job safety and p( z) is estimated by
statistically comparing the smaller market wage
that workers are paid on safer jobs compared to
higher wages paid on riskier ones, other things
equal. Examining risky jobs empirically con-
fines the study to jobs with relatively low values
of safety, e.g., to those in the neighborhood of z,
in the figure. Since most workers hold relatively
safe jobs (located closer to a point like z,, in the
figure), people holding risky jobs surely place
smaller values on safety than the median per-


### ---Economics-2002-0-08.txt---
son, much like the difference between people of
types 01 and &2 in the figure. Workers choosing
safe jobs are willing to pay at least as much for
safety as people choosing risky jobs, so the
wage premium on risky jobs is likely to be a
lower bound on the average person's willing-
ness to pay for safety.
Thaler and I estimated a "value of life" of
about $800,000 in dollars of Year 2000 pur-
chasing power. Other labor-market studies us-
ing data on a wider range of risks have found
much larger values. The broader range of risks
in these studies is the most probable reason
for the larger estimates: they include more
between-variation (e.g., the differences between
z1 and Zh), whereas our study was largely con-
fined to within-variation (around zl). Similar
considerations apply to housing and land mar-
ket studies that impute values for crime, cli-
mate, and pollution. Here, too, revealed
preference implies that estimated pollution and
crime gradients are likely to be lower bounds
for the average citizen because they ignore im-
portant sorting considerations.
C. Time-Series Imputations
The main practical difficulty in assessing
changing standards of living is that goods
change their character over time. The prices of
tractors and automobiles today differ from 30
years ago, not only because manufacturing pro-
ductivity and input prices have changed, but
also because the products themselves have im-
proved. The nature of the problem is starkest
when entirely new goods appear on the market.
If their introduction is successful and they sup-
plant older varieties, how should they be linked
into a price index?
Conceptually, the only possibility is to think
in terms of the costs of providing ultimate ser-
vices. Technical changes reduce the cost of ser-
vices. Autos were successful because they were
a superior way of producing transport services
compared to animals. Electricity produced heat
and light more efficiently than steam and lan-
tems, and radio, television, and movies reduced
the cost of entertainment services relative to live
performances. In these examples, technical
changes should be factored into price indexes
for transport services, power, and entertainment
services. In practice it is extremely difficult to
link entirely new goods to old goods in this
way. Adjusting for quality improvements of ex-
isting goods is more manageable.
Rising incomes naturally cause product qual-
ity to improve over time, because the income
elasticity of demand for quality is positive.
Even when the prices per unit quality of goods
do not change, rising incomes increase the de-
mand for quality and raise average transactions
prices over time. Offsetting the rise in demand
for quality is that some aspects of quality (like
ornate detail on early twentieth-century houses)
are labor intensive, which causes their prices to
rise as incomes rise. As long as the cost factor is
not dominant, there is upward bias in measured
prices and downward bias in measured real liv-
ing standards from a change in the composition
of goods toward more expensive varieties.
Transactions prices rise not because cost has
increased, but because the quality of what is
being referred to as a particular good has in-
creased. Income effects are represented by
movements along a given p( z) locus in Figure
1. The same envelope of offer functions define
p(z), but bid functions shift up and to the right
as income rises because the willingness to pay
for increments of z increases with income. 01
and 0& in Figure 1 could represent two people
with the same underlying utility functions but
different incomes. With constant returns to
scale in production, prices of each variety do
not change as income rises, but average quality
purchased and average transactions prices both
increase. We should not confuse movements
along the p( z) locus with changes in the cost of
living. Most consumption decisions change as
income rises, and these are part and parcel of
the same general phenomenon. Standardized
comparisons that control for the changing com-
position of goods eliminate this kind of bias.
To assess changes in the real costs of living,
we should account for shifts in the price-quality
locus or technological changes that extend the
real range of choice. Such shifts can cause
quality-specific prices either to rise or fall. For
example, p( z) and the cost of living go up in the
income-increasing experiment above if goods
are supplied inelastically. For example, rising
real incomes increase the demand for amenities
associated with geographic location, raising
site values and the costs of housing services
in the preferred locations. On the other hand,


### ---Economics-2002-0-09.txt---

innovations that extend the quality range of
goods tend to reduce the real costs of services
and reduce living costs for those who buy them.
Productivity-improving quality changes gen-
erally reduce the real prices of goods. Prices and
available qualities are always changing. Some
sellers are innovating and attempting to increase
profits by extending the desirable characteristics
in their goods and reducing prices below those
of competitors. The prototypical example ap-
pears in Figure 2. The first-period equilibrium is
the same as before, where goods are labeled zll
and Zh I and equilibria are found at points A and
B. In the second period the attributes of goods
have changed to Z12 and Zh2 so the price-quality
locus has moved down, and the average price
per unit quality has declined. (A ray from the
origin through A is steeper than one through D
and similarly for B and E.) Quality-adjusted
price indexes require measuring the distance
between the two price-quality loci, shown in
Figure 2 as the curve that connects A and B and
the one that connects D and E. The distance
between F and D is a measure of the quality-
adjusted change in price at quality level z,12
When technical change is so large that z could
not be produced in period 1 (a 32-bit computer
chip did not exist in 1980) shown, for example,
by Zh2', direct price comparisons of the im-
proved product are impossible. In principle this
can be overcome with sufficient structural
knowledge of bid functions. In this case, the
requirement amounts to knowing the exact
shape of 02( z) and of 02'( z), which represents
different indifference curves for the same con-
sumer. The conceptually appropriate measure of
distance is the difference between actual price
in period 2 and what type 2 buyers would have
been willing to pay for Zh2' in period 1 had it
been available, shown in Figure 2 as the dis-
tance between G and H. Generally such detailed
structural knowledge is unavailable, so distance
must be measured by using overlapping variet-
ies whose quality is more or less comparable
across adjacent periods. For example, top-of-
the-line goods in period 1 might be compared
with bottom-of-the-line goods in period 2.
Longer period comparisons are made by linking
or chaining indexes with common components
over the years.
Figure 2 contains a graphic example of why
these adjustments are important. Consider a
new good Zh2' not previously available, whose
current price, Ph2', exceeds that of the best prior
models. Unadjusted indexes would show rising
prices simply because Ph2' exceeds Ph 1. A more
accurate distance-based quality-adjusted index
would correctly show prices declining because
consumers would have been willing to pay more
than its period 2 cost in period 1, had it been
available. Note that there is a consumer whose
bid function, in this case 03( z), reflects higher
satisfaction at (Zh2', Ph2') than at any other
available (z, p) combination.
This example is transparent, but very rele-
vant. Until a few years ago, the National Income
and Product Accounts priced computers by the
box-by the package in which producers deliv-
ered them. In the early years of the computer
revolution boxes were getting bigger and more
powerful, and their prices were increasing. It
was as if soap were suddenly produced in bigger
bars and the index used the price per bar, not the
price per unit volume or weight. Computer pro-
ductivity was grossly distorted in the official
indexes, though the aggregate consequences of
the error were limited because investment in
computers was not such a large share of total
investment as is true today. But even when box
prices were falling, as has been true for many
years, unadjusted price indexes distort produc-
tivity. Prices are really falling much faster than
appears because products are improving so
much. The mainframe of yesterday is the laptop
of today. Considering that computers currently
make up almost half of gross business invest-
ment, eliminating these biases is important for


### ---Economics-2002-0-10.txt---
getting an accurate assessment of national in-
come. The recent report of The Presidential
Commission on Price Indexes shows that more
widespread failures to make quality adjustments
of goods in price indexes have serious negative
biases for assessing real wage and productivity
growth, and overstate inflation and the social
security and other entitlements that are indexed
to them.
III. Sorting and Stratification
In any market equilibrium, interpersonal dif-
ferences in tastes and technologies affect the
locations chosen by buyers and sellers on the
attributes map. Some of these differences are
inexplicable: sometimes there really is no ac-
counting for different tastes. Others have more
proximate causes, but might just as well be
summarized stochastically. For instance, the
preferences for material goods of a person from
humble origins that subsequently makes lots of
money often seem to differ from those of her
children. Families that are contemplating hav-
ing children are likely to prefer larger cars to
smaller ones and suburban to downtown dwell-
ing units. In the labor market, a person's supply
price for physically demanding or dangerous
work depends on age, physical condition, and
number of dependents, among other things. Dif-
ferent endowments affect productivities in dif-
ferent pursuits. Musicians cannot be tone-deaf;
football players tend to be large; while lawyers,
and many economists, have a propensity to talk.
What matters for economic allocations in all
of these cases are the direct manifestations of
tastes. Here, the reservation prices themselves,
not the specific causes that make preferences,
differ case by case. The distributions of bid and
offer functions are sufficient (in the statistical
sense) for ascertaining the demand, supply, and
equilibrium price of each variety. But when
reservation prices are systematically associated
with observable traits of buyers and sellers,
these markets become stratified in many ways.
Stratification and sorting are ubiquitous in spa-
tial equilibrium and have many interesting con-
sequences. Neighborhood, bandwagon, status,
and other social externalities are often invoked
to account for stratification, but most stratifica-
tion occurs without them.
Sorting by income is one of the most impor-
tant forms of stratification in goods, land, and
labor markets. As noted above, people who buy
high-quality goods, and live in better residences
and neighborhoods tend to be richer than other
people. Similarly, high-wage people use their
higher earning capacity to purchase more job
amenities and better working conditions. Strat-
ification of job quality by the skill characteris-
tics of workers can make it difficult to estimate
equalizing wage differences for the implicit at-
tributes of jobs. Sometimes the data on job and
worker characteristics are so colinear that the
ceteris paribus conditions required for identify-
ing taste parameters alone are overwhelmed by
income stratification and cannot be observed in
the data. Yet it is incorrect to take this as evi-
dence of failure of the equalizing or compensa-
tion principle in the labor market.
Stratification and colinearity is itself an im-
plication of the economic theory of preferences
when income effects are important. High-wage
jobs generally are the good jobs, not the bad
ones. They are staffed by skillful workers
whose higher incomes make job amenities more
valuable and who buy more of them. There is no
logical contradiction here. The identifying re-
strictions for backing out implicit valuations in
the data just are not satisfied. After all, some-
times there is not the right kind of variation in
the data to estimate a conventional demand
curve, but that does not imply that a demand
curve does not exist. These difficulties are less
often encountered in imputing implicit prices of
characteristics from goods and land market
prices. Prices and attributes of goods and land
are almost always measured independently of
the characteristics of buyers and sellers. Of
course many aspects of product attributes may
be highly correlated, making it difficult to ex-
tract the value of any single one of them. The
stratification problem more often arises in labor
markets, because observed wages always re-
flect the total bundle of both job and worker-
productivity attributes. The correlation between
them can be too large to separate the compo-
nents. In sum, potential for stratification places
limits on the empirical applicability of the he-
donic method. Sometimes it cannot be used, but
the test is always empirical.
Colinearity affects the precision with which
effects can be estimated, but sometimes there is
bias in estimating the importance of equalizing


### ---Economics-2002-0-11.txt---

differences. It is not that coefficients are noisy;
it is rather that they have the wrong sign. This
frequently occurs in the labor-market setting
when one estimates compensating differences
in wage functions. A good example involves the
trade-off between pensions and wages. Other
things equal, jobs with higher pension benefits
should have lower wages because the total
amount that employers are willing to pay for a
given worker should not vary with the compo-
sition of the compensation package and because
workers are willing to trade wages for pensions.
In Figure 3, the observed trade-off is shown by
the locus AB, which is the estimated market
relation of wages to pensions. Note that it is
positively sloped, but this is not because work-
ers do not view both wages and pension benefits
as goods. Instead, it reflects the fact that more
productive workers, who are richer, take some of
their income in the form of wages and some in the
form of pensions. The (pl offer function reflects
the bid by firms to low-productivity workers and
the (p2 function reflects the bid by firms to high-
productivity workers. Even if all workers had the
same preferences, as shown by the dotted offer
functions (the one to the northeast reflecting
higher utility), the market equilibrium would se-
lect points A and B. For any given worker, the
trade-off would be negative because then the (p or
0 curves would be relevant. But the market ob-
serves the AB line, because key productivity fac-
tors cannot be held constant. The AB line might
well be estimated with precision, depending on
the amount and nature of the data, but it identifies
neither a firm's nor worker's willingness to trade
off pensions for wages.
IV. Diversity and Specialization
Specialization, division of labor, and the or-
ganization of work socially create much of the
diversity observed in economics. In his compel-
ling discussion, Smith identified scale econo-
mies as the principal cause of specialization.
Instead of working alone and doing everything
by oneself, it is productive for a worker to join
teams and assign individual members to a few
mutually exclusive tasks. The division of labor
is one of the most important bits of economic
analysis at the extensive margin. How are pro-
ductive activities packaged and bundled to-
gether into jobs, and who works on them?
For the economy as a whole, the most impor-
tant reason by far for specialization and division
of labor are scale economies in utilizing ac-
quired skills. The returns to investing in a par-
ticular skill are proportional to the frequency of
its subsequent use. This makes it efficient to use
th'e skills one has already acquired as inten-
sively as possible and not to spread oneself too
thinly over a highly diversified portfolio. These
same connections between capacity and utiliza-
tion apply to all capital goods, not only to
human-capital varieties. The costs of construct-
ing an office building depend on its size; but
once it is built, it is efficient to keep the offices
as fully occupied as possible because the mar-
ginal cost of an unoccupied office is much
smaller than its average cost.
Specialization is optimal if learning new
skills involves significant fixed costs that are
only loosely linked to the intensity of subse-
quent utilization. Then it is best to learn a few
skills very well and use them all the time. These
basic forces produce enormous social gains
from trade. We could all build our own houses
and educate our own children. Instead, we use
markets to buy new houses built by expert
house builders and purchase educational ser-
vices for our children from expert teachers. The
houses are better and the children learn more.
Specialization and trade are important causes of
economic diversity among people in society.
Many aspects of economic diversity and its
manifestations in economic inequality serve
valuable social purposes. The fact is that sub-
stantial inequality is necessary for decentralized
societies to function. Many components of vari-
ance of earnings among persons are sustained


### ---Economics-2002-0-12.txt---
by personal activities that would characterize
the most free and open societies. They are nec-
essary to sustain both human-capital investment
incentives and work incentives.
For example, in almost every society doctors
earn more than other people. These wage dif-
ferentials persist in equilibrium in order to com-
pensate prospective medical students for their
arduous and costly training. The number and
quality of doctors would fall if earnings were
artificially compressed and the rate of return to
medical education was reduced. A society with
few doctors would score more egalitarian points
on a Gini coefficient, but it would not be a better
society. This example is trivial, but the point is
far more general and often not so obvious.
Much inequality in the overall distribution of
earnings is attributable to substantial differ-
ences in mean earnings among workers of dif-
ferent ages and educational attainments that
are associated with occupational choices and
human-capital investments over the life cycle.
They reflect rational personal choices that
change a person's economic status and current
incomes over a lifetime.
Rising earnings over working life as well as
earnings differences between occupational
and educational categories largely reflect re-
turns to human-capital investments. A clear
distinction between human-capital (lifetime)
wealth and current earnings is needed because
learning always involves choosing prospects
with smaller earnings now and higher earn-
ings in the future. Observing that a person has
low current earnings is no signal of lifetime
poverty if future earnings will be high. Sim-
ilarly, high current earnings are no signal of
excess wealth if a person paid the price in low
previous earnings. The point is that the dis-
tribution of current income is far more un-
equal than the distribution of human-capital
wealth. Inequality indexes based on current
data alone give a very misleading impression
of true inequality.
The reasoning is most easily understood in
terms of an example. Consider a completely
equal society in which all workers have exactly
the same age-earnings profiles over their ca-
reers. Then the distribution of annual earnings is
a deterministic function of the age distribution
of workers. Societies with more variation in
worker age show more inequality, but that is not
a very interesting aspect of inequality. In fact,
the age distribution makes an enormous differ-
ence to measured inequality indexes: earnings
data used to assess inequality that are not age
standardized are practically worthless for as-
sessing inequality. Remarkably, such adjust-
ments are seldom made. Standardizing current
earnings data for education presents more diffi-
cult conceptual problems because family back-
grounds and personal financial barriers on
educational choices distort investment margins
and make wage differentials not fully equaliz-
ing on costs. Nonetheless, some portion of ed-
ucational wage differences-and, judging from
the remarkable uniformity of estimated rates of
return to education in different countries, per-
haps a major portion-are equalizing on their
costs. They represent productive, socially man-
ufactured diversity and inequality that we can-
not live very well without.
V. Personal Productivity and the Distribution of
Earnings
Of course, not all differences are willfully
created. Many are caused by inherited interper-
sonal differences in talents and tastes. The he-
donic or characteristics approach to labor
markets bears similarities to statistical factor-
analytic ideas in accounting for earnings differ-
ences across individuals. Factor analysis
partitions observed variance into a small num-
ber of unobserved, latent "causes" or factors. A
leading example is intelligence testing, where
test scores are thought to reflect the quantitative,
analytical, verbal, and mechanical abilities of
subjects. Similarly, personal productivity and
earning power are ultimately determined by
such things as strength, intelligence, dexterity,
and attention to detail. Think of a model in
which a person's earning power is "scored" as
the sum of the amounts of each attribute pos-
sessed, times their market prices. If the number
of factors is small, important proximate causes
of the distribution of earnings are reduced to
small dimensions. The economic rationale for
compacting the determinants of earnings into a
small set of universal factors and prices turns on
the existence of unique economywide prices
("loadings") on the factors. Since these price
weights are parameters in any factor represen-
tation of earnings across persons, dimensionality


### ---Economics-2002-0-13.txt---
is reduced only if the same prices apply to all
persons.
The implausibility of invariance in any mar-
ket equilibrium is transparent in the goods mar-
ket. Is it possible that the marginal value of a
unit of comfort in an automobile should be the
same as a unit of comfort in an easy chair? Not
at all. These commodities represent different,
imperfectly substitutable services that cannot be
unbundled into such components. We do not see
easy chairs in autos and bucket seats in living
rooms. No "arbitrage" opportunities are avail-
able for trading comfort in one kind of good
with comfort in an entirely different class of
goods, because those characteristics cannot be
untied from the larger bundle of attributes for
which the good was designed. Again, the Law
of One Price does not apply to characteristics,
and their implicit value usually differs among
categories of goods. It would be the same only
by accident.
Similarly, why should the value of another
unit of strength to, say, an accountant be the
same as its value to an athlete? It would be the
same if there were aggregate markets for such
things as strength and intelligence and if a unit
of "accounting strength" was a perfect substi-
tute for units of "athletic strength" in all pro-
ductive activities. The images of accountants on
the 50-yard line and linemen running interfer-
ence against the IRS is not, however, reassuring
in this regard. Once again the bundling of per-
sonal productivity characteristics and the im-
possibility of untying bundles and repackaging
them into something else is crucial. The mar-
ginal products of underlying factors vary across
activities-strength is more important to profes-
sional athletes than to accountants-and the
shadow prices of these factors vary across ac-
tivities as well. Thus, athletes are stronger than
accountants and accountants have more quanti-
tative skills than athletes. This is another impor-
tant manifestation of sorting and stratification in
spatial equilibria.
Activity-specific prices generate comparative
advantage. Just as differences in the relative
abundance of sunshine to rainfall in Portugal
and England give each country its comparative
advantage in wine or cloth, so too does strength
give people who have it a comparative advan-
tage in some forms of athletics, while arithmetic
skills and attention to detail give other people
comparative advantage in accounting. Compar-
ative advantage has interesting consequences.
For one, people observed in various job and
educational categories tend to be selected and
stratified by the personal attributes that give
them a competitive edge in a specific field. A
person's financial self-interest is served by se-
lecting the occupation that maximizes expected
earnings. If this is a major consideration in
occupational choice (though certainly not the
only one), observed earnings of individuals who
voluntarily chose an occupation might be a poor
estimate of what the earnings of people who
avoided that occupation would have been.
Obviously, the earnings of successful athletes
or actresses are not representative of the average
person's prospects in those fields. But the point
is more subtle in other important applications,
for instance in interpreting income differences
between people with more and less education.
As seen above, if all people were identical, the
education-earnings premium would be sus-
tained by the supply conditions that pay must
compensate for incurring the costs of invest-
ment to equalize net advantages across trades.
When people differ, things are more compli-
cated. Those who expect the largest returns on
their educational investments are more likely to
make them. Ability rents persist in equilibrium.
There are two main reasons why rates of
return to human-capital investments and human
wealth differ among people. First, natural tal-
ents complement occupation-specific human-
capital investments in different ways. Verbal
ability is indispensable for lawyers and quanti-
tative ability for engineers and scientists, for
example. People with greater endowments of
such traits have better prospects for success in
those activities. Another way of saying it is that
there are "ability" rents in occupational choices.
Wage differences are not fully equalizing on the
costs of acquiring skills because natural endow-
ments and premarket investments cause these
costs to differ among people. Second, there are
substantial financial barriers to educational in-
vestments because human capital is not legal
collateral for investment loans. The main man-
ifestation of this is traditionally seen in high
stratification of educational attainments of chil-
dren according to parental wealth. Financing
difficulties cause inefficiencies and inequities in
human-capital investment decisions because


### ---Economics-2002-0-14.txt---
some socially desirable investment opportuni-
ties are not available to poor people. Here, too,
earnings differences are not fully equalizing on
educational costs. They manifest the effects of a
form of financial "noncompeting groups," as
well as the effects of true differences in costs
and talents.
The effects of equal educational opportuni-
ties on the distribution of earnings depends on
interpersonal differences in talents, abilities,
and motivation on the one hand, and on the
importance of noncompeting groups and finan-
cial barriers on the other. Econometricians have
assessed the "ability-bias" in estimated rates of
return to higher education. This work is best
interpreted in terms of a one-factor representa-
tion of skill where individuals are essentially
rank ordered from most able to least able, or
according to absolute advantage. Then, if finan-
cial barriers are not too negatively correlated
with ability, people with more education tend to
be more able than those with less, and the wage
difference between college and high-school
graduates is an upwardly biased estimate of
what noncollege graduates would have earned
had they gone to college. As a practical matter,
the estimates of bias typically are rather small.
The characteristics model enriches analysis by
allowing selection by comparative advantage
rather than absolute advantage. Here abilities
and talents have different values in different
labor-market pursuits.
For example, Robert Willis and I (1979)
modeled educational choice by combining tra-
ditional human-capital ideas with the theory of
comparative advantage, and developed a
method to estimate the behavior determinants of
actual choices observed in the data. We found
that high-school and college graduates do in-
deed have different comparative advantages
across skills that dominate the selection process.
Detailed analysis of the earnings patterns of
World War II veterans showed the usual result
that high-school graduates would not have
earned as much as those who actually chose to
get their college degrees. But we also discov-
ered that persons who subsequently gained col-
lege degrees probably would have earned
relatively less as high-school graduates than
those who voluntarily discontinued their educa-
tion after high-school graduation. Positive se-
lection at both levels of school is inconsistent
with a simple rank-order interpretation or
single-factor model of ability. It is only consis-
tent with two or more dimensions of ability that
are negatively correlated across people. Com-
parative advantage also accounts for why most
estimates of ability-bias interpreted as a single
factor (absolute advantage) are so small. Those
who leave school early do relatively well in
their pursuits so that simple cross-sectional es-
timates are not much different from ability-
corrected ones.
VI. Manufactured Inequality
The production of income is not determinis-
tic. Sometimes, random forces play an impor-
tant role in assigning earnings to individuals.
For example, some occupations are risky. The
arts come to mind, where only a few individuals
can support themselves on the earnings from
their trade. Musicians have very skewed earn-
ings distributions, but most young music stu-
dents who choose to enter the field understand
that there is only a small chance that they will
end up at the desired end of the distribution.
Somewhat counterintuitively, perhaps, the
variance in outcomes that is introduced by this
randomness can improve welfare. The idea is
rooted in early work by Milton Friedman (1953)
and examined again in a different context by
Theodore Bergstrom (1986). Indivisibilities
play a key role here. Most people live in one
and only one house. Area amenities enjoyed
depend on the location of the house and on
individuals' choices on location that are corre-
lated with income. For example, rich people
may choose to live in New York City rather
than in Kankakee, Illinois because there are
more ways to spend income in New York than
there are in Kankakee. Conversely, the life of a
poor person in Manhattan is difficult because
the amenities are expensive and tend to be tar-
geted toward high-income people. There is
complementarity in the utility function between
the quality of housing, in this case proxied by
urban amenities, and the level of consumption
of other goods. The situation is illustrated in
Figure 4.
A consumer may choose to live in a high-
quality house, Zh, or a low-quality house, zl,
with corresponding house prices Ph and Pl- Be-
cause of the complementarity in consumption


### ---Economics-2002-0-15.txt---

between other goods and housing, those whose
incomes are below Yk derive higher utility from
living in the low-quality house in a low-amenity
location and those whose incomes are above Yk
derive higher utility from living in the high-
quality house in a high-amenity location. But
consumers with incomes between YI and Y2 can
improve their expected utility by entering into
gambles, which would offer them expected util-
ity that lies along the line that connects A and B.
For example, an individual with income yo who
chooses to live in a low-quality house offering
utility U(yo - Pl, zl) would prefer a fair gam-
ble that paid income Yi half the time and income
Y2 half the time. Were he to lose the gamble, he
would live in the low-quality house and derive
utility U(y, - pl, Z,). Were he to win, he would
live in the high-quality house and derive utility
U(Y2 - Ph, Zh). His expected utility would be at
point C, which yields more utility than the cer-
tain utility obtained at point D.
Occupational lotteries of this sort manufac-
ture inequality but make the individuals who
enter the occupation better off. Because the
variance in outcomes gives individuals a shot at
a much better standard of living, they willingly
bear the risk that results in observed ex post
inequality. Going to a high-stakes law firm in
New York may turn out to be a good option,
offering a partnership, high income, and an en-
tertaining city in which to spend income. Those
who lose the law-firm lottery accept jobs as
corporate counsel in Kankakee, buy a less ex-
pensive house, and enjoy fewer amenities. Al-
though it is better to win the lottery than to lose
it, the existence of the risky occupation makes
all individuals who enter better off in an ex-
pected utility sense, primarily because the in-
equality manufactured by this occupation
allows different combinations of income and
amenities that are complementary.
VI. Conclusion
Despite the importance of diversity in eco-
nomic life, only a small part of economic theory
is devoted to analyzing differences. Competi-
tive markets value diversity and sort out com-
plex patterns of tastes and technologies that
translate into supply of and demand for an enor-
mous variety of products and factors of pro-
duction. Markets accommodate diversity by
establishing values that make differentiated
items relatively close substitutes at the margin.
The markets match buyers and sellers in
marriage-type equilibria where agents sort ac-
cording to their talents in response to market
prices. To bring about the appropriate sorting,
markets must create inequality in values. Thus, in
labor markets, large differences in earnings can
result even when individuals are ex ante identical.
The theory of diversity applies universally
and is manifest in many economic problems. In
addition to issues involving earnings inequality,
occupational choice, and the differentiation of
products, risk analysis of environmental safety
concerns and price index problems are analyz-
able using standard economic approaches to
diversity. In such problems, sorting is key, so
market valuations understate the average indi-
vidual's distaste for disagreeable attributes and
overstate the average individual's preference for
agreeable ones. Sorting plays a role in price index
problems, where we seek to ascertain shifts in
prices as a result of technology shifts, not move-
ments along a price line that results, say, from
increases in real income. Thus, price might appear
to rise because richer people buy new varieties of
a commodity that has superior attributes that are
not captured in standard measurement.
Although tastes may differ, it is the reserva-
tion prices themselves and not the causes of the
differences that have consequence for economic
allocation. Differences in talents are behind
much of occupational choice where the theory
of comparative advantage is central. Individuals
specialize in skills because the fixed costs of
skill acquisition is only loosely linked to the
levels of utilization. It pays for a worker to learn


### ---Economics-2002-0-16.txt---
one thing well and exploit it over and over
again. Talents are multidimensional in general,
so those who go on to college are better at
college jobs than those individuals who do not
go on to college. But the converse is also true:
Those who opt against college are better at their
jobs than those who complete college would be
at noncollege jobs. Rather than strict hierarchy,
comparative and even some absolute advantage
play important roles.
This essay has explored three themes: Mar-
kets value diversity, markets sort buyers and
sellers appropriately to take advantage of heter-
ogeneous talents and tastes, and sorting and
choice create income inequality.
Value is determined in diverse markets in the
standard way, equating supply with demand.
The difference is that there are more margins on
which to operate. Not only is quantity a choice
variable, but consumers and producers can sub-
stitute along varying dimensions of quality.
Equilibrium is established when no seller can be
made better off by altering the quality of his
product and offering it to different buyers and
when no buyer can be made better off by sub-
stituting a different quality good for the one that
he currently consumes.
Just as value is determined by market equi-
librium, so too is the allocation of buyers to
sellers set by the market. Sellers who have a
comparative advantage in producing high-
quality products sell to consumers who are will-
ing to pay a sufficient premium for additional
quality. Conversely, sellers who have a compar-
ative advantage in producing low-quality goods
cheaply cater to consumers who prefer to sub-
stitute away from high quality so that they can
spend the saved dollars on other goods.
Finally, income inequality results from heter-
ogeneity. Some of this is determined by nature
as individuals are born with different abilities,
but inequality is also manufactured by actions
that individuals take. The most obvious actions
involve investments in human capital, either
through formal schooling or work experience.
Such investments create inequality, but are ben-
eficial to individuals and society as a whole
because they improve the overall standard of
living. A more subtle variant involves gambles
that individuals take as they choose to enter
risky occupations or make risky investments.
Because of indivisibilities, risky payoffs allow
individuals to couple the consumption of large
amounts of some goods with high-quality ver-
sions of others, such as living in expensive
cities when income turns out to be high. Losers
of occupational lotteries combine their lower
consumption with lower-quality indivisible
goods, consuming less and living in less expen-
sive cities. Expected utility is higher than it
would be, absent this type of inequality.
Markets value diversity. Individuals, using
their respective talents and different prefer-
ences, respond to these valuations and create
important induced differentiation in consump-
tion patterns, earnings, and occupational choices.
## Economics-2003-0


### ---Economics-2003-0-02.txt---
Macroeconomics was born as a distinct field
in the 1940's, as a part of the intellectual re-
sponse to the Great Depression. The term then
referred to the body of knowledge and expertise
that we hoped would prevent the recurrence of
that economic disaster. My thesis in this lecture
is that macroeconomics in this original sense
has succeeded: Its central problem of depression
prevention has been solved, for all practical
purposes, and has in fact been solved for many
decades. There remain important gains in wel-
fare from better fiscal policies, but I argue that
these are gains from providing people with bet-
ter incentives to work and to save, not from
better fine-tuning of spending flows. Taking
U.S. performance over the past 50 years as a
benchmark, the potential for welfare gains from
better long-run, supply-side policies exceeds by
far the potential from further improvements in
short-run demand management.
My plan is to review the theory and evidence
leading to this conclusion. Section I outlines the
general logic of quantitative welfare analysis, in
which policy comparisons are reduced to differ-
ences perceived and valued by individuals. It
also provides a brief review of some exam-
ples-examples that will be familiar to
many-of changes in long-run monetary and
fiscal policies that consumers would view as
equivalent to increases of 5-15 percent in their
overall consumption levels.
Section II describes a thought-experiment in
which a single consumer is magically relieved
of all consumption variability about trend. How
much average consumption would he be willing


### ---Economics-2003-0-03.txt---
welfare gain for the group. We can also specify
the compensation in terms of one or a subset
of goods, rather than all of them: There is no
single, right way to carry these comparisons out.
However it is done, we obtain a method for
evaluating policies that has comprehensible units
and is built up from individual preferences.
There is a great tradition of quantitative pub-
lic finance that applies this general framework
using well-chosen Taylor expansions to calcu-
late estimates of the compensation parameter A,
"welfare triangles" as Arnold C. Harberger
called them. Today we use numerical simula-
tion of general-equilibrium models, often dy-
namic and subject to unpredictable shocks, to
carry out welfare analysis with the general logic
that I have just sketched. Some examples will, I
hope, convey the applicability of this approach
and some of the estimates that have emerged.
Martin J. Bailey's (1956) thought-experiment
of a perfectly predictable inflation at a constant
rate, induced by sustained growth in the money
supply, was a pioneering example of the quan-
titative evaluation of policy. In a replication of
the Bailey study, I estimated the welfare gain
from reducing the annual inflation rate from 10
to 0 percent to be a perpetual consumption flow
of 1 percent of income.1 Some economists take
estimates like this to imply that inflation is a
relatively modest problem, but 1 percent of in-
come is a serious amount of money, and in any
case, the gain depends on how much inflation
there is. The gain from eliminating a 200-
percent annual inflation-well within the range
of recent experience in several South American
economies-is about 7 percent of income.
The development of growth theory, in which
the evolution of an economy over time is traced
to its sources in consumer preferences, technol-
ogy, and government policies, opened the way
for extending general-equilibrium policy analy-
sis to a much wider class of dynamic settings. In
the 1980's, a number of economists used ver-
sions of neoclassical growth theory to examine
the effects of taxation on the total stock of
capital, not just the composition of that stock.2
The models used in these studies differ in their
' Lucas (2000). My estimates are based on the money
demand estimates in Allan H. Meltzer (1963).  2 For example, William A. Brock and Stephen J.
Tumovsky (1981), Christophe P. Chamley (1981), Law-
details, but all were variations on a one-good
growth model in which consumers (either an
infinitely lived dynasty or a succession of gen-
erations) maximize the utility of consumption
and leisure over time, firms maximize profit,
and markets are continuously cleared.
In general, these studies found that reducing
capital income taxation from its current U.S.
level to zero (using other taxes to support an
unchanged rate of government spending) would
increase the balanced-growth capital stock by
30 to 60 percent. With a capital share of around
0.3, these numbers imply an increase of con-
sumption along a balanced growth path of 7.5 to
15 percent. Of course, reaching such a balanced
path involves a period of high investment rates
and low consumption. Taking these transition
costs into account, overall welfare gains amount
to perhaps 2 to 4 percent of annual consump-
tion, in perpetuity.
Production per adult in France is about 70
percent of production per adult in the United
States. Edward C. Prescott (2002) observes that
hours worked per adult in France, measured as
a fraction of available hours, are also about 70
percent of the comparable U.S. figure. Using
estimates for France and the United States of the
ratio (1 + Tr)/( - Th) that equals the mar-
ginal rate of substitution between consumption
and leisure in the neoclassical growth model, he
shows that tax differences can account for the
entire difference in hours worked and, amplified
by the indirect effect on capital accumulation,
for the entire difference in production. The
steady-state welfare gain to French households
of adopting American tax rates on labor and
consumption would be the equivalent of a con-
sumption increase of about 20 percent. The con-
clusion is not simply that if the French were to
work American hours, they could produce as
much as Americans do. It is that the utility
consequences of doing so would be equivalent
to a 20-percent increase in consumption with no
increase in work effort!
The gain from reducing French taxes to U.S.
levels can in part be viewed as the gain from
adopting a flat tax on incomes,3 but it is doubt-
rence H. Summers (1981), Alan J. Auerbach and Laurence  J. Kotlikoff (1987), and Kenneth L. Judd (1987).  3 See also Robert E. Hall and Alvin Rabushka (1995).
2
MARCH 2003


### ---Economics-2003-0-04.txt---
ful that all of it can be obtained simply by
rearranging the tax structure. It entails a reduc-
tion in government spending as well, which
Prescott interprets as a reduction in the level of
transfer payments, or in the government provi-
sion of goods that most people would buy any-
way, financed by distorting taxes. Think of
elementary schooling or day care. The gains
from eliminating such fiscal "cross-hauling" (as
Sherwin Rosen [1996] called the Swedish day-
care system) involve more than eliminating "ex-
cess burden," but they may well be large.
The stakes in choosing the right monetary
and fiscal policies are high. Sustained inflation,
tax structures that penalize capital accumulation
and work effort, and tax-financed government
provision of private goods all have uncompen-
sated costs amounting to sizeable fractions of
income. We can see these costs in differences in
economic performance across different countries
and time periods. Even in the United States,
which visibly benefits from the lowest excess
burdens in the modem world, economic analy-
sis has identified large potential gains from fur-
ther improvements in long-run fiscal policy.
II. Gains from Stabilization:
A Baseline Calculation
In the rest of the lecture, I want to apply the
public finance framework just outlined to the
assessment of gains from improved stabilization
policy. Such an exercise presupposes a view of
the workings of the economy in which short-run
monetary and fiscal policies affect resource al-
location in ways that are different from the
supply side effects I have just been discussing.
One possibility is that instability in the quan-
tity of money or its rate of growth, arising from
government or private sources, induces ineffi-
cient real variability. If that were all there was
to it, the ideal stabilization policy would be to
fix the money growth rate. (Of course, such a
policy would require the Federal Reserve to
take an active role in preventing or offsetting
instabilities in the private banking system.) But
this cannot be all there is to it, because an
economy in which monetary fluctuations induce
real inefficiencies-indeed, any economy in
which money has value-must be one that op-
erates under missing markets and nominal ri-
gidities that make changes in money into  something other than mere units changes. Then
it must also be the case that these same rigidities
prevent the economy from responding effi-
ciently to real shocks, raising the possibility that
a monetary policy that reacts to real shocks in
some way can improve efficiency.
If we had a theory that could let us sort these
issues out, we could use it to work out the
details of an ideal stabilization policy and to
evaluate the effects on welfare of adopting it.
This seems to me an entirely reasonable re-
search goal-I have been thinking success is
just around the comer for 30 years-but it has
not yet been attained. In lieu of such a theory, I
will try to get quantitative sense of the answer to
the thought-experiment I have posed by study-
ing a series of simpler thought-experiments.
In the rest of this section, I ask what the effect
on welfare would be if all consumption vari-
ability could be eliminated.4 To this end, con-
sider a single consumer, endowed with the
stochastic consumption stream
(1) c, = Aete- (l/2)r2e,
where log(se) is a normally distributed random
variable with mean 0 and variance oC2. Under
these assumptions
E(e-(1/2)t02tt) = 1
and mean consumption at t is Ae t. Preferences
over such consumption paths are assumed to be
(2) E{ ;-y},
1 + p 1-y '
where p is a subjective discount rate, y is the
coefficient of risk aversion, and the expectation
is taken with respect to the common distribution
of the shocks so, el ... .
Such a risk-averse consumer would obvi-
ously prefer a deterministic consumption path
to a risky path with the same mean. We quantify
this utility difference by multiplying the risky
path by the constant factor 1 + A in all dates
and states, choosing A so that the household is
4 This calculation replicates the one I carried out in
Lucas (1987, Ch. Il).
VOL. 93 NO. I
3


### ---Economics-2003-0-05.txt---
indifferent between the deterministic stream
and the compensated, risky stream. That is, A is
chosen to solve
(3) E: E t ((1 + A)ct) l-
Many questions have been raised about this
estimate, and subsequent research on this issue
has pursued many of them, taking the discus-
sion deep into new scientific territory. In the
next four sections, I will review some of the
main findings.
III. Removeable Variance: Two Estimates
(Aegt)l -Y
t=0
where ct is given by (1). Canceling, taking logs,
and collecting terms gives
(4) A ^ YI '2.
A 2 y r
This compensation parameter A-the welfare
gain from eliminating consumption risk-
depends, naturally enough, on the amount of
risk that is present, cr2, and the aversion people
have for this risk, y.
We can get an initial idea of the value to the
economy as a whole of removing aggregate risk
by viewing this agent as representative of U.S.
consumers in general. In this case, to estimate A
we need estimates of the variance o02 of the log
of consumption about its trend, and of the co-
efficient y of risk aversion. Using annual U.S.
data for the period 1947-2001, the standard
deviation of the log of real, per capita consump-
tion about a linear trend is 0.032.5 Estimates of the
parameter y in use in macroeconomics and pub-
lic finance applications today range from 1 (log
utility) to 4. Using log utility, for example, the
formula (4) yields the welfare cost estimate
(5) A = (0.032)2 = 0.0005,
about one-twentieth of 1 percent of consumption.
Compared to the examples of welfare gains
from fiscal and monetary policy changes that I
cited above, this estimate seems trivially small:
more than an order of magnitude smaller than
the gain from ending a 10-percent inflation!
5 The comparable figure using a Hodrick-Prescott trend  with the smoothing parameter 400 is 0.022.  Even if we do not know exactly how much
consumption risk would be removed by an op-
timal monetary and fiscal policy, it is clear that
it would fall far short of the removal of all
variability. The major empirical finding in mac-
roeconomics over the past 25 years was the
demonstration by Finn E. Kydland and Prescott
(1982), replicated and refined by Gary D.
Hansen (1985) and by many others since then,
that technology shocks measured by the method
of Robert M. Solow (1957) can induce a rea-
sonably parameterized stochastic growth model
to exhibit nearly the same variability in produc-
tion and consumption as we see in postwar U.S.
time series. In the basic growth model, equilib-
rium and optimal growth are equivalent, so that
if technology shocks are all there is to postwar
business cycles, resources are already being al-
located efficiently and a variance-reducing
monetary-fiscal policy would be welfare reduc-
ing. Even if the equilibrium is inefficient, due to
distorting taxes, missing markets or the like, in
the face of unavoidable technology and prefer-
ence shocks an optimal monetary and fiscal
policy will surely be associated with a positive
level of consumption variance. We need to es-
timate the size of that part and remove it from
the estimate of ao used in (4).
Matthew D. Shapiro and Mark W. Watson's
(1988) study is one of several relatively atheo-
retical attempts to break down the variance of
production and other variables into a fraction
due to what these authors call "demand" shocks
(and which I will call "nominal" shocks) and
fractions due to technology and other sources.
Their study represents quarterly U.S. time series
over the period 1951-1985 as distributed lags of
serially independent shocks. The observables
include first differences of a measure of hours
worked, a log real GDP measure, and the cor-
responding implicit price deflator. To these
three rates of change are added an ex post real
interest rate (the three-month Treasury bill rate
4
MARCH 2003


### ---Economics-2003-0-06.txt---
minus the inflation rate) and the change in the
relative price of oil. The coefficients of an in-
vertible vector autoregression are estimated,
subject to several restrictions. This procedure
yields time series of estimated shocks g t and
decompositions of the variance of each of the
five variables into the fractions "explained" by
the most recent k values of each of the five
shocks.
Shapiro and Watson apply a variety of the-
oretical principles to the interpretation of
their estimates. They do not consistently fol-
low the general-equilibrium practice of inter-
preting all shocks as shifts in preferences,
technologies, or the behavior of policy vari-
ables, but they have in mind some kind of
monetary growth model that does not have a
long-run Phillips curve.6 Real variables, in
the long run, are determined by real factors
only. Nominal shocks can affect real variables
and relative prices in the short run but not in
the long run. This idea is not tested: Long-run
neutrality is imposed on the statistical model.
In return it becomes possible to estimate sep-
arately the importance of nominal shocks to
the short- and medium-run variability of out-
put, hours, and real interest rates.7
In the five-variable scheme that Shapiro and
Watson use, there are two nominal variables-
the inflation rate and the nominal interest rate-
and three real ones-output, hours, and the
relative price of oil. They assume as well five
shocks, two of which are nominal in the sense
of having no effect on real variables in the long
run. They are not able to measure the effects of
the two dimensions of nominal instability sep-
arately. The other three shocks are taken to be
real. The assumed exogeneity of oil price
shocks plus a long-run neutrality hypothesis on
hours are used to estimate the importance of
three distinct real shocks. This aspect of their
identification seems to me questionable, and in
any case it is of an entirely different nature from
the neutrality of nominal shocks. I will just
lump the effects of the real shocks together, as
6 To remove any doubt on the latter point, they quote  from Milton Friedman's (1968) Presidential Address.
7 A similar, and similarly motivated, identification pro-  cedure was used in Olivier J. Blanchard and Danny Quah  (1989). Thomas J. Sargent and Christopher A. Sims (1977)  is a predecessor in spirit, if not in detail.  TABLE 1-PERCENTAGE OF VARIANCE DUE TO NOMINAL  SHOCKS AT DIFFERENT FORECAST HORIZONS
Quarter Output Hours Inflation Interest rate
1 28 36 89 83
4 28 40 82 71
8 20 31 82 72
12 17 27 84 74
20 12 20 86 79
36 8 12 89 85
x0 0 0 94 94
Shapiro and Watson do with the two nominal
shocks, and interpret their paper as partitioning
the variance of output and hours into nominal
and real sources. The resulting Table 1 is a
condensation of their Table 2.
The two zeroes for output and hours in the
last, long-run, row of Table 1 are there by the
definition of a nominal shock. But the two 94-
percent entries in this row for inflation and the
nominal interest rate could have come out any
way. I take the fact that these values are so close
to 1 as a confirmation of Shapiro and Watson's
procedure for identifying nominal shocks. Ac-
cording to Table 1, these nominal shocks have
accounted for something less than 30 percent of
short-run production variability in the postwar
United States. This effect decays slowly, with
no change after one year, a reduction to 20
percent after two years, and so on.
One can ask whether a better estimate of the
importance of nominal shocks could have ob-
tained by using Ml or some other observable
measure of monetary shocks. Many studies
have proceeded in this more direct way,8 and
much has been learned, but in the end one does
not know whether the importance of monetary
shocks has been estimated or just the impor-
tance of a particular, possibly very defective,
measure of them. Information on future prices is
conveyed to people by changes in monetary
aggregates, of course, but it is also conveyed by
interest-rate and exchange-rate movements, by
changes in the fiscal situation that may lead to
tighter or easier money later on, by changes in
financial regulations, by statements of influen-
tial people, and by many other factors. Shapiro
and Watson's method bypasses these hard
8 For example, Lawrence J. Christiano, et al. (1996).
VOL. 93 NO. 1
5


### ---Economics-2003-0-07.txt---
measurement questions and goes directly to an
estimation of the importance of nominal shocks
in general, those we know how to measure and
those we do not, whatever they may be.
A second reason for preferring the procedure
Shapiro and Watson used is that the effects of
nominal shocks as they estimate them include
the effects of real shocks that could have been
offset by monetary policy but were not. What-
ever it is that keeps prices from rising in pro-
portion to a given increase in money must also
keep relative prices from adjusting as neoclas-
sical theory would predict they should to, say,
an increase in the OPEC-set price of oil. Effects
of either kind-those initiated by monetary
changes and those initiated by real shocks-will
last only as long as the rigidity or glitch that
gives rise to them lasts, vanishing in the long
run, and will be identified as arising from the
"nominal," or "demand," shock under the Sha-
piro and Watson identification procedure. Thus
I want to interpret the estimates in columns 2
and 3 of Table 1 as upper bounds on the vari-
ance that could have been removed from output
and hours at different horizons under some
monetary policy other than the one actually
pursued. The table gives no information on
what this variance-minimizing monetary policy
might have been, and there is no presumption
that it would have been a policy that does not
respond to real shocks.
Shapiro and Watson applied the theoretical
idea that nominal shocks should be neutral in
the long run to obtain an estimate of the fraction
of short-run output variability that can be attrib-
uted to such shocks. Prescott (1986a) proceeded
in a quite different way to arrive at an estimate
of the fraction of output variability that can be
attributed to technology shocks. He used actual
Solow residuals to estimate the variance and
serial correlation of the underlying technology
shocks. Feeding shocks with these properties
into a fully calibrated real-business-cycle model
resulted in output variability that was about 84
percent of actual variability.9 In a complemen-
tary study, S. Rao Aiyagari (1994) arrived at an
estimate of 79 percent for the contribution of
9 Questions of measurement errors are discussed in the  paper and by Summers (1986) in the same volume. In  Prescott (1986b), estimates of 0.5 to 0.75 for the contribu-  tion of technology shocks to output variance are proposed.  technology shocks, based on comovements of
production and labor input over the cycle.
Shapiro and Watson find that at most 30
percent of cyclical output variability can be
attributed to nominal shocks. Working from the
opposite direction, Prescott and Aiyagari con-
clude that at least 75 percent of cyclical output
variability must be due to technology shocks.
These findings are not as consistent as they may
appear, because there are important real factors
besides technological shocks-shocks to the tax
system, to the terms of trade, to household tech-
nology, or to preferences-that are cyclically
important but not captured in either of the cat-
egories I have considered so far.l? Even so, on
the basis of this evidence I find it hard to imag-
ine that more than 30 percent of the cyclical
variability observed in the postwar United
States could or should be removed by changes
in the way monetary and fiscal policy is
conducted.
IV. Risk Aversion
The estimate of the potential gains from sta-
bilization reviewed in Section II rests on as-
sumed consumer preferences of the constant
relative risk aversion (CRRA) family, using but
two parameters-the subjective discount rate p
and the risk-aversion coefficient y-to charac-
terize all households. This preference family is
almost universally used in macroeconomic and
public finance applications. The familiar for-
mula for an economy's average return on capital
under CRRA preferences,
(6) r = p + yg,
where g is the growth rate of consumption,
makes it clear why fairly low 3y values must be
used. Per capita consumption growth in the
United States is about 0.02 and the after-tax
return on capital is around 0.05, so the fact that
p must be positive requires that y in (6) be at
most 2.5. Moreover, a value as high as 2.5
would imply much larger interest rate differen-
lO For example, Shapiro and Watson attribute a large  share of output variance to a shock which they call "labor  supply" [and which I would call "household technology,"
following Jess Benhabib et al. (1991) and Jeremy
Greenwood and Zvi Hercowitz (1991)].
6
MARCH 2003


### ---Economics-2003-0-08.txt---
tials than those we see between fast-growing
economies like Taiwan and mature economies
like the United States. This is the kind of evi-
dence that leads to the use of y values at or near
1 in applications.
But the CRRA model has problems. Rajnish
Mehra and Prescott (1985) showed that if one
wants to use a stochastic growth model with
CRRA preferences to account for the entire
return differential between stocks and bonds-
historically about 6 percent-as a premium for
risk, the parameter y must be enormous, per-
haps 50 or 100.11 Such values obviously cannot
be squared with (6). This "equity premium puz-
zle" remains unsolved, and has given rise to a
vast literature that is clearly closely related to
the question of assessing the costs of
instability.12
One response to the puzzle is to adopt a
three- rather than two-parameter description
of preferences. Larry G. Epstein and Stanley
E. Zin (1989, 1991) and Philippe Weil (1990)
proposed different forms of recursive utility,
preference families in which there is one pa-
rameter to determine intertemporal substitut-
ability and a second one to describe risk
aversion. The first corresponds to the param-
eter y in (6), and can be assigned a small
value to fit estimated average returns to cap-
ital. Then the risk-aversion parameter can be
chosen as large as necessary to account for
the equity premium.
Thomas D. Tallarini, Jr. (2000) uses prefer-
ences of the Epstein-Zin type, with an intertem-
poral substitution elasticity of 1, to construct a
real-business-cycle model of the U.S. economy.
He finds an astonishing separation of quantity
and asset price determination: The behavior of
aggregate quantities depends hardly at all on
attitudes toward risk, so the coefficient of risk
aversion is left free to account for the equity
premium perfectly.13 Tallarini estimates a wel-
fare cost of aggregate consumption risk of 10
percent of consumption, comparable to some
11 See also Lars Peter Hansen and Kenneth J. Singleton  (1983).  12 Two especially informative surveys are John H.  Cochrane and Hansen (1992) and Narayana R. Kocherla-
kota (1996).  13 Similar results, obtained in a closely related context,  were reported by Hansen et al. (1999).  of the supply-side gains cited in Section I, and
two orders of magnitude larger than the estimate
I proposed in Section II.14 As Maurice Obstfeld
(1994) shows, this result is basically the for-
mula (4) with a coefficient of risk aversion two
orders of magnitude larger than the one I used.
Fernando Alvarez and Urban J. Jermann
(2000) take a nonparametric approach to the
evaluation of the potential gains from stabiliza-
tion policy, relating the marginal cost of busi-
ness-cycle risk to observed market prices
without ever committing to a utility function.
Their estimation procedure is based on the ob-
servation that consumption streams with a wide
variety of different risk characteristics-or
something very nearly equivalent to them-are
available for sale in securities markets. They
use a mix of asset-pricing theory and statistical
methods to infer the prices of a claim to the
actual, average consumption path and alterna-
tive consumption paths with some of the uncer-
tainty removed. They call the price differentials
so estimated marginal welfare costs, and show
that they will be upper bounds to the corre-
sponding total cost: my compensation parame-
ter A. The basic underlying hypotheses are that
asset markets are complete and that asset-price
differences reflect risk and timing differences
and nothing else.
The gain from the removal of all consump-
tion variability about trend, estimated in this
way, is large-around 30 percent of consump-
tion.15 This is a reflection of the high risk aver-
sion needed to match the 6-percent equity
premium, and can be compared to Tallarini's
estimate of 10 percent. But the gain from re-
moving risk at what Alvarez and Jermann call
business-cycle frequencies-cycles of eight
14 James Dolmas (1998) uses still another preference  family, obtaining much higher cost estimates than mine.  Like Tallarini, Christopher Otrok (1999) develops and an-
alyzes a complete real-business-cycle model. He uses a  preference family proposed by John Heaton (1995). His cost  estimates are close to mine. A recent paper by Anne
Epaulard and Aude Pommeret (2001) contains further  results along this line, and provides a very useful quantita-  tive comparison to earlier findings.  15 Alvarez and Jermann offer many estimates in their  Tables 2A-2D. My summary is based on Table 2D, which  uses postwar (1954-1997) data and requires that consump-  tion and dividends be cointegrated. From this table, I follow  the authors and cite averages over the columns headed "8  years" and "inf."
VOL. 93 NO. 1
7


### ---Economics-2003-0-09.txt---
years or less-is two orders of magnitude
smaller, around 0.3 percent. Most of the high
return on equity is estimated to be compensation
for long-term risk only, risk that could not be
much reduced by short-run policies that are
neutral in the long run.
Accepting Shapiro and Watson's finding that
less that 30 percent of output variance at
business-cycle frequencies can be attributed to
nominal shocks, the lower Alvarez and Jermann
estimate of 0.3 should be reduced to 0.1 if it is
to serve my purpose as an estimate of the value
of potential improvements in stabilization pol-
icy. But it is important to keep in mind that this
estimate is not smaller than Tallarini's because
of a different estimate of risk aversion. Tallarini's
estimate of y - 100 is the parametric analogue
of Alvarez and Jermann's "market price of
risk," based on exactly the same resolution of
the equity premium puzzle. The different cost
estimate is entirely due to differences in the
consumption paths being compared.
Resolving empirical difficulties by adding
new parameters always works, but often only by
raising more problems. The risk-aversion levels
needed to match the equity premium, under the
assumption that asset markets are complete,
ought to show up somewhere besides securities
prices, but they do not seem to do so. No one
has found risk-aversion parameters of 50 or 100
in the diversification of individual portfolios, in
the level of insurance deductibles, in the wage
premiums associated with occupations with
high earnings risk, or in the revenues raised by
state-operated lotteries. It would be good to
have the equity premium resolved, but I think
we need to look beyond high estimates of risk
aversion to do it. The great contribution of
Alvarez and Jermann is to show that even using
the highest available estimate of risk aversion,
the gain from further reductions in business-
cycle risk is below one-tenth of 1 percent of
consumption. The evidence also leaves one free
to believe-as I do-that the gain is in fact one
or two orders of magnitude smaller.
V. Incomplete Markets and Distribution Effects
The calculations I have described so far treat
households as identical and individual risks as
diversifiable. But as Per Krusell and Anthony A.
Smith, Jr. (1999) observe, "it is quite plausible  that the welfare costs of cycles are not so high
on average, but may be very high for, say, the
very poor or currently unemployed members of
society." Several recent studies have pursued
this possibility.16 Doing so evidently requires
models with incomplete risk sharing and differ-
ently situated agents.
Krusell and Smith (1999, 2002) study a
model economy in which individual families
are subject to three kinds of stochastic shocks.
There is an aggregate productivity shock that
affects everyone, and employment shocks that
differ from person to person. Families are infi-
nitely lived dynasties, but every 40 years or so
a family draws a new head, whose subjective
discount rate is drawn from a fixed distribution.
Dynasties with patient heads will accumulate
wealth while others will run their wealth
down.17 The sizes of these shocks are chosen so
that the model economy experiences realistic
GDP fluctuations, unemployment spells have
realistic properties, and the overall wealth dis-
tribution matches the U.S. distribution: In the
model, the wealthiest 5 percent of households
own 54 percent of total wealth; in reality, they
hold 51 percent.
It is essential to the substantive question that
motivates this study that neither the employ-
ment shocks nor the uncertainty about the char-
acter of the household head can be diversified
away. Otherwise, the individual effects of the
aggregate productivity shocks would be the
same as in the representative agent models I
have already discussed. One may argue over
why it is that markets do not permit such diver-
sification, but it seems clear enough that they do
not: Where is the market where people can be
insured against the risk of having irresponsible
or incompetent parents or children?
These exogenous forces acting differentially
across households induce different individual
choices, which in turn lead to differences in
individual capital holdings. The state space in
this economy is very large, much larger than
i6 For example, Ayse Imrohoroglu (1989), Andrew  Atkeson and Christopher Phelan (1994), Krusell and Smith  (1999, 2002), Kjetil Storesletten et al. (2001), and Tom
Krebs (2002).  17 This way of modeling wealth changes within a fixed  distribution across families was introduced in John Laitner  (1992).
8
MARCH 2003


### ---Economics-2003-0-10.txt---
anything people were working with numerically
15 years ago, and without the method developed
in Krusell and Smith (1998) it would not have
been possible to work out the predictions of this
model. A key simplification comes from the fact
that the impact on any one family of the shocks
that hit others has to work through two prices,
the real wage and the rental price of capital.
These prices in turn depend only on the total
stock of capital, regardless of the way it is
distributed, and total employment, regardless of
who has a job and who does not. By exploiting
these features, solutions can be calculated using
an iterative procedure that works like a dream:
For determining the behavior of aggregates,
they discovered, realistically modeled house-
hold heterogeneity just does not matter very
much.
For individual behavior and welfare, of
course, heterogeneity is everything. In the
thought-experiments that Krusell and Smith run
with their model, removal of the business cycle
is defined to be equivalent to setting the aggre-
gate productivity shock equal to a constant. It is
important to be clear on what the effect of such
a change would be on the behavior of the em-
ployment shocks to which individuals are sub-
ject, but the magical character of the experiment
makes it hard to know how this question is best
resolved. I will describe what Krusell and Smith
did, and deal with some other possibilities later on.
Suppose that a shock y = az + - affects an
individual's behavior, where z is the aggregate
shock and e is idiosyncratic. We project the
individual shock on the aggregate, e = cz + 7J,
where the residual qr is uncorrelated with z, and
then think of an ideal stabilization policy as one
that replaces
y = az + e = (a + c)z + r1
with
y = (a + c)E(z) + *1.
Not only is the direct effect of the productivity
shock z removed but also the indirect effects of
z on the individual employment shocks e.18 In
18 This is a linear illustration of the more generally  defined procedure described in Krusell and Smith (1999).  this particular application, removing the vari-
ance of the aggregate shock is estimated to
reduce the standard deviation of the individual
employment shocks by 16 percent.19
The first such thought-experiment Krusell
and Smith describe involves a comparison be-
tween the expected utility drawn from the
steady state of the economy with aggregate
shocks and the expected utility from the steady
state of the economy with aggregate shocks and
their indirect effects removed in the way I have
just described. The welfare gain from eliminat-
ing cycles in this sense turns out to be negative!
In a model, like this one, in which markets for
risk pooling are incomplete, people will engage
in precautionary savings, overaccumulating
capital in the effort to self-insure. This implies
larger average consumption in the more risky
economy. Of course, there are costs to accumu-
lating the higher capital stock, but these costs are
not fully counted in a steady-state comparison.
In any case, as Krusell and Smith emphasize,
there is nothing really distributional about a
steady-state comparison: Every infinitely lived
dynasty is assigned a place in the wealth distri-
bution at random, and no one of them can be
identified as permanently rich or poor. The
whole motivation of the paper is to focus on the
situation of people described as "hand-to-mouth
consumers," but a steady-state comparison
misses them. This observation motivates a sec-
ond thought-experiment-one with much more
complicated dynamics than the first-in which
an economy is permitted to reach its steady-
state wealth distribution with realistic aggregate
shocks, and then is relieved of aggregate risk.
The full transition to a new steady state is then
worked out and taken into account in the utility
comparisons. In this experiment, we can iden-
tify individuals as "rich" or "poor" by their posi-
tion in the initial wealth distribution, and discuss
the effects of risk removal category by category.
The average welfare gain in this second ex-
periment is about 0.1 of 1 percent of consump-
tion, about twice the estimate in Section II of
this paper. (Krusell and Smith also assume log
utility.) But this figure masks a lot of diversity.
Low wealth, unemployed people-people who
19 Here and below, the numbers I cite are taken from
Krusell and Smith (2002).
VOL. 93 NO. 1
9


### ---Economics-2003-0-11.txt---
would borrow against future labor income if
they could-enjoy a utility gain equivalent to a
4-percent perpetual increase in consumption.
Oddly, the very wealthy can also gain, as much
as 2 percent. Krusell and Smith conjecture that
this is due to the higher interest rates implied by
the overall decrease in precautionary savings
and capital. Finally, there is a large group of
middle wealth households that are made worse
off by eliminating aggregate risk.
These calculations are sensitive-especially at
the poor end of the distribution-to what is as-
sumed about the incomes of unemployed people.
Krusell and Smith calibrate this, roughly, to cur-
rent U.S. unemployment insurance replacement
rates. If one were estimating the costs of the de-
pression of the 1930's, before the current welfare
system was in place, lower rates would be used
and the cost estimates would increase sharply.20 It
would also be interesting to use a model like this
to examine the trade-offs between reductions in
aggregate risk and an improved welfare system.
Storesletten et al. (2001) study distributional
influences on welfare cost estimates with meth-
ods that are closely related to Krusell and
Smith's, but they obtain larger estimates of the
gains from removing all aggregate shocks. They
use an overlapping generations setup with 43
working age generations, in which the youngest
cohort is always credit constrained. In such a
setting, the young are helpless in the face of
shocks of all kinds and reductions in variance
can yield large welfare gains. But if the age
effects are averaged out to reflect the impor-
tance of intrafamily lending (as I think they
should be) the gains estimated by Storesletten et
al. under log utility are no larger than Krusell
and Smith's.21 In contrast to earlier studies,
however, the Storesletten et al. model implies
that estimated welfare gains rise faster than
proportionately as risk aversion is increased:
From Exhibit 2, for example, the average gain
increases from 0.6 of a percent to 2.5 as y is
increased from 2 to 4.
Two features of the theory interact to bring
this about.22 First, and most crucial, is a differ-
20 See Satyajit Chatterjee and Dean Corbae (2000).  21 Based on Exhibits 2 and A.3.1.
22 Storesletten et al. do a good job of breaking the  differences into intelligible pieces. I also found the example  explicitly solved in Krebs (2002) very helpful in this regard.  ence in the way reductions in the variance of
aggregate shocks affect risks faced at the indi-
vidual level. In the Storesletten et al. simula-
tions, a bad realization of the aggregate
productivity shock increases the conditional
variance of the idiosyncratic risk that people
face, so aggregate and individual risks are com-
pounded in a way that Krusell and Smith rule
out. A second difference is that idiosyncratic
shocks are assumed to have a random walk
component, so their effects are long lasting. A
bad aggregate shock increases the chances that
a young worker will draw a bad individual
shock, and if he does he will suffer its effects
throughout his prime working years.
The effects of these two assumptions are
clear: They convert small, transient shocks at
the aggregate level into large, persistent shocks
to the earnings of a small fraction of house-
holds. Whether they are realistic is question of
fact. That individual earnings differences are
highly persistent has been clear since Lee
Lillard and Robert Willis's pioneering (1978)
study. The fanning out over time of the earnings
and consumption distributions within a cohort
that Angus Deaton and Christina Paxson (1994)
document is striking evidence of a sizeable,
uninsurable random walk component in earn-
ings. The relation of the variance of earnings
shocks to the aggregate state of the economy,
also emphasized by N. Gregory Mankiw (1986)
in connection with the equity premium puzzle,
has only recently been studied empirically.
Storesletten et al. find a negative relation over
time between cross-section earnings means and
standard deviations in Panel Studies of Income
Dynamics data. Costas Meghir and Luigi
Pistaferri (2001) obtain smaller estimates, but
also conclude that "the unemployment rate and
the variance of permanent [earnings] shocks
appear to be quite synchronized" in the 1970's
and 1980's.
These issues are central to an accurate de-
scription of the risk situation that individual
agents face, and hence to the assessment of
welfare gains from policies that alter this situ-
ation. The development of tractable equilibrium
models capable of bringing cross-section and
panel evidence to bear on this and other mac-
roeconomic questions is an enormous step for-
ward. But Krusell and Smith find only modest
effects of heterogeneity on the estimates of wel-
10
MARCH 2003


### ---Economics-2003-0-12.txt---
fare gains from the elimination of aggregate
risk, and even accepting the Storesletten et al.
view entails an upward revision of a factor of
only about 5.
The real promise of the Krusell-Smith model
and related formulations, I think, will be in the
study of the relation of policies that reduce the
impact of risk by reducing the variance of
shocks (like aggregate stabilization policies) to
those that act by reallocating risks (like social
insurance policies). Traditionally, these two
kinds of policies have been studied by different
economists, using unrelated models and differ-
ent data sets. But both appear explicitly in the
models I have reviewed here, and it is clear that
it will soon be possible to provide a unified
analysis of their costs and benefits.
VI. Other Directions
My plan was to go down a list of all the
things that could have gone wrong with my
1987 calculations but, as I should have antici-
pated, possibilities were added to the list faster
than I could eliminate them. I will just note
some of the more interesting of these possibil-
ities, and then conclude. The level of consump-
tion risk in a society is, in part, subject to
choice. When in an economy that is subject to
larger shocks, people will live with more con-
sumption variability and the associated loss in
welfare, but they may also substitute into risk-
avoiding technologies, accepting reduced aver-
age levels of production. This possibility shows
up in the precautionary savings-overaccumu-
lation of capital-that Krusell and Smith (1999,
2002) found. As Garey Ramey and Valerie A.
Ramey (1991) suggested, this kind of substitu-
tion surely shows up in other forms as well.
In an endogenous growth framework, substi-
tution against risky technologies can affect rates
of growth as well as output levels. Larry E.
Jones et al. (1999) and Epaulard and Pommeret
(2001) explore some of these possibilities,
though neither study attributes large welfare
gains to volatility-induced reductions in growth
rates. Gadi Barlevy (2001) proposes a convex
adjustment cost that makes an erratic path of
investment in knowledge less effective than a
smooth path at the same average level. In such
a setting, reducing shock variability can lead to
higher growth even without an effect on the  average level of investment. He obtains welfare
gains as large as 7 percent of consumption in
models based on this idea, but everything
hinges on a curvature parameter on which there
is little evidence. This is a promising frontier on
which there is much to be done. Surely there are
others.
VII. Conclusions
If business cycles were simply efficient re-
sponses of quantities and prices to unpredict-
able shifts in technology and preferences, there
would be no need for distinct stabilization or
demand management policies and certainly no
point to such legislation as the Employment Act
of 1946. If, on the other hand, rigidities of some
kind prevent the economy from reacting effi-
ciently to nominal or real shocks, or both, there
is a need to design suitable policies and to
assess their performance. In my opinion, this is
the case: I think the stability of monetary ag-
gregates and nominal spending in the postwar
United States is a major reason for the stability
of aggregate production and consumption dur-
ing these years, relative to the experience of the
interwar period and the contemporary experi-
ence of other economies. If so, this stability
must be seen in part as an achievement of the
economists, Keynesian and monetarist, who
guided economic policy over these years.
The question I have addressed in this lecture
is whether stabilization policies that go beyond
the general stabilization of spending that char-
acterizes the last 50 years, whatever form they
might take, promise important increases in wel-
fare. The answer to this question is "No": The
potential gains from improved stabilization pol-
icies are on the order of hundredths of a percent
of consumption, perhaps two orders of magni-
tude smaller than the potential benefits of avail-
able "supply-side" fiscal reforms. This answer
does depend, certainly, on the degree of risk
aversion. It does not appear to be very sensitive
to the way distribution effects are dealt with,
though it does presuppose a system of unem-
ployment insurance at postwar U.S. levels. I
have been as explicit as I can be on the way
theory and evidence bear on these conclusions.
When Don Patinkin gave his Money, Interest,
and Prices the subtitle "An Integration of Mon-
etary and Value Theory," value theory meant, to
VOL. 93 NO. 1
11


### ---Economics-2003-0-13.txt---
him, a purely static theory of general equilib-
rium. Fluctuations in production and employ-
ment, due to monetary disturbances or to shocks
of any other kind, were viewed as inducing
disequilibrium adjustments, unrelated to any-
one's purposeful behavior, modeled with vast
numbers of free parameters. For us, today, value
theory refers to models of dynamic economies
subject to unpredictable shocks, populated by
agents who are good at processing information
and making choices over time. The macroeco-
nomic research I have discussed today makes
essential use of value theory in this modem
sense: formulating explicit models, computing
solutions, comparing their behavior quantita-
tively to observed time series and other data
sets. As a result, we are able to form a much
sharper quantitative view of the potential of
changes in policy to improve peoples' lives than
was possible a generation ago.
## Economics-2004-0


### ---Economics-2004-0-02.txt---
I frequently find economists who express a
view of the system that is very far from mine.
For example, many young economists and eco-
nomics students say that they expect to get no
benefits at all from Social Security. This expec-
tation does not seem sensible to me. If there is
no legislation changing Social Security, trust
fund assets and payroll tax revenue (and reve-
nue from the taxation of benefits) are projected
to be sufficient to pay all the benefits scheduled
under current law until 2042 (Board of Trustees
of Social Security and Medicare, 2003). After
the trust fund assets are exhausted the payroll
tax revenue would continue to be available to
pay benefits, with the flow of revenues at that
time sufficient to pay roughly three-quarters of
the benefits scheduled in current law. The esti-
mate for the end of the 75-year projection pe-
riod shows enough revenue to pay roughly
two-thirds of scheduled benefits. With initial
benefits indexed to earnings, average real ben-
efits would be higher than today, although re-
placement rates would only be roughly 60
percent of current levels for the medium
worker. This projection is a far cry from no
benefits.
Moreover, I anticipate that Congress will act
before the trust fund is exhausted, both lowering


### ---Economics-2004-0-03.txt---
makes sense to have a progressive benefit for-
mula; that it makes sense to limit benefits to
those who are old enough and stop working or
are even older (whether they stop or not); and
that having been generous to early cohorts, it
makes sense now to continue with a system that
is only partially funded.
This is not to say that I agree with all of the
details of the current structure by any means. Of
course we should change benefit and tax rules
so that we restore actuarial balance-so that
projected revenues are sufficient to pay for pro-
jected benefits over at least 75 years. And other
changes would be desirable as well. I am just
arguing that the overall design of Social Secu-
rity makes good sense. In addition to presenting
the basis of my support for the broad structure
of Social Security, I will identify some rules
needing change and I will speculate on why
some economists seem to have a different view
from mine.
But I will not get into the debate of whether
there should be fully funded individual accounts
financed from existing payroll tax revenues
(carve-out accounts). Nor shall I discuss the
political and economic issues associated with
the potential role of stocks in Social Security.
Those controversial subjects would take up
most of the address and I prefer to write about
more fundamental issues. Those interested in
my view as to why carve-out accounts would
not be good policy in the United States today
can turn to Chapter 8 in my book with Peter R.
Orszag (2004), which also contains a package
of changes to restore actuarial balance and
strengthen protection of some vulnerable
groups. We discuss the potential role of stocks
as well.
I will not say much about the advantage of a
mandate to save for retirement-there is little
call for eliminating such a mandate. After a
discussion of a framework for thinking about
Social Security (Section I), I will consider an-
nuitization (Section II), treatment of the family
(Section III), the interaction among income dis-
tribution, insurance, and labor supply (Section
IV), the degree of funding (Section V), and
adjustments over time to benefits and taxes
(Section VI).3 Not discussed but worth keeping
3My approach has some similarity to the three-  dimensional analysis of different pension systems in Assar  in mind are the supporting antipoverty pro-
grams as they affect the elderly [Supplemental
Security Income (SSI) and Medicaid], and the
provision of medical insurance for the elderly
(Medicare). Nor will I discuss the Disability
Insurance program, which is a critical part of
Social Security.
I. Providing Retirement Income
One-third of the elderly received at least 90
percent of their income from Social Security in
2001, with nearly two-thirds receiving at least
half (Social Security Administration, 2003). Yet
Social Security was always meant to be a foun-
dation for retirement income and not a level to
be relied on exclusively. The average new
award for a retired worker in 2002 was just over
$900 per month. For a worker retiring in 2002 at
age 62 (the modal retirement age), a worker in
the middle of the earnings distribution received
a benefit of roughly one-third of (wage-
indexed) lifetime average earnings in 2000 dol-
lars. If the worker had a nonworking spouse of
the same age, the benefit would be larger-
about one-half of the worker's lifetime average
earnings.4 These are low replacement rates-
you would not want to retire on one-third to
one-half of what you had earned on average in
your lifetime. Benefits would look even lower
compared to earnings over the last decade of
work for a worker with the typical age-earnings
profile. As a foundation for retirement income,
Social Security is something substantial to build
on. As a level to live on, it is clearly inadequate.
Excessive reliance on Social Security, despite
its relatively low replacement rates, together
with a more general picture of many workers
with inadequate wealth at retirement age, seem
Lindbeck and Mats Persson (2003). They refer to the three
dimensions as the distinction between defined benefit and
defined contribution, funded and unfunded, and actuarial  and nonactuarial. All three are matters of degree, not zero-  one choices. A primary difference is that my presentation is  focused on issues particularly salient in the U.S. context,  while I think that theirs was influenced by the Swedish  reform.
4 Of women receiving benefits in 2002, roughly one-  third received benefits solely as beneficiaries. The rest had  at least ten years of earnings history. For the latter group,  the replacement rate for the couple would be lower than the  one reported for the case of a nonearning spouse.
MARCH 2004
2


### ---Economics-2004-0-04.txt---
the best evidence for evaluating whether work-
ers make adequate preparation for retirement.
I prefer the term "inadequate preparation" to
"insufficient savings." Preparation involves
multiple decisions. Indeed, one decision is to
save, to have less consumption than after-tax
earned income. Another is investing well. A
third is getting adequate insurance for earnings
risk to have a satisfactory outcome in retirement
despite a possibly adverse earnings experience.
And a fourth is using insurance to arrange in-
come flows after retirement. There are lots of
ways that workers could end up with inadequate
consumption after retirement relative to what
might sensibly and efficiently be done with ear-
lier earnings.
In addition to having low savings, many
workers have problems converting savings in
different years into retirement incomes in later
years in different states of nature. We know
from 401(k) studies that many workers do not
diversify sensibly and many do not choose a
sensible portfolio for long-term investments.5
The tendency of many workers to accept the
default allocation set by their employers is sug-
gestive that they do not have a clear view of
how to choose a portfolio. Outside employer-
organized retirement savings, others pay advi-
sors as much as 1 percent of assets each year to
help them select mutual funds (in what are
called wrap accounts). Paying 1 percent extra
per year reduces the accumulation at the end of
a 40-year career by roughly 20 percent.6 Mutual
funds, even very similar ones, come with quite
different annual charges. While the average of
charges of mutual funds containing equities is
currently 1 1/4 percent of assets per year (includ-
ing a prorating of front loads), some workers
pay much more. A fee of the average size takes
away roughly 25 percent from what would be
there at retirement without any fee. Thus many
workers find it harder to accumulate enough for
retirement than they might, than an idealized
theory says they should. To be clear, I am not
proposing that these market opportunities be
banned-although improvement in regulation
would be welcome. Rather, I am saying that
analysts of Social Security should be realistic
5 For an overview on 401(k)'s, see Alicia Munnell and  Annika Sund6n, 2004.
6 Deposits into an account each year for 40 years are  present in the account for roughly 20 years on average.  about the actual functioning of the market
alternatives.
Investing is only part of the story. We lack
market institutions to provide good insurance
for the risk in earnings trajectories, thereby af-
fecting the realized pattern of assets at retire-
ment relative to earnings potential. In the
Arrow-Debreu framework, workers have deter-
ministic budget constraints from selling their
labor supplies conditional on all the states of
nature in which they have labor that they choose
to sell. That is, they transfer resources across
states of nature to those where the purchasing
power is needed more. Making the same point
in a finance vocabulary, markets do not cur-
rently exist for directly hedging the risks in
earnings opportunities, and if they did exist I do
not think we would see many workers using
them.7
In addition to problems in converting earn-
ings opportunities into wealth devoted to retire-
ment consumption, the wealth that is privately
allocated to retirement consumption does not
make adequate use of annuities. This problem
would be more severe without the annuities
provided by Social Security, since the utility
value of the marginal annuity decreases with the
extent of existing annuitization.
These shortcomings in providing for retire-
ment income fall on surviving spouses even
more heavily than on workers. While 5 percent
of elderly married couples have incomes below
the poverty line, with another 3 percent near
poverty, these figures more than triple when we
consider widows. Indeed, widowhood is associ-
ated with a roughly 30 percent drop in income
relative to needs (Karen Holden and Cathleen
Zick, 1998).8 This is strongly suggestive of
inadequate protection of family members.
To my mind, the heart of the context for
thinking about Social Security is that it substi-
tutes for poor decision making and for missing
insurance opportunities (missing perhaps be-
cause poor decision making implies low de-
mand). The various shortcomings that are
apparent even in the presence of Social Security
7 If they existed, one could hedge some of earnings risk  through traded indices of wages in different regions and  industries. One could try to approximate that through trad-  ing in assets correlated with the indices.  8 Of course this is dependent on the relative measures of  need of singles and couples.
VOL. 94 NO. 1
3


### ---Economics-2004-0-05.txt---
would be more severe in the absence of a pro-
gram. These different shortcomings in prepara-
tion for retirement relate to different issues-
inadequate overall provision for retirement
relates to having a mandatory program, inade-
quate annuitization relates to providing benefits
in annuitized form, inadequate protection of
family members relates to providing benefits for
surviving spouses and young children. I start
with the annuitization issue, since there is little
overt move to end the mandatory nature of
Social Security as a whole. But there are calls
for decreasing the role of annuities in Social
Security.
But first a word on the Arrow-Debreu frame-
work. I have referred to it above as a way to
describe the properties of a Pareto-optimal al-
location. I think that when economists quickly
consider economic issues outside their own sub-
disciplines, they frequently think implicitly in
terms of the Arrow-Debreu model with its con-
nection to first-best outcomes (also incorporat-
ing overlapping generations for some issues). In
contrast, economists thinking about issues in
their subdisciplines often share a framework
that is more complex and are more inclined to
do second-best analyses, which are more di-
rectly policy-relevant. As in other subdisci-
plines, analysts of Social Security are well
aware of the issues I have identified, although
the issues are not present in all analyses by any
means. The Arrow-Debreu model tends to start
our thinking in terms of the standard, fully
rational model of individual decision making
and in terms of a complete set of markets. That
is a reasonable place to start as long as it is not
also the end of modeling and thinking. For
example, simulations of Social Security reforms
that assume an overlapping generations model
with fully rational lifetime utility maximization
should not be taken as the whole story for Social
Security policy-making. It is inadequate and
potentially misleading to study the effects of
Social Security in models in which there is no
particular reason for Social Security to exist in
the first place. This would be akin to treating
Pigouvian taxation to correct externalities as
distortive by ignoring the externalities.
Interest in the description of behavior that
deviates from that in the Arrow-Debreu model
has grown enormously lately. Long before be-
havioral economics became a hot topic, public
policies reflected recognition that the model of  homo economicus, while very useful, is not a
fully adequate basis for the design of all poli-
cies. For example, federal legislation introduced
a "cooling-off' period during which contracts
with door-to-door salespeople could be can-
celled without penalty precisely because of de-
viations from homo economicus. And social
security discussions have long recognized inad-
equate savings for retirement by many workers
and inadequate annuitization by most. In addi-
tion, social security systems have been con-
cerned about protection of the family and not
just the worker.9 Also possibly relevant, but not
much studied, is whether significant numbers of
workers retire too soon for their own good.
These issues of poor choices in the presence of
available opportunities are in addition to in-
surance market limitations that come from
market incompleteness and from asymmetric  information.
Inadequate attention to the future in general
and its stochastic structure in particular implies
some form of time inconsistency. Normative
criteria for evaluating institutions become more
complicated without time consistency through-
out the population. Insofar as individuals are not
time-consistent, it seems essential to do norma-
tive evaluations in terms of shorter periods (e.g.,
years) as well as in terms of lifetimes. We care
about actual consumption levels as well as the
levels of lifetime resources.
This requires more than just a positive theory
of how people determine consumption but also
normative criteria for evaluating consumption
at different times. The vocabulary of someone
being different selves at different times is sug-
gestive, although I am concerned that taking it
too literally, failing to recognize the tight links
between the different selves who are the same
person at somewhat different ages, is failing to
address adequately the underlying issues.'? And
9 The growth of two-career families has altered the na-  ture of this concern and presumably the most sensible  design for the system, but has not made the problem go  away. There is a tension in social security systems, just as  there is in income taxation, between treatment of individu-  als and treatment of the family. Diversity in the way re-
sources are allocated within different families affects the
evaluation of different benefit designs.  10 More generally, there is a difference between taking a  model literally and taking it seriously-which involves  learning from models in order to think about a reality that is  more complex than is captured in any model-indeed that is
4
MARCH 2004


### ---Economics-2004-0-06.txt---
since the political process is not equivalent to a
consistent approach to policy over time (which,
it seems to me, is an essential property of de-
mocracy given divergent preferences and
views), we must consider issues from multiple
perspectives.11
An education built around the Arrow-Debreu
model may lead to overvaluing the fundamental
welfare theorem. The wonderful properties of
competitive equilibrium in certain unrealistic
circumstances lead the profession to be very
aware of distortions that prevent first-best out-
comes. But some distortions are associated with
redistribution and with easing other deviations
from first-best rules. Stressing the distortions
caused by government policies and not giving
equal weight to the redistribution and insurance
and revenue generation accomplished by these
policies, effectively doing partial first-best
thinking rather than complete second-best
thinking, can lead to unbalanced inferences
about policies.12
II. Annuitization
Some mandate for retirement saving is not
particularly controversial among policy-oriented
economists, so I begin with mandatory annuiti-
zation. First, let us consider the point of pay-
ments that are conditional on being alive. With
some saving for retirement (over and above
precautionary balances) a worker can learn of
rates of return (and risks) available in the mar-
ket for investing for different lengths of time
(that is, including an illiquidity premium). Any-
one investing for some period of time (for ex-
ample, bank certificates of deposit, insurance
contracts, mutual funds with an early with-
drawal penalty, direct loans) could wonder how
much more might be paid if the investor were
still alive provided there was no payment at all
if the investor were no longer alive. With a
what a model is all about. On this subject, see Alfred  Marshall (1948, p. 366).  11 That is, thinking only in terms of lifetime utilities and  sustained government policy rules seems to me inadequate.  12 For example, when Congress removed the retirement  test between the age of full benefits and age 70, some  wanted to remove the test for all those over age 62. Noting  only that the test discourages work, without noting its ef-  fects on the timing and size of benefit receipt would be an  example of such partial first-best thinking.  noticeable probability of the investor's dying
before reaching the end of the contract period
and little cost for checking whether the investor
is still alive, it would be worthwhile for a bor-
rower (bank, insurance company, mutual fund,
or direct borrower) to offer some additional
payment in return for being freed from payment
in the event of the death of the investor.
This is the essence of an annuity and the
essence of why for an investor with no interest
in bequests and a tolerance for some illiquidity,
an annuitized asset dominates the same asset
without an annuity feature. This is how the
Arrow-Debreu model works when markets are
complete-the gain from annuitization can be
thought of as a lowering of the price of future
consumption by forgoing deliveries after one's
death. The formal argument for the dominance
of annuitization was made by Menahem Yaari
(1965) in the context of a conventional annuity
that guarantees payments over the rest of one's
life. But the argument is much broader than that
(Thomas Davidoff et al., 2003). Moreover, sim-
ulations show a sizable quantitative importance
of annuity opportunities.
People do care about their children. But, a
bequest motive does not eliminate the advan-
tage of some annuitization. With a bequest mo-
tive and complete Arrow-Debreu markets, one
would determine how much of one's lifetime
budget constraint to give away and when to give
it (e.g., when children reach some age). It would
seem very odd to prefer to have one's children
receive an amount in present value that was
conditional on how long one lived (even if one
did not want to make a transfer before dying).
So, one would still use annuities, the purchase
of commodities conditional on being alive, for
all of one's own planned consumption. That is,
having a bequest motive is not a basis for doing
no annuitization in a complete market setting-
unless one was roughly risk neutral about both
the amount of bequest and its timing. Without
complete markets, a willingness to invest in
illiquid assets for future consumption leads to
the same advantage for some annuitization.
13 This is the way a defined benefit system works for  workers without any dependents eligible for benefits. The  risk could be shifted from the borrower to the set of inves-
tors by distributing a fraction of the amount not paid to  deceased investors to surviving investors. This is the way
that CREF annuities work.
VOL. 94 NO. 1
5


### ---Economics-2004-0-07.txt---
Despite the advantages of annuities, we see
only a small fraction of people doing voluntary
annuitization.14 Furthermore, those who do an-
nuitize make very odd choices. They buy nom-
inal annuities. There is wide popularity of what
are called guarantees-continued payments af-
ter death up to some limit.15 Such guarantees
undo some of the underlying annuitization, and
are a relatively expensive form of holding non-
annuitized wealth (given the relative adminis-
trative costs on annuities and other accounts).
They represent an increase in the riskiness of
one's bequest, not a decrease. That is, an annu-
ity without a guarantee costs less, allowing one
to leave one's heirs a determinate amount in
present value, rather than a random amount
depending on the date of death.'6 More gener-
ally, many features of insurance markets are
hard to reconcile with sensible decisions by
households and the equilibrium industry re-
sponse we would expect in the presence of
sensible demands. The extremely limited op-
tions available for annuitization seem to reflect
the natural response of the supply of insurance  to the nature of demand.17
Some have tried to explain this limited use of
annuities by the degree of annuitization that
already exists in government programs. But vol-
untary annuitization, while present for centuries
before the creation of these programs, was not
extensive in the population and is unlikely to
become extensive if the programs were re-
moved. Asymmetric information is another can-
didate for explaining this situation, and it does
cause an adverse selection effect on pricing that
14 There is a thriving market in what are called variable  annuities, but these are tax-favored investment vehicles
with a bit of insurance included (to get the favorable tax  treatment) and an option to purchase a genuine annuity, an  option that appears to be rarely taken. With the recent  addition of a lump-sum option in many defined benefit  plans, many workers may be forgoing an annuity, although  it is difficult to tell since some may simply be waiting to
annuitize later.
15 Among TIAA-CREF annuitants roughly three-  quarters choose some guarantee period (John Ameriks,
2002).
16 Guarantees may play a role in addressing adverse  selection, but that is, itself, a reflection of poor functioning
in this market relative to ideals.
17 Although markets provide both term life insurance  and whole-life contracts, the only annuities in the market are  for payments over the rest of one's life, from the date of the  first payment.  would discourage some individuals from annu-
itizing. While large systematic differences in
life expectancy do exist, much of the difference
is readily attributed to easily measured factors,
so insurance companies could do more to over-
come this problem, given the potential for large
gains to the insured.18 In the United Kingdom,
there is a sizable market for individual purchase
of annuities because of a large tax incentive for
their purchase from assets in tax-favored indi-
vidual retirement accounts. In the presence of
this demand, suppliers are offering annuities
with better prices for those with "impaired
lives." We do not see this risk classification in
the United States, presumably because there is
not a ready market in which firms could take
advantage of selection by risk classification and
better pricing since so few households purchase
annuities on an individual (nongroup) basis. So,
adverse selection alone can not explain the low
level of annuitization that is present.'9
I believe the major issue behind this pattern
of insurance demand is the failure of many to
understand the advantages of annuitization.
This plausibly relates to the failure of much of
the population to understand the properties of
stochastic variables, as has been documented by
cognitive psychologists. It is to be expected that
the set of insurance products that are marketed
will reflect the shortcomings of consumer
understanding-it is very expensive to try to
sell a product the virtues of which potential
customers do not understand. I think that with-
out Social Security, inadequate annuitization
would be even more widespread than inade-
quate savings.
In any event, social security systems in ad-
vanced countries typically provide benefits as
annuities, annuities that are generally indexed to
prices or wages (or a combination). This is a
simple application of the view that in a manda-
tory program, individuals should be given what
we think they would want if they were well-
18 Antidiscrimination rules do limit the variables that
insurance companies can recognize in pricing. But more  could readily be done with allowable categories, such as  smoking, type of job, earnings level. The adaptations of the  life insurance market to the presence of adverse selection  are suggestive that adaptations would occur if the market for  annuities were of a comparable size to that for life insur-
ance.  19 Note that there is considerable risk classification for
life insurance.
6
MARCH 2004


### ---Economics-2004-0-08.txt---
informed and well-educated. The presence of
mandatory annuitization does not prevent be-
quests, although it raises the cost and requires
action to do so. Those surviving to the start of
their benefits and with sufficient life expectancy
can use part of their monthly Social Security
benefits to finance a long-term life insurance
contract, thereby providing a bequest with an
explicit choice of the relationship between the
real size of the bequest and the date of death.
This action contrasts with simply leaving un-
spent funds to one's heirs, a strategy that leaves
an amount dependent on the history of con-
sumption relative to the income earned on  assets.20
In other words, the government's choice be-
tween providing retirement benefits as annuities
or as lump sums can be considered as a choice
of a default, one which most individuals could
reverse-by purchasing life insurance if pro-
vided an annuity or purchasing an annuity if
offered a lump sum (B. Douglas Berheim,
1991). Reversing the government choice,
though, takes time, thought, and effort and it has
a cost. That is, the government provides annu-
itization at a far lower cost than does the private
market. The absence of selling costs (other than
equivalent information provision) and econo-
mies of scale contribute to this advantage. Ad-
ministrative costs of Social Security are less
than 1 percent of annual expenditures, and a
great deal of that is due to the disability pro-
gram, which is naturally more expensive to run.
In contrast, privately provided insurance has
higher costs-life insurance company account-
ing generally recognizes over 10 percent of
premia used for administrative costs and profit.
The private market is more expensive and does
not do a better job of delivering annuity prod-
ucts that people need.21 This is one reason to
20 The timing of the purchase of both life insurance and  annuities is important for obtaining insurance. Waiting to  insure passes up insurance opportunities. The effects of  waiting depend on the extent of risk classification in the  pricing of insurance.  21 With any commodity, selling costs could be avoided  by mandating payment for government provision. What  distinguishes retirement annuities from most other products  are the similarity of needs of different workers (compared  with the diversity of tastes for different commodities) and  the reasons why a retirement income mandate is needed.  These reasons suggest that public provision is not blocking  an otherwise creative dynamic product development. The  have government provision rather than a man-
date to purchase an annuity in the private mar-
ket.22 As with many other settings, we expect
individuals to undo little of what is provided.23
So it makes sense to offer what we think people
might sensibly want. Moreover, the wider func-
tioning of the life insurance market than the
annuities market suggests a further advantage to
using substantial annuitization as the default.
A mandatory retirement income program re-
quires a choice of the form of benefit and it is
hard to think of a basis for choosing the form
which is other than what makes sense for the
bulk of the population. It seems to me that this
is an annuity in some form.24
A. Lifetime Income Distribution
Mandated annuitization affects lifetime
income distribution.25 Suppose one were
nature of the cash-in, cash-out annuity product also suggests  that we are not missing cost improvements that would  otherwise come. The small size of replacement provided by  Social Security leaves lots of room for such private devel-  opments if they did represent a significant opportunity.  22 With mandated private purchase, if allowed, we would  get risk classification and separate pricing, as has happened  in the United Kingdom. Separate risk classification has  advantages and disadvantages, and it is unclear whether it
would be better.
23 While many of the elderly have life insurance policies,  these appear to arise mostly from coverage for funeral  arrangements, small old policies that were not terminated,  and tax avoidance among the wealthy, rather than from a  conscious attempt to undo annuitization.  24 Mandatory annuitization in a social security program  raises the interesting question of how monthly benefit  should vary over time-with prices, wages, and possibly
other variables such as rates of return. Relevant for this
issue are the age structure of optimized expenditures, the  relative importance of both real and relative consumption,  and the allocation of risk bearing between the elderly and  the rest of the population. Currently, benefits in force are  increased for inflation as measured by the CPI. While this is  a reasonable solution, I suspect it would be better, on a  revenue neutral basis, to have lower initial benefits that then
grew faster (for example as a weighted average of prices  and wages). This would help the longer-lived more than the  shorter-lived, but the effect on expected lifetime income  distribution could be partially adjusted by changing the benefit  formula. But this issue has not received detailed analysis.  25 A full analysis of the income distribution effects of  Social Security should consider the disability program along  with the retirement income program since there is a negative  correlation between life expectancy and the likelihood of  collecting disability benefits and dying young enough to  leave children who collect young survivor benefits.
7
VOL. 94 NO. I


### ---Economics-2004-0-09.txt---
comparing two mandatory programs, one with
lump-sum payments and one with annuities.
This comparison would be easy if individual
choices between annuitization and nonannu-
itization were unaffected by the government
choice. Then one would simply compare the
implicit price of the trade-off between annu-
ities and lump sums in the alternative manda-
tory programs with the explicit price at which
individuals could make transactions. For ex-
ample, if everyone annuitized and the market
had a single price for all annuities, then we
would compare the price implicit in the com-
parison of the programs with the actual uni-
form price. In this case, we would find
mandatory annuitization attractive because
the government would be likely to have a
better price than the market.26 Conversely, if
everyone would purchase life insurance to
undo a mandatory annuity (and rates were
uniform), then we would find mandated an-
nuities unattractive since the private market
price for life insurance would likely be larger
than the implicit price if the government
switched from annuities to lump sums.
The story becomes a little more compli-
cated if we assume that everyone annuitizes
and the market would offer different prices to
different people. This might happen with a
mandate to purchase annuities in the private
market if the market had some degree of price
diversity by risk class.27 Then, in addition to
the difference from the average price with and
without the government annuity, we would
note the differences in prices for differ-
ent people. Relative to annuities priced dif-
ferently for different groups, the uniform
annuitization implicit in the mandated annu-
itization would favor those with longer ex-
pected lives-women relative to men, male
high earners relative to male low earners,
female high earners relative to female low
earners. A progressive benefit formula can be
26W. H. Beveridge (1942) argued that in the United  Kingdom the government systematically did better than  private insurance markets.  27 Annuity pricing that varies with stochastic health out-  comes implies a risk of the classification to which one will  belong. With annuitization done at a single time in life, the  degree of risk classification involves a tension between  providing more insurance and providing more accurate la-
bor market incentives.  used to offset the systematic variation in life
expectancy with earnings within genders.
For this or any income distribution compar-
ison, we must have a counterfactual, prefera-
bly a plausible one. Without a mandate, the
relevant counterfactual is that approximately
no one would annuitize. Pretty much every-
one would lose the insurance gains from an-
nuitization.28 We can compare the mandate
with this counterfactual in two steps-first the
value of annuitization assuming actuarially
fair pricing and then the difference, described
above, between fair and uniform pricing.
Since those groups with shorter life expec-
tancies have more to gain from fair annuiti-
zation [assuming CRRA preferences in the
usual range and realistic mortality rates (Jef-
frey Brown, 2003)] this counterfactual shows
much less diversity in the utility value of
annuitization than the previous comparison.29
Indeed, Brown finds that the utility value of
annuitization (relative to wealth) is similar for
groups divided by gender, race, and educa-
tion. Thus the differences in expected pay-
ments from different life expectancies have
less distributional impact in utility terms than
in expected payment calculations.30
281 ignore the role of access to minimum income guar-  antees (SSI).  29 Someone with a higher probability of dying would  find a larger decrease in the price of consumption when  going from unconditional purchase to purchase conditional  on being alive with fair pricing. Without annuitization,  someone with a higher probability of dying would generally  consume less in later years, ceteris paribus, and so have less  consumption on which to receive a price decrease. Given  the preference structure in Brown, the net result of these two  effects is that those with shorter lives gain more from fair  annuitization, tending to offset the redistribution from a  change from fair to uniform annuity pricing. Interpretation  of the Brown analysis of the total impact of annuitization is  aided by the analysis in Bernheim (1987) of the valuation of  marginal annuitization relative to life expectancy and li-  quidity constraints.  30 Implicitly this income distribution discussion has as-  sumed rational lifetime consumption allocation-the only  behavioral element being an unexplained, and unexplain-  able (on rational grounds), failure to purchase annuities.  Similarly, the simulations showing the value of annuiti-  zation assume optimal consumption paths both with and  without annuitization. Any full normative evaluation of  annuitization should reflect the fact that those living  longer after retirement will have a larger marginal utility  of consumption for any given wealth for retirement  consumption.
MARCH 2004
8


### ---Economics-2004-0-10.txt---
B. Labor Incentives
The implicitly uniform-price annuitization in
Social Security also affects labor market incen-
tives. The use of uniform annuity pricing (over-
all or within still heterogeneous risk classes)
violates the conditions for first-best optimiza-
tion. Compared to first-best pricing, the deci-
sion that would be distorted is that of labor
supply. If annuity pricing is breakeven, then
some are being taxed on work while others are
being subsidized compared to a system where
annuities are priced for individual life expec-
tancies. An alternative counterfactual would be
a failure to annuitize at all. Without annuitiza-
tion, we would have more accurate labor market
incentives person-by-person, but earnings would
finance less satisfactory consumption trajecto-
ries. We would fail to insure not only life ex-
pectancy realizations but also changes in life
expectancy as information accrues. That is,
even unfair annuities can raise individual wel-
fare if the alternative is no annuities.
I conclude that having a mandated retirement
income program provide its benefits as annu-
ities is sensible.
III. Workers and Families: Young Child,
Spouse, and Survivor Benefits
Social Security provides more than just re-
tirement benefits for workers. It provides bene-
fits for disabled workers and their families, for
young children of a deceased worker, and for
elderly spouses and surviving spouses. In addi-
tion, a divorced spouse may be eligible for the
same benefits as a spouse if the marriage lasted
at least ten years.31 Benefits other than worker
benefits are referred to as auxiliary benefits.
These benefits are subject to a maximum
rule-a beneficiary receives the largest benefit
he or she is eligible for-with no increment for
also being eligible for a smaller benefit. That is,
if someone has worked at least ten years, on
retirement he or she is eligible for a retired
worker benefit. He or she is also eligible for a
spouse benefit if married to a retired worker
beneficiary. But the total amount of benefit is
equal to the maximum of the two benefits. Sim-
31 There is a family maximum that proportionally re-  duces all benefits except those of the worker if it binds.  ilarly, someone eligible for a worker benefit and
also eligible for a survivor benefit receives only
the larger benefit.32 A central design feature is
that these auxiliary benefits are not paid for on
an individual basis-workers with the same
earnings history receive the same retired worker
benefits whether or not they have family mem-
bers or ex-spouses collecting auxiliary benefits.
Auxiliary benefits raise four questions. Does
it make sense to mandate benefits for family
members and ex-spouses? Does it make sense to
base benefits on a maximum rule? Does it make
sense to finance all of the auxiliary benefits
from the program as a whole rather than in part  or in full from the benefits of the retired worker?
Are the details of benefit determination rules as
well-designed as might be?
Let me start with the first, most basic ques-
tion. It makes sense to provide auxiliary benefits
since studies suggest that significant numbers of
workers do not insure their lives adequately and
would not make good choices between single-
and joint-life annuities. More generally we are
learning more about the ways in which the
allocation of resources within the family does
not conform to a single maximization with a
single budget constraint. Since the government
cares about the different family members (and
not just the worker), direct allocations to family
members matter since they will change the al-
location of resources within the family. Protect-
ing family members is a role governments have
recognized for centuries.
The other questions are more complex and
need more detailed analyses. Two issues are
central here. These are the positive and norma-
tive issues of how consumption is actually al-
located within families and how to combine
evaluations and rules that affect both individu-
als and families. Research on the determination
of allocations within the family is still in an
early stage of development. And normative
analysis has not progressed much beyond iden-
tification of the dilemma in recognizing both
32 If the spouse or survivor benefit is larger, the person is  referred to as having dual eligibility. In 2002, 38 percent of  elderly women received only a worker benefit, 34 percent  received only an auxiliary benefit and 28 percent were  "dually entitled." These fractions are expected to change as
more and more women with substantial careers reach retire-
ment age.
VOL. 94 NO. 1
9


### ---Economics-2004-0-11.txt---
individuals and families.33 So my answers here
are speculative and primarily meant to identify
where research might lead us to policy
improvements.
Offhand, the maximum rule does not provide
labor incentives well (incentives are stronger for
workers who have spouses likely to collect aux-
iliary benefits since two benefits are increased
by more earnings, and weaker for workers who
are likely to receive a larger spouse benefit since
further earnings by someone receiving a spouse
benefit do not increase that benefit). A similar
(but less extreme) issue arises with income tax-
ation of a lower-earning spouse.
Offhand, the cost of auxiliary benefits should
be shared between a worker and the program as
a whole. The benefit formula is progressive,
with a higher replacement rate for lower earn-
ers, reflecting differences in retirement needs.
As part of responding to needs, it seems right to
recognize dependents in determining need and
so benefits. But the current rule is not the only
way to do that. Some provision of auxiliary
benefits for children from the general program
makes sense, in keeping with our generalized
support of children in education; some provi-
sion for spouses is relevant in the role of
progressivity-two can not live as cheaply as
one. But the current system has gone too far and
I share in the criticism that too much is given to
the nonworking spouses of high earners.34 Us-
ing system resources to finance large transfers
to those in the upper tier of the earnings distri-
bution offsets too much of the progressivity in
other portions of the system. Designing a dif-
ferent system would be politically sensitive and
complex and would need detailed analysis.
The determination of survivor benefits has
also received considerable criticism. Recogniz-
33 If one wants to do a normative analysis solely on the  basis of individual experience, one needs to consider how  resource allocation within the family is affected by the rules  determining benefits and the impact of benefits on marriage  rates. Such an analysis could consider the effects of extend-  ing auxiliary benefits to all long-term relationships, includ-  ing same-sex marriages.  34 Scaling back the spousal benefit for spouses of high  earners (for example by a cap), or a more general overhaul  of auxiliary benefits is likely to meet considerable political  resistance. This suggests not tackling this issue in reform  plans hoping for an early restoration of actuarial balance. In  addition, a general overhaul should be preceded by consid-  erable further analysis.  ing the role of couples in sharing resources at
least partially, it makes sense to relate the ben-
efits of an elderly survivor to the benefits that
had been received by the couple-a survivor
replacement rate. Currently, survivor replace-
ment rates vary with the past earnings of hus-
band and wife, usually, but not always, between
one-half and two-thirds.35 A uniform survivor
replacement rate seems more likely to approxi-
mate relative needs than the current system. The
much higher poverty rate of widows than of
couples, noted above, suggests a higher survi-
vor replacement rate is needed, with three-
quarters having been suggested by some
analysts.36 The change to a uniform and higher
survivor replacement rate could be financed out of
a suitable mix of the total resources of the program
and the benefits of the couple while both are alive.
The current recognition of divorce is to allow
benefits for unremarried divorced spouses and di-
vorced surviving spouses after at least ten years of
marriage. Since there is a family maximum, some
of these benefits are paid by the system as a whole
and some out of the other auxiliary benefits. The
adaptation of the system for the growth in divorce
seems to me a major issue for research. I do not
know if we can design a system that would be
better, recognizing both labor market incentives
and income distribution issues, or if such a design
could survive political hurdles.37 But it is worth
thinking hard about.
35 It is common to cite the range of one-half to two-thirds  for the survivor's replacement rate, ignoring actuarial ad-  justments. But there are cases above this range once we  include adjustments for the ages at which the benefits are
claimed.
36 Among the TIAA-CREF annuitants who choose a  joint-life annuity from the three available options, roughly  70 percent choose a full benefit to the survivor, nearly 20  percent choose two-thirds, and the rest choose one-half.  Roughly 70 percent of men and 30 percent of women  choose joint-life annuities (Ameriks, 2002).  37 Research hurdles come from combining concerns
about individuals and families. Incentives for retirement
depend on benefits relative to individual earnings, while  need reflects family incomes. Political hurdles come from  the diversity of views about the structure of benefits. Some  like the discouragement of labor force participation by those  with children, others prefer not to subsidize that activity.  Divorced women are among the most vulnerable beneficia-  ries. With the benefits for divorcees with limited earnings  tied to the benefits for spouses, reducing spouse benefits for  high earners affects both well-off and vulnerable groups.  Finding a way to satisfy diverse constituencies will not be  easy, as is shown by repeated groups looking at this issue.
10
MARCH 2004


### ---Economics-2004-0-12.txt---
In sum, mandating benefits for the families of
workers is important, along with mandating
savings and mandating annuitization-the in-
clusion of family benefits in Social Security
makes sense. There is good reason to think that
the current rules can be improved, but research
difficulties and political hurdles will need to be
overcome if we are to make improvements.
IV. Income Distribution, Insurance, and Labor
Supply38
In determining retirement benefits, Social Se-
curity first averages the best 35 wage-indexed
annual earnings,39 then it uses a progressive
benefit formula to determine what real benefits
would be if first claimed at the age for full
benefits (commonly, if somewhat misleadingly,
called the normal retirement age),40 and then it
adjusts benefits for the age at which they start.
Moreover, between age 62 (the earliest age at
which retirement benefits can be claimed) and
the age for full benefits (which is in transition
from 65 to 67), benefits are only paid if earnings
are low enough, referred to as an earnings or
retirement test. Each of these steps in determin-
ing benefits affects income distribution, insur-
ance, and labor supply. I will skip over
implications of using 35 years (as opposed to
more or fewer years or all of lifetime earnings
subject to tax)41 and of using a wage index to
weight the earnings in different years in de-
termining benefits (as opposed to using an
interest rate)42 and concentrate on the effects
38 For a discussion of the links among tax theory, incom-  plete market theory, and social security, see Diamond  (2002).
39 Earnings after age 60 enter in nominal terms, not in  indexed form. This should be changed to have labor incen-  tives not vary this way with inflation.  40 Such progressivity is missing in Europe, where in-  come distribution issues are addressed more fully in other  parts of retirement income provision.  41 Depending on the nature of the underlying stochastic  process of wage rates, both underweighting early years  (relative to the use of interest rates) and not counting some  low years may or may not help with insuring lifetime  earnings-this is not an area that has received much re-  search attention.
42 We can contrast the earnings incentives between ben-  efit formulas that accumulate earnings with a wage index  and those that accumulate with a (presumably higher on  average) interest rate. This is most readily done in a break-  even comparison, assuming the same level of resources for  of a progressive benefit formula and a retire-
ment test.43
Consider the stochastic process of earnings
opportunities. Individual workers face consider-
able risks that are only partially correlated with
the economywide average earnings used in in-
dexing. Wages move differently by industry and
firm and region and some individuals have ca-
reer opportunities strongly affected by industry
and firm and region developments. We do not
have trading in the type of indexes Robert J.
Shiller (1993) has proposed in order to give
workers the ability to hedge these aspects of
their risks.44 Even if we managed to have trad-
ing in such indices, it is beyond credibility that
most workers would take appropriate advantage
of these opportunities. When many workers can
not sort out the basics of portfolio diversifica-
tion in their 401(k)s, there is no reason to an-
ticipate successful execution of far more
complex financial strategies. By having replace-
ment rates that are higher for lower levels of
lifetime earnings, a social security system that
a cohort in each case. Using a wage index gives less weight  to the earlier years and more weight to the later years than  does use of an interest rate. Thus, use of a wage index would  be implicit taxation on younger workers and implicit sub-
sidization of older workers and would be a distortion in a
first-best world. However, the annual income tax is progres-  sive, so that an upward-sloping age-real earnings profile  implies that on average older workers have higher marginal  income tax rates than younger workers. Thus, the sum of the  marginal income tax plus the implicit Social Security tax is  smoother across ages with a wage index than with weight-  ing by interest rate. Also, preferences are not intertempo-  rally additive. The standard of living to which retirees have  become accustomed is more affected by earnings later in  life than earlier in life. While the effect of introducing a  standard-of-living effect into annual utility has been ex-  plored in simulations of the value of annuities (Davidoff et  al., 2003), no similar analysis has been done for the weight-  ing given earnings in different years.  43 I do not discuss the issues behind the choice of 62 as
the earliest age of eligibility for retirement benefits (EEA).  Increasing the EEA helps those who would otherwise retire  too early for their own good and hurts those who are right  in their early retirement decision and are hurt by the illi-  quidity from benefit nonavailability until the EEA. Measur-  ing the size of the two groups would be very hard and only  a little has been done in identifying people who are affected.  Increasing the EEA would have little effect on long-run  Social Security financing as explained below. Similarly, it  would be hard to design a good method for automatically  indexing the EEA.  44Robert C. Merton (1983) has examined the role of  Social Security in sharing aggregate earnings risks more
widely.
VOL. 94 NO. I
11


### ---Economics-2004-0-13.txt---
makes benefits a progressive function of life-
time earnings offers insurance about lifetime
earnings that is not available in the market.
If the taxes and benefits for a cohort broke
even in present value terms, the use of a pro-
gressive benefit formula would imply that the
labor supplies of lower earners were being sub-
sidized and those of higher earners were being
taxed.45 This is the familiar pattern with insur-
ance with asymmetric information-a combina-
tion of insurance and incentives neither of
which satisfy the conditions for first-best opti-
mization. This effect of progressivity is in
addition to the effects from annuity pricing dis-
cussed above. Some of the effects of annuitiza-
tion and progressivity would be offsetting-
those with higher earnings of each gender tend
to live longer-and some would be compound-
ing-women on average have lower earnings
and longer lives. That taxes and benefits do not
break even on a cohort basis is discussed in the
next section.
The progressivity in the benefit formula uses
taxes that distort labor supply in order to redis-
tribute income and provide insurance. The pro-
gressive annual income tax also redistributes
income, provides insurance against earnings un-
certainty, and distorts labor supply. Since these  two institutions work on different tax bases and
provide payments at different times, there is
room for each of them to contribute despite the
presence of the other. Annual income taxation
recognizes short-term needs, coming from bor-
rowing constraints and from behavior that is not
time-consistent. It also recognizes capital in-
come as part of determining tax rates. Ex post,
all of one's Social Security taxable earnings (in
the best 35 years) contributed to benefits in a
way that varies with age but not with the level
of annual earnings, given lifetime earnings.
This avoids the distortions coming from having
different marginal tax rates in different years as
a function of annual earnings, or annual capital
income. The use of a lifetime measure also
separates out issues of lifetime earnings from
the age-earnings profile in doing redistribu-
45 This resembles an EITC being financed by a positive  income tax. Unlike the EITC, which has a region of high  marginal taxes as the subsidies are phased out, Social Se-  curity has a monotonic transition from marginal subsidies to  marginal taxes.  tion.46 While both annual income taxation and
lifetime social security have received analyses
of the trade-off among redistribution, insurance,
and distortions, there has not been much work
considering the simultaneous use of both  institutions.
A. Retirement Test
For a mandate to save for later consumption
to have bite, workers can not be allowed to
claim benefits whenever they want, including
immediately. To claim Social Security retire-
ment benefits, a worker must be at least 62. The
system could simply start paying benefits at age
62. Instead, between age 62 and the age for full
benefits, workers can only start receiving bene-
fits if their current earnings are low enough,
corresponding to full or partial retirement for
many workers.47 Any delay in the start of ben-
efits increases their monthly amount, tending to
counterbalance the delay in the start of benefits.
The impact of this retirement test on labor mar-
ket incentives is in addition to effects discussed
above that apply to each year of labor supply.
That is, the effect of Social Security on incen-
tives for continued work past age 62 has two
parts. One is the effect of a delay in the start of
benefits together with their later increase as a
consequence of the delay in their start.48 The
46 For example, if everyone had the same age-earnings  profile, Social Security would do no redistribution within a  cohort, while annual income taxes would subject each per-  son to earnings subsidies when younger and taxes when  older.
47 Benefits are paid to workers younger than the age for  full benefits if earnings are below the exempt amount, which  equals $11,640 in 2004. Earnings above this amount result  in a 50-percent reduction in benefits, until benefits reach  zero. Rules are different for the year in which the age for  full benefits is reached. After reaching the age for full  benefits, benefits may be claimed whatever the ongoing  level of earnings. A worker can receive a larger benefit by  delaying the start of benefits up to age 70.  48 The start of benefits can be delayed even if the worker  retires. For a worker without liquidity constraints, labor  supply is not encouraged by a net subsidy from delay (in the  case of a long expected life) since delay is available any-  way. But work is discouraged for those with shorter life  expectancies. While some eligible workers do not claim  benefits right away, overwhelmingly, retired workers do  claim fairly quickly. For those who would claim as soon as  they stopped working, work is encouraged by a larger  increase in benefits from delay as a result of a longer  expected life.
12
MARCH 2004


### ---Economics-2004-0-14.txt---
second is the extent to which additional work,
and so additional payroll taxes, increase the
measure of lifetime earnings and so add to  benefits.
For an average worker at ages 62 and 63,
Social Security had a roughly zero marginal tax
for the average worker when the age for full
benefits was 65.49 With the increase in the age
for full benefits there will be a small tax at these
ages. While implicit taxes used to be much
larger above the age for full benefits, the retire-
ment test has been eliminated for those ages.
With differences in life expectancy, a zero tax
on an average worker implies that some workers
are taxed and some are subsidized by the pres-  ence of the retirement test.50
The retirement test has two effects. One is to
raise (delayed) monthly benefits for those con-
tinuing to work. To the extent that a worker
would have consumed out of benefits received
while still working, the delay in the start of
benefits raises later consumption (for both the
worker and possibly a surviving spouse) since
more is saved. This is advantageous to the ex-
tent that consumption falls too much after re-
tirement.51 The combination of a delay and
increase in benefits is also redistribution across
workers based on life expectancy along the lines
discussed above. On the other hand, benefit
ineligibility while continuing to work discour-
ages work for those not fully valuing their in-
creased later benefits and those with shorter life
expectancy. Empirical estimates find that the
overall labor supply effect is modest, suggesting
that the increase in monthly benefits effect is
more important. The retirement test also helps
49 Courtney Coile and Jonathan Gruber (2001). The mar-  ginal tax reflects the loss of a year of benefits, the increase  in benefits thereafter, the payment of the payroll tax, and the  increase in benefits from an increase in AIME, since
earnings in a late year are likely to be among the top 35.  For example, of the Health and Retirement Survey sam-  ple of those born in 1931, over one-third of men and  four-fifths of women had fewer than 35 years of positive  earnings when entering the year in which they turned 61.  Without a tax on continued work, increasing the age at
which benefits can first be claimed, without other
changes, would not save money for Social Security on a  permanent basis.  50 Of course, these earnings are also subject to the annual
income tax.
51 Also valuable is that the higher monthly benefits come  as an annuity while savings from benefits would not provide
this insurance.  with the risk in earnings trajectories that comes
from how opportunities to earn (and disutilities)
develop toward the end of a career. The retire-
ment test addresses that risk to the extent that
there is taxation on continued work and those
continuing to work are less needy on average
than those who stop working earlier.52 Thus I
conclude that the retirement test does distort
labor supply, but that distortion is more than
offset by the gains from improved lifetime con-
sumption allocations and increased insurance.
Limiting the range of ages at which the re-
tirement test applies makes sense. Otherwise
some of those working to very advanced ages
would have replacement rates above 100 per-
cent and, if liquidity-constrained, would prefer
to have part of benefits while still working.
Currently the age for the end of the retirement
test is the age for full benefits. I am not aware of
any analysis of the optimal choice of an age for
the end of the retirement test.
B. Labor Supply at Younger Ages
I have focused on the retirement decision
since elasticities here are larger than those with
earlier labor supply decisions. But younger
workers pay payroll taxes and anticipate an
increase in benefits once they retire as a conse-
quence of the earnings that were subject to tax.
The effect on labor supply is relevant for choos-
ing the size of a mandatory retirement income
system. This incentive depends on the perceived
link between taxed earnings and retirement (and
disability) benefits. While those nearing retire-
ment age often gather information on the work-
ings of the system and seek advice on the
advantages of different timing of retirement,
younger workers are not well informed.53 Some
52 1 note that in a model with homogeneous life expect-  ancy, if we have fully rational workers and if the increase in  benefits implies an implicit tax, there is an increase in  insurance insofar as early retirement is a consequence of an  adverse realization of opportunities. This is a familiar opti-
mal insurance result-that one taxes observable variables in
the states where they signal a lower marginal utility of  consumption.  53 Information is also supplied in annual statements  which give individual benefit levels for different retirement  ages. Someone anticipating no benefits at all might see no  link (although inconsistent anticipations about the future are  common). Presumably that would change with a reform that  was widely perceived as restoring long-run sustainability.
VOL. 94 NO. 1
13


### ---Economics-2004-0-15.txt---
simulations have assumed that younger workers
perceive no increase in future benefits as a con-
sequence of additional earnings. This leads to a
big boost in apparent efficiency from a switch to
individual accounts if it is also assumed that
money going into individual accounts has no
implicit tax. Both of these assumptions seem
wrong to me.
I believe that there is wide awareness of the
existence of some link between earnings and
later benefits, although understanding of how
the link works is not so wide. Misperception of
the link sometimes takes the form of imagining
that Social Security is like a corporate defined
benefit pension that heavily weights later years.
This perception would correspond to an implicit
tax at some ages and an implicit subsidy at
others, not a full tax at all ages. The extent to
which labor supply is affected by concern that
there will be no benefits would be greatly mod-
ified by any reform that restored actuarial bal-
ance, not just one with individual accounts.
Insofar as workers have high subjective dis-
count rates, mandating savings in any form af-
fects labor incentives and the exact link between
taxes and benefits is of reduced consequence.
My sense of a small difference between pension
systems in incentives for younger workers is
supported by the evidence of quite modest labor
market responses in Latin American countries
that have introduced individual accounts.
I have now argued for the use of a mandatory
retirement income system paying annuitized
benefits to workers and their families based on
a progressive benefit formula and using a retire-
ment test at some ages but not at others. I turn
next to two issues that bear more on reform
options, as well as reflecting the history of the
system. First I will discuss the redistribution
across cohorts and then the use of automatic
indexing as well as periodic legislation.
V. Benefits by Cohort
Social Security is often criticized for distort-
ing labor supply and savings. Despite the link-
ing of these two decisions, the issues are very
different. I have already noted that mandatory
annuitization with uniform pricing distorts labor
supplies relative to an idealized alternative, but
seems to be a welfare improvement relative to a
world with no annuities. And I discussed other
labor market issues where Social Security com-
bines incentives with redistribution and insur-
ance. In contrast, the rules of Social Security do
not distort savings. That is, Social Security cer-
tainly affects savings and so national capital.
But the term distortion is usually reserved for an
intervention that would prevent Pareto optimal-
ity in an economy that would otherwise satisfy  the conditions of the Fundamental Welfare The-
orem. To examine this meaning of distort (as
opposed to merely change) we need to consider
the impact of Social Security on the marginal
return to private savings (the size of a tax
wedge). By itself, Social Security has no effect
on the return to marginal savings since benefit
levels do not depend on capital income. Social
Security does interact with the income tax, but
the effect of the existence of Social Security on
the income taxation of the return on marginal
savings can have either sign for differently sit-
uated workers, although it probably includes a
wedge on average.54
A mandate to pay taxes and receive benefits
would affect private savings even if there were
no marginal distortion at all. Effects come from
the requirement that people pay taxes at levels
and times when they might not have saved the
same amount. Effects also come from redistri-
bution, both within and across generations, that
is, from income effects as opposed to substitu-
tion effects. I am not aware of any study of the
impact on savings from the progressive benefit
formula-the presence of higher benefits rela-
tive to taxes for low earners who have a lower
54 Perhaps the largest effect comes from the cutoffs
below which benefits are not taxed or are taxed at a lower
rate. Since the cutoffs are compared with income including  capital income, there is an increase in the tax wedge on  savings for those who are affected in this way. Another  effect comes from the possibility that taxable benefits might  increase the marginal tax bracket. But Social Security dis-  places some private savings. Whatever savings are dis-  placed by Social Security might themselves have affected  the marginal tax rates (depending on the tax treatment of  displaced savings). Moreover, one needs to consider the  effect of Social Security on the income tax rate when the  savings are done as well as when the proceeds are  received-the employer share of the payroll tax is not part  of taxable income for the income tax. Thus, the effect could
be positive or negative depending on the level of displaced  savings and their income tax treatment. This indirect link is  present in many other programs that are not talked about in  this way. For example, government support of education  raises earnings and so marginal tax rates. The implied  increase in savings distortions does not seem to be of
consequence.
MARCH 2004
14


### ---Economics-2004-0-16.txt---
Cumulative: billions of 2002 dollars  14,000
400 188, 6 19 190 0- 12,000
,- S " >^ Cumulative Sum: net  transfers to all cohorts bom in
B,/~ i'~ r t h Y and prior to each year
300 / 10,000
Net transfers to cohort
born in each year
200 / / 8,000
100 < / ' 6,000
0 4,000
-100 / " 2,000
-200 I,,,,,,,,, , I I,,, I, , ,,, ,,,,,, , ,,,,,,,,,,,,, 0,,
1876 1886 1896 1906 1916 1926 1936 1946
Birth Year
FIGURE 1. NET INTERCOHORT TRANSFERS UNDER SOCIAL SECURITY
Source: Leimer, "Cohort-Specific Measures of Lifetime Net Social Security Transfers," Social Security Administration  Office of Research and Statistics Working Paper No. 59, February 1994, updated to present value 2002 dollars.
propensity to save than high earners.55 The re-
distribution across generations has received par-
ticular attention and has led to consideration of
the impact on national capital.
A. Transfers by Cohort
Everyone is aware of the decision to pay
earlier cohorts of retirees benefits far larger than
could have been financed by the taxes they paid
and the interest that could have been earned on
them. Figure 1, an updating to 2002 dollars of
analysis done by Dean R. Leimer (1994), shows
the lifetime transfers by cohort (left scale) and
the cumulative net payments by cohort (right
scale) for cohorts born through 1949, and so
55 The difference in propensities to save is also relevant  for the impact of any use of payroll tax revenues to lower
income tax rates.  turning 55 this year.56 The aggregate net trans-
fers to these cohorts is roughly $11.5 trillion.
How much did this early generosity reduce
national capital? We have some estimates but
they are surely not reliable. A believable time-
series econometric study is probably not doable
and there is no consensus that one has been
done satisfactorily. Another approach would be
by simulation. But a credible simulation re-
quires modeling the appropriate underlying
behavior-the extent to which different workers
would save on their own without such a pro-
gram. Surely, a simulation with all workers
being fully rational lifetime utility maximizers
has no credibility. And we would also need to
track the effects on national savings from Social
56 To extend the figure to later cohorts, we would want to  consider how actuarial balance is restored, and I do not
present such a figure. Leimer assumed phased-in tax in-  creases to balance the present value of taxes and benefits.
VOL. 94 NO. 1  15


### ---Economics-2004-0-17.txt---
Security displacing transfers to the elderly from
the government (through the program for the
poor elderly-Old Age Assistance, which be-
came SSI) and from individuals (through cash
gifts and shared housing).
While the impact on national capital would
be an interesting positive question if we could
answer it well, it is important to recognize the
additional issues needed for a normative analy-
sis. The goal of Social Security's early gener-
osity was to raise the consumption of early
cohorts of elderly. Apart from business-cycle
effects, higher consumption implies lower
savings-implying that lower national capital
was required by the goal, not an unintended side
effect. A normative evaluation of the impact of
the redistribution to early cohorts would con-
sider how much their wages were lower than
those of later cohorts and how little they had
saved, as well as the return on capital. It
would also consider the pattern of transfers
within benefited and paying cohorts. However
such an analysis would come out-balancing
very worthwhile transfers with some less
worthwhile ones-most of the transfers are
now history.
Given the infinite horizon present value bud-
get constraint of Social Security (in the absence
of transfers from general revenues) this early
generosity is the cause of lower benefits in the
future than could otherwise be afforded. That is,
the legacy of the early generosity of Social
Security shows up in assets that are not there. If
they were present, they would be earning inter-
est that could contribute to paying for benefits.
The cumulative curve in Figure 1 gives a sense
of the magnitude of the trust fund that is not
there because of Social Security's history. But,
Figure 1 is by cohort, and so does not show how
much larger the trust fund would be today if
every cohort had been on a breakeven basis.
Although such a calculation is doable, it would
not be the best basis for insight into reform
options. Rather, that comes from considering
the elements likely to constrain reform. Past
payments are history and political consider-
ations suggest that it is unlikely that benefits
will be directly reduced for those already retired
or those nearing retirement, although these ben-
efits might be affected by changes in tax treat-
ment or in the inflation indexing of benefits,
changes that would apply to everyone. A partial
picture of that constraint would be that cohorts  over 55 would not be affected by reform.57 The
measure is not exact since cohorts over 55
would be affected by any payroll tax change and
slightly younger cohorts are likely to have lim-
ited changes in benefits as we phase in any
benefit reductions that are part of a reform. An
ideal definition of this constraint would con-
form to a theory of political constraints on re-
form coming from past generosity. We do not
have a full theory, but this gives a reasonable
sense of the size of the legacy that needs to be
financed from future cohorts.
Peter Orszag and I have referred to the miss-
ing assets on this cohort basis as a legacy debt.58
Thus the legacy debt is not a debt in the tradi-
tional sense of that word, but that term crystal-
lizes the need to allocate the cost of the assets
that are not there across cohorts. Spreading the
cost of that early generosity across cohorts is
inherent in any plan that restores actuarial bal-
ance. While only an approximation to the real
constraint, the number is roughly $11.5 trillion
(a bit more than one year's GDP). If we were to
go to full funding, then this is roughly the cost
that would fall on the generations during the
buildup to full funding. Alternatively, instead of
ever achieving full funding, we can consider a
wider allocation of the legacy cost by aiming to
preserve a ratio of the legacy cost to taxable
payroll. This would parallel the idea of preserv-
ing the ratio of the public debt (or the interest on
the public debt) to GDP. Spreading the legacy
cost over all future cohorts implies less than full
funding of Social Security. Without extensive
evaluation of its consumption transfers, the ef-
fect of Social Security on national capital is not,
by itself, a basis for concluding that the system
should have been fully funded or should be-
come fully funded.
The baby boomers are much larger than ear-
lier cohorts. The 1983 legislation included pay-
roll tax revenues in excess of current outlays in
order to build a trust fund which would then be
used to finance the retirement of this very large
cohort. That is, taxes were higher early to allow
57 In his charge to the Commission to Strengthen Social  Security, President Bush included the principle that Social  Security reform not affect the benefits of anyone 55 or older  (Commission to Strengthen Social Security, 2002).  58 This is the same as the "closed group" measure of  balance, with the group including everyone 55 and over.  16
MARCH 2004


### ---Economics-2004-0-18.txt---
them to be lower later.59 Politically, the trust
fund is very likely to be used for Social Security
purposes in the sense that the constraint on
future Social Security expenditures includes the
value of the assets in the trust fund. A separate
issue is the extent to which the higher payroll
taxes since 1983 increased national capital.60
This is a source of controversy, with a wide
range of presumptions and no ability to settle
the question econometrically.61 I believe that a
large part was saved-despite the large federal
deficit outside Social Security for the 1980's
and early 1990's. In my view, a larger unified
deficit, if Social Security had not been in sur-
plus, would not have had a strong effect on tax
and spending legislation. Congress had great
difficulty in legislating tax and spending
changes to lower the deficit. Without the Social
Security surplus, a somewhat larger unified def-
icit would not have changed the basic character
of the situation-a deficit widely perceived as
being too large and a difficulty in raising taxes
and lowering spending. Looking beyond the
baby boomers we do not currently perceive a
need to single out a cohort that will differ
greatly from others and perhaps call for some-
thing other than a smooth adjustment of taxes
and benefits.
Redistribution across cohorts has not been
done in a lump-sum fashion, but through the
choice of tax rates and benefit formulas. Thus
the redistribution has affected labor supplies as
well as savings decisions. In the early days, the
generous benefit formulas (in effect or antici-
59 That has shown up in the assets in the trust fund-  currently over $1.5 trillion or roughly 2.8 times annual  expenditures. This ratio of trust fund to expenditures is  projected to peak at 4.7 in 2016.  60 Note that the analysis needs to be done in terms of  taxes and benefits, the causes of changes in the trust fund.  The question of the impact of the trust fund on national  capital requires a distinction among different ways in which  trust fund size can be changed.  61 There has been a relatively short time during which  there is a plausible linkage between Social Security and the  rest of the budget. Moreover, specific pieces of legislation  imply different time shapes of revenue changes and spend-  ing changes over subsequent years. Thus, there is no simple  link between deficits and lagged deficits (or between unified  deficits and Social Security surpluses) that could reliably be  discovered by time-series analysis. In particular, it is not  credible to believe that econometric analysis could uncover  the counterfactual pattern of taxes and spending that would  have occurred if the 1983 Social Security legislation had
involved lower tax rates.  pated in the future) subsidized labor, just as the
lower benefits relative to taxes for younger
workers today taxes labor.62 This is similar to
the role of the progressive benefit formula dis-
cussed above. Given the pattern of redistribu-
tion by cohort shown in Figure 1, much of
redistribution served as an incentive for much of
the working life of recipients. This is in contrast
with analysis in two-period models where the
initial elderly recipients of transfers receive a
lump-sum transfer and all later cohorts have
implicit taxes on earnings to pay for it. Both the
transfers and the taxes have influenced labor
supply.
VI. Automatic and Legislated Adjustments to
Aggregate Realizations and Risk Allocation
The actuarial projection for the 1983 reform
envisioned a buildup of the trust fund, followed
by its decline back to the precautionary level of
one year's expenditures at the end of the 75-
year projection period. It has not worked out
that way. Instead of having just enough money
for 75 years of expenditures, plus a small trust
fund at the end, it is now projected that the trust
fund buildup will be sufficient to pay currently
scheduled benefits only until 2042. That is, the
policy that was designed for a 75-year horizon
will, if the projection is correct, cover all of
expenditures for only 60 years. By the scale of
preparing for long-term outcomes, that does not
seem to me to be too bad. Of course one could
argue, with hindsight, that Congress should
have looked further into the future than 75
years, although it was hard enough to reach
agreement on legislation even with that target.  Current discussions have extended the notion
of actuarial balance to include "sustainability"-
that the ratio of the trust fund to annual expen-
ditures not decline at the end of the horizon.
This criterion of sustainable solvency is meant
to avoid a repeat of the post-1983 experience
where the projected actuarial deficit returned
quickly (although the trust fund exhaustion date
was distant). Projected deficits returned quickly
because of what is called the terminal year
problem, or the cliff problem. That is, each year,
62 The effects of benefit increases of the already retired  (through 1972) affect labor supply insofar as they were  anticipated earlier. A similar issue arises for benefit in-  creases at different times during a career.
VOL. 94 NO. 1  17


### ---Economics-2004-0-19.txt---
the realized net cash balance of Social Security
is added to the trust fund and another year is
added at the end of the 75-year horizon. With a
constant tax rate and the current benefit for-
mula, the added year is in worse fiscal shape
than the average of years before. Indeed of the
current 75-year actuarial deficit of 1.9 percent
of taxable payroll, a full 1.1 percent is due to the
fact that the projection now goes 20 years fur-  ther into the future than it did in 1983.
The 1983 legislation included future de-
creases in benefits by increasing the age for full
benefits. At the time of the 1983 legislation,
there was still a tax rate increase on the books.
That was kept and took effect in 1990. Indeed
from the initiation of the program in 1935 until
1990, there was always a future tax rate increase
on the books. Given the political ease of raising
benefits or cutting taxes, and the political diffi-
culty of raising taxes or cutting benefits, having
future tax rate increases and future benefit de-
creases on the books lowers the political cost of
preserving balance, since it is easier to legislate
future pain than current pain. Avoiding a recur-
rence of actuarial imbalance a short time after
reform requires a substantial trust fund at the
end of the projection period, so that it can fall
for awhile without triggering imbalance,
and/or a change in the time shape of taxes and
benefits. A changed time shape can be legis-
lated directly (as we legislated an increase in
the full benefit age in 1983 and have legis-
lated future tax increases) or could be ex-
pected from the adoption of further automatic
adjustments (for example, by including an
adjustment for life expectancy).
Before considering the choice between legis-
lated changes and automatic adjustment, let us
consider the allocation in a complete-market
Arrow-Debreu equilibrium. In the model, out-
comes are fully specified. Given subjective be-
liefs about the probability structure of the states
of nature, one can express the value of equilib-
rium for an individual. Also fully specified is
standard modeling of incomplete markets,
which replaces complete market auctioneer-
announced future allocations by accurate pre-
dictions of future market equilibria as repeated
trading unfolds. Time-inconsistent individual
behavior does not interfere with the ability to
describe outcomes in this way, although it will
generally interfere with the efficiency properties
of equilibrium.  Most social security systems lack the com-
pleteness that is needed to specify outcomes
solely in terms of underlying economic vari-
ables (and the stochastic structure of states of
nature). U.S. legislation determines the payroll
tax rate for each year into the indefinite future.
The level of earnings that are subject to tax each
year is automatically indexed-thereby relating
taxable earnings to economic outcomes.63 Leg-
islation also sets down the rules for benefit
payments in terms of individual earnings histo-
ries and price and wage indices. While each part
is fully specified, no mechanism ensures that the
Social Security budget constraint is satisfied.
Thus, there is the expectation that sooner or
later something will have to be changed. That is,
in order to model future labor and consumption,
we need to model future legislative outcomes.
This is hard.64 In some exercises, the Congres-
sional Budget Office has been instructed by law
to ignore some possible future legislation (such
as extensions of sunsets of income tax changes).
But this is not a satisfactory solution for aca-
demic analysts, nor for individuals who are
making lifetime plans.
We have a theory using incomplete contracts
as part of the theory of the firm. In that theory
agents have well-defined property rights and
well-specified behaviors that determine the out-
comes not covered by the contracts, With in-
complete legislation, the future legislative
process plays a key role in determining out-
comes that are incompletely specified.6 Ana-
lyzing an equilibrium that includes a legislative
process is difficult-requiring modeling the in-
teraction of the personal preferences of elected
officials with their concerns about reelection, as
well as election outcomes (R. Douglas Arnold,
1990). It is not that this is unknowable in prin-
ciple, but that we are a long way from a genu-
63 Some of the income tax revenue from the taxation of
benefits goes to Social Security as well. This revenue is  dependent on future income tax rates.  64 In the list of reasons why members of the Panel on  Privatization of Social Security of the National Academy of  Social Insurance disagreed on the advantages of individual  accounts, a central element was the divergence of views on  the political implications of accounts-particularly the sus-  tainability both of rules for the accounts and of the structure  of traditional benefits (Diamond, 1999).  65 The legislative process can also change what is com-  pletely specified, but at least we can analyze what happens  if there are not any changes.
18
MARCH 2004


### ---Economics-2004-0-20.txt---
inely usable, empirically validated theory and
we are studying a process that generates very
limited data relating outcomes to underlying
factors.66
Incomplete specification is not a necessary
part of a mandatory social security system. For
example, in Chile workers are required to save
10 percent of covered earnings in mutual funds,
using the accumulation for an annuity purchase
or phased withdrawals after reaching benefit
eligibility. Thus the workings of the system are
fully specified in terms of economic out-
comes. 7 This does not imply that the Chilean
government will never change the rules of the
system. Indeed, it has made frequent changes in
some details. But it does mean that we can
analyze the outcomes of the current system un-
der the assumption of no further legislation
without being internally inconsistent. We can-
not do that for the United States-there are
states of nature that require some legislative
change, indeed the probability of such a future
need is very high today.
The Chilean approach of a fully funded de-
fined contribution system is not the only way to
have a fully specified system. Sweden has one
too. In Sweden, the payroll tax rate is 18.5
percent. While 2.5 percent of payroll goes into
fully funded individual accounts, 16 percent is
used for a partially funded system, called a
notional defined contribution system (NDC).
An NDC system mimics a fully funded de-
fined contribution system in that it accumu-
lates a notional balance for each worker that
increases each year by taxes paid and a no-
tional interest rate.68 At retirement, this bal-
ance is converted into an annuity based on the
66 For example, if we want to project a legislative re-  sponse to a possible drop in fertility, we do not have much  of a database for evaluating the relationship. With underly-  ing country differences being very significant in social  security politics, we may have basically one data point.  67 When workers purchase real annuities from insur-  ance companies, there is always the possibility that the  insurance companies will become unable to pay the con-  tracted amounts. But even with recognition of this  possibility, we still have a fully specified outcome-as  we do in models with incomplete markets and bankruptcy
rules.
68 That is, unlike the United States where benefits de-
pend on earnings subject to payroll tax, in Sweden benefits  depend on taxes paid. Since the Swedes currently seem  determined not to change the tax rates this difference is  likely to have little consequence for the future.  life expectancy of that cohort and the same  notional interest rate.69 The notional interest
rate is set administratively (with automatic
adjustment), not by returns realized on assets
held. In this way an NDC system mimics a
defined benefit system. Thus it is very much a
hybrid. Whether this system is referred to as a
defined benefit system or an unfunded defined
contribution system matters since the vocab-
ulary with which a system is described can
influence the politics of both creation and
adaptation.
By itself a well-structured NDC system, with
a decent size buffer stock of assets, will have
little probability of needing legislative interven-
tion as long as economic growth is large
enough. Even so, the Swedes have gone further
by introducing an automatic balancing system. I
will not digress to describe the Swedish auto-
matic balance rules. It suffices to say that if
economic growth is sufficiently slow, the no-
tional interest rate is automatically lowered-
reducing both benefits in payment and future
benefits in response to this slower rate of
growth. Thus the Swedish system can be ana-
lyzed for an indefinite future without an as-
sumption about the structure of future
legislation, so one does not need a fully funded
system to have that property. Sweden, like
Chile, puts all of the risk of future outcomes on
the side of benefits and none on the side of
taxes.70
Some simple ways for pretty much ensuring
automatic balance can illustrate alternative ap-
proaches. In the French and German pension
systems, workers accumulate "points" based on
earnings that have been subject to tax. Think of
this as a sum of wage-indexed wages over a
worker's career. The accumulations of points
determine relative pensions for retirees. Un-
like what is actually done in France and Ger-
many, points could be converted into cash
benefits by automatically adjusting the value
of a point to exhaust available revenues. Con-
versely, we could think of adjusting the tax
69 Also automatically adjusted is the relationship be-  tween the level of benefits and the age at which an individ-  ual starts them. There is not automatic adjustment for the  earliest age at which retirement benefits can be claimed.  70 To some, this is the heart of a defined contribution
system, rather than a relationship involving realized rates of  return on assets actually owned.
VOL. 94 NO. 1
19


### ---Economics-2004-0-21.txt---
rate each year to produce enough revenues to
cover expenditures for given values of
points.71 Both types of adjustment need a
small buffer stock of assets (or borrowing
ability) because of lags between setting ben-
efit or tax rules and the determination of ac-
tual expenditures and revenues.72
U.S. Social Security uses price and wage
indexing in the determination of both benefits
and the payroll tax base.73 This reliance on
automatic adjustments decreases the frequency
of the need for legislation.74 One popular pro-
posal is to extend automatic adjustments to in-
clude an adjustment for life expectancy. Such a
change would play two roles-one is to have an
automatic adjustment rather than legislating in
anticipation of or in response to life expectancy
changes. The other is to decrease the actuarial
imbalance in a way that may be easier politi-
cally than comparable direct changes.
But what mix of benefit and revenue changes
is the best response to increased life expectancy?75
71 To some, this is the heart of a defined benefit system,  including possibly placing the risk outside the labor market,  as can be done if the risk is shifted to corporations or  general revenues.  72 One difference is that if we attempt to increase tax  revenues (as opposed to lowering benefit payments), we  face the risk of exceeding the maximum that could be  collected (i.e., moving to the wrong side of the Laffer  curve). Presumably, with a sensible execution of this ap-  proach, this risk would be so low as not to be a problem.  Adjustment possibilities are more complex than just some  combination of tax increases and benefit decreases (or the  converses). In the presence of a projected deficit, benefit  reduction can be large enough to lower tax rates and tax  increases can be large enough to raise benefits. Recognizing  more complexity, some tax rates could go up while others  go down and benefits for some groups could go up while  benefits for other groups go down. Indeed, several proposed  reform plans include increased benefits for some vulnerable  groups along with general benefit cuts.  73 The current indexing is not complete-there is no  adjustment of benefits for inflation between the years a  worker is 60 and 62. This gap should be closed.  74 Indeed, the 1972 automatic indexation for inflation
(which was done incorrectly) was an attempt to codify how  Congress had been behaving, thereby reducing the fre-  quency of the need to legislate. The automatic indexing was  done incorrectly because congressional actions had been  unsatisfactory in structure, without this being as apparent as  when the changes became automatic and inflation increased.  75 We could also consider an automatic adjustment of the  earliest eligibility age and of the actuarial adjustments for  the age at which benefits start. The latter, but not the  former, is included in Sweden. Indexing the earliest  eligibility age is complex since the sizes of the groups  Part of an approach to this question is to ask
how individual lifetime plans should vary with
life expectancy. This depends on how the po-
tential earnings trajectory and the difficulty
(disutility) of work change along with life ex-
pectancy. If both opportunities and difficulties
in a year depended on the proportional position
of that year relative to life expectancy (and
mortality rates also depended on relative age),
then all of an optimal individual adjustment
would come in working longer. That is, optimal
work would be a fixed fraction of life expec-
tancy. The change in Social Security with the
same pattern has all of the adjustment in lower
benefits for each age of retirement.
However, I suspect that the proportional case
assumes too large a change in both earnings
opportunities and difficulty in work relative to
life expectancy. If the optimal outcome for an
individual were to work a smaller percentage of
life expectancy, then a sensible approach would
spread the implied drop in lifetime consumption
over both pre- and postretirement years. De-
creased preretirement consumption corresponds
to an increase in the Social Security tax rate. In
historic data, where the steady growth in life
expectancy has been accompanied by a steady
growth in real earnings, we have a steady de-
cline in the percentage of life expectancy
worked. This suggests a mix of tax and benefit
changes since we do expect a continued corre-
lation between life expectancies and earnings
levels.76 I also believe that, at least among ac-
ademic economists, the life cycle of productiv-
ity relates to more than just health and it is
unclear how such other factors are correlated
with life expectancy. I think an automatic ad-
justment for life expectancy that included ad-
justment in both benefits and tax rates would be
a good idea.
Should we have more automatic adjustments
helped and hurt by an increase are not likely to be simply  related to life expectancy.  76 Automatic adjustment of benefits for life expectancy  is naturally done on a cohort basis, while any adjustment in  taxes is naturally done on a yearly basis. Thus more rapid  increases in life expectancy would fall differently on differ-  ent cohorts when taxes are included in the adjustment than  when they are not. My plan with Orszag (2004) takes the  approach of a mix of automatic tax and benefit changes for  life expectancy, while Model 3 of the Commission to  Strengthen Social Security does all its automatic adjustment  for life expectancy on the side of benefits.  20
MARCH 2004


### ---Economics-2004-0-22.txt---
and so even less pressure for legislation? For
example, we could use additional adjustments
depending on real wage growth. Or we could go
directly to automatic adjustments based on
overall financial balance so Congress never
again needed to legislate.77 Such indexing
would need to choose the mix of revenue and
benefit changes in the response to imbalance. It
strikes me as implausible that a system with a
sensible tax rate would want to do all of the
adjustment on the side of benefits.78 That is, it
seems likely that the optimal size of a social
security system relative to the economy varies
with the same factors that affect actuarial
balance.
Relying on fully automatic adjustment
rather than assuming there will be periodic
new legislation bears some similarity to a
familiar distinction from macroeconomics-
rules vs. discretion for monetary policy. Parallel
issues include the concern about setting rules
without fully knowing how the economy adjusts
to the policy actions and recognition that the
economy may evolve so that currently good
rules may become less so in the future. But
there are also different issues. Social Security
set up for the indefinite future involves a level
of detail complexity that seems higher than set-
ting rules for the Fed. Moreover, Congress
could invite the Fed to set out a rule it will then
follow. Thus we need to ask whether Congress
would do a better job in setting out rules once
and for all rather than adjusting them from time
to time. While legislating from time to time is
an inherently easier intellectual problem, we
need to be concerned about the asymmetries in
the political ease of legislation addressing sur-
pluses and deficits, an asymmetry that is re-
duced by legislating automatic adjustments.
Also there may be more similarity across the
77 With this approach, Social Security would become  fully specified and so easier to analyze and more in keeping  with Arrow-Debreu thinking. But, making it easier to ana-  lyze does not necessarily make it better. Just as mathemat-  ical convenience, for example from additive preferences,  while convenient for theoretical analysis, does not neces-  sarily add to empirical reliability.  78 If the tax rate is thought to be too high and politically  can not be lowered, then doing the adaptation to anticipated  higher cost outcomes fully in terms of lower benefits may  make sense as a political fallback. I, for one, do not think the  current tax rate and replacement rates in the United States
are too high.  political spectrum in normative evaluations of
the impacts of monetary policy than of the eval-
uations of the sizes of taxes and benefits for
different workers and family structures. As with
monetary policy, I think that some discretion
can improve outcomes.
In considering possible automatic adjust-
ments, one can look at how adjustment is cur-
rently debated and how it was done before. In
our last major reform in 1983, there was an
explicit sense of balancing benefit and revenue
changes (Paul C. Light, 1985). Currently, we
view both benefit reductions and tax revenue
increases as candidates to contribute to restoring
a projected position of financial balance. The
Commission appointed by President Bush put
forth two plans which restored actuarial balance
(Commission to Strengthen Social Security,
2002). One of them included new dedicated
revenues, and both of them included large trans-
fers of general revenues, which one cannot help
but think of as in large part coming from new
revenues and not just spending decreases and
certainly not benefit decreases. The plan that
Orszag and I have put forth explicitly divides
some of the proposed changes for restoring ac-
tuarial balance (both one-time changes and new
automatic changes) between revenue changes
and benefit changes.
A. Fully Funded Defined Contribution and
Partially Funded Defined Benefit
The parallel to the workings of the Arrow-
Debreu model and the completeness of the spec-
ification makes economists more comfortable
thinking in terms of mandated fully funded de-
fined contribution systems than the type of par-
tially funded defined benefit system we have.
So, I want to draw out some comparisons. One
is that portfolio risk in a mandatory fully funded
defined contribution system is highly correlated
with the portfolio risk of the rest of individual
retirement savings. Thus the increased use of
defined contribution private pensions raises the
value of a defined benefit Social Security system
relative to individual accounts.79 In contrast, a
79 Social Security needs to be considered in the context  of all retirement income provision, not just by itself, recog-  nizing the great diversity in the extent to which people have  private sources of retirement income. The Social Security  reform debate has recognized non-Social Security retirement
VOL. 94 NO. 1
21


### ---Economics-2004-0-23.txt---
system that is less than fully funded will have less
correlation with the returns on private retire-
ment savings, as it adjusts benefits in response
to the growth of tax revenues as well as the  returns on whatever assets are held.80 This com-
parison holds even with initial benefits fully
automatically adjusted for the actuarial position-
returns on assets and the growth of taxable earn-
ings are only partially correlated. Thus portfolio
diversification considerations suggest an advan-
tage to having (at least) some underfunding in
Social Security to complement private savings.
This diversification advantage comes with
the redistribution to earlier cohorts that is inher-
ent in a less than fully funded system.81 Thus
one can readily argue for a Pareto gain (ex ante)
from moving from a fully funded system to a
partially funded system with the risk associated
with the incomplete funding falling on bene-
fits.82 Note that the reverse argument does not
work-just adding funding to an unfunded sys-
tem that provides all of retirement benefits will
not generate a Pareto improvement. The gain
from diversification plays out over time, while
the redistribution required to build up funding
hurts the oldest cohorts who provide the funding
and are affected by the diversification argument
very little or not at all.83 Thus the diversification
income issues in that some reform proposals have been  packaged with increased tax incentives for individual retire-  ment savings. The debate has not included the possibility of  a mandatory widening of employer-provided retirement in-  come (with a government-provided default) along the lines  of the recent reform in Australia and earlier discussion in the
United States (President's Commission on Pension Policy,  1981). The diversity in private savings is also relevant for  considering the right size for mandated benefit provision.  80 For example, with an NDC system, the notional assets  in an account earn a notional rate of return that might be set  to equal the growth rate of the wage bill (if other factors are  not too strong). Then, one can consider the correlation  between the return on assets and the growth rate of the wage
bill over different time horizons. Since the internal rate of
return in a pay-as-you-go system is related to the timing of  tax payments and benefits as well as the growth rate of the  wage bill, a more complicated correlation could be exam-  ined.
81 In principle, diversification could also be accom-  plished by swaps of different tax revenues.  82 Throughout this address, I have assumed that the  interest rate is above the growth of wages, so that the  economy is not on the wrong side of the golden-rule level of
capital.  83 This logic is clear in a two-period model. With more  periods and externalities, one might find a complex way to  argument by itself does not lead to the possibil-
ity of a Pareto gain from adding funding to an
unfunded system, just from reducing funding of
a fully funded defined contribution system.
The comparison above assumed all of the
response in the unfunded system occurred in
benefits. By having some of the response to
aggregate shocks fall on taxes, a less than fully
funded system is capable of doing additional
risk sharing across generations that does not
occur with a fully funded defined contribution
system (Douglas Gale, 1990). Of course how
good a job Congress does in adapting such a
system (whether done automatically or by re-
peated legislation) is a further issue that must be
recognized. Thus, the current system provides
insurance for individual earnings risk through
the progressive benefit formula and the retire-
ment test and provides insurance for aggregate
earnings risk through the defined benefit struc-
ture with less than full funding.
My broad conclusion here is that the absence
of a complete specification of Social Security is
not by itself an argument that there is anything
wrong with our current approach.
VII. Concluding Remarks
Occasionally, I run into people who believe
that no one in his right mind would design a
retirement income system like the one we have.
Some of the details do seem far from satisfac-
tory to me. However, looking at the big picture,
this structure makes sense. Mandated savings
makes sense if you think that many workers
would not provide themselves a reasonable re-
placement rate. This is not just an issue of
avoiding poverty, but one that extends quite far
up the income distribution. Mandating annuiti-
zation makes sense if you think that workers do
not adequately understand the value of annu-
ities. Protection of spouses and children makes
sense if you think that many workers would not
do that adequately. Relating benefits to a mea-
sure of lifetime earnings surely makes sense. A
progressive benefit formula makes sense to pro-
vide higher replacement rates for lower earners,
in order to supplement annual income taxation
benefit everyone, taking advantage of the externalities to  offset the payment for funding. But I have not seen anyone  show such a possibility.
MARCH 2004  22


### ---Economics-2004-0-24.txt---
as part of lifetime earnings insurance and redis-
tribution, to offset some of the redistributive
effects of uniform annuitization, and to address
the low antipoverty protection for the elderly
(SSI) in contrast with other advanced countries.
The retirement test at some ages makes sense.
Having redistributed to earlier cohorts,
spreading the implied cost over the indefinite
future (not fully funding Social Security) makes
sense and incomplete funding contributes to
risk sharing across cohorts. Relying on a mix of
a smaller mandatory system than is common in
Europe and voluntary private supplementation
makes sense, even though the voluntary system
is so incomplete in its coverage (and in need of
improved regulation). This is not to say there
are not other approaches that have led to sys-
tems that function reasonably well. It is just to
say there is no need for radical reform in order
to have a good system-just a need to put the
program on a stronger financial footing while
improving the benefit structure at the same time.
I chose to write about why Social Security is
better than many people think rather than why
trying a radical reform would be worse than
many people think. A preference for a radical  reform can reflect different values and different
political predictions from mine. However, I
think that much of the apparent appeal of radical
reform lies in the implausible implicit assump-
tion that such a reform will pass into legislation
untouched by political hands, making for a
faulty comparison with the current system
which has flaws introduced and preserved by
the political system. A major reason for my
concern about radical reform is the potential for
ill-advised design, driven by political ideology
rather than a realistic assessment of likely out-
comes. A better goal than seeking radical re-
form is trying to improve the highly satisfactory
current structure.
## Economics-2005-0


### ---Economics-2005-0-01.txt---
Social insurance is a subject I have been
studying for nearly 40 years. The intellectual
and policy revolution in social insurance that is
occurring around the world is among the most
significant and positive developments of current
economics.1
Social insurance programs have become the
most important, the most expensive, and often
the most controversial aspect of government
domestic policy, not only in the United States
but also in many other countries, including de-
veloping and industrialized nations. In the
United States, these programs include Social
Security retirement, disability, and survivor in-
surance, unemployment insurance, and Medi-
care insurance for those age 65 and older.
Together these programs accounted for 37
percent of federal government spending and
more than 7 percent of GDP in 2003. These
ratios have increased rapidly in the past and are
projected to increase even faster in the future
because of the more rapid aging of the
population.
I will discuss how the major forms of social
insurance could be improved by shifting to a
system that combines government insurance with
individual investment-based accounts: unem-
ployment insurance savings accounts (UISAs)
backed up by a government line of credit, per-  sonal retirement accounts (PRAs) that supple-
ment ordinary pay-as-you-go Social Security
benefits, and personal retirement health ac-
counts (PRHAs) that finance a range of Medi-
care choices. I think that such reforms would
raise economic well-being and are also appeal-
ing on broader philosophical grounds.
Several nations are now doing this for their
retirement programs, including such diverse
countries as Australia and Mexico, England and
China, Chile and Sweden (Feldstein, 1998a;
Feldstein and Horst Siebert, 2002). The focus
by governments around the world on social
insurance pension reform is driven in part by the
realization that the aging of their populations
implies that the tax rates required to fund social
insurance pension benefits will rise rapidly if
the programs are not changed.
The impetus for broader social insurance re-
form comes from the recognition that existing
programs have substantial undesirable effects on
incentives and therefore on economic perfor-
mance. Unemployment insurance (UI) programs
raise unemployment. Retirement pensions induce
earlier retirement and depress saving. And health
insurance programs increase medical costs. Gov-
ernments are driven by a desire to reduce the
economic waste and poor macroeconomic perfor-
mance that these disincentives create and to avoid
the resulting tax consequences, as well as the
increased tax cost, of the aging population.
Economic research has helped policy offi-
cials to recognize these undesirable effects and
to redesign social insurance programs. The pace
of reform and the nature of the program changes
differ from country to country, reflecting initial
conditions and local political realities. Reforms
are inevitably only partial and part of an ongo-
ing process. But the reforms generally make the
programs more economically efficient, provid-
ing more protection relative to the financial
costs and the economic distortions. I will exam-
ine some of the favorable changes that have
already occurred in U.S. unemployment, retire-
ment, and health care programs.
Before looking at these specific types of so-
cial insurance, I want to discuss three general


### ---Economics-2005-0-03.txt---
questions. Just what is social insurance? Why
do, or should, we have such programs? And
what are the principles by which such programs
should be evaluated and redesigned?
I. Social Insurance and Welfare Programs
The word "insurance" is used to describe
these transfer programs because they deal with
risks: the risk of job loss, of health care ex-
penses, and of inadequate assets during retire-
ment. But social insurance is very different
from private insurance. The key distinction is
that participation in social insurance programs
is mandatory or is induced by substantial fiscal
subsidies.
Social insurance programs are also very dif-
ferent from welfare programs. Welfare benefits
are means tested, i.e., they are paid only to those
with incomes (and assets) below some level. In
the United States, these means-tested programs
include Medicaid, food stamps, subsidized
housing, school lunches, and others.2 In con-
trast, social insurance programs are "event con-
ditioned." Benefits are paid when some event
occurs in an individual's life regardless of the
individual's income or assets. Unemployment
benefits are paid to those who lose their jobs and
Medicare benefits to those who are ill and over
65. Social Security benefits are available to
those over age 62, disability benefits to those
unable to work, and survivor benefits to the
widows and children of deceased workers.
Unlike welfare programs, social insurance
programs are not designed to be vehicles for
income redistribution. Although some fraction
of social insurance outlays is paid to those with
low incomes, most of the benefits go to middle-
and higher-income households. This is particu-
larly true in the United States, where cash ben-
efits to retirees and the unemployed are positively
related to previous earnings and where health care
is provided by private hospitals and physicians,
even when financed by social insurance.
Social insurance may appear to be redistrib-
uting income to the poor because benefits are
paid to those who are temporarily poor due to
the event that triggered the payment of benefits.
This ignores the permanent or lifetime income  of these recipients. It also ignores the effect of
the social insurance on the incentive to accu-
mulate funds for these rainy days. Social Secu-
rity benefits that replace 50 percent or more of
after-tax pre-retirement income reduce signifi-
cantly the incentive to save for old age and
therefore depress income in retirement. Unem-
ployment benefits with high replacement rates
have a similar effect on saving to finance spells
of unemployment.
The lack of redistribution is well illustrated
by the Social Security retirement program. Last
year, a new retiree who had annual earnings at
or above the Social Security program maximum
taxable amount ($87,900 in 2004) for at least 35
years received a benefit of $21,900. In contrast,
someone with lifetime earnings in the middle of
the earnings distribution received only about
two-thirds as much in retirement benefits. And
someone with low earnings (i.e., 45 percent of
the average wage) received benefits of less than
$9,000 a year. This lack of redistribution is
compounded by the rules governing benefits to
spouses and widows. A retiree who previously
had maximum taxable income and who retired
with a dependent spouse received more than
$32,000 a year from Social Security, while the
widow of a low-income earner would receive
less than $9,000 a year.
The Social Security program appears to be
redistributive because everyone pays the same
tax rate, while the ratio of benefits to lifetime
earnings is designed to fall as those earnings
rise. In practice, however, this apparent redis-
tribution is offset by the longer expected life of
higher-income individuals, their increased use
of spousal benefits, and the later age at which
they begin to work and to pay taxes. Research
by Jeffrey Liebman (2002), based on a large
sample of actual individual earnings histories,
showed that less than 10 percent of Social Se-
curity benefits represented net redistribution
across income groups within the same birth
cohort. Julia Lynn Coronado et al. (2000)
showed that the combination of taxes and ben-
efits for the Social Security program leaves the
lifetime Gini coefficient of the population's in-
come essentially unchanged. In addition, the
general equilibrium effects of Social Security
tilt the pretax distribution of income toward
higher income individuals by reducing capital
accumulation, which in turn lowers real wages
and raises the return to capital.  2 See Robert A. Moffitt (2003) for detailed studies of a
variety of welfare programs.


### ---Economics-2005-0-04.txt---
Unemployment insurance also does not redis-
tribute to the poor. In Massachusetts, a state con-
sidered to have a very generous UI program, the
UI benefits were financed in 2003 by a payroll tax
on only the first $10,800 of earnings (with a zero
marginal tax rate above that level), while basic
benefits were 50 percent of previous wages up to
more than $50,000 of wages per year.
An individual who earns $50,000 a year pays
the same tax as someone who earns $11,000 a
year but would receive benefits that are nearly
five times as high.3 Taken by itself this would
mean a substantial redistribution from low-
wage earners to higher-wage earners. Moreover,
since benefits are paid only to individuals who
have earned some minimum amount during the
past year, those with long spells of unemploy-
ment may not be eligible for any benefits at all.
Although the same Medicare rules apply to
everyone over age 65, higher-income seniors
often get substantially more benefits than those
with lower incomes. Mark McClellan and
Jonathan Skinner (1997) concluded that Medi-
care produced net transfers from the poor to the
wealthy as a result of the higher annual expen-
ditures and longer survival times of wealthier
Medicare beneficiaries. In the same spirit, Skin-
ner and Weiping Zhou (2004) found greater use
of mammography screening, diabetic eye ex-
ams, and other indicators of good care among
high-income Medicare groups than among
those with lower incomes.
The very high level of spending on the mid-
dle class social insurance programs hurts the
low-income population in another way: by put-
ting a drain on the government budget in a way
that reduces the funds available for helping the
poor. Social insurance programs cost $800 bil-
lion in 2003, while federal spending on all
means-tested programs, except Medicaid, was
less than $150 billion.4 Over the past four de-
cades, the spending on means-tested programs
(except Medicaid) has remained relatively con-
stant (rising from 1.0 percent of GDP to 1.3
percent of GDP) while the social insurance pro-  grams that are not means tested rose from 2.7
percent of GDP to 7.4 percent of GDP.
The negative effect of social insurance spend-
ing on means-tested programs is not only an
observed fact but is also what optimal tax theory
implies. The deadweight burden of an extra
dollar of taxes increases with the share of income
taken in taxes. The high level of taxes that is
needed to finance middle-class social insurance
programs therefore increases the deadweight bur-
den of any incremental taxes that would be used to
finance means-tested poverty programs. The large
social insurance programs thus reduce the optimal
size of means-tested poverty programs.
II. Why Social Insurance?
Some writers see social insurance in broad
philosophical terms, reflecting their specific
views of the appropriate role of government in
society. One such view, more common in Eu-
rope than in the United States, is that social
insurance should be judged by its contribution
to social solidarity, i.e., to the sense that all of
the individuals in the nation are, in effect,
viewed as a single family and treated equally.
This leads to the principle of uniform health care
for all, although this is more often an asserted
political goal than a practical reality. Similarly,
they may reject any role for company-based
private pensions in order that all workers par-
ticipate in a common pay-as-you-go state plan.
The opposite philosophical view is that the
provision of health care or retirement income is
not a legitimate role for government because it
forces individuals to participate in a common
program rather than taking personal responsi-
bility and making decisions that reflect their
own preferences. Milton Friedman's Capitalism
and Freedom (1962) is the classic statement of
this view that social insurance programs are
inappropriate because they infringe upon indi-
vidual liberty.
The social solidarity view is often combined
with the statement that individuals are incapable
of making the complex decisions required to
plan for retirement income or to choose health
insurance or health care. The opposite view
emphasizes that individuals differ in their tastes
and are better able than governments to judge  what is in their own best interest.
I believe in the diversity of individual pref-
erences and the ability of most individuals to act  3 The unemployment tax is technically levied on the  employer but the incidence is likely to be primarily on the
employee.  4 Although Medicaid is a means-tested program, more  than half of its outlays are for nursing home care for the  very aged rather than care for those with low lifetime
incomes.


### ---Economics-2005-0-05.txt---
in their own self interest. But I also believe that
there is a role for government that justifies the
provision of social insurance benefits. I come to
this conclusion on utilitarian grounds rather
than from any philosophical commitment to so-
cial solidarity.
There are two distinct reasons for providing
social insurance. Both reflect the asymmetry of
information. The first is that asymmetric infor-
mation weakens the functioning of private in-
surance markets. The second is the inability of
the government to distinguish between those
who are poor in old age or when unemployed
because of bad luck or an irrational lack of
foresight from those who are intentionally
"gaming" the system by not saving in order to
receive transfer payments. Both problems show
that the case for social insurance cannot be re-
jected simply by arguing that such programs force
people to act against their own best interests.
But these problems of asymmetric informa-
tion or any other market failures do not neces-
sarily justify government action. While a
perfect and benevolent government would be
better than a private market burdened by market
imperfections, actual governments are neither
perfect nor necessarily benevolent. Political ac-
tors do not maximize a social welfare function,
but reflect political pressures and bureaucratic
preferences. Moreover, social insurance pro-
grams impose costs that must be weighed
against the benefits of overcoming market im-
perfections. Both require empirical evaluation.
Consider first the asymmetry of information
in insurance markets. To be specific, consider
the case of private annuities. If individuals can
buy annuities on actuarially fair terms they may
increase their expected utility by annuitizing
their assets at retirement. But if individuals dif-
fer in their life expectancy and know more
about their mortality prospects than the insur-
ance company can learn, those with shorter life
expectancy will want to annuitize a smaller
portion of their wealth. Insurance companies
will recognize the resulting self-selection and
offer annuities with premiums that reflect the
mortality rates of the long-lived individuals
who are their most likely customers. This pro-
duces a downward spiral in the demand for
annuities that is limited only when, at some
point, the risk-reducing value of annuitizing
outweighs the less than actuarially fair pricing
of individual annuities.  A mandatory social insurance program like tra-
ditional Social Security circumvents this asymme-
try of information by providing everyone with a
retirement annuity rather than a lump sum at re-
tirement age. But whether this is better than an
imperfect private annuity market, in which some
annuitize little and others not at all, depends on the
implicit rates of return available on the social
insurance annuity, on the private annuity, and on
non-annuitized saving. It also depends on the de-
gree of diversity in preferred spending patterns in
retirement and in attitudes about bequests, since
complete annuitization at retirement would not
permit the purchase of retirement homes or other
major consumer outlays or the making of bequests
or inter vivos gifts.
The problem of information asymmetry in
private annuities could be reduced if individuals
purchased annuities at relatively young ages,
before they could accumulate much information
about their own likely mortality risks in old age.
Alternatively, a mandatory annuity could be
more attractive if it were based on the higher
return available in an investment-based pro-
gram rather than in a mature pure tax-financed
pay-as-you-go program.
Two conclusions follow from this. First, the
existence of asymmetric information may jus-
tify a social insurance program (a government
annuity in this case) but does not necessarily do
so. The case for a mandatory annuity program
depends on calculations that could be done but
that have not yet been done. Second, the appro-
priateness of a social insurance program and its
optimal size can be increased if the cost of the
social insurance option is reduced, something
that depends on how it is financed.
Consider now the second form of asymmetric
information that might provide a rationale for a
social insurance program: the government's in-
ability to distinguish those who are poor
through bad luck or inadvertence from those
who deliberately choose to act in a way that
leads to eligibility for free benefits. A primary
reason for social insurance programs is that
some individuals would not act in their own
interest, saving far too little for their retirement,
for health care after they are no longer working,
or to finance consumption when they are unem-
ployed. Although some economists may reject
the likelihood of such irrational behavior as a
basis for policy analysis, as individuals we all
recognize that such irrationality exists in prac-


### ---Economics-2005-0-06.txt---
tice. Recent work on behavioral economics has
helped to make the possibility of such irratio-
nality or myopic behavior a part of mainstream
economics.
But such departures from rational saving by a
fraction of the population need not justify the
general provision of social insurance benefits.
Why not simply provide means-tested benefits
instead of the universal provision of social in-
surance benefits? The primary reason for not
doing so is that some rational and farsighted
individuals would be induced by a means-tested
system to act in a way that allows them to
qualify for benefits. Doing so would impose tax
costs on the rest of the population that could
make overall well-being lower than in a univer-
sal (i.e., not means-tested) program.
Consider a simple example of a means-tested
retirement program (Feldstein, 1987). Assume
that some fraction of the population is myopic
and would not save anything for retirement. A
means-tested program would provide a benefit
for all such myopic retirees. How would ratio-
nal working-age individuals respond to such a
system? They would have the choice of either
saving for their own retirement or consuming all
of their income before they retire and receiving
the means-tested benefit. The potential means-
tested benefit acts as a kind of tax on saving,
reducing the incremental retirement consump-
tion that saving would produce. A rational in-
dividual would decide whether to act as if he or
she is myopic by comparing the lifetime utilities
with optimal positive saving and with no sav-
ing. Those with relatively high incomes would
not be tempted by the means-tested benefit. But
others with lower incomes would have higher
lifetime utility by increasing their consumption
during working years even if the means-tested
benefits would only provide lower consumption
during retirement than optimal saving would
allow. Although they would achieve higher life-
time utility through their action, their benefits
would be financed by tax-financed transfers,
which would make others worse off.
There is no way for the government to dis-
tinguish between the genuinely myopic and
those who are rational utility maximizers gam-
ing the system. The government could, in prin-
ciple, set the means-tested benefit so low that
very few rational individuals would be tempted.
My judgment is that our relatively affluent so-
ciety would not accept that policy. The means-  tested benefits would be set at a higher level that
would tempt many rational individuals to save
nothing.
A policy of forcing everyone to save for his
or her own retirement would eliminate the prob-
lem of those who game the system. The only
adverse effect of such a policy is that some
individuals might be required to shift more of
their lifetime consumption to their retirement
years than they would prefer. For them, part of
the mandatory saving would be a tax to the
extent that they valued the saving less than
current consumption.
The choice between such a mandatory saving
plan-essentially a kind of investment-based
Social Security pension-and a means-tested
benefit should depend on numbers. How many
people would receive means-tested benefits?
How much deadweight loss would be involved
in financing those benefits? How many people
in a mandatory saving plan would have to pro-
vide more for their retirement than they want?
In the absence of such a mandatory invest-
ment-based option, the policy choice is between
a means-tested program and a universal pay-as-
you-go retirement benefit. Such a pay-as-
you-go plan forces all individuals (after the
initial generation) to receive a lower rate of
return than they could obtain on private saving.
As such, it also imposes a tax on labor income
since each extra dollar of earnings would induce
an additional pay-as-you-go tax liability. The
reduction in saving that is induced by the pay-
as-you-go system also causes a fall in capital
income and therefore in corporate and personal
tax revenue that requires higher marginal tax
rates to recover the lost revenue.
Both of these examples of asymmetric informa-
tion show that a social insurance program may be
an appropriate response to a market failure but that
it need not be. Even when there is a market failure,
it may be better to do nothing or to have a means-
tested welfare program. The choice depends in
part on the relative costs of the different options,
and those in turn depend on the design of the
potential social insurance program. Whether such
a program is investment-based or purely tax fi-
nanced on a pay-as-you-go basis is an important  feature of that cost.
Economists can help to evaluate these choices
by estimating the relevant costs and benefits of the
different options. My own conclusion is that
investment-based social insurance programs for


### ---Economics-2005-0-07.txt---
retirement, unemployment, and health care of the
retired population are more appropriate than pay-
as-you-go programs, means-tested programs, or a
policy of doing nothing.
There is an important political economy
reason for economists to work on improving
the design of social insurance programs rather
than advocating means-tested programs for
unemployment and old age. Elected govern-
ments will inevitably seek to create universal
benefits to capture political support from the
largest possible majority of voters. Otto von
Bismark introduced social insurance in Prus-
sia in 1881 in an attempt to win support for
his conservative government and to fend off
the appeal of the nascent social democrats.
Even if it were economically desirable to do
so, economists could not prevent the spread of
social insurance by arguing that means-tested
programs would be more efficient. If econo-
mists don't analyze the effects of social in-
surance programs and recommend rules that
reflect good economics, the political process
will inevitably produce inferior programs.
III. Principles of Social Insurance
Accepting that there is a reason for mandatory
social insurance programs does not imply the ap-
propriateness of the programs that we have inher-
ited from the past. Today's Social Security and
unemployment insurance were enacted nearly 70
years ago. Economic conditions, administrative
technologies, and assumptions about economic
behavior have all changed dramatically since then.
And yet during these past 70 years, the key social
insurance programs have expanded without fun-
damental change.
Before I consider some of the specific ways
in which our basic social insurance programs
can be reformed and strengthened, I want to
discuss broader principles that can help us to
think about each of the specific programs. I'll
begin with three fundamental political princi-
ples and then turn to four economic principles.
A. Three Political Principles
Political principles involve value judgments
to a greater extent than the economic principles
to which I will turn later. I can explain the
political principles that shape my view about
appropriate reforms but I cannot prove that they  should determine policy. You may or may not
agree with them. Of course, you might agree
with me about specific reforms even if you
reject some or all of these principles.
Permitting Individual Choice.-Individuals
differ in their preferences. We do not all have
the same risk aversion, the same time prefer-
ence, the same relative taste for goods and lei-
sure. Letting individuals choose among options
in a way that reflects their individual prefer-
ences should be an important aspect of social
insurance design. For Milton Friedman, such
freedom to choose is paramount. For me, it is
important but not decisive. In cases where
asymmetric information creates serious effi-
ciency problems, I might restrict that choice.
But I prefer to allow as much choice as possible.
I think that allowing individuals to make their
own choices is morally correct and generally
improves individual, and therefore social,
well-being.
But allowing choice means that programs
should be designed so that choice enhances
economic efficiency rather than creating dead-
weight losses. A good example of such a pro-
gram redesign was the Social Security reform
that introduced the actuarial adjustment for
early and delayed retirement in a way that, in
principle, will allow individuals to decide when
they will start collecting benefits without chang-
ing the actuarial present value of their benefits.5
Creating Program Transparency.--Social
insurance programs involve complex rules
about the benefits to be received, the taxes to be
paid, and the link, if any, between them. Who
among you is confident about even the most
basic Social Security rules that determine ben-
efits at retirement? If you are a man, what
benefit would your wife receive if she collects
on her own rather than as your spouse? How
would that change if she earned more or worked
another year? If she decides to retire at age 62  rather than 65? I'm told that there are more than
2500 separate rules in the Social Security
handbook.
The complexity of the rules weakens the per-
ceived link between the payroll taxes paid and
SThis adjustment will provide actuarially equivalent  benefits with a 3 percent real rate of return.


### ---Economics-2005-0-08.txt---
subsequent benefits. Many employees may sim-
ply regard their Social Security payroll tax as
similar to the income tax, thereby increasing the
perceived marginal tax rate and raising the
deadweight loss of the tax.
Lack of transparency also permits programs
to have effects that might not be politically
acceptable if they were more explicit. For ex-
ample, some defenders of the current Social
Security system believe it permits a substantial
amount of redistribution that Congress would
not be willing to build into an investment-based
system of individual accounts. Although the
Social Security rules do not actually achieve
that redistribution, the important political prin-
ciple is that it is inappropriate in a democracy to
use a deliberately opaque system to achieve a
redistribution of income that would be rejected
if proposed in a more transparent way.
The Social Security program lacks transpar-
ency because it is a defined benefit system
rather than a defined contribution plan of the
sort that now characterizes most private pen-
sions. Converting Social Security to a defined
contribution plan-even an unfunded "no-
tional" system such as Sweden and Italy now
have-would allow individuals to see the link
between their taxes and the resulting benefits.
An explicit decision by Congress to supple-
ment the contributions of low-income earners
in such a defined contribution plan would
achieve income redistribution without a loss
of transparency.
Recognizing Political Dynamics.-When we
economists talk about policy design, we gener-
ally think about enacting permanent reforms.
But experience shows that legislated rules do
change and that the initial conditions influence
the path of that change. When designing a par-
ticular program or advocating a particular de-
sign, economists should recognize that some
designs are more stable than others and should
anticipate how a program might evolve.
The Medicare drug legislation enacted in
2003 is a good example. Medicare beneficiaries
will pay the first $250 a year in drug expenses,
followed by a 25-percent coinsurance rate to a
maximum benefit limit. Patients must then pay
100 percent of the drug cost up to $3600 in
out-of-pocket payments (in 2006). Above that,
Medicare will pay 95 percent of any additional
drug costs.  This rather strange design was accepted to
limit the total cost of the plan while delivering
benefits to a very large number of senior citizen
voters. An economically more rational plan
with the same budget cost would have insured at
least part of the range that is currently uninsured
and kept total costs down by a larger deductible.
But that would have had the political disadvan-
tage of giving benefits to fewer individuals. It
seems likely that future legislation will address
the residual insurance gap in a way that will
raise the total cost of the program.
There is another and potentially more signif-
icant aspect of the future evolution of this Medi-
care drug program. If all of the drugs consumed
by seniors come to be covered by government
insurance, there will be strong pressure to reg-
ulate the price of those drugs. Such price regu-
lation is, in turn, likely to discourage the
development of drugs for those diseases that
particularly affect the elderly. It would be sadly
ironic if an insurance plan initiated to improve
drug access for seniors led ultimately to a re-
duced availability of new drugs for this group.
B. Four Economic Principles
Let me turn now from these three political
principles-permitting individual choice, creat-
ing program transparency, and recognizing po-
litical dynamics-to four economic principles.
Recognizing the Economic Effects of Social
Insurance Programs and Their Taxes.-Non-
economists who write about social insurance
programs often implicitly assume that social
insurance programs do not affect the behavior
of beneficiaries or the overall performance of
the economy. Evidence shows that the opposite
is true. Social insurance programs have impor-
tant and sometimes harmful effects on the
economy that are not fully recognized by the
public, Congress, or the politically responsible  officials.
A substantial volume of work during the past
quarter century has shown the various ways in
which social insurance programs do affect indi-
vidual behavior and the overall economy. These
effects include reducing national saving, induc-
ing early retirement, raising the unemployment
rate, pushing up the cost of health care, and
crowding out private health insurance. Any se-
rious evaluation of social insurance programs,


### ---Economics-2005-0-09.txt---
and any attempt to improve their design, should
take these effects into account.
There is, of course, controversy about the
magnitude of these effects, just as there is about
most other economic parameters. Decisions
about program design have to use the evidence
that is available, even if parameter estimates
come with substantial uncertainty. But there is
clearly room for economists to use new data,
new statistical methods, and new natural policy
experiments to improve our knowledge and,
therefore, to improve policy design.
Adverse effects result from specific program
designs and are not inherent in the goals of the
programs. For example, John Gruber and David
Wise (1999) showed that the rules governing
retirement benefits induced early retirement in
several European countries but that different
rules at different times and in other countries
did not induce early retirement. The U.S. benefit
rules that now specify an almost actuarially fair
relationship between benefits and retirement
age reduces substantially the perceived bias in
favor of early retirement.
More generally, social insurance programs
not only distort economic behavior directly,
thereby creating deadweight losses, but also
create further deadweight losses because of the
taxes that are levied to finance those programs.
I believe that the deadweight losses of those taxes
are much larger than is generally recognized.
I will illustrate this with the effect of the
50-percent increase in the payroll tax rate that
could occur if there is no change in benefit
rules. Deadweight losses depend on marginal
tax rates. Consider an individual who now faces
a combined federal and state marginal rate of
income tax of 30 percent without social insur-
ance. The current 15.3 percent employer-
employee payroll tax rate,6 when adjusted for  the interaction with the income tax7 and for the  present actuarial value of the additional retiree
and survivor benefits that result from increased
taxable earnings, now increases the overall mar-
ginal tax rate from 30 percent to about 37.7
percent.8 A 50-percent rise in the 15.3 percent
marginal tax rate, adjusted for the income tax
interaction, would increase this effective mar-
ginal tax rate from 37.7 percent to 44.2
percent.9
The increase in the deadweight loss that
would result from this tax increase reflects both
the reduction in labor supply-broadly defined
to include not just working hours but also the
accumulation of human capital, the choice of
occupation, effort, etc., and the change in the
form of compensation-away from taxable cash
and to less valuable fringe benefits. Although
neither behavioral change can be measured ex-
plicitly, the resulting deadweight loss can be
calculated empirically by estimating the extent
to which the higher payroll tax would reduce
taxable labor income. It is appropriate to focus
on the decline in taxable labor income without
evaluating the two separate effects because the
relative price of the two components-the mar-
ginal tax rate on the reward for increased labor
supply and the marginal tax rate that determines
the net cost to the taxpayer of fringe benefits-
remains the same when the tax rate changes.
Taxable labor income is, therefore, a Hicksian
composite good that can be used to assess the
deadweight loss (Feldstein, 1999a).10
6 The 15.3 percent rate includes Medicare as well as the
Social Security pension and disability taxes. Currently the  pension and survivor insurance portion is 10.6 percent of  taxable payroll. The disability tax is 1.8 percent and the  Medicare portion is 2.9 percent. The costs of these three  components will rise at different speeds but the combined  cost will eventually increase the required tax to 150 percent  of the 15.3 percent rate.  7 Since the employer half of the 15.3 percent payroll tax  is excluded from the personal income tax base, the effective  marginal rate of tax in this example is 30 percent plus the  7.65 percent paid by the employee plus 70 percent of the  7.65 percent payroll tax paid by the employer: 0.30 +  0.0765 + 0.70(0.0765) = 0.43. The extent to which a labor  supply response causes the tax to be shifted does not alter  the appropriate calculation of the marginal tax rate.  8 Feldstein and Samwick (1992) show that the present
actuarial value of the incremental benefits varies substan-
tially among different age and demographic groups, from no  value for young workers and some married women to more  than a 100 percent offset of the incremental tax for older  men with dependent wives. If this offset is approximated by  50 percent of the 10.6 percent of the old age and survivors  portion of the tax, the 43 percent marginal tax rate calcu-  lated in footnote 8 is reduced to 37.7 percent.  9 The increase in the payroll tax rate is subject to the  income tax offset (reducing the additional 7.65 percent to  6.5 percent). There is no incremental benefit associated with  the higher tax rate.  10 The situation is more complex when we deal with  taxes on capital income. These distort choices among finan-  cial instruments by both issuers and purchasers, choices  about the form of business (corporate vs. non-corporate,  domestic vs. foreign) and choices about saving vs. spend-  ing. The key elasticity that matters in the saving vs. spend-


### ---Economics-2005-0-10.txt---
The elasticity of taxable labor income with
respect to the net-of-tax share, i.e., to one minus
the marginal tax rate on labor income, is much
greater than the traditional elasticity of labor
supply as measured by labor force participation
and average hours worked. Estimating this elas-
ticity is now a subject of very active research
among public finance economists. Although a
wide range of estimates has been produced,
some studies are more reliable than others. I
believe that a conservative estimate is that the
compensated elasticity of taxable income with
respect to the net-of-tax rate is one-half.
Using this elasticity and the 2004 taxable
payroll implies that a rise in the effective mar-
ginal tax rate from 37.7 percent to 44.2 percent
increases the annual deadweight loss by $96
billion, or nearly one percent of GDP.11 Since
the 6.5-percent increase in the marginal tax rate
applies only to taxable labor income (about 40
percent of GDP), the deadweight loss is equal to
about one-third of the incremental tax revenue.
Even this understates the relative size of the
deadweight loss because it ignores the reduction
in the tax base and therefore in the tax revenue
that results from the higher marginal tax. When
that reduction in taxable income is taken into
account, the incremental deadweight loss is
nearly 50 percent of the incremental revenue.12
The true cost per additional dollar of payroll tax
revenue is therefore $1.50.
Note that this is just the deadweight loss or
excess burden-i.e., the pure waste-associated  with the incremental tax. It does not include the
deadweight loss of the existing tax or the direct
burden of the taxes themselves. And it does not
include the deadweight loss caused by the pro-
gram distortions.
Although scaling back the rise in future ben-
efits would reduce the increase in the dead-
weight loss, it would also reduce the protection
that Social Security provides to future retirees.
An alternative approach is therefore to redesign
the program so that the increased financing re-
quired for the aging population has less of the
character of a tax.
One way to do that is to strengthen the tax-
payers perception of the link between taxes paid
and future benefits. That is one of the advan-
tages of shifting from the existing complicated
defined benefit rules to a defined contribution
system, even to a notional defined contribution
system. Although a notional defined contribu-
tion plan would remain a pay-as-you-go system,
it would clearly link each worker's social insur-
ance tax payment to his or her resulting future  benefits.
A defined contribution system would provide
a tax-benefit link for those groups in the popu-
lation that now receive no extra benefits at all in
exchange for their additional taxes. For them,
the Social Security payroll tax is a pure tax just
like the income tax. These include both young
and older workers who are not in the top 35
wage-indexed earning years of their life, the
basis on which Social Security benefits are cal-
culated, as well as working women who will
eventually claim benefits based on their hus-
bands' earnings.
Although an unfunded notional defined con-
tribution system would provide some remedy,
the very low implicit rate of return in an un-
funded system implies that the payroll tax
would retain much of its distorting character. A
pay-as-you-go plan that substitutes a 2-percent
real return for private saving that would other-
wise earn a 5-percent real return is equivalent
over a lifetime of saving and dissaving to a tax
rate of about 75 percent.13  ing distortion is not the elasticity of saving with respect to  the net-of-tax return but the elasticity of future consumption  with respect to that net of tax return; Feldstein (1978b).  Saving is equivalent to expenditure on future consumption.  The relevant elasticity is therefore much larger than the elas-  ticity of saving. If saving does not respond to changes in the net  interest rate, the relevant compensated elasticity is equal to one  minus the marginal propensity to save.  " The formula for the increase in the deadweight loss is  0.5 E (t22 - t12) TLI/(1 - t,) where TLI is taxable labor  income, t2 = 0.442 and t, = 0.377. With TLI equal to 40  percent of GDP or $4.5 trillion and E = 0.5, the implied  increase in the deadweight loss is $96 billion.  12 With a compensated elasticity of 0.5 and an income  effect of 0.15, raising the marginal tax rate from 37.7  percent to 44.2 percent on an initial tax base of $4.5 trillion  reduces taxable income by $199 billion and therefore re-  duces tax revenue by $88 billion. The net tax increase is
thus reduced from $293 billion to $205 billion and the
deadweight loss per dollar of incremental revenue increases  to 46 percent.  13 An individual who can get a real net of tax rate of
return of (say) 5 percent in an individual retirement account  (IRA) or a 401(k) plan converts one dollar saved at age 45  (in the middle of his working life) to $4.32 at age 75 (in the  middle of his retirement). But if the implicit return on a  pay-as-you-go Social Security tax is only 2 percent, the


### ---Economics-2005-0-11.txt---
A much more substantial reduction in the
effective tax rate would be achieved by financ-
ing the increased cost of Social Security and
Medicare by a funded system that would permit
future benefits to be financed without a large
increase in the tax rate. Moreover, to the extent
that the additional saving that individuals do
earns a favorable rate of return, they might not  consider it a tax at all. I will return to this issue
later when I discuss Social Security reform
more fully.
Designing Programs by Balancing Protec-
tion and Distortion, while Seeking Reforms that
Improve the Available Tradeoff.-Social insur-  ance programs generally involve a tradeoff of
protection and distortion. Social insurance pro-
grams protect individuals against undesirably
low levels of consumption during old age, spells
of unemployment, or when hit by large medical
bills. They also protect individuals from the
need to work longer than health warrants, to
accept a job when additional searching would
be adequately productive, or to forego appropri-
ate medical care because of an inability to pay.
But the same social insurance programs also
distort incentives in ways that cause inefficient
use of resources: early retirement, low saving,
unproductively long job searches, and excessive
consumption of medical care.
Social insurance program parameters should
be chosen to balance protection and distortion.
The level of Social Security benefits should
reflect the fact that high benefits relative to
previous income improve the protection against
reduced consumption in old age but also depress
saving and may induce early retirement. A high
level of unemployment insurance benefits helps
the unemployed to maintain consumption but
also encourages longer spells of unemployment
and the choice of jobs that have a greater like-
lihood of leading to a layoff. Low co-payments
in health insurance reduce the risk of foregoing
needed care or suffering a major drop in other
consumption, but they also lead to an increased
demand for care that is worth less than its cost
of production. More complete protection in  each program also raises the program cost and,
therefore, creates greater distortions through the
tax system.
As protection becomes more complete, the
marginal value of protection declines and the
incremental distortion rises. The primary goal
of social insurance should, therefore, generally
be to prevent catastrophic losses: poverty in old
age, long-term loss of income when unem-
ployed, very expensive out-of-pocket medical
costs, and the consequences of permanent
disability. More generally, at the optimum,
the marginal value of additional protection
should just equal the marginal cost of the
distortion. Economists can help the policy
process by evaluating the protection and dis-
tortion created by different changes in pro-
gram design.
Useful economic analysis can go beyond select-
ing an optimal point on a protection-distortion
frontier. It is important to seek ways to shift the
frontier, permitting less distortion at each level of
protection. Reforms based on individual accounts
that I describe later in the paper would achieve
that improvement.
Redesigning Programs to Keep Pace with
Changing Conditions.--Three important changes
that should influence the design of our social in-
surance programs have occurred since those
programs began: a changed economy, new tech-
nology, and a different understanding of the effect
of government programs on individual behavior.
The Social Security and unemployment in-
surance programs were created during the de-
pression of the 1930s when individual savings
had been destroyed by widespread bank failures
and when many individuals had been unem-
ployed for a year or more because of a lack of
aggregate demand. Keynesian economists in the
1940s like Harvard's Seymour Harris praised
the unfunded character of the new Social Secu-
rity program for its ability to depress national
saving and stimulate aggregate demand (Harris,
1941). In contrast to those depression years,
conditions in the past half-century have been
very different, with relatively low unemploy-
ment rates and a system of government deposit
insurance that protects individual savings. The
unemployment insurance and Social Security
that may have been appropriate in the 1930s is
no longer appropriate for the economy of the
twenty-first century.  dollar paid into such a plan at age 45 only grows to $1.81.  The mandatory saving in the form of the low-return Social  Security is therefore equivalent to a 75.6 percent tax (that  reduces the gain of $3.32 to $0.81).


### ---Economics-2005-0-12.txt---
A second relevant change has been in the
technology of financial administration made
possible by the introduction of computers.
When Social Security was created, President
Roosevelt wanted it to be a funded system
rather than a pay-as-you-go system.14 There
was of course no way to have individually con-
trolled personal retirement accounts and the Re-
publicans in Congress did not want to trust the
government to manage a large pool of funds.
And since the Congressional Democrats were
eager to start paying benefits, the result was a de
facto shift to a pay-as-you-go structure. The
creation of individual investment accounts for
every adult, which would have been technically
impossible in the 1930s, is no longer even dif-
ficult. Today more than 90 million Americans
own mutual funds, including IRAs and 401(k)
plan accounts. In contrast to the formidable task
in the 1930s of keeping track of everyone's
Social Security account without the help of
computers, the creation of a system of individ-
ual investment-based accounts would now be
relatively easy.
The third important change has been in the
economic profession's understanding of how
fiscal incentives affect individual behavior. In
the 1930s, economists assumed that individuals
were so unresponsive to taxes and benefits that
any behavioral response could simply be ig-
nored. Most economists continued to ignore the
adverse incentive effects even when the top
marginal tax rate was over 90 percent, as it was
from 1944 to 1963. The adverse effects of high
unemployment insurance benefits on job search
and on the choice of jobs were also ignored.
Today economists recognize that high mar-
ginal rates of income tax and the marginal tax
rates implicit in various benefit rules reduce
taxable income and create substantial dead-
weight losses.
These three changes imply that if Social Se-
curity and unemployment insurance were being
created now, the programs would likely be sig-
nificantly different from those in current law.
Economists today would regard the adverse ef-
fect of Social Security on saving and capital
accumulation as a deterrent to growth rather  than as a favorable source of Keynesian de-
mand. The widespread ownership of mutual
funds, IRAs, and 401(k)s would be a natural
starting point for any new social insurance pro-
gram. And every aspect of behavior would be
assumed to be more responsive to tax rates and
program design.
More generally, the reforms that will be en-
acted in the future will inevitably evolve as
economists learn more and as the set of feasible
options changes. An interesting example of this
changing perception of what is feasible is the
possible transition to personal retirement ac-
counts in an investment-based Social Security
program. About 20 years ago, when I served as
chairman of the Council of Economic Advisers
in the Reagan administration, the Social Secu-
rity retirement program was on the verge of a
crisis. The trust fund was about to reach zero
and the projected taxes to be collected over the
next few years were not large enough to pay the
benefits specified in law. President Reagan ap-
pointed a bipartisan commission to find a solution.
The resulting plan called for an acceleration of
scheduled future tax increases, the taxation of
Social Security benefits, and a variety of other
smaller measures.
President Reagan was unhappy with these
proposals and asked a small group of us in the
Administration whether there wasn't some-
thing better to be done, perhaps along the
lines of the Chilean reform that used in-
vestment-based personal retirement accounts
instead of a pay-as-you-go system. None of us
could design a feasible transition to such a
plan. It looked to me and to the others as if
accumulating funds to finance such per-
sonal retirement account annuities would in-
volve a double burden on the transition gen-
eration that was both unfair and politically
infeasible.
I now know that that was wrong. Research
that Andrew Samwick and I have done in recent
years (Feldstein and Samwick, 1998a, 1998b,
2002) shows that it would be possible to tran-
sition gradually to a completely investment-based
plan without ever increasing the combination of
pay-as-you-go taxes and personal retirement ac-
count (PRA) saving by more than 2 percent of
payroll earnings, or about 1 percent of GDP, and
without reducing the benefit that retirees receive
from the combination of the traditional tax-
financed program and the new investment-based  14 See Sylvester J. Schieber and John B. Shoven (1999)  for a valuable discussion of the origins of the Social Secu-  rity legislation.


### ---Economics-2005-0-13.txt---
annuities.15 The key, we learned, is to have a
transition in which the personal retirement ac-
count annuities gradually substitute for pay-as-
you-go benefits, allowing the pay-as-you-go tax
rate to decline and the PRA contribution rate to
increase until the transition is complete.
Of course, the demonstration that such a tran-
sition is feasible doesn't mean that it is desir-
able. A pure investment-based PRA plan would
involve more risk than many individuals might
want, a subject to which I will return later. But
a shift to a mixed system that avoids an increase
in the payroll tax rate or in private saving might
be an economic improvement. I'm sorry that I
couldn't offer that solution when President Re-
agan asked for it.
My point in recalling this is that economic
research has changed what we regard as feasi-
ble. Similarly, future research can and will de-
velop new ways to provide social insurance
protection with greater economic efficiency and
more responsiveness to individual tastes. A ba-
sic principle of designing social insurance pol-
icies should be a willingness to accept such
ideas when they become available.
Separating Social Insurance from Income
Redistribution.-As I indicated earlier, social
insurance programs are not means tested. Eligi-
bility for benefits does not depend on the in-
come or wealth of the recipient but on an event
like reaching age 65, beginning a spell of un-
employment, or incurring a medical problem.
Not surprisingly, the evidence that I cited makes
it clear that today's social insurance programs
do not redistribute income to the poor. Indeed,
the positive correlation of income and longevity
tilts the net benefit of Social Security and
Medicare to households with higher life-
time incomes. The structure of unemployment
insurance rules causes a similar shift in that
program.
There is, of course, a role for means-tested
programs that are more narrowly focused on
individuals who demonstrate that they have low
income or assets. Although I doubt the desir-
ability of the myriad of existing in-kind pro-
grams like food stamps and housing subsidies  (Moffitt, 2003), I have no doubt about the ap-
propriateness of transferring income to the very
poor.
There is, moreover, a clear case for being
more generous to some demographic groups
than to others. The existing Supplemental Se-
curity Income program provides means-tested
benefits to those over age 65 whose Social Se-
curity benefits plus private resources do not
together reach some minimal level. A more
generous means-tested program, targeted at in-
dividuals over age 75, would not distort labor
supply to the same extent that it would for
younger ones. It is possible, therefore, to have
more protection with less distortion in such a
means-tested program. It is a shameful feature
of our Social Security system that, even with the
Supplemental Security Income program, 10 per-
cent of those over age 65 are in poverty while
Social Security provides nearly $500 billion a
year in benefits to individuals who are finan-
cially more comfortable.
To the extent that distributional concerns mo-
tivate the design of social insurance, the empha-
sis should be on eliminating poverty and not on
the overall distribution of income or the general
extent of inequality. Like most economists, I
accept the Pareto principle that an economy is
better off if someone gains and no one loses.
This is true even if the gainer has above-average
income, causing a Gini coefficient measure of
income distribution to shift to greater inequal-
ity. Although there may be spiteful egalitarians
who reject this Pareto principle, I believe that
most economists agree with me. To see if you
do, ask yourself whether you think it would be
a good thing if everyone reading this article
received $50 by some magical process that did
not decrease the income or wealth of anyone
else. Since we are an above-income group, na-
tional inequality would rise. Nevertheless, I
think there are few who would reject bestowing
this extra wealth on us all.
This brings me to the end of my four economic
principles of social insurance. I turn now to dis-
cuss how the three major forms of social insurance
could be improved by shifting to a system that
combines government insurance with individual
investment-based accounts: unemployment insur-
ance savings accounts (UISAs) backed up by a
government line of credit, personal retirement ac-
counts (PRAs) that supplement ordinary pay-as-
you-go Social Security benefits, and personal  15 Alternative plans could achieve the transition without  any rise in taxes by allowing the Social Security Trust Fund  to borrow for a temporary period.


### ---Economics-2005-0-14.txt---
retirement health accounts (PRHAs) that finance a
range of Medicare choices.
IV. Unemployment Insurance
Although unemployment insurance is a rela-
tively small program with total federal and state
outlays in 2003 of $39 billion, it is particularly
important because of its impact on macroeco-
nomic performance. It is also significant as an
illustration of how reforms have been able to
reduce distortion while retaining protection for
those who need it. Moreover, it is a form of
social insurance where further reforms through
investment-based accounts could achieve sub-
stantial economic gains.
The unemployment insurance program in the
United States was created in 1935 in the depth
of the depression. The program is administered
by the individual states but under federal rules
that substantially restrict the scope of state gov-
ernments' actions. Benefits of a typical recipient
are 50 percent of previous earnings and can be
collected for up to six months. The European
unemployment benefit programs are substan-
tially more generous in both the relative level
and the duration of benefits, with clearly ad-
verse effects on European unemployment rates.
Thirty years ago, when I began doing re-
search on unemployment insurance (Feldstein,
1973a, 1973b), there was a general perception
that unemployment benefits were relatively low
and that they had little or no effect on economic
behavior. People were assumed to be unem-
ployed solely because there was inadequate ag-
gregate demand. Reformers focused on seeking
increases in the level and duration of benefits to
help those who were unemployed for what were
assumed to be reasons beyond their own control.
We now know that perception was wrong.
Unemployment insurance benefits raise the un-
employment rate in a variety of ways that econ-
omists have now analyzed and measured. But
back in the 1960s and 1970s, the higher unem-
ployment rates that were actually induced by
unemployment insurance were instead incor-
rectly perceived as due to inadequate demand.
When the government tried to reduce this high
structural unemployment with expansionary
monetary and fiscal policies, the result was ris-
ing inflation. Fortunately, this is now better
understood. Monetary policy no longer tries to
reduce structural unemployment. But although  unemployment insurance is therefore no longer
a source of increased inflation, it continues to
raise the rate of unemployment. This is a par-
ticularly serious problem in Europe where un-
employment rates remain close to 10 percent.
The old notion that unemployment benefits
were too low to affect the economy was the
result of a misleading comparison of the aver-
age weekly unemployment benefit and the av-
erage weekly wage. Although the average
benefit was only about 30 percent of the average
wage of all workers, the unemployed had sub-
stantially lower pre-unemployment wages than
the labor force as a whole. Unemployment in-
surance benefits actually averaged about 50 per-
cent of the pre-unemployment income of those
who received benefits, with even higher re-
placement rates in states that supplemented the
basic benefit with payments for spouses and
children. But even this substantially understated
the relevant replacement rate because benefits
were not subject to the income and payroll taxes
that were levied on wages. Since the combined
marginal rate of income and payroll tax for the
spouse of a high-earning individual could then
easily exceed 50 percent, the ratio of untaxed UI
benefits to the individual's net-of-tax potential
earnings could exceed 100 percent. For such a
person, it was possible to have a higher net
income by remaining unemployed than by re-
turning to work.
Even significantly lower benefit replacement
rates could have substantial adverse incentive
effects, as a number of studies eventually
showed. Although macroeconomists came to
recognize that much unemployment was not of
an involuntary Keynesian type but was a pro-
ductive search for good job matches, the accu-
mulating evidence showed that UI benefits were
inducing excessively long periods of searching
in which the gain from the marginal search was
less than the value of the foregone output. For
example, Larry Katz and Bruce Meyer (1990)
showed that the probability that an unemployed
person takes a job rises dramatically in the few
weeks just before their benefits would expire.
Jim Poterba and I (1984) found that the median
value of the reported reservation wage of new
UI recipients was actually higher than the wage
on their previous job, that it was an increasing
function of the UI replacement rate, and that it
came down only very slowly during their spell
of unemployment.


### ---Economics-2005-0-15.txt---
Longer durations of unemployment are not
the only adverse effect of UI benefits. The prac-
tice of temporary layoffs in which unemployed
individuals have a spell of unemployment but
return to their original employer is substantially
encouraged by high UI replacement rates (Feld-
stein, 1976, 1978a). High benefits also encour-
age individuals to accept work in firms with
high seasonal or cyclical layoffs. That reduces
the wage that such firms have to pay and thus
subsidizes the expansion of those high unem-
ployment industries.
As all of this became clear, the most obvious
first reform was to include unemployment ben-
efits in taxable income. Although there was
initially strong opposition to this idea, it was
hard to argue with the position that cash income
is cash income and should be taxed. The notion
that taxing unemployment insurance would in-
appropriately burden the poor was clearly con-
trary to the fact that the income tax allows a
substantial exclusion of income before any tax
is levied. A poor UI recipient would pay no tax.
The initial legislative compromise was to in-
clude only half of UI benefits in taxable income
and to do so only for relatively high-income tax-
payers. This provided a natural experiment that
Gary Solon (1985) used to show that the relative
duration of unemployment fell for those whose
benefits were taxed. Later, in the Tax Reform Act
of 1986, the UI benefits were fully subject to the
income tax like all other forms of labor income.
Taxing UI benefits eliminated the possibility
that an individual could have a higher net in-
come from UI benefits than by working. It is
hard to know what the aggregate effect on un-
employment has been, but my personal estimate
is that the unemployment rate probably fell by
about one-half percentage point after benefits
were taxed, an effect equal to more than
500,000 jobs at any time.
The evidence that UI benefits cause substan-
tial distortion led to analytic studies of the level
of benefits that optimally balances distortion
and protection. Martin Bailey (1978) presented
an analytic model in which the optimal level of
benefits depends on the individual's coefficient
of relative risk aversion and on the elasticity of
the duration of unemployment with respect to
the UI benefit replacement ratio. John Gruber
(1997) used this framework to derive an explicit
optimal UI benefit based on data on the effect of
unemployment on household food consump-  tion, concluding that the optimal replacement
rate should be much less than the 50 percent in
current law. More recently, however, Raj
Chetty (2003) showed that the measure of risk
aversion that is relevant to designing the opti-
mal UI benefit may be substantially greater than
the risk aversion that is relevant to financial
investments, because many types of household
spending cannot be adjusted in the short-run,
which is relevant to unemployment spells. Chet-
ty's analysis points to optimal UI replacement
rates that are close to the levels that we observe
in the United States.
These calculations of optimal UI benefits as-
sume that individuals have no financial assets.
In contrast, if individuals save optimally, the
optimal value of UI benefits--especially for
short and moderate spells would be very much
less. Although there is evidence that individuals
who face greater income uncertainty have
somewhat higher saving rates, it would be
wrong to assume that in the absence of unem-
ployment insurance everyone would save
enough to finance consumption optimally dur-
ing spells of unemployment. Some individuals
would be too short-sighted to save for potential
unemployment.
What is the optimal response to this problem?
One possibility would be to continue the current
system of paying UI benefits but with the level
and time path of benefits selected to balance the
gain from protection and the loss from distortion.
Another possibility would be to shift to a means-
tested program, although that would induce some
individuals to game the system, saving nothing so
that they could qualify for means-tested benefits
when they became unemployed. The same prob-
lem of asymmetric information would prevail, as
in the case of Social Security retirement benefits
that I discussed before: the government could not
distinguish individuals who were too short-sighted
to save from those who were gaming the system.
On efficiency grounds, the choice between the
current system and government means-tested ben-
efits would depend on the response of unemploy-
ment to the benefit level and on the relative
number of those who would save optimally, those
too shortsighted to save, and those who would
choose not to save in order to qualify for the  means-tested benefits.
A third possibility is to require everyone to
have an unemployment insurance savings ac-
count earmarked to pay benefits if unemploy-


### ---Economics-2005-0-16.txt---
ment occurs. Dan Altman and I (Feldstein and
Altman, 1998) explored a variety of such pos-
sible plans. In a typical plan, each individual
would be required to accumulate funds in an
unemployment insurance savings account until
the balance was enough to pay benefits for two
spells of six months at 50 percent of the indi-
vidual's current wage. These funds would be
invested and would earn a market rate of return.
After a transition period to accumulate account
balances, anyone who would be eligible for
unemployment benefits under today's UI rules
would instead be able to withdraw the same
amount from his unemployment insurance sav-
ings account. If a balance remains in the ac-
count when the individual reaches retirement
age, the funds would be available for the indi-
vidual to take and spend. An individual who
dies before retirement bequeaths the account
balance. In short, individuals would regard the
funds in the UISA as their own money. For
someone who expects to have a positive balance
in his account until retirement, the UISA plan
would provide the same income protection as
the current UI system, but without any  distortion.
What about individuals who experience so
much unemployment that they use up the funds
in their UISA? Such individuals would be able
to borrow from a government UI fund to receive
the same benefits that they would withdraw if
they had a positive account balance. After they
return to work, they would again save to repay
the loan with interest and to rebuild their UISA
balance. If they expect their account to accumu-
late a positive balance in the future, the dollars
that they borrow would be a very real obligation
and the incentives to return to work would not
be distorted by the government loan. They
would have full protection and no distortion
while unemployed and would accumulate per-
sonal wealth after they returned to work.
It is only those who expect that they will have
a negative balance in their account when they
retire for whom this plan would represent no
improvement over current law. For them, the
protection and distortion would be the same as
it is with the current UI rules.
The extent of the gain from introducing unem-
ployment insurance savings accounts therefore de-
pends on the proportion of the unemployed who
expect to retire with negative balances and on the
sensitivity of unemployment to the change in in-  centives. Dan Altman and I did some preliminary
empirical analysis of this approach using a sample
of men in the National Longitudinal Survey. We
found that, even with no favorable behavioral re-
sponse of unemployment to the improved incen-
tives, less than 10 percent of benefits would be
paid to those who eventually retire with negative
balances (or who had negative balances when our
data sample ended).
Our analysis thus implied that the UI program
could be redesigned around individual unem-
ployment insurance savings accounts in a way
that substantially reduces the current distorting
effect while not reducing either the availability
of funds when unemployment occurs or the
protection against relatively large cumulative
amounts of lifetime unemployment. More re-
search on this potential form of unemployment
insurance would certainly be valuable.
V. Social Security16
Social Security is the largest social insurance
program in the United States, with expenditures
in 2003 of $470 billion, or 22 percent of total
federal government spending. It includes not
only annuities for retirees and survivors but also
a separate program of disability insurance that
accounts for some 15 percent of the total Social
Security outlays. Since the disability insurance
program involves a range of very different is-
sues, I will not be considering it in this article.
Social Security is now a defined benefit, pay-
as-you-go program in contrast to the defined
contribution, investment-based structure of most
private pensions. In a defined benefit program,
an individual's benefit at retirement depends on
his earnings during his working years and not
on the performance of asset prices during that
time. The program is a pay-as-you-go one be-
cause most of the payroll taxes collected in each
year are used to pay concurrent benefits. There
is not the kind of asset accumulation and finan-
cial investment that there would be in a private
16 Feldstein and Liebman (2002a) provides a survey for  the Handbook of Public Economics of the large theoretical  and empirical literature on Social Security. See also my Ely
Lecture to the American Economic Association (Feldstein,  1996a) and a forthcoming article in the Journal of Economic  Perspectives (Feldstein, 2005b) that deals with the current
reform debate in more detail.


### ---Economics-2005-0-17.txt---
pension. The benefits are financed by a payroll
tax on earnings currently up to about the eighty-
fifth percentile of the distribution of wages
($87,900 in 2004). The payroll tax rate devoted
to the Social Security program other than dis-
ability is now 10.6 percent, divided equally
between employers and employees.
Benefits take the form of an annuity that is
indexed to the CPI to retain its real value during
the individual's retirement years. The level of
benefits at retirement depends on the average
wage-indexed earnings of the individual during
his or her highest 35 earning years. The benefit
formula provides higher annual benefits per dol-
lar of previous earnings at lower earnings levels
than at higher levels. Individuals who retire
before their normal retirement age (now rising
gradually from 65 to 67) receive an actuarially
reduced benefit, while those who retire after
their normal retirement age receive an actuari-
ally increased benefit.
Couples may collect benefits either on the basis
of their separate earnings records or as 150 percent
of the benefits of the individual with the higher
benefit level. A surviving spouse can receive 100
percent of the benefit of the higher earning spouse.
These rules for spouse benefits have the effect of
causing many women who pay Social Security
taxes to get little or nothing back for their taxes
since their benefits are based on their husbands'
incomes. This is true not only for married women
but also for younger women who expect to marry
and for divorced women and widows who will
also expect to claim benefits based on their former
(or future) husbands' earnings.
I became interested in Social Security as a
graduate student in the 1960s when I realized
that the tests of consumption theory-Fried-
man's work on the permanent income hypoth-
esis and Modigliani's work on life cycle
saving- completely ignored the role of Social
Security even though it had become the major
source of retiree income. I realized also that the
theory of Social Security's effect on saving was
more complex than a simple displacement of
financial wealth by Social Security. To the ex-
tent that Social Security induces earlier retire-
ment, it raises the desired level of financial
wealth. The net effect of Social Security on
saving therefore depends on the balance be-
tween the positive induced retirement effect and
the negative wealth displacement effect, an is-
sue that could be settled only empirically.  My initial time series analysis (Feldstein, 1974)
implied that Social Security "wealth," the present
actuarial value of future Social Security benefits,
significantly reduced personal saving. Reestimat-
ing this equation 22 years later with a corres-
ponding amount of additional data produced reas-
suringly similar results (Feldstein,1996b) The
conclusion that Social Security depresses private
saving was also supported by household data and
cross-country analysis. Other researchers who
looked at this question generally supported the
primary conclusion, although with estimates of
varying magnitudes (Congressional Budget Of-
fice, 1998).
This adverse effect of Social Security on sav-
ing is relevant to understanding the significance
of Paul Samuelson's very important 1958 over-
lapping generations paper (Samuelson, 1958).
Samuelson showed that a pure pay-as-you-go
Social Security system in an economy without
capital and without technical progress would
generate an implicit rate of return on each gen-
eration's taxes equal to the rate of growth of the
population. This occurs because the number of
taxpayers is larger by the rate of growth of
population than the number of retirees. If tech-
nical progress is added to this economy, the
implicit return in a pure pay-as-you-go system
is still the rate of growth of the tax base, now
the sum of the growth rate of population and the
growth rate of productivity.
Samuelson noted that this positive rate of return
meant that an unfunded Social Security program
could raise welfare in an economy that has no
capital assets. But what happens when we recog-
nize that all economies do have capital stocks and
that Social Security transfers act as a substitute for
real capital accumulation? With that more realistic
description, the reduction in the rate of saving
caused by the provision of pay-as-you-go annu-
ities can cause a reduction in the present value of
all current and future consumption.
To understand why, consider first an oversim-
plified textbook economy in which there are no
capital income taxes. Each generation of workers
receives an implicit pay-as-you-go return equal to
the sum of population and productivity growth but
foregoes the larger return equal to the marginal
product of capital. For each such taxpayer gener-
ation, there is, therefore, a cost of having a pay-
as-you-go Social Security program rather than
providing for retirement consumption by saving
and investing in real assets (or the financial assets


### ---Economics-2005-0-18.txt---
that represent a claim on those real assets.) How-
ever, the initial generation of retirees had the good
fortune to receive benefits without ever having
paid taxes.
It can be shown that aggregating the consump-
tion losses of all generations of taxpayers back to
the initial date using a discount rate equal to the
marginal product of capital produces a present
value loss just equal to the windfall gain of the
initial retirees. (Feldstein and Liebman, 2002a;
Feldstein, 2005b) In short, with these simplified
"textbook" assumptions, the introduction of a pay-
as-you-go Social Security program does not re-
duce the present value of national consumption
but rather redistributes it from later generations to
the first one. More generally, whenever the pro-
gram is expanded, those who are about to retire or
who will soon retire receive a windfall gain at the
expense of all future generations but with no
change in the present value of consumption over
all generations.
This neutrality result depends, however, on the
implicit assumption that there are no distorting
capital income taxes.17 With capital taxes, the
appropriate intra-generational rate of discount of
consumption is less than the marginal product of
capital. Moreover, the appropriate rate for aggre-
gating the consumption of different future gener-
ations may not be a market rate at all but a
discount rate equal to the rate of decline in the
marginal utility of consumption. With a realistic
growth rate and any plausible value of the elastic-
ity of marginal utility with respect to consump-
tion, the appropriate rate of discount would be far
less than the marginal product of capital.'8 With
that discount rate, the net present value of the loss
of consumption due to introducing and then re-
peatedly expanding a pay-as-you-go Social Secu-
rity would be very large. Similarly, shifting from
a pure pay-as-you-go program to a mixed program
with a substantial investment-based portion would
cause a large rise in the present value of
consumption.
The reduction in saving and in the present
value of consumption is not the only adverse  effect of a pay-as-you-go program. A second
important effect is the distortion of labor supply
and of the form in which compensation is paid
because of the increase in the marginal tax rate.
The relevant marginal tax rate is the statutory
rate net of the anticipated increase in the actu-
arial value of benefits. The increase in benefits
is zero for many married women. It is also zero
for individuals who are not in one of their 35
highest earning years, typically when they are
either young or old, so that the higher effective
marginal tax rate comes when the individual's
attachment to work is relatively weak. Many
individuals may also underestimate the effect of
additional earnings on future benefits. In all of
these cases, the payroll tax may create a sub-
stantial deadweight burden.
This incremental deadweight loss from dis-
torting the labor supply would be essentially
eliminated if individuals earned a market return
on their Social Security savings, as they would
in an investment-based system. That would
make the actuarial present value of their benefits
equal to their Social Security savings. The only
labor supply distortion would result if some
individuals were forced to do more saving for
retirement than they preferred or thought that
the implicit actuarial terms of the annuity did
not reflect their own mortality risk. A mixed
system that combines pay-as-you-go and invest-
ment-based components would reduce but not
eliminate the labor supply distortion.
A third distortion caused by a traditional pay-
as-you-go system is the incentive to retire early
when an implicit tax results from the loss of
benefits caused by delayed retirement. Although
the United States has now largely eliminated
this by an appropriate actuarial adjustment, this
distortion remains a major problem in Europe
and elsewhere (Gruber and Wise, 1999). Early
retirement increases the annual cost of Social
Security benefits and reduces the available labor
income tax base. This leads to a higher marginal
rate of Social Security tax, further increasing
that source of deadweight loss. When combined
with formal or informal restrictions that prevent
reducing wages to offset the high payroll tax
rates, these taxes contribute to the high unem-
ployment rates that we see in Europe. The U.S.
experience shows that this problem can be elim-
inated within the pay-as-you-go system. It
would, of course, also be eliminated in an
investment-based system in which retirement  17 For an explicit derivation of the neutrality result and an  examination of the implication of capital income taxes and of  other discount rates, see Feldstein and Liebman (2002a).  18 For example, with a per capita growth rate of two
percent and an elasticity of the marginal utility function of  two percent per year, the rate of decline of the marginal  utility of consumption would be 4 percent.


### ---Economics-2005-0-19.txt---
income is withdrawn from personal accounts,
which can be bequeathed if the individual dies
before exhausting the account or before annu-
itizing the accumulated balance.
The analysis of these three types of distortion  should make it clear that the shift to a "notional"
defined contribution system would help only a  little to reduce the adverse effects of the current
pay-as-you-go system. A notional defined con-
tribution system is one in which each individual
has an account that is credited with his tax
payments and with a notional rate of return on
his accumulated balance, but in which there is
no actual investment in financial assets. The
notional rate of return that is feasible in the long
term is the modified Samuelson return, i.e., the
rate of growth of the tax base. Since there is no
real capital accumulation, the reduction in the
present value of consumption is not changed.
The distortion in labor supply and in the form of
compensation is reduced (but not eliminated)
because individuals can more clearly see the
link between their taxes and their future bene-
fits. A notional defined contribution system also
reduces the distortion in retirement decisions
because individuals reduce their future benefits
if they retire early and increase them by delayed
retirement. But even with this improved trans-
parency, the low implicit pay-as-you-go rate of
return leaves a substantial distortion in work
and compensation incentives.
Although the scope for reducing the substan-
tial deadweight losses of the pure pay-as-you-go
system and for increasing the present value of
all future consumption should provide a strong
incentive for a change in policy, they are not the
reason that has driven the political process in
many countries to move from a pure pay-as-
you-go to a mixed system or to consider such a
change. The primary driving force is the recog-
nition that the increasing age of the population
will require a very large tax increase or benefit
cut if nothing is done to change the existing
system. This is not a temporary effect of the
baby boom generation reaching retirement age
but a permanent result of the trend to increased
longevity. This demographic change is signifi-
cant not only because it drives the political
process but also because it increases the poten-
tial gain of making such a change.
The desirability of shifting to an investment-
based or mixed system depends on four issues: (a)
the transition process and its cost; (b) the ongoing  administrative costs; (c) the riskiness of financial
investments; and (d) the effect on the income
distribution and especially on the poorest group. I
have done work on these issues during the past
decade, both alone and with colleagues Jeffrey
Liebman, Elena Ranguelova, and Andrew Sam-
wick. I will now summarize what I have learned.
I commented earlier on the transition prob-
lem when I discussed my experience with Pres-
ident Reagan. The common view that the
transition from a pure pay-as-you-go system to
a mixed system requires the transition genera-
tion to "pay double"-once to save for their
own retirement and once to meet obligations to
existing retirees-is wrong. As examples of
what could be done, Andrew Samwick and I
(1998a, 1998b, 2002) showed how the projected
rise in the pay-as-you-go tax rate to more than
19 percent19 could be avoided if individuals
contribute just 1.5 percent of wages out-of-
pocket to personal retirement accounts. The key
to the transition is using personal retirement
account annuities to supplement the pay-as-
you-go benefits. The growth of the PRA annu-
ities offsets the slowdown of the pay-as-go-
benefits that results from not increasing the tax
rate as the population ages.
There is no free lunch in this process. The
key is that additional saving during the transi-
tion years can reduce long-run costs. This extra
saving could be voluntary, induced by a match-
ing PRA contribution out of existing payroll tax
receipts.20 Although the matching would reduce
the "trust fund" balances, the transition need not
involve borrowing by the Social Security sys-
tem from general revenue (Feldstein and Sam-
wick, 2002).21
19 The 19 percent is based on Social Security Administra-  tion's "intermediate" demographic and economic assumptions  but ignores the effect of the higher tax rate of the size of the tax  base for the payroll and personal income taxes.  20 The matching rate could be higher for low income  individuals to assure very high levels of participation. In the  extreme, the entire contribution for low-income individuals
could come from payroll tax revenue, requiring no contri-  bution of their own. High income individuals would gener-  ally welcome a chance for more tax favored saving and  could therefore be induced to participate with little or no
matching.  21 Stated differently, the Social Security Trust Fund  could remain positive and be rising at the end of the 75 year  projection period, showing that the system has long-run
stability.


### ---Economics-2005-0-20.txt---
Even a transition in which the initial personal
retirement account deposits are financed wholly
by government borrowing could eventually
raise national saving and the present value of
future consumption. Financing the initial de-
posit to personal retirement accounts by gov-
ernment borrowing would have no immediate
direct effect on national saving because the in-
creased budget deficit would be offset by the
deposit of those funds into the personal retire-
ment accounts. Over time, the availability of the
PRA annuities could permit reducing the pay-
as-you-go benefits (relative to those projected in
current law) without lowering total retirement
income. This reduction in the pay-as-you-go
benefits would mean that the annual rise in the
budget deficit would be less than the amount
transferred to the PRAs. That difference would
be an increase in national saving.22
I turn next to the issue of the administrative
cost of PRAs. Some critics of PRAs argue that
the administrative costs of a PRA program
could offset all of their higher return relative to
the pay-as-you-go system. Although there have
been bad cost experiences in some countries,
this certainly need not be so. Sweden's recent
PRA program involves administrative costs
equal to between 30 and 100 basis points of the
assets, an amount that will come down further
as the total assets grow, since the administrative
costs depend on the number of transactions and
not on the value of the assets. TIAA-CREF
operates an individual account system with a
variable annuity for a charge of only 37 basis
points.23
The issue of risk is an important consideration
in both the pay-as-you-go and investment-based
systems. Although pay-as-you-go programs do
not have asset price risk, they have the political
risk that future taxpayers may not be willing to  raise taxes when demographic or economic
changes would make it necessary to do so in order
to finance promised benefits. The United States
enacted benefit cuts in 1983 by increasing the age
for full benefits. Many Latin American countries
cut cash benefits in the 1980s and 1990s. More
recently, Germany, Italy, and Japan have an-
nounced or enacted reductions in state pension
benefits.24 Perhaps the most reliable way to avoid
future legislation that causes an unexpected reduc-
tion in retirement income is to develop a mixed
system that does not require a future rise in the
payroll tax rate.
The issue of asset price risk is more complex.
On the basis of a substantial amount of research,
I believe that a suitable mixed system that com-
bines tax-financed pay-as-you-go benefits with
investment-based PRA annuities can satisfy
three conditions: a substantially lower long-
term cost of financing retirement income than
the tax projected for the pay-as-you-go system;
a higher expected level of benefits from the
combination of pay-as-you-go and the PRA an-
nuities; and a very low probability that the ac-
tual level of combined benefits will be less than
the pay-as-you-go benefits projected in current
law.25 The low risk could be achieved by a
combination of three things: the floor on retire-
ment income provided by the pay-as-you-go
benefits in the mixed system, restrictions on the
investments that can be made in the PRAs, and
explicit guarantees provided by either the gov-
ernment or the private market. Because individ-
uals differ in their risk preferences, the solution
that can best reflect those different preferences
may be the availability of a variety of alterna-
tive guarantees from the private organizations
that manage the PRAs and PRA annuities (Feld-
stein, 2005a).
I turn, finally, to the issue of the distributional
effect of the shift from our pay-as-you-go sys-
tem to a mixed system. I have already discussed
the evidence that the current Social Security
system does very little redistribution and leaves
some 10 percent of seniors with incomes below
the poverty line. Women who were never mar-
ried, widows, and particularly those who were
widowed or divorced at a relatively early age  22 Feldstein and Liebman (2002a, section 7.1.3) used an
overlapping generation model to show how such a debt  financed transition could raise the present value of con-  sumption. The rise in saving does not happen in the first  period but begins after that. The debt service on the initial  borrowing cannot be financed by additional borrowing  alone; the growth of the debt must be less than the growth  of the economy.  23 See Shoven (2000) for several discussions of admin-  istrative issues. The chapter by Fred T. Goldberg, Jr., and  Michael J. Graetz (2000) shows how administrative costs  can be reduced while maintaining the individual account
structure.  24 See John McHale (2001) for more evidence on this
point. 25 See Feldstein (2005a, 2005b) for a more extensive
discussion of the risk issue.


### ---Economics-2005-0-21.txt---
generally have quite low benefits under current
law and could do substantially better under a
mixed system (Feldstein and Liebman, 2002b).
Divorced women would benefit if the total of
the husbands and wives' PRAs are pooled and
divided at the time of divorce.
While a PRA itself does not cause any in-
come redistribution, the redistributive structure
of the pay-as-you-go benefits could, in princi-
ple, be changed to make the combined benefit
achieve any degree of redistribution.
In summary, it seems clear from the research
that has been done that the current pay-as-you-go
system could be gradually replaced with a mixed
system that includes investment-based personal
retirement accounts in a way that maintains or
exceeds the benefits that are projected in current
law, while sharply reducing the long-run cost of
achieving those benefits. This transition could be
financed with relatively small additional PRA sav-
ing by individuals or by using existing payroll tax
revenue. Even if the tax revenue is used, the initial
fiscal deficit would not decrease national saving
because of the concurrent increase in private sav-
ing. National saving would rise in the long run
because the PRA savings would exceed the in-
creased fiscal deficits.
A mixed system would eliminate the need for
a future increase in the Social Security payroll
tax and would, therefore, avoid the political risk
that future taxpayers would be unwilling to raise
taxes to finance promised benefits. It could be
designed so that, despite the asset price uncer-
tainty, there would be little risk that the com-
bined benefits would be less than the currently
projected pay-as-you-go benefits. The remain-
ing asset-price risk could be substantially re-
duced by guarantees that could be produced by
the private financial market.
VI. Medicare
Medicare, the federal health care program for
those over age 65, is more difficult to reform
than either unemployment insurance or Social
Security. The program is more complex and the
reaction to proposed changes is often more
emotional. And yet without reform, Medicare
costs will rise even more dramatically than the
cost of Social Security retirement benefits, re-
flecting the increasing numbers of the very old
(who consume relatively more medical care)
and the changing medical technology that pro-  vides new opportunities to spend money to pro-
long life and increase the quality of life.
Before looking at Medicare, it is useful to
consider the basic theory of health insurance
and the current way that the government pro-
vides a kind of quasi-social insurance for the
population under age 65 by its favorable tax
treatment of employer payments for health in-
surance. This is important in itself and suggests
an approach that may be useful for reforming
Medicare.
The basic theory of insurance implies that a
risk-averse individual will prefer an actuarially
fair insurance policy to an uncertain and exog-
enous distribution of potential losses. But the
distribution of potential health spending is not
exogenous and the gain from risk reduction
must be balanced against the distorting effect of
insurance on the demand for care. As insurance
becomes more complete, the marginal gain
from additional risk reduction declines and the
marginal deadweight loss from distorting the
demand for health care rises. At the optimum
level of health insurance (e.g., at the optimum
coinsurance rate) there is a deadweight loss
caused by the distortion in the demand for care
because individuals, advised by their doctors,
make decisions about diagnosis and treatment
based on a net price of care that is very much
less than the cost of producing that care. That
level of insurance is, however, efficient because
the deadweight loss from distorted demand is
less than the gain from risk reduction.
In actual practice, the demand for health in-
surance is greatly increased by the tax treatment
of excluding employer payments for health in-
surance from the taxable income of employees.
Allowing employees to buy health insurance
with pretax dollars in this way changes the
nature of health insurance. For someone with a
marginal tax rate of 40 percent, the ability to
buy health insurance at a cost of only 60 cents
per dollar of premium substantially increases
the demand for health insurance with low de-
ductibles and low coinsurance rates. This in-
creases the deadweight loss caused by the
distortion in demand for care.
Direct attempts to eliminate or even reduce
the tax subsidy or to constrain it by requiring
minimum deductibles or coinsurance rates have
not been politically successful. When the Rea-
gan Administration proposed to limit the em-
ployers' deduction for health insurance premi-


### ---Economics-2005-0-22.txt---
ums, it was unable to get any member of the
President's own party to introduce the legisla-
tion in Congress.
Recently, however, Congress enacted legisla-
tion to shift the incentives away from excessive
health insurance. The new health savings ac-
count (HSA) rules, enacted as part of the 2003
Medicare legislation, allow individuals or their
employers to deposit up to $5,000 of pretax
income into a health savings account if they
have a health insurance policy with an equally
large deductible and with protection against cat-
astrophic expenses. The individual foregoes the
advantage of the tax-free income in the form of
the employer-paid premium, but gets an even
larger tax-free income in the form of the health
savings account contribution. Assets in these
IRA-like accounts earn tax-free investment in-
come. Funds not spent in one year automatically
carry forward to the future and can be used to
finance any kind of health care without paying
tax. Funds can also be withdrawn for any other
kind of spending by paying tax at that time.
The health savings accounts create a strong
incentive to choose policies with high deduct-
ibles instead of the current comprehensive low-
deductible and low coinsurance policies. This,
in turn, should change the nature of the demand
for care. Until individual health spending
reaches the deductible limit, money spent on
health care is the individual's own money and
not that of an insurance company. Spending
below the high deductible limit, therefore,
would not have any of the distortion caused by
current policies with low deductibles and low
coinsurance rates. And the requirement that the
policies provide protection for catastrophic lev-
els of spending means that the most important
form of protection is retained or increased at the  same time that the distortions are reduced.26
Of course, anyone who spends several days
in a hospital will exceed the deductible limit. At
that point, the insurance company is paying for
care as it would today and the patient and his
doctor no longer have the incentive to be cost
conscious. The favorable incentive effects of
the HSA could be increased without reducing
the individual's insurance protection by replac-
ing the deductible with a 50-percent coinsur-  ance rate on spending up to twice the level of
the HSA saving deposit. For example, the limit
associated with the $5,000 HSA deposit would
shift from a $5,000 deductible to a 50 percent
co-payment on the first $10,000 of care, causing
significantly more individuals and health spend-
ing to be in the cost-conscious range.
The shift from the current tax-induced com-
prehensive insurance to large deductibles or co-
insurance is not only a way to limit excessive
health care spending, i.e., spending that individ-
uals and their doctors recognize as less valuable
to them than the cost of production. It is also a
way of making health spending reflect each
individual's preferences. While all of us want
good health, the lifestyles choices that individ-
uals make show that some of us value it more
than others. Although we all understand the
adverse health effects of obesity, smoking, and
the lack of exercise, not everyone acts on this
information. Many people knowingly make the
tradeoff to enjoy more eating, to smoke, and to
avoid the rigors of exercise. Just as people make
different lifestyle choices, some are more will-
ing than others to sacrifice more of other con-
sumption to increase spending on health care.
Health savings accounts will allow this expres-
sion of taste in health care spending instead of
effectively inducing almost everyone to pur-
chase high-cost health care.
Health savings accounts may be a model for
Medicare reform. If nothing is done, the cost of
Medicare to the federal government will rise
from 2.4 percent of GDP to about 6 percent by
2030 and 8 percent by 2050. The rising cost of
Medicare is similar to, but even more dramatic
than, the rising cost of Social Security retire-
ment benefits. The remedy for this problem
should have two components: changing the
spending incentives to slow the growth of
Medicare outlays, and using a mixed financing
system to raise the needed funds without the
sharp tax increase that would otherwise be
needed (Feldstein and Samwick, 1997; Feldstein,
1999b).
If health savings accounts are successful, the
high deductibles and coinsurance that will
evolve because of the HSAs for those under age
65 may establish a precedent that will also af-
fect future Medicare benefits and therefore the
spending incentives of the Medicare population.
A mixed financing system for Medicare
could combine a tax-financed Medicare annuity  26I discussed this type of health insurance reform in
Feldstein (1971) and Feldstein and Gruber (1995).


### ---Economics-2005-0-23.txt---
for retirees geared to the then-current cost of
health care plus an opportunity for individuals
during their working years to accumulate funds
in retirement health savings accounts. These
combined funds could be used at retirement to
pay for the type of health plan that the retiree
prefers: a comprehensive insurance plan of the
type that Medicare now provides; membership
in a health maintenance organization that pro-
vides a managed care plan; or a lower cost plan
with substantial deductibles and coinsurance.
Alternatively, working age individuals could
use the funds contributed annually to their re-
tirement health savings account to purchase
health insurance for their retirement years,
thereby minimizing the problem of asymmetric
information in policy choice at retirement
that would occur in buying insurance after
retirement.
VII. Conclusion
The reform of social insurance is clearly a
work in progress in the United States and in
other countries as well. Policymakers can do
much to improve the major social insurance
programs that protect the unemployed, the aged,
and the ill. Economists can contribute to this
process by improving our understanding of the
effect of social insurance rules and by deriving
new program designs. In this paper I have em-
phasized the use of personal investment-based
accounts created and regulated by the govern-
ment and earmarked for unemployment bene-
fits, for retirement income, and for health care
during retirement. Such accounts have the po-
tential to provide a better tradeoff of increased
protection and reduced distortion. They also
give individuals greater discretion in tailoring
benefits to their own tastes.
I am an optimist about economic policy. I
have examined what is wrong with our current
social insurance programs and what could be
done to improve them in the future. I believe
that the policy process does evolve and that
economists have contributed to that evolution.
We see that in the important reforms of the past
two decades that I have described. But there is
still much for economists to do in designing
better policies for the future and in educating
the public and the political decision makers
about the desirability of making such changes.
## Economics-2006-0


### ---Economics-2006-0-03.txt---
You cannot simply tell a person in dire
need, wait for the market to take care of
you. That is a most callous thing to say,
and only makes a person feel owned, and  with no control over his life.
Letter to the Editor,
New York Times, 2005
[I]t is not enough to simply liberate peo-
ple and assume that they will automati-
cally pursue economic prosperity. People  need to be instilled with certain beliefs,
like the belief that ... individuals have the
power to shape their own destiny. ... It's
important to understand the beliefs that
encourage people to work hard and grow
rich.
David Brooks,
New York Times, 2005
I. Consumers and Markets
Economic theories and ideologies are
founded on the principle that consumers have
well-defined preferences, and consistently be-
have to advance their self-interest. Jeremy
Bentham (1789) said, "My notion of man is
that ... he aims at happiness ... in every thing he
does." Herbert Simon (1957) said, "The rational
man of economics is a maximizer, who will
settle for nothing less than the best." Some
economists have even taken self-interest to ex-
plain choice tautologically:


### ---Economics-2006-0-04.txt---
excessive fees and overselling. However, the
sweep of decentralization and privatization is, I
believe, widely viewed by economists as an
almost universal success, with the failures
due to correctable flaws in market design. Ro-
mantics of the economic right would carry the
concepts of self-interested consumers and
free markets even further, embracing a wither-
ing of authority and a nirvana of Hayekian
self-reliance.
Most reasoned discussions of privatization
among economists concentrate on information
asymmetries, incentives, economies of scale
and scope, risk management, and the relative
efficiency and sustainability of alternative
forms of market organization. There are serious
economic questions as to whether, for example,
the technologies of network industries inevita-
bly lead to concentration, with an attendant loss
of choice and efficiency. There are serious ques-
tions as to whether adverse selection will defeat
the efficiency gains from competition in multi-
ple-payer privatized insurance markets. It is a
worthy scientific enterprise to study these is-
sues, and look to the historical record of privat-
ization for answers, but not one that I will take
up in this paper. I will concentrate, instead, on
the decision-making of consumers, the market
outcomes they achieve as a result, and the in-
fluence of these outcomes on their attitudes
toward markets.
In the general public we see widespread un-
ease about market solutions. Free trade and
globalization, privatization of social insurance,
and deregulation of energy markets all elicit
opposition from many consumers, sometimes
reasoned but often inchoate. It is no coincidence
that support for market solutions is concentrated
among the economically successful, and oppo-
sition among the less successful. Free choice
has moral appeal, but moral fiber is strongest
when not cut by self-interest. Market mecha-
nisms have to compete for votes with alternative
resource allocation schemes more favorable to
the underdogs; and in this competition, fairness
to me is my primary concern, efficiency is
someone else's problem. In addition, there is
ideological opposition to market solutions. In
the liberal orthodoxy, markets are dominated by
the powerful and rapacious, and the motives of
government bureaucrats are purer than those of  private bureaucrats. In this ideology, the process
of privatization often serves the interests of the
politically connected. The Enrons and Halibur-
tons of this world reinforce these views. How-
ever, ideologies themselves are woven from
human sentiments, and antipathy to market so-
lutions is more than just doctrine.
My concern in this paper is that it is not
enough to find ways to handle information and
technology issues in privatization if consumers
are not up to the task of functioning satisfacto-
rily in such markets. The argument is not that
consumers should be coddled; they may need to
see the stick to get the incentives for self-
reliance right. However, the efficiency and sta-
bility of an economy requires that all consumers
be part of the franchise, in reality and in per-
ception, so that good economic policies, includ-
ing privatization and free markets when they
make sense, receive broad support. I will dis-
cuss these issues at two levels. First, I will give
a selective review of the behavioral evidence on
consumer decision-making, and how this influ-
ences market outcomes and attitudes toward
markets. Second, I will summarize results that
my research group has obtained on a current,
concrete privatization issue, the new Medicare
Part D prescription drug program, which is of-
fering market choices within a social insurance
program. I will ask whether consumers are, in
fact, able to manage their choices adequately in
this new market, and whether they will, in fact,
gain from the added choice offered by privat-
ization. The following fundamental questions,
explored in pioneering papers by James J. Choi
et al. (2003) and Richard H. Thaler and Cass R.
Sunstein (2003), comprise an important scien-
tific agenda:
* Are consumers sufficiently consistent in ad-
vancing their self-interest in specific markets
to achieve the levels of efficiency and well-
being that privatization promises?
* What can be done as part of the design of
privatization, such as information, instruc-
tion, and support structures, to help consum-
ers satisfactorily pursue their self-interest?
* When privatization is in consumers' self-
interest, how can they be enlightened and
convinced to support the change?


### ---Economics-2006-0-05.txt---
II. The Challenge of Choice
Agoraphobia (ayopa` + 6f3o(, literally  "fear of the marketplace") Fear of leav-
ing a safe place, fear of being in situations
from which escape might be difficult or
embarrassing; fear of losing control in a
public place such as a restaurant or shop-
ping mall.
Psychology Today
Studies of consumer perceptions, motiva-
tions, and behavior give a complex picture of
self-interest and the determinants of well-being.
Consumers often find choice overwhelming,
and decision-making uncomfortable. In the
words of a Dutch proverb, "He who has choice
has trouble." We routinely use procrastination,
precommitments, habit, imitation, social norms,
defaults, and superstitions to avoid confronting
choice. We pass up trading opportunities, par-
ticularly in unfamiliar situations. We are suspi-
cious of trading partners, and fearful of
deception, exploitation, or unfair treatment. In
short, we exhibit various degrees of agorapho-
bia, a term that means literally "fear of the
marketplace," adapted by psychiatrists to mean
fear of leaving a safe place for a situation from
which it might be difficult or embarrassing to
escape. Reflect on the major decisions in your
own lives-choice of college, occupation, car,
house, and spouse-and in most cases you will
feel you made the right choice, but will recall
the choice process itself as an emotional, stress-
ful experience.
By rational calculation and accumulated ex-
perience, we benefit from choice. Then, why do
consumers fear markets and find choice trou-
bling? First, there is market risk. Forget the
antiseptic, well-lighted budget sets and markets
of economics textbooks. Real-life markets are
rough, murky, tumultuous places where com-
modity attributes shift, supply is uncertain,
prices are volatile, and information is imperfect.
Caveat emptor prevails, and caution and calcu-
lation are vital. The sure-footed may thrive, but
their success may come in part from the failures
of the less experienced and nimble. Second,
there are personal risks, including the risk of
misperception and miscalculation, of misunder-
standing the available alternatives, of misread-  ing one's own tastes, of yielding to a moment's
whim and regretting it afterward. Finally, there
is social risk, the interactions between people
that trade requires; the stress of information
acquisition, search, and bargaining; the stress of
dealing with pushy or deceptive sales tactics;
and the risk of being embarrassed or defrauded.
How do consumers deal with these risks?
And what is it about these risks that leads to
broad biases against market-based resource al-
location? Perhaps such inference is rooted in
human psychology. Consumers often have the
perceptual illusion that other freeway lanes or
supermarket lines move faster than their own,
because the occasions on which this occurs are
particularly noticeable and irritating. Similarly,
they may have the perceptual illusion that they
are particularly unlucky, or subject to discrim-
ination and exploitation in markets, because
their bad experiences stand out. Markets that
work well for you are invisible, those that don't
are a source of frustration and grief.
III. The Consumer's Mind
What if everything is an illusion and noth-
ing exists? In that case, I definitely over-
paid for my carpet.
Woody Allen
To understand how consumers deal with mar-
ket, personal, and social risks, it is useful to
study how they think, and the social context of
thought and trade. While the mutual benefit of
trade is the aspect emphasized in economics,
trade is also a contest, with the issues, emotions,
and stresses that competitions entail: Is the play-
ing field level and the referee fair? Will my
opponent play by the rules? Can I match her
knowledge and skills? The competition itself,
not just the outcome, becomes a source of plea-
sure or pain. Trade is part of the way that
humans as social animals define and defend
themselves, a process that is both cognitive and
visceral.
Mind and trade are linked in human prehis-
tory. I relate an evolutionary tale, adapted from
Matthew Ridley's book The Origins of Virtue.
A few million years ago, the great apes estab-
lished family groups that were successful in the
essentials-obtaining food, protecting them-


### ---Economics-2006-0-06.txt---
selves from predators, and reproducing. In com-
mon with other animals, they evolved a sense of
personal space sufficient to provide some de-
fense against attack, and a system of trust and
reputation that allowed them to suspend their
"fight or flee" defenses and live together with
family members. These spatial social interac-
tions had a physiological basis-reward path-
ways in the brain and neurotransmitters that
facilitated social contact, reciprocity, and mu-
tual aid. Some of these apes discovered that
through division of labor, specialization, and
trade, they could be more productive and fertile,
and live better and longer. But trade, particu-
larly outside the family group, was risky busi-
ness. To get close enough to a stranger to trade
flints for furs, one had to risk being attacked.
The most successful apes dealt with this by
developing the ability to form bonds of trust
over larger social groups than the family. This
was accomplished by adapting the brain's vis-
ceral reward pathways that already allowed
family units to function. Second, these apes
developed analytic, social, and communication
skills that allowed them to operate in larger
social and economic groups. These were cere-
bral activities, and evolution selected species
with more cerebral capacity. Among these apes
were our ancestors. They gave us large brains,
with the capacity to explore the corners of our
universe, and to engage in sophisticated eco-
nomic activities. They also gave us an emo-
tional reward system that processes economic
actions in much the same visceral way that it
processes personal interactions: when to ap-
proach and when to avoid, whom to trust, and
when to form personal or professional bonds.
The evolutionary tale I have just told is spec-
ulation, based on observations of contemporary
apes and other animals, and fossil records.
However, the role of trust and reward pathways
in the brain, and how they affect economic
conduct, is something that we can investigate
experimentally, using the tools of brain science
and the new discipline of neuroeconomics to
study the processing of economic choice prob-
lems at a physiological level. Brain measure-
ments include maps of energy consumption,
observed under experimental treatments that al-
ter electrochemistry and cognitive task. These
measurements fall short of Edgeworth's wistful  call in 1881 for a hedinometer to record plea-
sure, but they provide some insight into the
sensations that economists call utility.
The early biologists observed that as the hu-
man embryo developed, it seemed to go through
stages of evolution, from a simple one-celled
creature to its complex final form. That view
was superficial, but it does seem to be the case
that human physiology, and in particular the
structure of the brain, is consistent with a lay-
ering of added functionality over a simpler and
more primitive core. The aspects of brain func-
tion that we identify with being human-lan-
guage, the cognitive processes of deduction and
induction, the ability to empathize and interact
with others-are primarily sited in the frontal
lobe of the cerebrum, the outer layer of the brain
whose relative size and complexity in humans
differentiate us from most other species. The
more primitive limbic system, buried at the base
of the cerebrum, is heavily involved in emotion
and the reward pathways associated with sen-
sations of pain and pleasure. The limbic system
is active in animal behavior at a visceral level:
approach and avoidance, foraging, territory, and
reproduction. The electrochemistry of the lim-
bic system is similar in all animals, and on
the evolutionary scale clearly predates human
development.
Most people think of economic activity as
quite cerebral, learned through lengthy educa-
tion and shaped by culture. If the brain is the
hardware, then the utilitarian calculus might be
pictured as software, an operating system that is
stored and run at various, possibly relocatable,
hardware sites, and is modified, Linux-like, by
experience and selection. In this view, monitor-
ing the brain can tell you something about the
burden the software places on the hardware, but
relatively little about what the software is doing.
The picture that is now emerging, however, is
that economic behavior, like the brain itself, has
layers. Working a spreadsheet to balance a re-
tirement portfolio is indeed a high-level, learned
skill. Economic trading, however, also seems to
involve relatively primitive circuits in the lim-
bic system. Therefore, you should not be sur-
prised to learn that brain hardware is associated
with economic decisions in a substantial and
relatively direct way. Specifically, the limbic
system and its reward pathways qualify as the


### ---Economics-2006-0-07.txt---
brain's primary center for recording pleasure,
and are active when we are involved in matters
of threat, trust, sex, and economic trade.' If you
have ever dismayed over convincing students
that economics is a sexy subject, you can now
tell them that shopping and sex share the same
neurotransmitters and receptors.
The linkages from physiological sensation to
conscious interpretation and reasoning may be
complex, and physiology alone may give an
incomplete picture, just as computer hardware
monitoring gives an incomplete picture of what
software is doing. Nevertheless, it should be
clear than any ability to measure directly in the
brain the impact of economic choice tasks on
reward pathways is potentially an immensely
powerful tool for linking economic activities
and consumer well-being.
How do organisms process sensations of
pleasure and pain? The answer goes directly to
the question of whether there is a single, abso-
lute physiological scale of well-being or utility,
and whether the organism consciously or un-
consciously acts out of self-interest to maximize
this quantity. First, both behavioral observation
and brain studies indicate that organisms seem
to be on a hedonic treadmill, quickly habituat-
ing to homeostasis, and experiencing pleasure
from gains and pain from losses relative to the
reference point that homeostasis defines (see
Sanfay et al., 2003). People quickly grow to
accept the city in which they are located, their
job, their mate, and their health status. They
may recognize and complain about unfavorable
absolute states, but their levels of satisfaction by
various measures are not nearly as differentiated
as they would have to be if their sensation of
well-being were experienced on an absolute scale.
Second, the picture that emerges from brain
studies is that the dopamine reward pathways in
the limbic region play a central role in experi-
1See Limo R. Becerra et al. (1999), Kent C. Berridge  (2003), Meghana Bhatt and Colin F. Camerer (2005), Mi-  chael A. Bozarath (1994), Camerer (2003), Antonio  Damasio (2005), John Dickhaut et al. (2003), Ernst Fehr et  al. (2005), de Quervain et al. (2004), Paul W. Glimcher et
al. (2005), David Laibson (2005), Kevin McCabe et al.  (2001), Samuel M. McClure et al. (2004), Michael Kosfield
et al. (2005), Aldo Rustichini et al. (2003), Alan G. Sanfey  et al. (2003), and Fehr and Tania Singer (2005).  encing pleasure, and also mitigate, with a lag,
the sensation of pain (see Becerra et al., 1999;
McClure et al., 2004). Adaptation to homeosta-
sis and differentiation between the pleasure and
pain circuits coincide with the powerful endow-
ment and loss aversion effects, and sensitivity to
framing and context, found in behavioral stud-
ies, and suggest that these phenomena are tied
fundamentally to brain structure. This is good
news and bad news for utilitarians: the limbic
system reward pathways record pleasure and
pain on what seems to be close to a utilitarian
scale, but brain circuitry processes experience
in ways that are not necessarily consistent with
relentless maximization of hedonic sensation.
One of the interesting bits of contemporary
biology has been the establishment for a variety
of species of simple direct links from particular
genes to the production of, and receptors for,
specific neurotransmitters, and from this to spe-
cific social behavior. One peptide, oxytocin, is
particularly involved in bonding and trust be-
tween animals, most notably between parents
and their offspring. This is relevant to econom-
ics because, in the words of Kenneth Arrow,
"every commercial transaction involves an ele-
ment of trust." In a study that strikes at the heart
of consumer sovereignty, Fehr et al. (2005) and
Michael Kosfield et al. (2005) administer oxy-
tocin or a placebo to subjects, and then ask them
to play the trust game. In this game, an investor
is given 100 MU. She has the option of placing
Y MU with an anonymous trustee, who through
the experimenter receives triple this amount.
The trustee then volunteers to send Z MU back
to the investor. The trustee's subgame is a dic-
tator game in which norms of fairness and rep-
utation matter, but the rational response in a
single-shot anonymous game is to return noth-
ing. By backward induction, the investor should
send nothing. In fact, both the investment and
the return are usually positive, with the level of
investment higher in subjects who are adminis-
tered the "trust" peptide oxytocin. Oxytocin has
no effect, however, on play of the dictator sub-
game, where trust does not matter. The conclu-
sion is that economic perceptions and decisions
are sensitive to brain chemistry, and susceptible
to chemical manipulation.
Neuroeconomics is a new subject, and the
future will determine its potential and limits for


### ---Economics-2006-0-08.txt---
understanding economic choice behavior. It al-
ready seems to confirm and explain, however,
that brain structure and chemistry are behind
some systematic anomalies in economic behav-
ior, particularly failures to form perceptions and
pursue self-interest consistently when con-
fronted with choices involving remote, uncer-
tain, or ambiguous outcomes, failures to recall
or anticipate in full color the sensations that
outcomes produce, and the quick adaptation to
circumstance, the hedonic treadmill.
IV. Personal Risk
What information consumes is rather ob-
vious: it consumes the attention of its
recipients. Hence a wealth of information
creates a poverty of attention, and a need
to allocate that attention efficiently among  the overabundance of information sources
that might consume it.  Herbert Simon, 1971
A large literature from behavioral eco-
nomics and psychology finds that people  often make inconsistent choices, fail to
learn from experience, exhibit reluctance  to trade, base their own satisfaction on
how their situation compares with others',
and in other ways depart from the stan-
dard model of the rational economic
agent. If people display bounded ratio-
nality when it comes to maximizing
utility, then their choices do not neces-
sarily reflect their "true" preferences,
and an exclusive reliance on choices to
infer what people desire loses some of
its appeal.
Daniel Kahneman and
Alan Krueger, forthcoming
The biological evidence that the human brain
is complex and layered, more an imperfect
meeting of minds than an optimizing computer,
follows and supports behavioral evidence from
cognitive psychology and experimental eco-
nomics showing that humans are, well, all too
human in the ways they retrieve and evaluate
information, and process decisions.2 In over-  view, these studies suggest that homo economi-
cus-sovereign in tastes, steely-eyed and
point-on in perception of risk, and relentless in
maximization of happiness-is a rare species.
While consumer behavior in familiar market
settings may have these characteristics, when
we approach the consumer from a different an-
gle, asking direct and unusual questions about
beliefs or values, or offering novel products and
services, we find alarming variations from the
story of consistent advancement of self-interest.
All these apparently normal consumers are re-
vealed to be shells filled with heuristics that
have been shaped by evolutionary selection and
experience. These heuristics often work. For
example, two of my rules which seem success-
ful are: "Never buy a Rolex from a street
vender" and "Never accept an e-mail offer to
transfer millions of dollars to my bank ac-
count." However, throw the consumer a curve
ball, in the form of a question that fails to fit a
standard heuristic for market response, and the
essential "irrationality" of the organism is re-
vealed. For most economists, this is the plot line
for "Stepford Consumers," a real horror movie.
Even if this bleak portrayal is true, however, it
does not mean that policy conclusions based on
consumer rationality are wrong, only that the
consumer may need to be coaxed and wheedled
into responding to market choices with suffi-
cient diligence to approximate rational promo-  tion of self-interest.
Most of the evidence on consumer decision-
making comes from laboratory experiments.
Economists reviewing the experimental evi-
dence sometimes comment that markets punish
inconsistencies, and consumers learn to avoid
them. They then conclude that while these flaws
may appear in experiments, they are not impor-
tant for economic behavior. This may be true in
repeated, familiar market settings where the
conduct and rewards of others provide good
2 Edited volumes that survey this subject include Kah-  neman et al. (1999), Kahneman and Amos Tversky (2000),  Thomas D. Gilovich (2002), John H. Kagen and Alvin E.  Roth (1995), George Loewenstein et al. (2003), and Charles  R. Plott (forthcoming). See also Charles Bellemare et al.  (2005), Ronald Bosman et al. (2005), Camerer (1999),  Camerer and Thaler (1995), Donald Green et al. (1998),  Teck H. Ho et al. (forthcoming), Michael D. Hurd et al.  (1998), and Olaf Johansson-Stenman and Hector Svedsater
(2003).


### ---Economics-2006-0-09.txt---
TABLE 1-FACTUAL AND AFFECTIVE MEMORY
Effect Description
Affective attenuation Affective memories are recalled/anticipated with diminished intensity  Availability Memory reconstruction is tilted toward the most available and salient information  Primacy/recency Initial and recent experiences are the most available  Reconstructed memory Imperfect memories are rebuilt using contemporary cues and context, historical exemplars,  customary search protocols  Selective memory Coincidences are more available than noncoincidences  Subjective time History is compressed and attenuated, duration neglected
examples. Some consumers are slow learners,
however, and many markets are inconsistent
teachers, providing more irritation than illumi-
nation, giving random awards and punishments
that consumers cannot always translate into ac-
curate road maps for successful behavior. Even
if consumers do learn from experience, remem-
ber P. T. Barnum's comment that "there is a
fool born every minute," additional mugs for
the market game. Importantly, the sting of mar-
ket punishment breeds agoraphobia. Just as
children humiliated in the classroom may be
turned off rather than educated, consumers hu-
miliated in the marketplace may develop an
aversion to markets, where opportunities for
choice may be interpreted as opportunities for
mistakes, embarrassment, and regret.
A. Memory and Perceptions
There are now extensive experiments and
insights from cognitive psychology showing
that memory is imperfect and perceptions are
often biased and statistically flawed (for de-
tailed surveys see Matthew Rabin, 1998; Mc-
Fadden, 1999). Consider, first, factual and
affective memory. Our memories guide our per-
ceptions of alternatives and our preferences, and
imperfections in remembering facts and sensa-
tions can distort our perspective, leading to in-
consistent behavior and disappointment. Table
1 summarizes some of these effects; I will com-
ment on how they can lead to suboptimal mar-
ket outcomes.
What we store and retrieve from memory
is affected by mood and emotion. Laura
Carstensen (Susan M. Charles et al., 2003;
James J. Gross et al., 1997) finds that advertise-
ments are remembered better, and influence  choice more, when the affective content of the
ad matches the mood of the consumer. George
Loewenstein (1996) finds that emotional sen-
sations are more easily remembered than non-
emotional ones, but emotions themselves are
difficult to retrieve from memory-we remem-
ber experiencing episodes of pleasure or pain,
and these memories can powerfully condition
our behavior-"once burned, twice shy"-but
we fortunately cannot relive the experiences in
their original intensity.
Finding and retrieving information from
memory is a complex cognitive task. The an-
swer may be on the tip of your tongue, but
sometimes the tip of your tongue is hard to find.
We use contemporary cues to guide memory
search, and to fill in and bluff when memory
fails. Consequently, what we remember is in-
fluenced substantially by current context and
mood, and these are vulnerable to manipulation
in the presentation of choice alternatives.
Selective memory is the phenomenon in
which we remember what draws our attention.
Coincidences stick in our minds, noncoinci-
dences are forgotten. This influences probability
judgments. A good example is the belief in the
"hot hand" in athletics, the idea that players can
get in the groove for some period of time and
play consistently above their game. Objectively,
the hot-hand phenomenon does not exist-the
observed distribution of runs of success is con-
sistent with independent Bernoulli trials, not
with heterogeneous spurts and slumps. The ex-
planation is that long runs are coincidences that
are selectively remembered. One of the impli-
cations of selective memory for market behav-
ior is that people build up elaborate and
complex beliefs about causal relationships be-
tween events, taking natural events personally,


### ---Economics-2006-0-10.txt---
TABLE 2-JUDGMENT AND THE FORMATION OF PERCEPTIONS AND BELIEFS
Effect Description
Anchoring Judgments are influenced by quantitative cues contained in the decision task  Context/framing History and framing of the decision task influence perception and motivation  Endowment/reference point Status quo is a "safe" known alternative: "The devil you know is better than the devil
you don't"
Extension Representative rates are more available than integrated experience  Prominence/order The format or order of decision tasks influences the weight given to different aspects
Prospect Probability calculus is inconsistent; asymmetry in gains and losses
Regression Causal structure attributed to fluctuations; failure to anticipate regression to mean
Representativeness Frequency neglect in exemplars
and persuading themselves that they are system-
atically lucky or unlucky in handling market
risk.
Another important memory effect is subjec-
tive time. You all know the canard, "Time flies
when you are having fun." We have trouble
keeping time scales straight in our memories.
We telescope time, so past events seem more
recent than they actually were. We are unsuc-
cessful in integrating sensation over time. In a
phenomenon studied by Daniel Kahneman,
Alan Krueger, and others (Kahneman and
Krueger, forthcoming; Donald C. Redelmeier
and Kahneman, 1996), episodes of pleasure or
pain are remembered selectively in terms of
peak and most recent sensation. This can lead
consumers to choices that "remember" better
than they "experience." There is a relationship
between subjective time and brain structure--
current sensation is recorded in the limbic sys-
tem and its reward pathways, memory of past
and anticipation of future sensations are proc-
essed in the cerebrum, more analytic and less
colorful. David Laibson and colleagues have
studied this as the physiological explanation for
hyperbolic discounting (Fehr, 2001; Laibson,
2005; Laibson et al., 2005). A final comment is
that subjective time is not a new element in
explaining consumers' sensations and behavior.
Francis Y. Edgeworth (1881) proposed, follow-
ing William S. Jevons (1871), that the same
objective time may correspond to different rates
of thought and feeling in different periods, so that
the utility of an experience will be the subjective
time integral of the sensations involved.
Perceptions and beliefs are influenced by the
way we process information (see Table 2).
Memory plays a role, e.g., selective memory is  implicated in regression and representativeness
effects. We overemphasize recent, available ex-
perience in forming beliefs, and depend heavily
on readily available cues to construct our per-
ceptions when we need them to make choices.
In experiments, consumers are often influ-
enced by the context and framing of perceptual
tasks and choices, and anchor their perceptions
to cues contained in the choice task. Anchoring
affects statements of willingness to pay (WTP)
for public goods obtained by direct elicitation
when consumers have incompletely articulated
tastes for these goods (see Green et al., 1998).
In addition, anchoring distorts responses to fac-
tual questions in surveys. Beyond this, why
should economists be interested? The answer is
that anchoring effects appear clearly in market
transactions involving complex commodities.
For example, houses and automobiles are typi-
cally sold by bargaining, starting from an initial
listing price or manufacturer's suggested retail
price. Field experiments with real estate agents
show that manipulation of initial offers can in-
fluence bargaining outcomes. A study by Itamar
Simonson and Amos Tversky (1992) finds that
when products are positioned so that one ap-
pears to be a bargain, a form of anchoring, then
consumers will flock to the apparent bargain
alternative. When I told a friend who owns a
Boston seafood restaurant that he could use this
result to reposition his wine list and increase his
profits, his response was "tell me something I
didn't learn in hotel school."
Anchoring is one example of how consumers
may be influenced by context and framing that
should be irrelevant to choice. A second impor-
tant example is the endowment effect, also
called a reference point or status quo effect, in


### ---Economics-2006-0-11.txt---
Median
O1 100
90
80
70
60
50
40
30
20
10
0 Ask
Bid
0 10 20 30 40 50 60 70 80 90 100
Quantity
FIGURE 1. PENCIL EXPERIMENT OFFERS
which consumers show a reluctance to trade
away from any position in which they are es-
tablished. The endowment effect appears in
stated preference studies, where WTP for an
increased amount of a commodity is typically
far less than willingness to accept (WTA) a
reduced amount of the commodity. Some gap is
expected, due to diminishing marginal utility,
but experiments show gaps far too large to be
explained by classical income and substitution
effects. For example, a study by McFadden et
al. (1988) of stated WTP for changes in reliabil-
ity of electricity supply found that mean stated
WTP for a change between two levels, neither
of them the status quo, was valued consistently
by consumers independently of their status quo,
but in comparisons between the status quo and
any alternative, the status quo was given extra
value, independent of its level. It appears that
the hedonic treadmill is at work, with people
habituating to their current state, and viewing
changes with distaste.  A dramatic illustration of the endowment ef-
fect is the now-classic cup experiment of Jack  L. Knetsch (1989), in which a random assign-
ment of coffee cups in a class, followed by an
opportunity to trade, produced a large gap be-
tween WTP and WTA, with far less trading than
should be needed to move from a random allo-
cation to a Pareto optimal one (see also Kahne-
man et al., 1990). I repeated this experiment in
an introductory microeconomics course at
Berkeley, using pencils embossed with the
course name. About half of the 345 students,
172, were randomly assigned a pencil. Then, a
Vickery sealed-bid uniform-price double auc-
tion was held to reallocate the pencils (see Kiho
Yoon, 2005). In this auction, each bidder has an
incentive to report her true value, independently
of the strategies of others. The income effect of
being endowed with a pencil is negligible, so
that with random assignment the distributions
of money marginal utilities of a pencil should be
the same for buyers and sellers. Then if con-
sumers are neoclassically rational, there should
be no endowment effect.
Consider a market with N participants with
values v, > "> VN, and K randomly allocated


### ---Economics-2006-0-12.txt---
pencils. In the incentive-compatible Vickery
double auction, successful buyers pay vK+ 1,
and successful sellers receive vK, with the mar-
ket operator covering the difference. The num-
ber of pencils J initially allocated to the K
highest value participants has a binomial distri-
bution, b(K, KIN). The volume in the efficient
auction is then K - J, which has mean K(N -
K)IN and variance K2(N - K)/N2.
In the experiment, the expected volume is
86.25, with a standard deviation of 6.56. The
actual market-clearing price was vK+ 1 = K =  35, and the number of market-clearing transac-
tions was 32. Under the hypothesis of no en-
dowment effect, the probability of 32 or fewer  transactions is on the order of 10-16. The me-
dian offer to buy was 10 cents and the median
offer to sell was 100 cents. A runs test confirms
(T = 12.5) that buyers and sellers do not have
the same value distribution. Thus, there is a
strong, trade-suppressing endowment effect,
generated instantaneously by a random alloca-
tion of pencils. Either tastes are changing endo-
genously, with quick habituation to the status
quo, or agoraphobia is real-consumers find
trade an edgy experience, instinctively mistrust
the market, and resist trading for small gains.
Consumer preferences among risky pros-
pects-lotteries-show a number of behavioral
anomalies that appear to be related to the en-
dowment effect. In summary, consumers appear
to evaluate lotteries as changes from a reference
point that may be sensitive to framing, and to
exhibit asymmetric loss aversion in which
losses loom larger than gains, with consumers
displaying risk aversion for gains and risk
seeking for losses, a certainty effect in which
there is a pure preference for sure things over
lotteries, and a prospect effect in which the
probabilities of low-probability events are over-
estimated. One of the consequences of these
effects is that consumers will often refuse to
take any share of either side of an offered lot-
tery, a result consistent with the observed pau-
city of real-world wagers. An additional reason
that individuals are suspicious of lotteries, and
often avoid them, is the superstitious belief that
there are hidden causal forces at work, interven-
tions that place the lottery in ambagious rela-
tionship to the rest of life.
There is experimental evidence that endow-
ment effects are attenuated when traders are
experienced (see Mikhail Myagkov and Plott,
1997; John A. List, 2004). Thus, the observed
paucity of trades in lotteries may occur primar-
ily for novel events and inexperienced traders.
These facts are consistent with a proposition
that learning by observing and by doing may be
effective in selecting rational market behavior
rules in arenas with sufficient repetitiveness to
allow these effects to operate.
B. Calculation and Processing
The ideal rational consumer has the compu-
tational power to value complex commodities
and consistently handle risk, discounting, and
option calculations, and the logical clarity to
work through the consequences of decisions
and optimize choices. In practice, both compu-
tational and logical skills are limited. This may
be inconsequential for repeated short-lived
choices, such as picking out your breakfast ce-
real or deciding when to change lanes, but these
limitations become critical for unfamiliar, not
easily reversed choices, such as occupation, job
change, house, automobile, children. The defi-
ciencies are most severe when choice involves
small, ambagious risks in the distant future, as
in the case of smoking and other addictive ac-
tivities, a perfect storm in which distortion of
perceptions of time, risk, and affect combine
with difficult computations of options and con-
tingencies. Table 3 lists some of the effects that
impede accurate processing and maximization
of preferences.
A first limitation is that we miss many choice
opportunities, and are barely conscious of oth-
ers we make almost automatically. Driving an
automobile is an example. We may ignore op-
portunities to change lanes or pass, or may
decide to do so without conscious thought. Such
decisions are usually sensible; we develop hab-
its that work well and save scarce attention
time. They may not, however, be optimal. In
particular, lack of attention may lead to procras-
tination and default choices that are, after the
fact, clearly not optimal.
I think it is remarkable on balance how well
most people function in markets, even people
with little academic aptitude. This may be be-


### ---Economics-2006-0-13.txt---
TABLE 3-DECISION CALCULATION AND PROCESSING DESCRIPTION
Effect Description
Awareness Recognition of choices, subjective definition of choice set  Construal/constructive Cognitive task misconstrued, preferences constructed endogenously
Disjunction Failure to reason through or accept the logical consequences of choices
Engagement Limited attention to and engagement in the cognitive task
Innumeracy Limited capacity to "run the numbers"  Suspicion/superstition Mistrust of offers and questioning of motives of others in unfamiliar situations; avoidance  of choices that "tempt fate"
cause we are adapted to trade, and because we
are good at copying successful behavior. Nev-
ertheless, such processing deficiencies as dis-
junction and innumeracy do confuse choice.
Ellen Peters at Decision Research studies the
ability of people to understand and logically
relate numbers, an essential skill in trading that
involves prices or barter terms, or more com-
plex valuations requiring risk assessment or dis-
counting. Even if individuals do not consciously
"run the numbers" to determine choices, they
still have to form perceptions and make judg-
ments based on numerical information. The be-
havioral evidence is that innumeracy rates are
high and significantly distort decisions. Peters
and her coauthors (Peters et al., forthcoming)
find that half the population is unable to read
and make sense of numbers in the newspaper.
Among those who score badly on a battery that
measures basic numerical and logical skills, one
finds errors such as altering ratings of risk and
choices when probabilities are presented as
number of successes out of a hundred, number
of failures out of a hundred, or as percent suc-
cesses. In one telling experiment, subjects are
offered a prize if they draw a red jellybean from
their choice of bowls. Bowl A contains 9 red
and 91 white beans, while bowl B contains 1 red
and 9 white beans, so the odds of success are
objectively better with bowl B. Nevertheless,
subjects who score low in numeracy often
choose bowl A because it "gives more chances
to win."
One could be hard-nosed about such people
and say that if they have not educated them-
selves sufficiently to look after their own inter-
ests in markets, the consequences are on their
shoulders. The economically unsuccessful can
vote, however, and they demonstrably have  used the vote at various times and places to pick
bad governments and bad economic policies.
The argument against "sink or swim" is that
when designing market mechanisms, it is in
society's interest to take a protective interest in
this segment of the population, building in in-
formation and decision-making aids, and pro-
tection from market wolves, which give these
people a chance of success, thereby increasing
the fairness of these mechanisms and support
for them. This argument becomes stronger
when one considers the sociality of choice, and
observes that there is more than "self' in
self-interest.
V. Social Risk
In risk perception, humans act less as
individuals and more as social beings who
have internalized social pressures and del-
egated their decision-making processes to
institutions. They manage as well as they
do, without knowing the risks they face,
by following social rules on what to ig-
nore.
Mary Douglas and
Aaron Wildavsky, 1982
Man is a social animal, identified with family
and kin, and with troops, tribes, clubs, ethnici-
ties, and nationalities. This has several conse-
quences for economic choice behavior. First,
individuals may look to their social networks
for information. Second, they may look to social
networks for approval, and use social account-
ability to limit choice. Social norms can be
comforting, limiting options and regrets, but
they can also lead to embarrassment, ostracism,


### ---Economics-2006-0-14.txt---
and agoraphobia. Third, consumers may, out of
pure self-interest, engage in mutually beneficial
reciprocity, simple when the acts are synchro-
nous, involving more complex elements of rep-
utation and trust when they are not. Pursuing
comparative advantage, with division of labor
and trade, is a form of reciprocity. Fourth, they
may engage in genetic altruism, making choices
that are in the interest of their progeny rather
than themselves as individuals. Fifth, they
may exhibit altruistic behavior that does not
obviously serve their personal or genetic self-
interest, such as incurring costs to sanction
greedy behavior.
A. Information
One major way sociality works is through
transmission of information, learning by imi-
tation rather than learning by doing. People
constantly make interpersonal comparisons,
judging the desirability of options from the ap-
parent satisfaction and advice of others. While
personal experience is the proximate determi-
nant of the utility of familiar objects, and may
be extrapolated to similar objects, our primary
sources of information on new objects come
from others, through observation, advice, and
association. McFadden and Kenneth E. Train
(1996) show that in innovation games with un-
certain payoffs, it may pay to wait, and learn by
observing rather than learn by doing. Charles F.
Manski (1991) has explored the possibility that
individuals faced with dynamic stochastic deci-
sion problems that pose immense computational
challenges may simply look to others to infer
valuation functions to be used to judge the fu-
ture payoff of current acts, or to infer satisfac-
tory policies. An objection to such copycat
behavior is that it fails to take account of the
individual's idiosyncratic tastes, and correct-
ing this quickly gets the individual back into
the computational difficulties that imitation  was intended to circumvent. But if tastes as well
as perceptions are modified socially, the rele-
vance and value of the lessons from others
increases.
Economic demographer Hans Peter Kohler
(2001) has investigated the effect of word-of-
mouth communication from friends on choice  of contraceptive. He studies Korean peasant
women, who have access to relatively little pub-
lic information on efficacy, costs, and side ef-
fects of new contraceptives. Choices within
villages show little diversity, but there is sub-
stantial, persistent diversity across villages.
This pattern is not explained by income, ed-
ucation, or price differences. Word-of-mouth
communication from friends was found to be
the important explanation of most women's
choices. Lack of inter-village mobility ex-
plained multiple equilibria, with persistent inter-
village differences. Thus, some apparent taste
heterogeneity is due to the boundedly rational
practice of imitation in balkanized social net-
works. The implications of social information
networks for economic policymakers is some-
thing that is part of the bible of marketing-
product launch and penetration is critical to
tipping network opinion and ensuring success.
Serious education of network information lead-
ers through demonstration and experience is
important not only for promotion of a product,
but also for its design.
In addition to providing information, social
networks may discipline the behavior of mem-
bers through consensus on social norms, ac-
countability for choices, and sanctions for  behavior that violates norms.3 The individual
gains from affiliation with such networks if
imitation and conformity save energy, if the
"expectation that one will be called upon to
justify one's beliefs, feelings, or actions, to oth-
ers" improves decision-making, and if approval
is itself a source of pleasure. The classical idea
of herd mentality is that social animals find it
easier and more comfortable to adhere to a
group, accept group roles, and mimic group
behavior than to act independently. Account-
ability reinforces herd mentality in fixed groups,
and promotes safety in numbers. Individual
membership may be voluntary, as in the pella-
ton of tightly packed riders in a bicycle race,
with riders tightly clustered and constrained
in order to save energy in preparation for
"breakaways."
3 See Gary S. Becker (1976), Francis Bloch et al. (2005),  Alan P. Hamlin (1991), and Matthijs Poppe (2005).


### ---Economics-2006-0-15.txt---
B. Reciprocity and Altruism
Reciprocity is a simple form of social in-
teraction, present in economic trade and ex-
plained by self-interest. Reciprocity is easy to
establish when it is synchronous, as in bilat-
eral barter. Asynchronous reciprocity, how-
ever, requires reputation and trust. Norms for
fair practice, and sanctions for bad behavior,
may evolve in social networks to facilitate
asynchronous reciprocity, and individuals
may by habit or internalization conform to
these norms even in novel situations where
the normal cycle of approval and reputation is
suspended (see Fehr and Klaus M. Schmidt,
1999; Laetitia B. Mulder et al., 2005). Con-
sider the single-shot ultimatum game with
anonymous players. Player 1 proposes a divi-
sion of a prize of 100 units. If Player 2
accepts, the players get the proposed shares;
otherwise, they get nothing. It is rational for
Player 2 to accept any positive amount, and
thus rational for Player 1 to offer the mini-
mum positive amount. If, however, the prob-
ability of acceptance a(s) by Player 2 is less
than one when the share s offered by Player 1
is low, then Player l's optimal strategy is to
maximize a(s) vg (1 - s). Students in a cross  section of developed countries play similarly.
Offers are usually 42 to 50 percent of the
prize, and offers less than 20 percent are
rejected about half the time. These results are
consistent with social norms for fairness in
which individuals altruistically incur costs to
punish greedy behavior.
Sam Bowles and a team of experimental
economists and ethnographers have conducted
anonymous ultimatum game experiments in 15
isolated societies whose ways of life provide
natural experiments on the influence of cultural
norms (see Joseph Henrich et al., 2001, 2004).
The findings overall are that cultures where
cooperative activity is important, and particu-
larly where people are exposed to markets, in-
duce offers in the ultimatum game that are more
equitable.
Genetic altruism is the phenomenon of
self-sacrifice for the good of your family or
kinship group. Genetic altruism appears to
explain cooperation in most species, and
seems to have a convincing evolutionary ba-
sis. It has been a central theme of socio-
biologists in the past four decades, but the
concept itself is as old as the concept of
self-interest, as in a quote from Adam Smith
(1759):
Every man feels [after himself, the plea-
sures and pains] of the members of his
own family. Those who usually live in the
same house with him, his parents, his  children, his brothers and sisters, are nat-
urally the objects of his warmest affec-
tions. They are naturally and usually the
persons upon whose happiness or mis-
ery his conduct must have the greatest
influence.
Despite its recognized importance, particu-
larly in economic models of the family and
of intergenerational transfers, genetic altru-
ism has not been systematically studied as a
determinant of economic behavior. The oper-
ation of genetic selection could be very indi-
rect. Thus, the acquisition of language, the
exploitation of comparative advantage, the
formation of successful defenses against ma-
rauders and disease, and a disposition to "fair
play" that reduces interpersonal conflict may
all arise from the selective advantage of group
traits that promote sociality. Then altruistic
behavior, including pure altruism with gifts
to unrelated individuals with no possibility
of personal gain, might be explained as an
indirect consequence of genetic self-interest,
as might the "warm glow" most humans ex-
perience when placed in a supportive, coop-
erative environment, the distaste people have
for aggressive, greedy traders, the potlatch
pride of being more generous than your
neighbors.
Summarizing, physiological, behavioral, and
sociological evidence indicate strongly that
consumers will often fail to promote their
self-interest reliably when choices involve risk,
ambiguity, integration of experience, and per-
ceptions of remote and/or unlikely events. Con-
sumers' failures will loom large, and this may
generate agoraphobia. Market-oriented eco-
nomic policy needs to take into account how
consumers' market experiences and outcomes
will influence well-being and acceptance of
market solutions.


### ---Economics-2006-0-16.txt---
VI. Consumers and Medicare Part D
Medicare's Part D drug plan is extraordi-
narily complex. This government pro-
gram takes the cake, the candles, the
platter, and the crumbs.
Kathleen Pender,
San Francisco Chronicle
Medicare Part D is not that difficult to
understand. There has been a lot of con-
fusing information in the news about Part
D Medicare.
OregonHealthInsurance.com
The new Medicare Part D program that began
operation on January 1, 2006, provides pre-
scription drug coverage through Medicare-
approved plans offered by private insurance
companies and HMOs. Consumers in the Medi-
care population can choose to opt out, or to
enroll in one of the private plans available in
their geographic area. This is a large and
complex government program that provides
substantial entitlements for the elderly and sub-
stantial insurance against catastrophic drug
costs. If the entire eligible Medicare population
of 41 million were to enroll in this program,
then at current levels of prescription drug use,
the net subsidy from general government reve-
nues would be about $44.8 billion per year; this
includes some double counting of Medicaid,
veterans, and other programs that currently
cover prescription drug costs, and assumes that
all employer and union plans meet Medicare
requirements and qualify for the subsidy. There
is an adverse selection problem. If the approx-
imately 27 percent of the elderly whose annual
pharmacy bills are currently below $842, the
breakeven point in 2006, were to delay enroll-
ment until health conditions warrant, the net
cost of the program would rise another $4.2
billion. However, moral hazard is the bigger
issue.4 In the Medicare population, people with
prescription drug coverage average 1.1 more
prescriptions than those without. If the 26 per-
cent of the population who currently pay all
4 See Peter Adams et al. (2003), Dana P. Goldman et al.  (2004), Anne E. Hall (2004), Haiden A. Huskamp et al.  (2004, 2005), John R. Moran and Kosali I. Simon (2005),
and Z. Yang et al. (2004).  their pharmacy bills enroll in Part D, experience
this increase in number of prescriptions, and
face the current average monthly cost of a new
prescription, $66, then this increases the cost of
the program by $6.8 billion. In these worst
cases, the effect of adverse selection and moral
hazard together is projected to increase the cost
of the program to $55.8 billion.
The creation of a market in which private
companies compete to offer coverage, and in
which consumers have choices of carriers and
plans, was an important element in the Part D
legislation. For economists, it is an interesting
economic policy experiment in whether the
benefits of competition can overcome the prob-
lems of adverse selection and moral hazard that
always lurk in private insurance markets;
whether the Center for Medicare and Medicaid
Services (CMS) can efficiently manage its prin-
ciple/agent and underwriting relationship with
private insurers; and whether consumers can
understand and evaluate plan alternatives in
their own self-interest. In 2004, the National
Institutes of Health asked research groups work-
ing on the economics of aging if they could
provide information on the impact of the Part D
program. My research group attempted to do
this by modifying a survey we were planning to
study health perceptions and choices of the el-
derly. During the week of November 7-15,
2005, just before enrollment for Part D began,
we surveyed 4,739 persons age 50 and older and
gathered information on health conditions and
prescription drug use, knowledge and enroll-
ment intentions for Part D, and preferences
across different plans. Our initial findings are
given in Joachim Winter et al. (2005). I will
summarize a few findings here, with particular
attention to the question of whether consumers
are sufficiently self-reliant to take advantage of
the choices offered by the private market struc-
ture of this program.
The Part D program is complex because of its
interactions with existing employer or union-
provided drug coverage and with Medigap in-
surance, and its provisions for means-tested cost
reductions for low-income consumers. There
are five main classes of eligible consumers:
* Standard Medicare, including those with
Medigap policies that do not cover drugs


### ---Economics-2006-0-17.txt---
TABLE 4-2006 PRESCRIPTION DRUG BENEFITS UNDER
MEDICARE PART D STANDARD PLAN
Annual Percent Percent of
pharmacy Patient Medicare paid by patients with
bill pays pays patient higher bills
$0 $ 0 $ 0 - 85.4%
$250 $ 250 $ 0 100% 80.5%
$500 $ 313 $ 188 63% 77.4%
$842 $ 398 $ 444 47% 73.0%
$1,000 $ 438 $ 563 44% 70.7%
$2,250 $ 750 $ 1,500 33% 49.4%
$5,100 $3,600 $ 1,500 70% 16.3%
$8,000 $3,745 $ 4,255 47% 6.4%
$12,000 $3,945 $ 8,055 33% 2.1%
$20,000 $4,345 $15,655 22% 0.4%
$40,000 $5,345 $34,655 13% 0.1%
Standard Medicare with Medigap policies
that cover drugs
Employee- or union-provided coverage, in-
cluding drugs
Medicare Advantage (HMO or PPO) policies
that cover drugs
Medicaid beneficiaries
Generally, those in the last three categories re-
ceive Part D coverage by default. Those with
Standard Medicare will default out of Part D
if they do not take action, but have the choice
of enrolling in a privately offered plan, or of
converting to Medicare Advantage coverage.
In virtually all cases, there are Part D plans
that are more advantageous than Medigap
policy drug coverage. The analysis that fol-
lows applies to the people currently on Stan-
dard Medicare.
CMS has established a standard plan under
Part D that has an annual premium of $444, a
deductible of $250, pays 75 percent of prescrip-
tion drug pharmacy bills above $250 up to
$2,250, provides no additional benefits until
pharmacy bills reach $5,100, and pays 95 per-
cent of pharmacy bills above that level. CMS
requires approved private plans to offer compa-
rable coverage.
Table 4 summarizes consumer out-of-pocket
costs under the standard plan, not including the
annual premium, for various pharmacy bills.
The private insurers who provide drug coverage
within the Plan D framework may offer en-
hancements to the standard plan, at higher  premiums, including coverage for the $250 de-
ductible and/or for the gap or "doughnut hole"
in the standard plan, which pays no added ben-
efits for pharmacy bills above $2,250 or below
$5,100. They may offer broader formularies
than Medicare requires, variations in the coin-
surance or copayment tier structure, and con-
venience features such as broad pharmacy
participation and mail-order services. Approved
plans must have formularies that include at least
two drugs in each therapeutic category; the frac-
tion of the 100 most frequently prescribed drugs
included in currently approved formularies
ranges from 65 percent to 100 percent, with a
median of about 90 percent. Enrollees may
change plans annually. There are penalties for
late enrollment, currently a 1-percent increase
in premiums per month's delay past the initial
enrollment period, which ends in May 2006. In
evaluating alternatives, consumers need to take
into account not only their current pharmacy
bills, but also the probabilities of developing
new health conditions that will require treat-
ment, and the distribution of costs of these
treatments. As a result, consumers are being
asked to make relatively complex plan assess-
ments, generally with relatively incomplete in-
formation on future prospects. Because of the
late enrollment penalties, there is not only a
current financial risk of making a poor decision,
but also an option pricing problem of determin-
ing the value of enrolling to lock in current
premium rates. Not surprisingly, some seniors
are finding this a difficult choice, and the media
has had a field day publicizing Part D's com-
plexity. The economic policy question is this:
After the dust settles, will most consumers have
made good use of the choices offered by the
private market, so that a market-oriented design
contributes to consumer well-being? Is further
intervention on behalf of the vulnerable
needed?
Our survey, entitled the "Retirement Perspec-
tives Survey" (RPS-2005), was fielded as a
self-administered Internet questionnaire from
November 7-15, 2005, using a panel of subjects
enrolled by Knowledge Networks, a commer-
cial survey firm. This panel was recruited from
a random sample of the underlying population,
and all panel members were provided with iden-
tical hardware (Web TVs) through which they


### ---Economics-2006-0-18.txt---
TABLE 5-NUMBER OF PRESCRIPTIONS
Age 50-64 2.8
Age 65 + All 4
Age 65+ Pay own pharmacy bills 3.3
Age 65+ Others pay pharmacy bills 4.4
TABLE 6--PERCENT WITH LITTLE OR No KNOWLEDGE OF
PART D
All 39.5
High SES 32.5
Bad health 49.8
Low cognition 46.9
Low SES, bad health, and low cognition 54.3
respond to periodic surveys. Members are com-
pensated for participation on the panel. For our
study, 5,879 members of the panel aged 50
and over were contacted. Of these, 4,738 indi-
viduals completed the survey. Our present anal-
ysis is restricted to those respondents who are in
the Medicare-eligible population, for the pur-
poses of our study defined as age 65 and older
(N = 1996).
The survey lasted about 22 minutes and cov-
ered, in addition to questions about Part D,
questions about health status and conditions,
long-term care choices, prescription drug use
and cost, and attitudes toward risk. We also use
the 2001 Medicare Current Beneficiary Survey
(MCBS) distribution of annual pharmacy bills,
and an AARP survey giving median prices of
commonly prescribed drugs (as of April 2005)
for nine health conditions. Table 5 gives the
average numbers of prescriptions used by vari-
ous groups. Notable is the increase in the num-
ber of prescriptions for those who have their
pharmacy bills paid by others, relative to those
who pay their own bills.
We find that despite the complexity of the
Part D program's competing plans, a majority
of the Medicare population has at least some
knowledge and intends to enroll. However, low-
income, less educated elderly with poor health
or some cognitive impairment are significantly
less informed and may fail to take advantage of
the program. Table 6 gives the fractions of the
Medicare population who just before enroll-
ment started said they had little or no knowl-
TABLE 7-PERCENT NOT LIKELY TO ENROLL
All 17.0
Good health 19.0
Bad health 11.7
Well informed 14.7
Poorly informed 19.6
edge of Part D. Table 7 gives the percentages of
the Medicare population who said just before
enrollment started they were unlikely to enroll
in a Part D plan. This does not include people
who will not enroll directly in Part D because
they already have prescription drug coverage
that is at least as good as the Medicare standard
plan. Overall, 17 percent say they are unlikely
to enroll. The percentages are higher for those
in good health, and those poorly informed. The
percentage differences are small, but statisti-
cally significant.
A revealing assessment of the consistency of
individual intentions is obtained by comparing
enrollment choices with the alternatives that
minimize the expected present value (EPV) of
out-of-pocket cost (OPC). Underlying the en-
rollment decision is an option value problem: If
an eligible person enrolls immediately in Part
D, her EPV of OPC in each year from 2006 to
the end of her life will be the $444 annual
premium plus her expected pharmacy bill, less
the Part D benefit. If, on the other hand, she
delays one year, then the EPV of her OPC is her
expected pharmacy bill for 2006 plus the EPV
of her OPC from 2007 forward, assuming that
she makes the decision to enroll or delay in
2007 and subsequent years to minimize EPV of
OPC, and assuming that these future decisions
take into account the new information she will
obtain on health and prescription costs as she
goes along, and the Medicare premium penalty
for late enrollment, which is 7 percent in 2007,
and 12 percent per year thereafter. With infor-
mation on the probabilities of developing new
health conditions, and the distributions of drug
costs for required therapies, this can be formu-
lated as a dynamic stochastic programming
problem, and solved by backward recursion to
determine a threshold depending on age, such
that if the current pharmacy bill is below the
threshold, an individual who seeks to minimize


### ---Economics-2006-0-19.txt---
m m m $1,000
$800
$600
$400
Enroll Now
Probably
Enroll Now
Probably
Delay
65 75 85 95
Age in 2005
FIGURE 2. ENROLLMENT THRESHOLDS MINIMIZATION OF EPV OF OPC
EPV of OPC cost will choose to delay. We
simplify this computation by approximating a
necessary condition for delay, ignoring the in-
fluence on expected cost today of the additional
information and contingent decisions that will
be gained as future health conditions and phar-
macy bills are realized. This approximation was
found to be reasonably accurate in a study of
retirement decisions by Robin L. Lumsdaine et
al. (1994). We implement this calculation using
U. S. Life tables, estimates from the Health and
Retirement Survey of the annual probability of
developing a condition requiring a new pre-
scription drug therapy, and estimates from our
survey and the MCBS of the distribution of
annual drug costs for a new therapy.5
Figure 2 gives the thresholds we obtain using
this approximation; these apply to people who
do not receive means-tested premium reduc-
tions. There are four factors that may modify
5 Some plans offer reduced or zero premiums, and may  be attractive to the healthy. However, most appear to be  available only to those who meet a low-income means test
or enroll in bundled HMO services.  this calculation for an individual. First, addi-
tional information on health that will be re-
vealed in the future, and decisions contingent on
this information, give delay some added option
value. Second, risk aversion gives immediate
enrollment added insurance value. Trial calcu-
lations indicate that the full option pricing cal-
culation, and risk aversion for a person with
moderate coefficient of absolute risk aversion,
have effects on the threshold for delay that are
relatively small, on the order of $100 or less.
Third, individuals may have different personal
probabilities for new health conditions and pre-
scription drug requirements than the ones we
have used. Fourth, individuals may have differ-
ent discount rates than the 5-percent discount
rate we have employed. For people with 2005
pharmacy bills above $802, the option of delay-
ing enrollment is "out of the money"-these
people can expect to reduce their OPC for pre-
scription drugs in 2006 with Part D coverage, in
addition to being insured against risks of high
future bills. The difference between the $802
threshold and the $842 break-even level for a
consumer's current pharmacy bill is the ex-
pected value of the consumer's new pharmacy


### ---Economics-2006-0-20.txt---
TABLE 8-ENROLLMENT INTENTIONS
Intended
choice
Action that minimizes EPV of OPC
Enroll Delay Total
Enroll 63.3% 19.4% 82.7%
Delay 10.0% 7.3% 17.3%
Total 73.4% 26.6% 100.0%
TABLE 9-PLAN CHOICE
Min EPV
Alternative Choice of OPC
Standard 46.9% 45.5%
Guaranteed Benefit 27.1% 3.3%
Major Cost Protection 6.0% 0.0%
No Copay 20.0% 51.2%
bills in 2006. About 72.5 percent of the Medi-
care population meet this condition. For those
with lower bills, there is an annual pharmacy
bill threshold that rises with age from just below
$500 to close to $750. Individuals who are
prepared to self-insure and are currently below
this threshold will probably find delay desirable,
while those between this threshold and $802
will probably find immediate enrollment desir-
able. Approximately 24.4 percent of the Medi-
care population falls in the region where delay
is probably desirable, and 3.1 percent in the
region where immediate enrollment is probably,
but not definitely, desirable.
Table 8 classifies enrollment intentions
against the action that minimizes EPV of OPC.
The table shows that the choice of 70.6 percent
of the population minimizes EPV of OPC.
However, there are 10 percent who intend to
delay even though it is likely in their self-
interest to enroll. On the other hand, 19.4 per-
cent of those intending to enroll would achieve
lower EPV of OPC by delaying. Of course,
some of that group may want the insurance
against catastrophic costs in the future, and
these could be rational decisions if there is very
strong aversion to the risk of large, low-proba-
bility losses.
A final part of our survey asked subjects for
their preferences among the alternatives of no
prescription drug coverage, the Medicare Part D  standard plan, and three hypothetical alternative
plans:
* Guaranteed Benefit Plan: Medicare pays 52.3
percent of approved prescription drug costs,
no matter how high or low these costs are.
The annual premium of $444 is the same as
the standard plan.
* Major Cost Protection Plan: Pays all ap-
proved prescription drug costs above $2,444
per year, but nothing until your cost at the
pharmacy reaches this level. The annual pre-
mium of $444 is the same as the standard
plan.
* No Copay Plan: You pay an up-front annual
premium of $1,889 per year, and all approved
prescription drug costs are then fully covered,
with no copayments.
The alternative plans all have the same actuarial
value as the standard plan for the Medicare
population, but differ in the degree to which
they provide insurance against major pharmacy
costs. The Major Cost Protection Plan and No
Copay Plan provide almost complete insurance
against major costs, with the latter eliminating
the deductible and charging an up-front pre-
mium for the actuarial value of this replace-
ment. The Guaranteed Benefit Plan is more
favorable than the Major Cost Protection Plan at
low pharmacy bills, but entails substantial risk
at high bills. These hypothetical alternatives
vary more from the standard plan than most
products currently being offered, but prefer-
ences among them provides some indication of
preferences for features of actual plans.
Enrollee choice among the alternative plans
is not explained well by cost minimization; only
36.3 percent of enrollees choose the plan that
minimizes EPV of OPC. Further, consumers do
not seem to place much value on the insurance
component of the alternative plans-among en-
rollees, the Guaranteed Benefit Plan that offers
relatively poor insurance against catastrophic
drug costs is the minimum cost alternative in
only 3.2 percent of cases, but is preferred by
27.1 percent, while the plans that offer almost
complete insurance are preferred by only 26
percent, even though they include the
minimum-cost alternative for 51.2 percent. We
conclude that consumers are likely to have


### ---Economics-2006-0-21.txt---
difficulty choosing among plans to fine-tune
their prescription drug coverage, and do not
seem to be informed about or attuned to the
insurance feature of Part D plans.
VII. Conclusions
We conclude from our survey that significant
fractions of the Medicare population, particu-
larly among those with low SES, bad health,
and low cognitive ability, are poorly informed
about the Part D prescription drug program, and
risk making poor plan choices. Most of the
Medicare population, 89.2 percent, intend to
enroll, although this drops to 80.4 percent among
the poorly informed. When one compares pref-
erences with alternatives that minimize the ex-
pected present value of out-of-pocket costs, one
finds that 10 percent of the elderly intend to
delay enrollment even though it increases their
expected costs, and 19.4 percent intend to enroll
immediately even though it increases their ex-
pected costs. Choice among plans is erratic, and
shows little attention to or concern about the
insurance features of Part D plans. Procrastina-
tion is a predictable behavioral response to the
complexity and ambiguity surrounding Part D,
making it likely that many who intend to enroll
will miss the May 15, 2006, enrollment dead-
line. Consequently, there is likely to be consid-
erable churning and grumbling in this market in  the future.
How could the Part D market be managed
to overcome consumers' lack of information,
behavioral aversion to market choices, and
procrastination when faced with ambiguous al-
ternatives? First, CMS should pursue an aggres-
sive marketing program to find the vulnerable
who are insufficiently informed to act in their
self-interest, sell the neglected and undervalued
benefits of the insurance that Part D offers, and
coax consumers into making sensible plan
choices. This could include giving insurers in-
centives to scour for vulnerable seniors. Mar-
keting of Part D should benefit consumers as
long as it is not done deceptively. Policies that
have proven effective in encouraging early re-
tirement in downsizing firms may also work in
this market. The most effective is "default in"
rather than "default out"-all individuals are
assigned a plan unless they choose a plan them-  selves or explicitly opt out; see Choi et al.
(2003). This could be done by providing step-
by-step decision forms that require seniors to
choose a plan, opt out, or let Medicare or an
ombudsman make a choice for them; one sug-
gestion is that these be called Plan D-EZ to
match simplified IRS forms. Another marketing
method that works for retirement is the use of
windows with attractive incentives. This could
be adapted to encourage Part D enrollment by
combining stiff late enrollment penalties with a
program to convert nonenrollees, such as a se-
ries of "last ever" penalty amnesty windows in
the future, particularly for the vulnerable. A
number of private plans are being offered with
quite low premiums and basic coverage, which
encourage enrollment of the healthy. If CMS
ensured that a basic plan, with zero premium, a
limited formulary, and copayments sufficient
for actuarial balance, was always a market op-
tion, then all seniors should enroll in either the
basic or a more comprehensive plan, assuring
affordable medications and catastrophic cover-
age for the entire Medicare population.
The new Medicare Part D prescription drug
insurance market illustrates that leaving a large
block of uninformed consumers to "sink or
swim," and relying on their self-interest to
achieve satisfactory outcomes, can be unrealis-
tic. To make the Part D market work, in the
sense that it provides choices that consumers
want, and achieves the efficiencies it seeks,
CMS will have to make a diligent effort to
manage the market, and to reach all consumers
and provide them with information and assis-
tance in making wise choices. What the Part D
market, and other market privatization initia-
tives, need is a component of Thaler and Sun-
stein's (2003) libertarian paternalism, in which
understanding consumers' limitations, helping
consumers to help themselves, and convincing
them that the market will serve their interests
are intrinsic parts of mechanism design.
## Economics-2007-0


### ---Economics-2007-0-03.txt---
Macroeconomics changed between the early
1960s and the late 1970s. The macroeconomics
of the early 1960s was avowedly Keynesian.
This was manifested in the textbooks of the
time, which showed a remarkable unity from
the introductory through the graduate levels.'
John Maynard Keynes appeared, posthumously,  on the cover of Time.2 Even Milton Friedman
was famously-although perhaps misleadingly-
quoted: "We are all Keynesians now."3 A little
more than a decade later Robert Lucas and
Thomas Sargent (1979) had published "After
Keynesian Macroeconomics." The love-fest was
over.
The decline of the old-style Keynesian eco-
nomics was due in part to the simultaneous rise
in inflation and unemployment in the late 1960s
and early 1970s. That occurrence was impossi-
ble to reconcile with the simple nonaccelera-
tionist Phillips curves of the time.
But Keynesian economics also declined be-
cause of a change in economic methodology.
The Keynesians had emphasized the depen-
dence of consumption on disposable income
and, similarly, of investment on current prof-
its and current cash flow.4 They posited a
Phillips curve, where nominal-rather than
real-wage inflation depended upon the un-
employment rate, which was used as an indi-
cation of the looseness of the labor market.
They based these functions on their own in-
trospection regarding how the various actors
in the economy would behave. They also
brought some discipline into their judgments
by estimating statistical relations.5
But a new school of thought, based on clas-


### ---Economics-2007-0-04.txt---
sical economics, objected to the casual ways of
these folks. New Classical critics of Keynesian
economics insisted instead that these relations
be derived from fundamentals. They said that
macroeconomic relationships should be derived
from profit-maximizing by firms and from utility-
maximizing by consumers with economic argu-
ments in their utility functions.
The new methodology had a profound effect
on macroeconomics. Five separate neutrality re-
sults overturned aspects of macroeconomics
that Keynesians had previously considered in-
contestable. These five neutralities are: the in-
dependence of consumption and current income
(the life-cycle permanent income hypothesis);
the irrelevance of current profits to investment
spending (the Modigliani-Miller theorem); the
long-run independence of inflation and unem-
ployment (natural rate theory); the inability of
monetary policy to stabilize output (the rational
expectations hypothesis); and the irrelevance of
taxes and budget deficits to consumption (Ricar-
dian equivalence).6 These results fly in the face
of Keynesian economics. They undermine its
conclusions about the behavior of the economy
and the impact of stabilization policy.
The discovery of these five neutrality propo-
sitions surprised macroeconomists. They had
not suspected that radically anti-Keynesian con-
clusions were the logical outcome of such seem-
ingly innocuous maximizing assumptions.
I. Neutralities and Preferences
How did macroeconomists react to the dis-
covery of the five neutralities? On the one hand,
the New Classical economists viewed their neu-
trality results as a telltale: that Keynesian econ-
omists of the previous generation had been
thinking in the wrong way. In their view, sci-
entific reasoning was producing a new, leaner,
more precise economics.
On the other hand, Keynesian economists, for
the most part, reacted differently. In due course
they came to view the neutralities as logically
impeccable. These New Keynesians accepted
the methodological dictums of the New Classi-
cal economics: that constrained maximization
of profit and utility functions is the appropriate
microfoundation for macroeconomics. They
also viewed the neutralities as having a certain
sort of generality. The neutralities do commonly
describe equilibria of competitive economies
with complete information, irrespective of peo-
ple's preferences-as long as those preferences
correspond to economists' typical descriptions
of them. The Keynesians then resurrected some-
but not all-of the Keynesian conclusions by add-
ing a variety of frictions to the New Classical
model. Those frictions include credit constraints,
market imperfections, information failures, tax
distortions, staggered contracts, uncertainty,
menu costs, and bounded rationality. This formu-
lation preserves many (but not all) Keynesian
conclusions regarding cyclical fluctuations and
macroeconomic policy.
This lecture will suggest a new stance in
regard to each of the five neutralities. Like New
Classical and New Keynesian economics, it will
derive behavior from utility and profit maximi-
zation. That captures the purposefulness of eco-
nomic decisions. But this lecture will also
question the generality of the preferences that
lead to the five neutralities. There is a sense in
which those preferences are very narrowly de-
fined. They have important missing motiva-
tion-since they fail to incorporate the norms of
the decision makers. Those norms reflect how
the respective decision makers think they and
others should or should not behave, even in the
absence of frictions. Preferences reflecting such
norms yield a macroeconomics with important
remnants of the early Keynesian thinking. They
also yield a macroeconomics that, in important
details, cannot be obtained only with frictions.
We shall see that, with such preferences, even
in the absence of frictions, each of the five
neutralities will be systematically violated. Spe-
cifically:
* A realistic norm regarding consumption be-
havior will make consumption directly de-
pendent on current income, in violation of the
neutrality of consumption given wealth;
* A realistic norm will make investment di-
rectly dependent on cash flow, in violation of
Modigliani-Miller;
* A realistic norm will make wages and prices
dependent on nominal considerations and
thus violate natural rate theory;  6 Of course, it took some time for the implications of  these neutrality results to be fully appreciated. For example,  life-cycle consumption and Modigliani-Miller were initially  considered as nothing more than useful codicils to Keyne-
sian thinking.


### ---Economics-2007-0-05.txt---
* A realistic norm will make income and em-
ployment dependent on systematic monetary
policy, and thus violate rational expectations
theory; and
* A realistic norm will make current consump-
tion dependent on the current generation's
social security receipts, in violation of Ricar-
dian equivalence.
Additionally, insofar as the behavior assumed
by the early Keynesians differed from the be-
havior that produces the neutralities, there is
likely to be a bias in favor of the Keynesians.
The Keynesians based their models on their
observation of motivations, rather than on ab-
stract derivations. If there is a difference be-
tween real behavior and behavior derived from
abstract preferences, New Classical economics
has no way to pick up those differences. In
contrast, models with norms based on observa-
tion will systematically incorporate such behav-
ior-although, of course, as with any method,
there is the possibility for error.
Inclusion of the "missing motivations in mac-
roeconomics" then combines the observations
of the Keynesians with the intentionality of
economic decisions in New Classical econom-
ics. Such a synthesis yields the best of the two
approaches.
Two Disclaimers.--Before beginning in ear-
nest, let me offer two brief disclaimers. First,
none of the behavior revealing of the norms that
are introduced in this lecture will be new. On
the contrary, I have purposefully chosen phe-
nomena that have been emphasized since The
General Theory by macroeconomists who have
followed Keynes in voicing their continuing
doubts about classical interpretations of macro-
economic behavior.
Second, this lecture will discuss different
norms that respectively correspond to the five
neutralities. I shall assume that these norms are
exogenous. Such assumptions of exogeneity are
standard in economic analysis. In a given prob-
lem in a given time frame, some terms are
assumed constant, while others are allowed to
vary. I ask you to withhold your doubts regard-
ing whether such exogeneity is a correct as-
sumption or not. The incorporation of such
endogeneity is the next step-not the first
step-in the study of the effect of norms on
macroeconomics, especially since such endoge-  neity may sometimes dampen, but will rarely
nullify, the conclusions of this lecture.
II. The Five Neutrality Results
For clarity, this section will now give an
overview of each of the five neutrality results.
A. Dependence of Consumption on Wealth,
Not Income
Standard theory tells us that, under only
somewhat special conditions, consumption de-
pends on wealth, which is the value of current
assets plus the discounted value of future earn-
ings.7 Thus there is no tendency for people to
make their expenditures conform to the pattern
of their income receipts (as long as their wealth
is given).
Changes in the pattern of current income that
leave overall wealth constant are neutral in their
effects on current consumption.
B. The Modigliani-Miller Theorem
One version of the Modigliani-Miller Theo-
rem says that a firm's investment strategy is
totally independent of its liquidity position.8
Thus, for example, a corporation with an unex-
pected windfall will not spend any additional
investment dollars. Instead, it will pass the  windfall on to shareholders or seek other finan-
cial investments, since it will make only those
investments whose risk-adjusted rate of return
exceeds the rate of return on capital.
Changes in the firm's finances will thus be  neutral in their effect on current investment.
C. Natural Rate Theory
According to Natural Rate Theory, there is
some single rate of unemployment that is the
only level that could be permanently maintained
without ever-increasing inflation or ever-
increasing deflation.9 A fiscal/monetary policy
mix that sought to maintain employment that
was any higher would result in permanently
increasing inflation. A fiscal/monetary mix that
7 See Friedman (1957) and Franco Modigliani and Rich-  ard Brumberg (1954).  8 See Modigliani and Merton H. Miller (1958).  9 See Edmund S. Phelps (1968) and Friedman (1968).


### ---Economics-2007-0-06.txt---
sought to maintain employment that was any
lower would result in permanently decreasing
inflation. Fiscal/monetary mixes that yield dif-
ferent levels of long-term (steady) inflation will
thus be neutral in their effects on long-term
unemployment.
D. Rational Expectations
According to Rational Expectations Theory,
a systematic response of monetary policy to the
business cycle will have no effect on the stabil-
ity of the macroeconomy.10 Wage and price
setters will foresee the systematic component of
the money supply; they will raise or lower
prices and wages exactly proportionally, and
thereby neutralize its effect on demand.
The stability of the economy is thus neutral
with respect to the systematic reaction of mon-
etary policy to the business cycle.
E. Ricardian Equivalence
According to Ricardian Equivalence, under
somewhat special conditions, a representative
consumer who receives a lump-sum intergen-
erational transfer (for example, in the form of a
social security payment) will not spend a single
dime extra." Instead, she will pass on the whole
extra income, dollar-for-dollar, to her heirs,
who will have to pay the higher tax bills nec-
essary to retire the increased debt incurred in
funding the transfer to the previous generation.
The transfer is neutral in its effect on current
consumption.
III. The Missing Motivation: Norms'2
Each of the neutralities is based on the as-
sumption that the respective decision makers
are utility maximizers. But in each case the
utility functions of the decision makers have  been very narrowly described. They depend
only on real outcomes. For example, in the
consumption-neutrality models, utility depends
on consumption and leisure; in Modigliani-
Miller, it depends only on the discounted real
return to shareholders.
But as early as the beginning of the twentieth
century, Vilfredo Pareto pointed out that such
characterizations of utility missed important as-
pects of motivation.13 According to Pareto, peo-
ple typically have opinions as to how they
should, or how they should not, behave. They
also have views regarding how others should, or
should not, behave. Such views are called
norms, and they may be individual14 as well as
social. The role of norms can be easily repre-
sented in people's preferences by modifying the
utility function to include losses in utility inso-
far as they, or others, fail to live up to their  standards.
Sociology has a further concept that gives an
easy and natural way to add those norms to the
utility function. Sociologists say that people
have an ideal for how they should or should not
behave. Furthermore, that ideal is often concep-
tualized in terms of the behavior of someone
they know, or some exemplar whom they do not
know. The standard utility function is then mod-
ified by adding a loss in utility, dependent on
the distance of behavior from that ideal.
Religion and religious identity give us a good
example of such norms. Consider the Gospels.
They are the most sacred texts of Christianity.
What do they describe? The life of Christ. How
should a Christian behave? "His life and con-
versation ought to be worthy of the Gospel of
Christ [emphasis added]."'" How is a good
Christian supposed to feel when she has not
lived up to her conception of that ideal?  Ashamed.16
10 See Lucas (1972), Thomas J. Sargent (1973), and  Lucas and Sargent (1979).  11 See Robert J. Barro (1974) for the modem reincarna-
tion of these ideas, first discovered by Ricardo.  12 This section, including much of its exact wording, has
been taken from a joint manuscript with Rachel Kranton  (Akerlof and Kranton 2006). I should emphasize that these  insights have been developed jointly. The initial instigation  of our project is wholly due to Kranton. It is impossible for  me to say which ideas or wordings are mine and which are
hers. 13 See Pareto (1920). George C. Homans and Charles P.
Curtis (1934) give an excellent summary of Pareto that is  fully consistent with the emphasis here. Jon Elster (1989)  also presents a similar conception of norms.  14 For example, the protagonist of the novel Rice Mother  (Rani Manicka 2002) did not believe she should wear red  with black.
15 See http://www.orthodoxytoday.org/articles/StBasil-
Behavior.php.  16 Of course, there are many interpretations of the Gos-  pel, and some of them are even contradictory. But that does  not affect whether the person should be ashamed or not. She


### ---Economics-2007-0-07.txt---
A. Importance of Norms in Motivation:
Some Examples
But religion is only one of the many realms
where people have such an ideal. To appreciate
the ubiquity of norms in motivation, it is useful
to see some further examples. Those examples
will demonstrate that people tend to be happy
when they live up to how they think they should
be; and they are, correspondingly, unhappy
when they fail to live up to those norms.
For the audience for this lecture, most of
whom are professors, teaching provides an es-
pecially familiar example. We have a view of
what it means to be a good teacher. On our
lucky days, when we live up to our standards
and our classes go well, we tend to be happy; on
our off days, when something goes awry in
class, we may even feel quite miserable.
Such motivation in the workplace is the rule,
rather than the exception. Most workers, like
teachers, care about the conduct of their jobs.
Randy Hodson (2001), who surveyed ethnogra-
phies of the US workplace, found that most
employees care about their dignity at work.
They want to conceive of what they do as use-
ful. And they feel a lack of dignity if they are
thwarted, either by their own actions or by the
actions of others. Those who are unable to get
such satisfaction are likely to show their dis-
pleasure by acting up in some way or other.
Studs Terkel's Working (1972) captures in a
single volume much of the ethnographic find-
ings summarized by Hodson. Terkel interviews
people from many different occupations about
their feelings about their jobs and concludes that
people "search for daily meaning as well as
daily bread" (1972, xi). Some of the interview-
ees are successful in this search: like the stone
mason, who cruises his Indiana county and
basks in pride as he not infrequently passes his
past work. At the opposite extreme is an Illinois
steelworker, whose work denies him the dignity
he seeks. He takes out his frustration at work by
being disrespectful, and, after hours, by getting
into tavern brawls. Most workers are some-
where between these extremes, but in all cases,
following Terkel, they have a feeling for how
they should behave at work. It is not just about  the money; it is also about living up to an ideal
about who they think they should be.
Such belief regarding how people should be-
have, and their behavior in accordance with
such belief, goes beyond the workplace. It af-
fects disparate areas, from playing golf to life in
the family. Betty Friedan's Feminine Mystique
gives what may be as good a description of
norms and their impact on people's lives as can
be found anywhere-in this case regarding the
norms for middle-class women of the previous
generation. Here is a brief sample of her de-
scription:
"Millions of women lived their lives in
the image of those pretty pictures of the
American suburban housewife, kissing
their husbands goodbye in front of the
picture window, depositing their station-
wagonsful of children at school, and smil-
ing as they ran the new electric waxer
over the spotless kitchen floor .... Their
only dream was to be perfect wives and
mothers; their highest ambition was to  have five children and a beautiful house,
their only fight to get and keep their hus-
bands .... They gloried in their role as
women, and wrote proudly on the census
blank: "Occupation, housewife" (Friedan
1963, 18).
Most women lived up to these norms. Some of
these were dissenters, like Friedan herself, who
disagreed with them, but felt compelled, never-
theless, to follow a norm with which they dis-
agreed. Friedan says they suffered from "the
problem without a name." In our terms, they were
losing utility because they were failing to live up
to what one part of them thought they should do.
We may appeal to religious texts, to work
ethnographies, and, like Friedan, to women's
magazines to see the role of norms. But is there
yet harder data, some form of natural experi-
ment, that indicates the importance of norms?
The sociologist Erving Goffman has found such
an example. He observed the behavior of chil-
dren of different ages when they were brought
to the local merry-go-round. Because appropri-
ate activity differs by age, the children should
have predictably different reactions. For the
toddlers, riding a wooden horse is an accom-
plishment. They show their joy at fulfilling what
they should do with smiles and waves as they
pass by. In contrast, for older children, there is  thinks she should be ashamed if she fails to live up to her  interpretation of the Gospel.


### ---Economics-2007-0-08.txt---
a gap between their conception of how they
should behave and riding the merry-go-round.
However much they may enjoy it, they also feel
the need to distance themselves from an activity
that is so age inappropriate. They manifest this
distance by riding a frog, rather than a "serious"
animal like a horse; alternatively they show off
by standing up "dangerously" during the ride. In
some way or other they play the clown.
Behavior at the merry-go-round is, of course,
just the stuff of kids. But Goffman supplements
it with a totally serious example. In surgical
operations, because of their inexperience, med-
ical students are given tasks that are ridiculously
easy.17 They respond in the same way as the
older children at the merry-go-round: they also  act the clown.18
In economics, as elsewhere, $500 bills do not
just lie on the street. If living up to norms is
such an important motivation, it must show up
in many economic examples, even if it is not
identified in exactly our language. Gary S.
Becker's Economics of Discrimination (1957)
offers an example of now-standard economics  that can also be interpreted in terms of such
norms. Becker's theoretical innovation was to
modify plain-vanilla economic utility by the
introduction of a discrimination coefficient. He
defined that as the loss in utility incurred by
exchange with someone from a different race-
for example, the loss of a white from an ex-
change with a black. The natural interpretation
is that the discrimination coefficient represents
the loss in utility for the white from physically
engaging in an exchange with a black. But this
representation of the utility function can also be
interpreted in terms of norms. There is a code as
to how blacks and whites should behave toward
each other. The white has a view that she should
not deal with a black. She loses utility equal to
the value of the discrimination coefficient-not
from the physical association-but ipso facto
from the violation of the code. There is reason
to believe that such norm-based interpretation
better reflects the nature of discrimination than
a physical exchange-based theory. In the pre-
Civil Rights period, when Becker was writing,
there can be no doubt that discrimination, and
the code that upheld it, was stronger in the
South than in the North. Yet exchanges between
blacks and whites were surely much more com-  mon in the South than in the North. At least one
statistic reflects such a difference: there were
significantly lower levels of residential segrega-
tion by race in the South than in the North.
B. Summary
Our examples are illustrative of behavior that
is pervasive. Sociology is dense in examples of
people's views as to how they and others should
behave, their joy when they live up to those
standards, and their discomfort and reactions
when they fail to do so.
We now turn to examining the role of
norms in each of the five macroeconomic neu-
tralities.20 In each case we shall ask whether  17 Goffman (1961) observed the behavior of such stu-
dents in medical operations.  18 Another example, the Milgram experiment (Stanley
Milgram 1963, 1965) demonstrates the strength of such  motivation-by showing the lengths that people will take to  do what they think they should be doing. To see this  interpretation of this experiment, which is only one of many  ways of viewing it, it is useful to give a brief description. On  arrival, subjects were told that they were involved in a  learning experiment. They were put in the role of the  "teacher," who should administer shocks to a "learner"
whenever he gave a wrong answer. The subjects are led to  identify with their role as teacher in this experiment, and  feel that they should obey the experimenter. Rather than  being another subject, and, rather than being wired, as it  appeared, actually the learner was an unwired, trained con-  federate of the experimenter. Subjects were then instructed  to administer shocks of escalating voltage as the learner  made errors. A surprising fraction of subjects escalated their  shocks to the maximum 450 volts-even though such a
dosage in real life would have been lethal. There are many  different versions of the experiment, but the version where  the confederate grunts and moans at 75 volts, asks to be let  out of the experiment at 150 volts, and refuses to give any  more answers at 300 volts, is typical. Here more than 60
percent of subjects went all the way. Nor is such motivation  limited to the laboratory. The rampage of the Nazi Reserve  Police Battalion #101 in Poland during World War II  (Christopher R. Browning 1999) gives a real-world mirror  of the behavior Milgram obtained in the laboratory. Like  Milgram's subjects, the members of this unit, were just  Ordinary Men (Browning's title). They were recruited from  the most prosaic civilian occupations.  19 See Douglas S. Massey and Nancy A. Denton (1993,  table 3.1, 64).
20 Some years ago, at a conference in Spoleto, Italy,  Edmund Phelps gave a still-unpublished lecture wondering  why the economics of the twentieth century had failed to  discover what was central to most of the arts, which was the
role of subjectivity. This paper is about the direct relevance  of such subjectivity for macroeconomics. I have very much  benefitted from enjoyable conversations with Professor


### ---Economics-2007-0-09.txt---
people's views as to how they should behave
will enter their utility function. In each case, we
shall see that such views will nullify the respec-
tive neutrality result. Indeed, we shall also see
that in each case there will be a natural norm
broadly consistent with Keynesians' views of  economic behavior.21
IV. Ricardian Equivalence
We shall begin our detailed discussion with
Ricardian equivalence. It was chronologically
the last of the neutralities to be appreciated by
modern economists. But it is also the simplest.
That makes it the best place to begin.22 If there
is missing motivation in the utility function, it
should be easiest to see here.
A very simple model demonstrates the es-
sence of Ricardian equivalence, as it was redis-
covered by Robert Barro after a lapse of almost
two centuries.23 In the model, there are just two
periods, periods 1 and 2. There are just two
people, a parent and her child. The utility of the
parent depends directly upon her own consump-
tion, in period 1; it also depends upon the utility
of her child. That utility depends upon his con-
sumption, in period 2.
The parent's utility function can be expressed
simply as U,(cl, U2(c2)), where c1 is the con-
sumption of the parent, C2 is the consumption of
the child, U, is the utility of the parent, and U2  is the utility of the child. The parent chooses her
consumption in period 1 to maximize her utility.
Whatever wealth remains, she bequeaths to her  child.
Ricardian equivalence takes the following form
in this model. Suppose that the government
gives a transfer, which we shall call a social
security payment, to the parent in period 1; but
then in period 2 it taxes the child to retire the
debt caused by this transfer.24 In this case, the
consumption of a parent who maximizes the
utility function U, and who leaves a bequest to
her child will be unaffected by her receipt of
social security.
The logic of this result is simple. With and
without social security the discounted value of
consumption of the parent and of the child is
constrained by the discounted value of the fam-
ily's earnings (plus its initial wealth). Social
security leaves that constraint unchanged. If the
parent found (c,, c2) to be the optimal division
of consumption between herself and her child in
the absence of a social security payment, this
same division of consumption between herself
and her child will optimize her utility with a
social security payment.
A vast literature explains why such Ricardian
equivalence is unlikely to be empirically de-
scriptive.25 The long list of reasons includes (a)
infinite, rather than finite, horizons; (b) strategic
bequests to obtain the attention of one's heirs
while alive; (c) childless families; (d) uncer-
tainty, including bequests made because of un-
certainty about the age of death; (e) differential
borrowing rates between the government and
the public; (f) growth of the economy in excess
of the interest rate, allowing steady debt issu-
ance; (g) lack of foresight regarding the effect
of social security on future taxes; (h) foreign
ownership of debt; (i) tax distortions;26, 27, 28 (j)  Phelps. He has summarized for me the content of that talk
in an e-mail.  21 For each of the five neutralities we see that the inclu-
sion of broader preferences, inclusive of norms, will bring  Keynesian behaviors back to life. But, of course, that does
not mean that the competitive forces and the maximizing  behaviors responsible for the five neutralities are not im-  portant as well.  22 That appreciation is of course due to Barro (1974).  23 This model is quite close to Ricardo's original discus-  sion. It is a considerable simplification of Barro's model.  His model had a sequence of overlapping generations, each  of which lived for two periods. Barro's contribution was not
only to show Ricardian equivalence in the two-generation  model, but also its extension to a sequence of generations  when parents' utility depended only on their own utility and  the utility of their own children. Ricardo's discussion,  which is close to the two-generation model here, was then  subsequently rediscovered. There is no uncertainty, and all  taxes are lump-sum. This proposition may be generalized,  for example, following Barro, to a model with m overlap-  ping generations, each of which has different consumption  when young and old. Each parent derives utility from his  own consumption and the utility of his child.  24 The tax and the transfer are both lump-sum.  25 The conventional wisdom is, of course, that social
security will affect aggregate savings. Martin Feldstein  (1974) and Feldstein and Anthony Pellechio (1979) act as if  increases in social security of the current generation will  result in increased consumption, so that the next generation  will have a lower capital stock.
26 I take this list mainly from the review article by John  J. Seater (1993).
27 Barro (1989) also gives a careful review of the frictional  reasons why Ricardian equivalence may not in fact occur.  28 In the case of strategic bequests, the bequest is an  unusual form of incentive payment for a service rendered.


### ---Economics-2007-0-10.txt---
constraints on the consumption of parents (so they
do not leave bequests); (k) myopia of the parents
regarding children's future tax payments.29
The preceding list gives empirical reasons for
failure of Ricardian equivalence; but, lengthy as
it is, it still ignores its theoretical challenge.
According to that challenge, under economists'
standard assumptions, with perfect certainty and
with perfect foresight, Ricardian equivalence
will occur. Such a result had previously been
unsuspected by economists.30
Two possible conclusions can be drawn from
this surprise. On the one hand, we might con-
tinue to assume that classical assumptions de-
scribe economic behavior. The five neutralities
that are the subject of this paper concern the
realignment to macroeconomics that occurred
as economists gained understanding of the con-
sequences of classical assumptions from the
mid-1950s to the mid-1970s.
Economists may have been correct in draw-
ing the conclusion that the early Keynesian eco-
nomics was too simplistic and naive. But they
could have drawn another conclusion from this
surprise. In this view, Ricardian equivalence is
a telltale: we do not believe, even in the pres-
ence of perfect foresight and perfect certainty,  that the parent will make an equal and opposite
offset of her social security transfer in terms of
an increased bequest to her child. Something
must be missing from the motivation in Barro's
model; otherwise, it would not have given rise
to results that are so surprising.
B. Douglas Bernheim and Kyle Bagwell
(1988) give further evidence suggesting that
Ricardian equivalence is such a telltale. They
show how the same logic would apply to a
network of gift-givers. Remarkably, any
member of such a network will be indifferent
whether she receives an extra dollar or any
other participant in the network is the recip-
ient. Such conclusions, suspect as they are,
suggest a problem with the model beyond the
lack of realism involved in perfect foresight
and perfect certainty. They also suggest miss-
ing motivation.
James Andreoni (1989) has put his finger on
what that missing motivation might be.31 A
bequest is a type of gift. The parent will receive
utility from giving such a gift. Ricardian equiv-
alence will fail if the parent has utility from
gift-giving. With a social security transfer, more
money is hers, and the same consumption allo-
cation to herself entails a greater gift to her
child. With declining marginal utility for bequest-
giving, she will then divide an increased social
security transfer between additional consumption
for herself and an additional bequest to her child.32
Andreoni thus describes the utility missing
from the standard utility function as that arising
from the "warm glow" from giving. Such a
characterization may be accurate. It also sounds
as if it is very close to classical assumptions-
that there is nothing fundamentally different
about this additional motivation. But this seg-
ment of the utility function is, in fact, very
different from economists' usual characteriza-
tion of motivation. We know that the "warm
glow" does not come from the utility the parent  This argument suggests that a "bequest" is not really what it
seems. This is an argument where the preferences of the  parent do play a role, but quite different from the type of  reason that I think would have surprised the Keynesians. I  want to show that parents who make bequests for the  conventional reasons, because they care about the welfare of  their children, will still routinely violate Ricardian equiva-  lence, even in the absence of most of the commonplace  frictions that almost surely invalidate exact Ricardian equiv-
alence.  29 This was Ricardo's own reason for dismissal of the
argument. He said that the parent would alter her bequest
because she would not take into account the added tax
payments of the child (see Gerald P. O'Driscoll Jr. 1977).  Uncertainty regarding the size of the future tax payments is  different from such myopia, in which the payment is alto-
gether ignored. But, with quadratic utility and expected  utility maximization, uncertainty regarding the child's fu-  ture tax payments will have no effect on the size of the  parent's bequest.  30 For example, Feldstein (1974) and Feldstein and Pel-  lechio (1979) engage in no theoretical soul-searching re-
garding the negative effects of social security on current  savings. There is a voluminous literature (see Roberto Ric-  ciuti 2003) examining the empirical validity of Ricardian  equivalence. Largely because of the problem of endogene-  ity, it is difficult to come to firm conclusions regarding its  empirical validity. There are studies with findings both for  and against such crowding out.  31 See also John Laitner (2002), Laitner and Henry Ohls-  son (2001), Alan S. Blinder (1975) and Michael D. Hurd  (1989), who have also modeled the bequest motive as com-
ing from the utility of the parent from giving the bequest.  32 Formally, she trades off the marginal utility of her  own consumption against the marginal utility from gift-  giving and the marginal utility she gets from her child's  consumption. In making this trade-off, she takes due ac-  count of the fact that one unit of consumption today is
traded off against (1 + r) units of consumption next period.


### ---Economics-2007-0-11.txt---
derives from her own consumption; nor, yet
more tellingly, does it derive from the utility of
her child (as the child's utility depends on its
own consumption). It enters the utility function
as a separate term.
What, then, could account for a "warm glow"?
Parent-to-child bequests are a form of gift. If there
is any type of economic transaction that is gov-
erned by norms, it is the giving of gifts.33 Parent-
to-child bequests also occur within families.
Therefore, they should also be affected by the
norms of family life. We have already seen one
example of such norms (Friedan's portrait of the
proper place of women in the early 1960s).
The norms of family life are not constant. They
vary by culture. They also change over time. As
the nature of the ideal family has shifted, so has
the ideal bequest. Actual bequests have changed in
tandem. For example, the ideal sixteenth century
Anglo-Saxon family was dynastic. The lineage
passed from father to oldest son.34 Fathers then  left the bulk of their estates to their oldest sons. In
the twenty-first century, in the ideal family, sib-
lings are equal. Most bequests are now evenly  divided between them.35
Summary.-Economic outcomes, such as the
consumption of the parent and the utility of the
child, are one determinant of bequests. But an-
other possible determinant is parents' views re-
garding how they should behave toward their
children. Just as Friedan's suburban housewives
waxed their floors, because they thought that is  what housewives should do, parents who leave
bequests derive a warm glow from bequests
because that is what they think they should do
for their children. Ricardian equivalence then
illustrates how odd neutralities can occur in
models that fail to take such norms into account.
A comment by David Romer (2001, 539)
tells us where we should venture next. He has
remarked that "quantitatively important" viola-
tions of Ricardian equivalence and of the per-
manent income/life-cycle hypothesis occur for
the same reasons. Ricardian equivalence is not
important for us as an empirical aspect of mac-
roeconomics. There are so many reasons other
than the role of norms for its violation. But it
does give us an initial window on the type of
motivation missing in classical macroeconom-
ics. Inclusion of such motivation will give us a
new perspective on the consumption function. It
allows us to return to a view in which consump-
tion will depend on current income, just as its
inclusion makes it natural to believe that social
security transfers will affect savings and con-
sumption, even in a world without frictions.
V. Consumption and Current Income
This takes us to the second neutrality. Ac-
cording to this result, other than its contribution
to a consumer's wealth, current income has no
independent effect on the consumption of a
utility-maximizing consumer.
Milton Friedman (1957) derived such
consumption-income neutrality in the two-
period model of Irving Fisher. In this model, the
consumer chooses her consumption between
two periods. She maximizes her intertemporal
utility function, given by the function U(cl, C2):
c, denotes her current consumption in the first
period; c2 denotes consumption in the second
period.36 If she maximizes U(c1, c2), a dollar of
income earned today will have the same effect
on her current consumption as a discounted
dollar earned in the next period. Thus, her con-
sumption will depend only on the discounted
value of her current and future income and the
rate of interest. This proposition is easy to
prove. It generalizes to many different com-
modities and to many different time periods,  33 The literature on gift-giving is of course replete with  the notion that gift-giving will be determined by what assets  people consider to be theirs and how much of those assets  should be given to others (Ruth Benedict 1946), rather than  by the final utility outcomes for the gift-giver and for the  gift-receiver. Theodore Caplow (1984) describes the im-  plicit rules for Christmas gift-giving in "Middletown." Peo-  ple believe that the gifts they should give, and receive, should  be given according to these rules. Caplow suggests that one  might consider these "rules" as norms for gift-giving.  34 For the history of the Anglo-Saxon family and the  change of its conception from dynastic to nuclear, see  Lawrence Stone (1977).
35 Using tax data, Mark D. Wilhelm (1996) found that only  10 percent of estates differed by more than 5 percent from  equality between bequests to siblings. His data are only for  bequests from estates larger than the federal minimum for  taxation. For a more general population, Jere R. Behrman and  Mark R. Rosenzweig (2004) have examined the difference in  bequests to twins. Once measurement error is taken into ac-  count, they find no significant differences in the bequests.  36 She receives income of Y, in period 1, income Y2 in  period 2, and she can borrow and lend at the rate of interest r.


### ---Economics-2007-0-12.txt---
and, with quadratic utility, to uncertain in-
comes.37 In standard terminology, the value of
her discounted income is called her wealth; the
amount of that wealth that can be spent without
its depletion is called permanent income.38 An
alternative expression of Friedman's hypothesis
is that consumption depends on permanent  rather than on current income.39
The permanent income hypothesis may be in
accordance with most standard economic mod-
els. Nevertheless, it contradicted prior thinking
about the consumption function. Keynes, and  his followers, believed that current income
played an especially important role in the de-
termination of current consumption.
"The fundamental psychological law [em-
phasis added], upon which we are entitled
to depend with great confidence both a
priori from our knowledge of human na-
ture and from the detailed facts of expe-
rience, is that men are disposed, as a rule
and on the average, to increase their con-
sumption as income increases, but not by
as much as the increase in income" (Key-
nes, The General Theory, 1936, 96).
It is true that The General Theory discussed a
long list of other factors that could affect con-
sumption. The list was sufficiently rich to in-
clude not only current income, but also all the
other determinants of wealth, such as expected
future income and the rate of interest. But that
does not make Keynes's theory identical to
Friedman's. In the Keynesian theory, consum-
ers are more sensitive to current income than to
other changes in income that have similar effect
on the consumer's wealth.
A. Empirical Results and Their Explanation
A large number of tests have demonstrated the
excess sensitivity of consumption to current in-
come, in concert with the Keynesian consumption
function. For example, John Y. Campbell and
N. Gregory Mankiw (1989) nested both Fried-
man's view that consumption depends solely on
wealth and the simplified Keynesian view that
consumption depends solely on income. They
suppose that a fraction of consumers A are pure
Keynesians, while a fraction (1 - A) behave ac-
cording to the permanent income hypothesis; they
estimate A from the extent to which consumption
overreacts to changes in income that would be
predictable from past changes in income and con-
sumption. Usefully, then, A gives a natural mea-
sure of the departure from the permanent income
hypothesis. The estimates of A are significant sta-
tistically and also of significant magnitude eco-
nomically: between 40 and 50 percent (depending
upon whether three or five periods are used to
predict the change in current income).
Other studies corroborate such excess depen-
dence on current income: John Shea (1985), for
union members whose contracts specified their  37 The simple proof is that her utility-maximizing con-  sumption will depend upon the intercept and the slope of the  budget line. The budget line states that the present dis-  counted value of consumption is the present discounted  value of her future income, which is what Friedman calls
her wealth. The intercept of the budget line is her wealth.  That is how much she could consume today if she consumed
nothing tomorrow. And the slope of the budget line is  determined by the rate of interest r: on the budget line for  every unit of c, she gives up (1 + r) units of c2. Her  consumption will be on the highest attainable utility indif-  ference curve. That will be the indifference curve that is just  tangent to the budget line. As a result, we see that, given the
utility function, c1 will be a function of W and r. Note that  current income does not come into this expression.  38 Formally, permanent income is the product of the rate  of interest and wealth.
39 The permanent income hypothesis also generalizes to  currently popular models of present bias. In these models  consumers have present bias in the form of "hyperbolic dis-  counting," which means that they put extra weight in their  utility functions on their current consumption. In this case, the  typical consumer's plans will not be consistent, but they can be  analyzed as if she has multiple selves. Her self today decides  on how much to consume today and then passes on the re-  maining assets to her self tomorrow. There is an exact analogy  to the parent's maximization in Barro's model of bequests. In  that model, today's consumer passes on assets to her child in  the next generation; in consumer theory, today's consumer  passes on assets to her new self in the next period. Since the  standard model of intertemporal consumption and Barro's  model of consumption are exactly isomorphic, Ricardian  equivalence then tells us that current consumption-which is  the consumption of the initial self-depends only on the con-  sumer's wealth. David I. Laibson (1997) thus shows that
consumption with forward-looking consumers with hyperbolic  discounting will balance the marginal utility of present con-  sumption out of wealth against the marginal utility of future  consumption according to an Euler condition. Such a condition  is wealth-based. It is the generalization of the tangency of the
utility indifference curve to the budget line in the two-period  model of Irving Fisher. Both Friedman and Laibson obtain  consumption that is determined solely by current income if  there is a constraint on current borrowing, and consumers'  desires for current consumption exceed their current income.  There is nothing inherent in the preferences in either case that  causes current consumption to be based on current income.


### ---Economics-2007-0-13.txt---
future wages; David W. Wilcox (1989), for social
security recipients who had been earlier notified of
changes in cost-of-living adjustments; Jonathan
Parker (1999), for payers of social security taxes
with predictable inter-year changes; Nicholes S.
Souleles (1999), for changes in disposable income
net of tax refunds; and James Banks, Richard
Blundell, and Sarah Tanner (1998), and Bern-
heim, Jonathan Skinner, and Steven Weinberg
(2001), for retirees.
Textbooks explain such excess sensitivity by
a variety of frictions, particularly borrowing
constraints. For example, Rudiger Dornbusch
and Stanley Fischer (1987) say: "Given that the
permanent income hypothesis is correct [sic],
there are two possible explanations."40 They are
liquidity constraints for consumers and myopia
in their projections of future income.
Thus, we see the realignment that occurred
because of the life-cycle permanent income hy-
pothesis: excess sensitivity may occur, but only
in the presence of credit constraints or myopia.
Such a view cannot have been adopted because
of its empirical support. Few studies have tested
this proposition, but those that do have rejected
it. For example, credit constraints cannot ex-
plain the reduction in consumption of retirees.
And, neither myopia nor credit constraint can
explain the reduction in union members' con-
sumption at the time of wage declines scheduled
in their union contracts (Shea 1995, 996).
The adoption of the permanent income/
life-cycle hypothesis then must rest on theoret-
ical, not empirical, reasons. But the theory fails
to take into account norms regarding what peo-
ple think they should, or should not, consume.
Such a norm-based theory will nest Keynes's
psychological law. Consumption-income neu-
trality will occur only in a singular special case.
B. Consumption and the Role of Norms41
Why should consumption be overly sensitive
to income? This section presents an argument in
three steps. First, sociology gives motivations
for consumption that are very different from the
reasons for it in the life-cycle model. A major
determinant of consumption is what people  think they should consume. Second, what peo-
ple think they should consume can often be
viewed either as entitlements or as obligations.
Finally, in turn, current income is one of the
major determinants of these entitlements, and
obligations.
Sociology of Consumption.-The motivation
emphasized by sociologists for consumption is
very different from that in the life-cycle model.
Sociologists describe consumption as largely
determined by the norms regarding what people
should consume. These norms, in turn, are de-
pendent upon the individual's situation and also
who she thinks she is.
Two examples illustrate such dependence on
norms. Following Pierre Bourdieu (1984), peo-
ple's consumption of cultural goods-the liter-
ature they read, the music they hear, and the art
they buy-reflects not just their individual
tastes. The upper class should not make lower-
class choices. Correspondingly, the lower class
should avoid appearing above their station.42
The epithet "lace curtain Irish" illustrates. To
the users of this phrase, those lace curtains were
indicative of those violating their social place.
Weber's analysis of the relation between re-
ligion and savings further reflects the role of
people's views regarding who they should be.
In The Protestant Ethic and the Spirit of Capi-
talism,43 Weber describes Calvinists as aspiring
to be "worldly ascetics." He concludes that
"economic acquisition is no longer subordi-  nated to man as the means for satisfaction of his
material needs.""44 Here the purpose of saving is
to live up to an ideal. The Calvinists are thrifty
because they think they should not be consum-
ing. That turns the motivation of the life-cycle
40 See Dornbusch and Fischer (1987, 284).
41 I am extremely grateful to Robert Akerlof for help in  formulating the argument of this section.  42 Bourdieu views this as important because of the role
of such differential consumption in the transmission of class  structure from one generation to the next. The focus on  consumption as a reflection of who people want to be can be  seen throughout the sociology of consumption. On the low-  brow-highbrow scale, a study by Ian Woodward (2003) is at  the opposite end of the spectrum from Bourdieu: Woodward
asked Australian housewives about the reasons for their
choice of furniture. Some went for comfort; others, for
aesthetics. But they also indicated, with a surprising degree  of moral fervor, that their choices reflected who they wanted  to be.
43 See Weber (1958).  44 Weber (1958, 53).


### ---Economics-2007-0-14.txt---
model on its head. There people save only because
of their desire for consumption in retirement.
Luigi Guiso, Paola Sapienza, and Luigi Zin-
gales (2003, 2006) have statistically affirmed
Weber's hypothesis that religion is correlated
both with attitudes toward savings and with
actual savings. In addition, they have more gen-
erally affirmed the quantitative significance of
culture for savings and consumption; in their
regressions, variables reflecting culture have as
much power as variables derived from the life-
cycle hypothesis in explaining cross-country
savings ratios.45
Consumption Entitlements and Obligations.-
While sociology is useful in giving us the gen-
eral insight that consumption depends on cul-
tural norms, we need to be more specific. What
is the nature of those norms? They can fre-
quently be described in two ways: as entitle-
ments and, also sometimes, as obligations to
spend. Again some examples will illustrate.
First, oddly, people have obligations to
spend. Social history is full of the obligation to
keep up appearances. Most Wall Street bankers,
for example, do not live like mothers on wel-
fare. They do not want to. But, even if they did,
it would occasion gossip. It is not what they
should do. History is replete with stories of the
debt of aristocrats struggling to maintain their
social obligations.46 As just one example, the
debts to British merchants by Southern planters,
who were keeping up with the Joneses of the
eighteenth century, are considered a significant
factor underlying the Southern support of the  American Revolution.47
In addition to obligations to spend, there are
also entitlements. The lost-ticket paradox of
Amos Tversky and Daniel Kahneman (1981,
457) gives an illustration. Eighty-eight percent  of respondents to a questionnaire said they would
buy a $10 theater ticket if they arrived at a theater
to see a play and found that they had lost a $10
bill. In contrast, only 46 percent said they would
buy a new $10 ticket in the same situation if
they had lost a previously purchased ticket.
Tversky and Kahneman explain this differ-
ence by "mental accounts," but an explanation
in terms of entitlements is equally valid. Tver-
sky and Kahneman say that those who have lost
the $10 bill do not connect that loss to the play.
In their mental account, its cost is just $10. But
those who have lost the ticket see themselves as
paying for it twice. In their mental account, its
cost is $20. Those with the lost ticket then tend
to opt out, because they see $20 as too much to
pay to see the play. But the difference in behav-
ior for those who lost the ticket and those who
lost the $10 bill could also have been interpreted
in terms of entitlements. Most people want to
think of themselves as responsible human be-
ings. When they lose the ticket, they do not feel
entitled to just buy another one. That is not the
type of person they aspire to be.
We should also observe that it is not coinci-
dental that the lost ticket paradox could be ex-
plained both by mental accounting and by
norms. Formally, any model of mental account-
ing can be translated into a model of norms: just
replace the rules of mental accounting as the
norms that people think they should follow.48
But even though norms and mental accounting
may be equivalent, interpretations in terms of
norms are important for this lecture. Mental ac-
counting has the connotation, whether rightly or
wrongly, of being a heuristic for quick decisions.
Such a heuristic will, of course, sometimes result
in cognitive error. Whether rightly or wrongly,
most economists would dismiss cognitive error as
unimportant. Why? because in their view people
are smart about what they want, and their deci-
sions are also very purposeful. But norms cannot
be dismissed so easily. As I argued earlier, people
feel strongly about adherence to them. Their  45 Guiso, Sapienza, and Zingales (2006, 39) report re-  gressions of savings ratios on GDP growth, dependency  ratios, and responses to the question: "Do you consider it  especially important to encourage children to learn thrift  and savings?" A one-standard-deviation difference to GDP  growth and to attitude toward thrift both produce a 1.8-  percentage-point difference in the savings ratio. (A one-  standard-deviation difference in the dependency ratio,  which could be the result both of cultural differences and of
life-cycle considerations, produces a 3.2-percentage-point
difference.)  46 See, for example, David Cannadine (1977).  47 See Woody Holton (1999).  48 But it turns out that there is quite possibly a substan-  tive difference between the two interpretations. With the
mental accounting interpretation the losers of the ticket  could be induced to buy one, if only a wise friend would  make them aware of the logical problems of their reasoning.  In contrast with the norms interpretation the friend cannot  be so helpful. Buying a new ticket is a departure from the  person's norm, and she loses utility by it.


### ---Economics-2007-0-15.txt---
absence from utility constitutes the missing
motivation of macroeconomics.
The Link of Entitlements and Obligations to
Current Income.-It remains to relate current
spending to current income. Norms may be
complex. But a web of evidence still reveals a
strong association between current income and
entitlements and obligations to spend. Such a
link, in turn, produces the excess sensitivity of
consumption on current income in Keynes's
Psychological Law.
A few examples follow.
* It is common practice in the United States for
parents, even for rich ones with no budget
constraint, to expect their children to assume
financial independence after their graduation
from college. They are indicating their belief
in the norm that the child is entitled to spend
what she earns. (Most parents, of course, give
their children a helping hand as they seek
their independence. But that does not mean
that they do not also strongly believe that their
children should live on their earnings, since that
norm is only one of their motivations.)
* In a thought experiment, consider a woman
living on $50,000 a year who learns that
her uncle will die in one year leaving her
$2,000,000. Even if she has considerable sav-
ings in the bank, it would be unseemly for her
to run down her savings in anticipation of the
bequest. She is not entitled to do so. She
should stick to spending from her current
income. This gives another example in which
norms regarding entitlements to spend are
related to current income, in violation of the
life-cycle hypothesis.
* People's expenditures are supposed to reflect
their stations in life, and those stations usu-
ally reflect their earnings. Thus, for example,
college students with little earnings are sup-
posed to live that way-like college students.
Their current spending is supposed to reflect
their current earnings, not what they will be
earning in the future. (At the other extreme,
as an obligation, the college president is often
expected to live in the presidential mansion.)
* Preliminary results from an experiment by
John Morgan and myself illustrate another
relation between entitlement and earnings. In
this experiment, subjects were asked to do-
nate to a charity before and after completing
a task. Those who were asked for the dona-
tion afterward were more likely to keep the
money than those who were asked before-
hand. Those who had completed the task felt
that they had earned the money and were thus
entitled to keep it for themselves.49
* The mental accounting model by Hersh M.
Shefrin and Richard H. Thaler (1988) is espe-
cially useful in our quest for a Keynesian con-
sumption function. Norms take many forms, so
their formal model is not unique.50 But it does
illustrate a possible link between consumption
and current income. In this model, people have
three separate mental accounts: current income,
current assets, and future income combined
with pension wealth. As consumers exhaust one
of these accounts and begin to use the next one
for their current consumption, they incur a dis-
continuous "penalty." Those penalties are psy-
chological in nature-this is a model of mental
accounting-and they take the form of a loss in
utility.51 Corresponding to Shefrin and Thaler's
assumptions regarding the nature of these costs,
as consumption rises, consumers will first fi-
nance it wholly from current income; then,
from current assets; and, finally, from future  income and retirement wealth.
As we discussed earlier, it should be no sur-
prise that there is an exact translation of such a
model into one with norms regarding entitle-  ments to consume. The rules of mental account-
ing become the norms regarding how money
should be spent. The basic norm is that con-
sumption should come from current income.
49 These are the results for females. The men gave al-  most nothing so their differentials are irrelevant. The
women gave on average about 10 percent of their earnings.  Those who were asked to donate before the task gave twice
as much as those who were asked afterward. The task lasted
40 minutes and was to highlight phrases in a manuscript to  be used in making an index.  50 Shefrin and Thaler themselves are explicit about the  possibility of other models.  51 We should also note that the Shefrin-Thaler model
has elements not discussed in the text. In general, the  discontinuous penalties from mental accounting are one  reason why consumption might be at a corner solution in  one of the three mental accounts. Shefrin and Thaler have
another reason. They view saving as taking willpower,  which entails a cost in terms of lost utility. The less  people save the less of this costly willpower they need to  expend. This gives another reason why consumption  might be on one of the boundaries of the mental accounts.  It is useful to remember that at one of the boundaries,  consumption will conform to current income.


### ---Economics-2007-0-16.txt---
And the discontinuous penalties correspond to
the losses of utility due to respective deviations
from that norm. In particular, Shefrin and Tha-
ler assumed that there is no such cost at all if
consumption comes only from current income.  That means that current income can be consid-
ered as consumers' entitlement to spend, since
any consumption that is less than current in-  come entails no deviation at all from the norm
regarding the account that should finance it.
* Shefrin and Thaler give an impressive array
of econometric facts in support of their
model. Insofar as these facts support their
mental accounting model, they also equally
well support its reinterpretation-with the  norm that current income is an entitlement to
spend. Those facts include: differential sav-
ings out of windfall and current income;52 a
less than one-to-one displacement of discre-
tionary saving by employee pension contri-
butions;53 undersaving for retirement;54 and a
marginal propensity to consume out of fully
anticipated bonuses that is much greater than
the marginal propensity to consume out of
monthly income.55
* Retired people are commonly believed to
tailor their consumption to a concept of
income rather than to the value of their
assets. Shefrin and Statman (1984) have
viewed this as another form of mental ac-
counting. They also present considerable
evidence regarding such behavior.
C. Summary
Considerable evidence suggests that people's
views regarding what they are entitled to spend
play a major role in their consumption choices.
It also suggests strongly that current income
plays a special role in those entitlements. She-
frin and Thaler have explained such patterns by
mental accounting. A reinterpretation of their
model shows that they also could have ex-
plained this behavior in terms of norms. Once  again we see that the current versions of the
life-cycle hypothesis have left out missing mo-
tivation that easily justifies the excess sensitiv-
ity of consumption to income in Keynes's
psychological law.
VI. Investment and Cash Flow
The debate concerning investment has been
surprisingly close to the debate about consump-
tion. The early Keynesians emphasized two  variables as determinants of investment: current
cash flow (with profits as a major component),
and the firm's current holdings of liquid assets.
Each of these variables is a measure of funds
available to firms for investment without seek-
ing outside finance.56 In contrast, the later liter-
ature denied any special role of liquidity in the  investment function.
The first such questioning came from
Modigliani and Miller, who assumed that man-
agers maximize shareholder value and that mar-
kets are frictionless and competitive. In this
case, a firm's financial position plays no role in
the value of the firm. The argument for this
independence proceeds as follows. By construc-
tion, Modigliani and Miller show how a com-
petitive equilibrium changes if a firm increases
its debt and buys back shares. In the new equi-
librium, investment will be unchanged, and
shareholders will offset the increase in the
firm's debt by a compensating increase in the
bonds in their respective private portfolios. The
reason the equilibrium changes in this way is
straightforward: if the markets for debt cleared
in the old equilibrium, they will again clear in
the new. If managers' choice of investment
maximized shareholder value in the old equilib-
rium, the same choice of investment maximizes
it in the new. Investment is therefore indepen-
dent of the firm's current financial position,
including its current liquidity position and its  current cash flow.
The advent of q-theory similarly questioned a
special place for current variables, such as cash
flow and liquid asset holdings in the investment
decision. In the original version of the theory,
James Tobin (1969) suggested that a firm's op-
timal investment strategy arbitrages between  52 Shefrin and Thaler (1988, 619-20).  53 Shefrin and Thaler (1988, 622-24).
54 Shefrin and Thaler (1988, 626-27). Especially, they  say that there would be vast undersaving in the absence of  social security and forced private pensions to prevent it.  There is some ambiguity regarding whether there is under-  saving in the presence of these institutions to counteract it.  55 Shefrin and Thaler (1988, 633).  56 See, especially, John R. Meyer and Edwin Kuh  (1957).


### ---Economics-2007-0-17.txt---
the value at which it can sell a unit of its capital
and its investment costs to produce a new unit
of capital. In this case, firms should invest up to
the point where the marginal cost of a new unit
of capital is the valuation of such a unit of
capital in the stock market. That valuation is the
market value of the firm's shares divided by its
capital stock, called the q-ratio. If markets are
efficient, q is also the expected discounted value
of current and expected future profits per unit of
capital.57 Since q-theory says that firms should
invest in capital up to the point where the cost of
an extra unit of capital stock is equal to the
present discounted value of the stream of earnings
from a unit of capital, again, as in Modigliani-
Miller, investment is independent of the firm's
finance decision.58
The empirical testing of q-theory also has a
striking parallel to the empirical testing of the
consumption function. Just as Campbell and
Mankiw showed that there was excess sensitiv-
ity to current income in the consumption func-
tion, Steven M. Fazzari, R. Glenn Hubbard, and
Bruce C. Petersen (1988) showed that invest-
ment depends not just upon q, but also upon the
current cash flows. Furthermore, as in the stan-
dard explanation of excess consumption sensi-
tivity, Fazzari, Hubbard, and Petersen similarly
suggest that credit constraints are responsible
for the dependence of investment on cash flow.
They continue with the Modigliani-Miller/
q-theory assumption that managers maximize
stockholder value. But they posit that the dif-
ference in information between managers and
financiers results in a wedge between the cost of
internal and external financing. This is clearest
for firms that are credit constrained-so that
credit-constrained firms will be especially sensi-  tive to available liquidity.59 But, as with credit-
constraint explanations of consumption, empirical
evidence, such as there is, rejects this hypothesis.
Steven N. Kaplan and Zingales (1997) analyzed
the subsample of firms that Fazzari, Hubbard,
and Petersen had considered most likely to be
credit constrained. They find credit constraint to
be rare. Furthermore, they also found that those
firms with the least constraint had the greatest
sensitivity to cash flows.60
There is, thus, remarkable similarity between
the consumption function and the investment
function. In both cases, economic theory sug-
gested rejection of earlier views regarding the
role of current flow variables-current income
in the case of consumption, cash flow in the
case of investment. In both cases, empirical
investigation showed the existence of excess
sensitivity to the current flow variable. In both
cases, these rejections support the previous
Keynesian theory. In both cases, economists
have sought to explain the divergence between
practice and theory by the presence of credit
constraints. In both cases, the empirical evi-
dence, such as it is, does not support the case
that credit-constraint explanations explain the
theoretical anomaly.
A. Theory of Excess Sensitivity of Investment
to Cash Flow
Whatever the similarities, consumption and
investment differ in one major respect. In the
case of investment, economists are already
aware of a fundamental reason why investment
will depend on current cash flow. Modigliani-
Miller and q-theory both assume that managers
57 See Andrew B. Abel (1979), Lawrence H. Summers  (1981), and Fumio Hayashi (1982).  58 This should not be a surprise, because the assumptions  of this version of q-theory are in accord with Modigliani-  Miller: competitive financial markets and investment that  maximizes shareholder value. Thus, the firm's current fi-
nancial position should play no role in investment. In q-  theory, current profits are just one component of the stream  of current and future profits that determine the value of q. In  this sense, they play no special role in the determination of  investment. This de-emphasis of current cash flow (and thus  current profits) in investment is analogous to the denial of  any special role of current income in the permanent income
hypothesis.  59 See, for example, Fazzari, Hubbard, and Petersen  (1988). Stewart C. Myers and Nicholas S. Majluf (1984)  also argued that cash flow would affect investment when  managers had information not available to investors.
60 An examination of the investment spending of firms  with cash windfalls from winning or settling lawsuits sup-  ports this finding (Olivier J. Blanchard and Florencio
Lopez-de-Silanes 1993). These firms had no problems re-
garding credit constraints; yet they invested in projects they  would not have otherwise pursued. Another striking finding  also shows excess sensitivity of investment to cash flow. In  1986, when the price of oil declined dramatically, non-oil  subsidiaries of oil companies cut their investment relative to  the median in their industry (Owen Lamont 1997). But  because this study examines the investment implications of  afall, rather than of a rise, in the price of oil, it is not useful  in resolving the role of credit constraint.


### ---Economics-2007-0-18.txt---
maximize shareholder value. In the now-standard
theory of the firm, the interests of the shareholders
and the interests of the managers are viewed as
different. The managers are only the agents of the
owners, and accordingly they maximize their own  interests instead. Such incentives are said to turn
the managers into "empire-builders,"61 who will
use the resources they control to increase their
own domains.
Empire-building can result from two types of
motivations. On the one hand, managers may
have only strict economic interests in mind:
they care only about their take-home pay, and
their effort on the job. Such managers, for ex-
ample, will be biased in favor of investments
whose operation or construction enhances their
firm-specific human capital, and thereby in-
creases their bargaining power.
On the other hand, empire-building may be
pursued as a goal of its own, for its own sake.
We saw earlier that most workers have views
regarding how they should or should not per-
form their jobs. Accompanying such views,
most managers and workers will have the fur-
ther view that the firm should be investing in
those jobs. For this reason, the agents making
the investment decision are likely to engage in
empire-building. We can represent such moti-
vation by adding a term to the utility function of
the agent-decision maker. Her utility function
will not only depend on her own pecuniary
returns and her expenditure of effort. It will also
include an additional term reflective of her
norms. She will lose utility insofar as the firm's
investment fails to live up to her ideal of what
she thinks it should be. In this case, the typical
norm is that she thinks that the firm should
engage in investment that will enhance her job
performance.
Following the logic of Michael Jensen (1986,
1993), empire-building, accompanied by the
abdication of corporate oversight in favor of
management interests, explains a correlation be-
tween investment and cash flow. Furthermore,
this correlation will occur regardless of the moti-
vation for the empire-building, whether for purely
economic reasons as in the principal-agent model,
or, instead, because of managers' norms for how
they think they should behave. Jensen has given  many instances of lax corporate oversight in favor
of management interests. For example, he has
cited the excess exploration and drilling opera-
tions of oil companies when retained earnings
were high, from 1975 to 1981,62 and the mainte-
nance of low-return operations in many US indus-
tries, as in the investments of General Motors
throughout the 1980s.63 In Jensen's views, share-
holders would have fared better if profits had been
returned to them, giving them the option of invest-
ing at a higher rate of return, or perhaps if profits
had been used for takeovers outside the industry.
To cure what he calls the "failure of corporate
internal control," Jensen has also suggested that
firms should issue large amounts of debt, perhaps
even by going private. In that case, the added debt
obligations act as a brake on excess investment.
Regarding investment behavior, Jensen is then on
the same page as Keynesian economists such as
Klein and Goldberger. They refer to "the prefer-
ence of many businessmen for internal as opposed
to external financing" (1955, 12-13) and also con-
sider it the major reason for the dependence of  investment on cash flow.
B. Sociology of the Corporation
Once again, we have seen a neutrality result
that depends on the goals of the respective de-
cision makers. Accordingly, the norms of cor-
porate decision makers are central to the
sociology of the corporation. For example, Dirk
M. Zorn (2004) has examined how the locus of
control has changed in large US firms over the
past 40 years. He has shown how this control
has shifted away from those with a production
or a sales orientation to those with a financial
orientation.64 Empirically, this is seen in the rise
of the chief financial officer. Prior to the 1960s,
corporate finances were handled by corporate
treasurers, whose duties were mainly restricted
to keeping the accounts and producing the bud-
gets. Now, most large corporations have re-
placed them by a CFO. With the change in title
has come a change in function. CFOs are typi-
cally central to major decisions. Such a change
affects investment decisions. If they are com-
mitted to their missions, managers with sales or
61 Empire-building is especially emphasized by Jeremy  C. Stein (2003), following Jensen (1986, 1993).  62 Jensen (1986, 327).  63 See Jensen (1993, 853).
64 That distinction was emphasized earlier, for example,  by Neil Fligstein (1990).


### ---Economics-2007-0-19.txt---
production orientations will be empire-builders.
In contrast, the role of the conscientious CFO is
to curb those enthusiasms. Fifty years have
elapsed since the publication of Modigliani-
Miller. According to Zorn, when it first ap-
peared, it did not describe the investment
decision of large corporations. Now, quite pos-
sibly, changes in corporate decision-making  since that time make it more realistic.65
C. Summary
The investment decision demonstrates once
again that the respective neutrality result depends
on the objective function of the decision makers.
VII. Natural Rate Theory
We now turn to natural rate theory. Once
again, the debate concerns the behavior of eco-
nomic decision makers. The early Keynesians
viewed wage setters, and possibly also price
setters, as setting nominal wages and prices,
respectively, without taking full account of in-
flationary expectations. In contrast, New Clas-
sical revisionists have assumed that wage and
price setters care only about relative wages or
prices, and therefore wage and price setting will
fully incorporate inflationary expectations. Such
behavior yields a long-run neutrality result with
severe limits on the ability of monetary and
fiscal policy to affect unemployment and out-
put. When wage and price setters care only
about relative wages and relative prices, accel-
erating inflation will occur if unemployment is
below a critical level, called the natural rate;
accelerating deflation will occur if unemploy-
ment is above it.
As we shall see, such spirals occur because,
at high levels of demand, the representative firm
will wish to set the price of its product relative
to the price of other firms' products-which we  call its real price-in excess of unity. A standard
natural rate model illustrates why this occurs. That
model assumes that in each period the typical firm
sets a desired real price for the following period;
in each period it also makes a bargain with its
labor regarding next period's real wages. Next
period's nominal price and nominal wage are then
respectively set by adjusting this desired real price
and this bargained real wage according to infla-
tionary expectations. When demand is higher, the
desired real price of the representative firm is
higher for two reasons: on the demand side, be-
cause the demand for its product is higher, and, on
the cost side, because the bargained real wage is
higher. That bargained real wage is higher both
because the typical employee's opportunity costs,
which take into account her chances of being
unemployed, are higher, and because the firm's
desire for her labor is higher. Since the firm's
owners, customers, and workers care only about
real prices or real wages, a given level of real
aggregate demand will be associated with a given
real wage bargain between the firm and its work-
ers, and a given desired real price for the firm's
product. If unemployment is sufficiently low-
below the natural rate-that desired real price will
be in excess of unity. If unemployment is above
the natural rate, it will be less than unity.
It is now easy to explain the inflationary and
deflationary spirals in natural rate theory. Con-
sider what happens when the representative firm
wishes to set its price above that of other firms.
In this case, actual inflation will exceed ex-
pected inflation. With such a positive gap be-
tween actual and expected inflation, inflationary
expectations will rise, as inflationary expecta-
tions are adjusted upward to conform to reality.
But the firm's desired real price, and therefore
the difference between actual and expected in-
flation, will be unchanged as long as unemploy-
ment is constant. There will be no abatement in
the rise in expected inflation. Inflationary ex-
pectations will be forever increasing, and infla-
tion will rise with it, as nominal prices and
wages adjust the real wage bargains and the
desired real prices for these increasing inflation-
ary expectations. By similar logic, if unemploy-
ment is above the natural rate, there will be a
deflationary spiral. The natural rate is the only
sustainable level of unemployment without ac-
celerating or decelerating inflation. It corre-
sponds to the exact level of demand where firms
wish to set a real price of exactly one.  65 Curiously, the rise of the CFO may have substituted  one overenthusiasm (from the point of view of shareholders)  for another. There is considerable division regarding whether  mergers and acquisitions have positive returns to the buyer.  Robert Bruner's meta-analysis (2002) of many different stud-  ies concludes that, on balance, the returns to bidders have been
zero. This is a poor return for an activity that has involved so  much corporate time and initiative. Furthermore, if some op-  portunities can be identified as having positive returns, then, to  reach an average return of zero, the marginal merger and  acquisition has negative payoff.


### ---Economics-2007-0-20.txt---
A. Acceptance of Natural Rate Theory
Most macroeconomists do not just view nat-
ural rate theory as a useful null hypothesis.
They also see it as a description of reality. Such
a view is revealed in textbook presentations.
Economists accept natural theory for theoretical
and empirical reasons.
Theoretically, they view the assumptions of
natural rate theory as realistic. A standard cri-
terion for an economic model is that participants
in the economy care only about real outcomes.
That is the fundamental assumption of natural
rate theory. Also, unlike our other neutrality
results, natural rate theory is insensitive to de-
viations due to "frictions," such as imperfect
information, taxes, myopia, or transaction costs.
As long as these "frictions" can be expressed
solely in real terms, the neutrality result of
natural rate theory will be robust.
Empirical considerations have also been in-
fluential in economists' acceptance of natural
rate theory. The original Phillips curve showed
a close fit between the rate of change of nominal
wages and the inverse of the unemployment rate
for 97 years of British data, between 1861 and
1957. There was no inflation adjustment in this
equation. In the United States in the late 1960s
and early 1970s, however, such a simple inverse
relation between changes in nominal wages and
unemployment broke down, as both price and
wage inflation rose, along with the unemploy-
ment rate. Natural rate theory offered an expla-
nation for this occurrence: it explained the rise
in inflation by the large oil supply shock and
also an increase in inflationary expectations,
both of which shifted the Phillips curve out-
ward; it explained the rise in unemployment by
a decline in demand.
Furthermore, new estimates of Phillips curves
seemed to show that the theory closely fit the data.
If inflationary expectations are formed as a simple
lag of past inflation, estimates of Phillips curves
should find that the coefficients on past inflation
sum to one. Many Phillips curve estimates fail to
reject that this sum is equal to one.66' 67 The stan-  dard errors of such estimates are quite large; thus,
they also fail to reject sums whose departure from
one is of sufficient size to result in departures of
economically significant magnitude from natural
rate theory. But the standard treatment of the Phil-
lips curve ignores this inconvenient fact.
The textbooks thus typically present natural
rate theory as a "just-so" story. It runs as fol-
lows. The previous Keynesian economists had
posited a Phillips curve without a dependence
on inflationary expectations. Friedman (1968)
and Phelps (1968) perceived that such a theory
could not result from models where the partic-
ipants in the economy are concerned only with
real variables. They modified the relationship so
that wage and price equations would be affected
one for one by inflationary expectations. Such
judicious use of economic theory explained the
otherwise-mysterious finding of the simulta-
neous increases in inflation and unemployment
of the late 1960s/early 1970s. The theory is also
consistent with most econometric estimates.
B. Nominal Considerations in Wage Behavior
We now turn to the same question regarding
wages that we asked concerning consumption
and investment. Is there "excess sensitivity"
relative to the respective neutrality? Natural
rate theory is based on the assumption that
wages and prices are set only with real con-
siderations in mind. "Excess sensitivity" here
66 See, for example, Robert J. Gordon (1977, table 3,  lines 6 and 7, 260).  67 Given the importance of such findings, it is remark-  able that their robustness to specifications of time period,  data, and exact specification of the Phillips curve has never  been subjected to tough tests-even though everything else  about the Phillips curve, including the natural rate of un-  employment itself, is considered to be estimated with great  imprecision. Akerlof, William T. Dickens, and George L.  Perry (2000) show a range of estimates for both wage and  price equations with many different specifications. These  estimates, particularly when made for periods of low infla-  tion, show considerable variation in the sum of the coeffi-
cients on lagged inflation, dependent on the specification.  Another bit of evidence that suggests such estimates will be  sensitive to specification comes from the high standard  errors on the natural rate itself (Douglas Staiger, James H.  Stock, and Mark W. Watson 1997); it would be surprising  that the sum of lagged coefficients could be estimated  precisely if another component of the Phillips curve, the  natural rate, could be estimated only with very low preci-  sion. Gordon's own estimates show very different values for  this sum of coefficients. Of course, there is a theoretical
reason why estimates of such a sum should not be robust.  With rational expectations, rather than a simple mechanical  theory of formation of inflationary expectations, Sargent  (1971) shows that there is no theoretical reason that they
should sum to one.


### ---Economics-2007-0-21.txt---
takes the form that nominal considerations af-
fect real wage or price setting in some way or
other.
Evidence of one form of violation of the
assumptions of natural rate theory is especially
stark. That evidence concerns downward wage
rigidity. Such wage behavior can easily be per-
ceived statistically by examining distributions
of wage-changes. These distributions are char-
acterized by a bunching of wage changes at
exactly zero; there are some wage changes just
above zero in these distributions, but almost no
wage changes just below.68 Careful studies have
documented such wage stickiness in Australia,
Canada, Germany, Japan, Mexico, New Zea-
land, Switzerland, the United States, and the
United Kingdom.69,70 There seems to be no way
to account for such nominal wage rigidity with
the basic assumptions underlying natural rate
theory: that participants in the economy care
only about real prices and real wages.
Wage stickiness also explains a macroeco-
nomic observation that is an anomaly for natural
rate theory. Unemployment was so massive in
the Great Depression that inflation should have
been below inflationary expectations throughout
this long period. With any natural-rate adaptive-
expectations Phillips curve, such high unemploy-
ment would have caused a deflationary spiral.  Data on inflation are available for 12 countries for
the Great Depression. Not a single one of them  shows such a spiral.71 For example, the United
States experienced rapid deflation from 1929 to
1933, but inflation systematically neither rose nor
fell for the next decade. The predictions of natural
rate theory are thus grossly violated. But sticky
wages offer a good explanation for such behavior.
For example, a dynamic simulation of the US
economy with money wage rigidity and with
Depression-level unemployment fits the data all
but exactly (Akerlof, Dickens, and Perry 1996).72
Nominal wage rigidity may not only be sta-
tistically perceptible; it can also be macroeco-
nomically important, even outside of Great
Depressions. Nominal wage rigidity imparts a
long-run trade-off between unemployment and
long-run inflation. This trade-off is of sufficient
size that it should deter central banks from
targeting very low levels of inflation. For exam-
ple, simulations of the US economy (Akerlof,
Dickens, and Perry 1996) show that an increase
of the inflation target from 0 to 2 percent will
permanently reduce unemployment by 1.5 per-
centage points.73
Norms as Explanation for Sticky Money
Wages.-It seems to be impossible, or all but
impossible, to explain the existence of sticky
money wages, without relaxation of the basic
assumption that the utility functions of employ-
ees or of employers contain real arguments. A
simple and natural amendment to the standard
model explains such sticky money wages: that
employees have a norm for what wages should
be. According to that norm, they will lose utility
from a money wage decline. Sticky money
wages then result, as the bargains between em-
ployers and employees reflect the presence of
this ideal in the utility function.
Indeed, the study by Bewley (1999) gives  68 These distributions have accumulations at zero, and
they are also asymmetric: there are more wage changes  above zero than below zero. This suggests that the accumu-  lations at zero do not occur just because there is a menu cost  for changing wages.  69 The following studies have all found significant signs  of nominal wage rigidity: Truman Bewley (1999), David  Card and Dean Hyslop (1997), Shulamit Kahn (1997),  David E. Lebow, Raven E. Saks, and Beth Anne Wilson
(1999), and Joseph G. Altonji and Paul J. Devereux (1999)  for the United States; Pierre Fortin (1996) for Canada;
Vincenzo Cassino (1995) and Simon Chapple (1996) for  New Zealand; Jacqueline Dwyer and Kenneth Leong (2000)  for Australia; Sara G. Castellanos, Rodrigo Garcia-Verdii,  and David Kaplan (2004) for Mexico; Sachiko Kuroda and  Isamu Yamamoto (2003a, b, c) and Takeshi Kimura and
Kazuo Ueda (2001) for Japan; Ernst Fehr and Lorenz Goette  (2003) for Switzerland; Thomas Bauer, Holger Bonin, and  Uwe Sunde (2003) and Christoph Knoppik and Thomas  Beissinger (2003) for Germany; Stephen Nickell and  Glenda Quintini (2001) for the United Kingdom; and Jonas
Agell and Per Lundborg (2003) for Sweden.  70 See, for example, Anthony P. O'Brien (1989) and  Christopher Hanes (2000).  71 See Janet L. Yellen and Akerlof (2006, 12).  72 There are other possible reasons for this failure of the
standard predictions from natural rate theory. Inflationary  expectations may not have been adaptive; the failure of  deflation to accelerate could be due to expectations that the  price level would return to some normal level. In the United
States, the National Recovery Act, which encouraged firms  to increase prices, and unionization, which gave a fillip to  wages, could also have affected the trade-off between in-  flation and unemployment. But since unemployment was so  very high for so very long, and since the absence of accel-  erating deflation was so universal across countries, this still
seems to be a dog that did not bark. It seems to point to a  problem with natural rate theory.  73 See Akerlof, Dickens, and Perry (1996, table 4).


### ---Economics-2007-0-22.txt---
direct evidence that such a norm exists and is
responsible for wage stickiness. His extensive
open-ended interviews sought to elicit why em-
ployers failed to cut money wages in the Con-
necticut recession of 1991-1992. Bewley
concludes that, even though substitute labor was
easily available, employers were reluctant to cut
wages because of the negative effects of such
cuts on morale. He says that managers were
afraid that cuts in money wages would cause
workers no longer to "identify" with their com-
panies.74 There might be no immediate conse-
quences during the recession. But employers
thought that such cuts would cause workers to
shirk after the recession had ended. They also
feared that their best workers would be more
likely to quit. These stories indicate that work-
ers are not thinking about their wages only in
real terms, relative to the price level or the
wages received by others. They also have a
special aversion to cuts in wages below their  current nominal levels.75
Norms about Wage Increases.-The motiva-
tion underlying resistance to money wage cuts
is so obvious, and the facts are so unexception-
able, that most macroeconomists accept the pos-
sibility that money wages are sticky. Even so,
they rarely appreciate the broader implications
of such violation of the assumptions of natural
rate theory. Their adjusted model is that price
and wage decisions are made only with real con-  siderations in mind, but desired wage changes
will be truncated insofar as they entail money
wage decreases. To my mind, such a view en-
tails a theoretical error. As we have seen, the
existence of money wage rigidity occurs be-
cause workers have a norm, which affects their
utility function, that their employers should not
make such cuts. The message of this finding is
that norms in the utility function yield at least
one clear violation of natural rate theory. That
suggests the further empirical possibility that
workers (and also employers and customers)
may also have other norms regarding what nom-
inal wages (and prices) should be. All such
violations are exceptions to natural rate theory,
and yield reasons for long-run trade-offs be-
tween inflation and unemployment.
Money wage rigidity is then potentially only
the tip of an iceberg. If there is one way in
which nominal wages enter utility functions,
because of employees' norms regarding what
their employers should or should not do, there
could also be many other ways.
There is another natural way whereby such
norms could enter utility functions: employees
may not only have a norm that they should not
take wage cuts. They may also have norms
regarding the nominal rate of increase of their
wages or salaries. For example, employees may
believe that their employer should give them a
nominal raise.
There is little research on the existence of
such norms. The two questionnaire studies that
have investigated it obtain strong and mutually
reinforcing results. Eldar Shafir, Peter Dia-
mond, and Tversky (1997) asked respondents to
comment on a vignette about two young women
who take their first jobs with the same initial
income. Specifically they asked respondents
who will be better off: Barbara, who receives a
5-percent raise in the presence of 4-percent in-
flation; or Ann, who receives a 2-percent raise
when inflation is zero; 79 percent of respon-
dents correctly said that Barbara would be
worse off than Ann economically. Nevertheless,
64 percent of respondents also said that Barbara
would be happier.76 Such responses are con-
trary to the natural rate hypothesis that em-
ployees only care about real returns. But an
easy explanation for this phenomenon occurs if  74 In more detail, Bewley (1999, 1-2) summarizes his  findings: "Other theories fail in part because they are based  on unrealistic psychological assumptions that people's abil-  ities do not depend on their state of mind and that they are  rational in the simplistic sense that they maximize a utility  that depends only on their consumption and working con-  ditions, not on the welfare of others. Wage rigidity is the  product of more complicated employee behavior, in the face  of which manager reluctance to cut pay is rational. Worker  behavior, however, is not always rational and completely  understandable. A model that captures the essence of wage  rigidity must take into account the capacity of employees to  identify with their firm and to internalize its objectives. This  internalization and workers' mood have a strong impact on
job performance and call for material, moral, and symbolic  reciprocation from company leadership."
75 Following the argument by Raj Chetty and Adam  Szeidl (2006), some employers may have been concerned  with the fact that their employees had fixed mortgages that  they would find difficult to pay with cuts in nominal wages.  This puts the violation of natural rate theory in another  place: why were these financial contracts in nominal rather  than in real terms?  76 Shafir, Diamond, and Tversky (1997, 351-52).


### ---Economics-2007-0-23.txt---
Barbara and Ann both think that their employer
should give them a nominal wage increase.
Another study, with a different form of ques-
tionnaire, independently found a similar re-
sponse. Robert Shiller found that 49 percent of
a sample of the general public either fully or
weakly agreed with the following statement: "If
my pay went up, I would feel more satisfaction
in my job, more sense of fulfillment, even if
prices went up as much." An additional 11
percent of the general public were undecided,
while only 27 percent completely disagreed. As
in the case of Ann and Barbara, such opinions
are consistent with the view that workers think
their employers should give them a nominal
wage increase: they will be disappointed when
it does not occur. Shiller's finding may be sim-
ilar to the public's view of Ann and Barbara.
But, as he reports, it is also in stark disagree-
ment with the view of professional economists
that underlies natural rate theory. Ninety per-
cent of economists weakly or strongly disagreed
with the statement; 77 percent were in complete
disagreement.77
Such norms-regarding the wage or salary in-
crease that employees think they should receive--
can be economically consequential. They cause
the long-run inflation-unemployment trade-off
to be downward sloping. With such a norm, at
higher levels of inflation workers will not expe-
rience disappointment from receiving lower
nominal wage increases than they think they
should receive; therefore, at higher inflation,
ceteris paribus, wage bargains will result in
lower real wages, which will reduce the relative
price that the firm wants to set, and therefore
raise the rate of sustainable employment. There
is a need for further research following Shafir,
Diamond, and Tversky and Shiller regarding
whether workers have norms regarding the nom-
inal wage increases they think they should receive.
High Inflation.-The opinions expressed re-
garding Barbara and Ann, and also the opinions
of Shiller's respondents, suggest that the long-
run trade-off between inflation and employment
is upward sloping. These answers were elicited
in the United States and thus are reflective of
respondents' views in an environment where
inflation has been low. But if inflation is very  high and therefore also very salient, the answers
to such questionnaires could be very different.
And they could impart a very different shape to
the trade-off between macroeconomic demand
and steady-state inflation.78 In such cases, peo-
ple may gain satisfaction only from wage and
salary increases that exceed inflation. Such
norms regarding how employers should behave
will then necessitate higher real wages (to main-
tain the same level of satisfaction) at higher
levels of inflation. The long-run inflation-
employment relation will then be downward
sloping. Such behavior gives a much stronger
rationale, even than current rational-expectations
credibility models (Barro and Gordon 1983; Ken-
neth Rogoff 1987), why central banks should
maintain price stability. Failure to appreciate this
realistic possibility again may be another case in
which the absence of norms from utility functions
has unduly blinkered macroeconomic thinking.79
77 Shiller (1997, 37).  78 Bankruptcy and financial considerations become es-
pecially important when inflation is very high. It is also  worth noting, at least parenthetically, that high levels of  bankruptcy at times of high inflation are themselves a symp-  tom of money illusion. Such bankruptcies reflect the non-  indexation of financial contracts.
79 In addition to the two questionnaire studies I have  mentioned, indexed contracts give another indicator for the  existence of nominal notions concerning what wage in-
creases should or should not be. Economists are often sur-
prised at the small fraction of union contracts that are
indexed at all. (Louis N. Christofides and Amy Chen Peng  2004, for example, analyzed a sample of almost 12,000
Canadian union contracts from 1976 to 2000. The mean
length of these contracts was slightly more than two years  (25 months). Only 19 percent of these contracts were in-  dexed.) But even when such indexation occurs, their form
violates the condition that they were struck with only real  considerations in mind. For an imperfect index such as the  CPI, which reflects both supply shocks and demand shocks,  the optimal COLA adjustment will be less than one, but it  will always be (almost) symmetric for positive and negative  deviations of inflation from a threshold. (See Jo Anna Gray  1978, Ronald G. Ehrenberg, Leif Danziger, and Gee San  1983, and David Card 1986 for the derivation of optimal  indexation.) But COLA adjustments are only positive. (Card  1986, S146, has expressed this in terms of a formula: w(t) =
w"(t) + max{0, a[p(t) - p1}, where w(t) is the nominal  wage, wn(t) is the nominal target, p(t) is the actual price  level, and p' is the threshold.) Thus, the form of the contract
violates optimality. In practice, this violation is also biting.  For example, in roughly one-third of a large Canadian  sample of indexed contracts, inflation was always below the  threshold (see Christofides and Peng 2004, 11, fn. 19). Thus,
the form of indexed contracts, when they exist, shows that  union wage negotiators think that COLA adjustments  should never be negative. The form of indexed contracts  gives another robust indicator that, indeed, wage setters


### ---Economics-2007-0-24.txt---
C. Prices
We have just seen that employees' norms
regarding nominal wages may affect bargained
real wages, and therefore cause trade-offs between
long-run inflation and long-run unemployment.
Similarly, customers' norms regarding price levels
and price changes may also cause long-run trade-
offs between output and inflation.
Indeed, models by Katsuhito Iwai (1981),
Julio J. Rotemberg (1982), and Andrew S. Cap-
lin and John Leahy (1991) all have long-run
trade-offs between inflation and unemployment.  Each of these models assumes that there are real
costs to nominal price changes. If, instead, there
were real costs to real price changes, the as-
sumptions of natural rate theory would still be
satisfied, and no such trade-off would occur.
These models then pose the question why there
should be such real costs from nominal price
changes. Iwai, Rotemberg, and Caplin and
Leahy all respectively assume that there is a
"menu" cost in making these changes known.80
But the physical costs of making such changes,
as in the printing of new menus, are trivially
small. Norms regarding price changes, how-
ever, give an alternative reason why these costs
might--indeed-be of sufficient size to induce
a significant long-run trade-off between infla-
tion and unemployment. Customers may think
that firms should not raise prices. In that case,
price increases (or increases of greater size) are
likely to induce angry customers to search for
alternative suppliers. At higher steady-state in-
flation, firms will be changing their nominal
prices more, and therefore will face more elastic
demands for their product. Producers' natural
microeconomic response to this increased elas-
ticity-a lower price for their product-will
produce a macroeconomic trade-off between in-
flation and aggregate demand.
Just as sticky money wages indicated that
employees have norms regarding wage change,
similarly, sticky prices indicate that customers
have norms regarding price change. Thus, the  extensive evidence on price stickiness reveals
violation of the assumptions of natural rate the-
ory, and also the existence of norms regarding
price change. Like wage changes, price changes
also agglomerate at zero. Dennis Carlton (1986)
has shown that prices are often sticky for sig-
nificant periods of time.81 Furthermore, prices
seem to be especially sticky in customer mar-
kets.82 Alan Kackmeister (2002) has compared
price changes at the end of the nineteenth cen-
tury to such changes a bit more than a century
later. Price changes of specific goods at retail
stores were recorded from June 1889 to Sep-
tember 1891; Kackmeister revisited the same
commodities and their price change for a com-
parable period, from June 1997 to September
1999. Price change in the late twentieth century
was five times more frequent than a century
earlier. Furthermore, in the nineteenth century,
the average spell of constant price for an indi-
vidual good was very long. It was approxi-
mately 80 months.83 Such constancy of prices
can easily be explained by customer norms re-
garding price change. The customers have a
notion of the price that they ought to pay at
stores where they are continued and knowing
customers. Kackmeister suggests that the de-
cline in long-term customer relationships is one
factor responsible for greater frequency of price
change today.
Emi Nakamura and J6n Steinsson (2005)
give an economic reason why customers would
have such a norm that firms should not change
prices. They view consumer purchases as habit-
forming. Thus, by buying a particular brand, or
patronizing a particular store, consumers are
putting themselves in a position where they can
be exploited. Their loyalty puts the firm in a
have notions regarding what nominal wage increases should  or should not be. This, of course, is just one of many
anomalies in the form of indexed contracts.
80oMarika Karanassou, Hector Sala, and Dennis J.  Snower (2003) find considerable long-run trade-off between  inflation and unemployment in a model with nominal price  staggering and money growth.  81 See also Blinder and Don Choi (1990) and Blinder et
al. (1998).  82 The meaning of customer markets was especially ex-
plored by Arthur Okun (1978).  83 derive this result from Kackmeister's data in the
following way. He finds that in the nineteenth century, only  5 percent of items changed their prices per month. This  means that the average spell of constant prices would have  been 20 months (the inverse). But that is a biased statistic
for the average length of time between price changes for an  item on the shelf. The difference between the average spell  of employment or unemployment and the average spell  being experienced by an individual suggests a rule of thumb  ratio for four to one. Using this ratio as a rule of thumb  suggests that the spell between price changes averaged over
the individual items on the shelf would be 80 months.


### ---Economics-2007-0-25.txt---
position where it can take advantage of the
consumer by raising prices. Firms then make an
implicit contract with their customers: they will
not change their prices unjustifiably. Since such
an implicit contract is easier to make (and en-
force) regarding nominal prices than real prices,
the implicit guarantee is in nominal terms. Na-
kamura and Steinsson have also discovered a
phenomenon that suggests strikingly that firms
do behave this way. Goods in store 126 (chosen
for its completeness of data) of Dominicks Finer
Foods chain frequently go on sale; when the
sale ends, their nominal price returns to the
exact same level. Such behavior is consistent
with the view that consumers think that prices
should not change (for whatever reason); and
that they are also likely to retaliate (change
brands) when prices do change.
I should also remark that in countries where
inflation is very high, customers will expect
price changes to occur frequently, and possibly
be of large magnitude. The inhibitions against
price changes when inflation is low are eroded
at high inflation. Thus, while norms concerning
prices give a negative long-run trade-off be-
tween inflation and unemployment at low infla-
tion, at high inflation that trade-off could very
well be reversed.
D. Summary
To summarize, there is considerable evidence
of violation of the assumptions and predictions
of natural rate theory. Wages and prices are
nominally rigid; there were no deflationary spi-
rals in the Great Depression; and questionnaire
respondents act as if they have a positive like for
nominal wage increases.84 This evidence sug-
gests that wage earners and customers have
views on what wages and prices should be. The
reflection of such views in utility functions pro-
duces trade-offs between inflation and unem-
ployment. Those trade-offs have significant
implications for economic policy. On the one
hand, central banks should avoid very low tar-
gets for inflation. On the other hand, they should
avoid high inflation, where the trade-offs be-
tween inflation and unemployment may be  reversed.  VIII. Rational Expectations Theory
Our discussion of rational expectations pig-
gybacks on our previous discussion of the nat-  ural rate.
According to rational expectations theory, in-
sofar as the central bank changes the money
supply systematically in response to employ-
ment conditions, the public will foresee that
response and change prices and wages exactly
to compensate. The public's anticipation will
then exactly offset the response. Monetary pol-
icy is neutral.85
There are two key assumptions underlying
this neutrality. The obvious one is rational ex-
pectations. To some, rational expectations re-
garding the effects of the money supply on
prices and wages would seem to be beyond the
sophistication of most wage and price takers,
and also of most wage and price setters.
Even in the case where all those involved in
buying and selling goods and labor services
have rational expectations, however, the neu-
trality results of rational expectations theory
require also that nominal considerations do not
enter into the setting of either wages or prices.
The previous descriptions of the ways in which
nominal wages and prices enter into preference
functions, via employees' views of the wages
that ought to be received and consumers' views
of the prices that ought to be paid, give further
reason why the neutrality results of rational
expectations will be violated. If prices and
wages are affected by people's notions of what
their nominal values should be, monetary policy
can be effective in stabilizing output-and pos-
sibly in raising its long-run level-even in the
presence of rational expectations.
IX. Economic Methodology
We have seen that the absence of norms plays
a key role in each of the five neutralities. Why
have economists made such systematic omis-
sions? The omission of norms from macroeco-
nomics, as well as from economics more
84 Also, COLA clauses are asymmetrically positive. See
footnote 79 above.  85 Empirically there is a theoretical puzzle of excess  sensitivity to monetary shocks (Lawrence J. Christiano,  Martin Eichenbaum, and Charles L. Evans 1998). Christina
and David Romer (1989) have shown that such a response  occurs with lags that would be surprisingly long if expected  monetary shocks were always neutralized.


### ---Economics-2007-0-26.txt---
generally, can be explained by economists' ad-
herence to positive economics.86 Friedman's
(1953) essay on positive economics describes
the methodological implications of such belief.
In particular, he says that economic theorists
should strive for parsimonious modeling. Ac-
cording to Friedman, they should even forsake
realistic assumptions in pursuit of such parsi-
mony. Maximization models with only objec-
tive arguments of utility have been defined as
more parsimonious than models where people,
additionally, lose utility insofar as they, or oth-
ers, fail to live up to their standards. As a result,
whatever the empirical validity or relevance of
such norms, positive economics has a method-
ological bias against their consideration. It priv-
ileges models without norms.
The prescriptions of positive economics re-
garding the conduct of empirical investigation
compound the bias against norms. Friedman
says that economists should not pay heed to the
stated intentions of decision makers, which
would include their norms as to how they and
others should behave. Instead, empirical work
should test only hypotheses that economists
consider to be based on parsimonious models.
If economic tests had great power, then it
would be easy, of course, to follow Friedman's
dictum of making more and more refined tests
of hypotheses with decreasing parsimony. If
norms really do affect behavior, this method
would reject models without norms and in due
course would arrive at models where people's
views regarding how they should behave affect
decision making. But economic tests lack
power. All economic models are very imprecise
in their specification of the independent vari-
able, the nature of the dependent variables, the
nature of leads and lags, and the nature of
residuals. Yet worse, most economic problems
involve simultaneity (as in supply and demand),
making establishment of causality difficult. In
almost any instance, such a large number of
models can be fitted statistically that it is ex-
tremely hard-and perhaps impossible-to sta-
tistically reject all the variants of models
without norms. As a result, the program of
positive economics-with its initial nulls of  models based only on utility with objective
variables verified only by statistical hypothesis
testing-has severe bias against explanations of
economic phenomena where norms play a role.
Summers (1986) illustrates the severity of
this bias. The conventional test of the efficient
markets hypothesis-that stock prices are the
expected value of future returns-looks for au-
tocorrelations of the excess returns on stocks
relative to bonds. Following Summers, it would
take approximately 5,000 years of data with
such a test to obtain as much as 50 percent
rejection of an alternative model where stock
prices are more than 30 percent away from their
fundamentals 35 percent of the time. With such
lack of power, nulls are important. When they
are not rejected, alternative theories, such as
those with norms, are not even considered. This
lecture has illustrated such reversion to norm-
less nulls. Consumption behavior, investment
behavior, and wage and price behavior-the three
most important components of most macro mod-
els-all display excess sensitivity relative to re-
spective neutralities. All of these violations could
be easily explained by norms. Yet in each case
economists have sought to explain such viola-
tions of classical theory by norm-less models.
In contrast to reliance on statistical testing,
disciplines other than economics typically put
much greater weight on a naturalistic ap-
proach. This approach involves detailed case
studies. Such observation of the small often
has been the key to the understanding of the
large. To me, the most dramatic example of
such a relation between the small and the
large occurs in the structure of life itself.
Francis Crick and James D. Watson87 conjec-
tured correctly that if they could describe the
crystalline structure of a single DNA mole-
cule, they would have unlocked the secret of
life. The duality between the structure of the
DNA molecule and the way in which organ-
isms are generated and reproduced is one of
the most beautiful findings of human knowl-
edge. It indicates the sense in which Crick and
Watson were, indeed, profoundly correct.
What are the implications for social science?
Positive economics, with its emphasis on statis-
tical analysis of populations, would suggest that
86 Some of the thoughts and wording in this section have  been presented in Akerlof (2005).  87 As dramatically described by Watson (1969).


### ---Economics-2007-0-27.txt---
the intensive study of a single molecule would
be an all-but-worthless anecdote. In the case of
DNA, we know that the exact opposite is true:
because DNA is a template that determines all
of the cells of the organism, and also its repro-
duction, one molecule may not tell all, but it
does tell a great deal. Form follows function.
Is there some reason to believe that economic
behavior and economic units are any different?
Economic decisions may not be as duplicable as
biological processes, but the basic reason why
science intensively studies the microscopic ap-
plies to economics as well. The individual eco-
nomic unit, be it a firm, a consumer, or an
employee, behaves the way it doesfor a reason.
And if these actors behave as they do for a
reason, we can expect to find those reasons from
the structures that we see in close observation;
and because of those structures their behavior
will also tend to be duplicated. This duality
between duplicability and structure explains
why much of science concerns very close ob-
servation, as it also explains why the study of
even a single part of a single DNA molecule
will be revealing.
Standard economic methodology says that
it is impossible to infer motivation of individ-
ual actors from intensive case studies. An-
thropologists and sociologists listen carefully
to individuals in such studies. When people
follow the norms, they use them to explain
their actions; when, on the other hand, they
violate the norms, they become the subject of
local gossip. Those case studies are revealing
because-like a language, which dictates how
one should speak-the norms are common
knowledge. In this lecture, we have seen one
prominent example of the use of such knowl-
edge: Bewley's interviews uncovered the
common understanding of the norms regard-
ing wage cuts among Connecticut employers
in the early 1990s.
Summary. -Positive economics systemati-
cally denies that norms can be understood from
intensive case study. Precedence given to mod-
els without norms because they are by definition
more parsimonious and statistical tests of low
power then jointly create a firewall against con-
sideration that norms play a role in determining
behavior. For these reasons, current economic
methodology inherently has created a biased  economics. In contrast, a more naturalistic ap-
proach would prescribe a different methodol-
ogy. In this case, economists would observe
decision makers as closely as possible, with the
express intent of characterizing their motiva-
tion, and would use such characterization as the
basis for modeling of economic structure. In-
deed, sociological and anthropological ethnog-
raphers do precisely that: they depict their
subjects' motivation from close observation.
X. Endogeneity of Norms
It is now time to discuss the endogeneity of
the norms. There is a special reason for its
consideration. Robert Lucas discovered that,
with endogenous rational expectations re-
garding inflation, monetary policy that was
intended to stabilize the macroeconomy
would, instead, be exactly neutral. Similarly,
is it not possible that endogeneity of the
norms, like Lucas's endogeneity of inflation-
ary expectations, will cause the neutralities
again to hold? We shall discuss this question
regarding all five neutralities. For the most
part, we find that the type of government
interventions being considered are usually of
such frequency, or of such order of magni-
tude, that they should provoke relatively little
change in the norms. Endogeneity of the
norms should have little effect, then, on our
previous conclusions.
A. Ricardian Equivalence
Let's begin by returning to Ricardian equiv-
alence, which is still the simplest case. We
found that if people have a norm regarding the
amount of their bequest, then lump-sum trans-
fers to an older generation will not be neutral.
There remains the possibility that the source of
the warm glow to the older generation is not the
total bequest, but instead the bequest to the
younger generation net of the transfer. In this
case, if the transfers change, then the norm
changes. Ricardian equivalence will again be
valid. While such changes in norms with the
size of transfers are a theoretical possibility,
they also seem highly unlikely. The size of the
transfers involved--especially for those rich
enough to make large nonaccidental bequests-
would seem to be too small to warrant such a


### ---Economics-2007-0-28.txt---
sophisticated calculation. Our earlier discussion
did discuss at least one change in the norms
regarding bequests, but that resulted from a very
large change in people's orientation. It resulted
from changes in their conception of the family--
of their own place within it and of the place of
their heirs. That also occurred over a very long
run-over the course of centuries.
B. Life-Cycle Hypothesis
Regarding the life-cycle hypothesis, we ar-
gued that consumption depends upon current
income because norms regarding how much
people think they should spend are linked to
it. But such a norm Wyould be highly unlikely
to change as a result'of the use of fiscal and
monetary policy for stabilization. In the first
place, such stabilization will make the adher-
ence to the norm less costly, not more costly,
in purely economic terms. Furthermore, mac-
roeconomic sources are responsible for only a
small fraction of the variation in individual
incomes. As a result, there is further reason
why the role of current income in norms is
unlikely to change as a result of macroeco-
nomic stabilization.
C. Cash Flow and Investment
The rise of the CFO suggests that norms
regarding investment have changed in large US
firms. Quite possibly, this change occurred be-
cause firms realized the need for financial con-
trols that compared the returns on inside and
outside options. Such an endogenous response
would make Modigliani-Miller correct. But,
following Zorn (2004), this change took 40
years. In the meantime, in the short run, follow-
ing our earlier logic, investments would have
depended on cash flow. And, of course, even in
the long run the CFO, who is only one voice
among many in corporate decisions, may not be
fully effective.
D. Natural Rate Hypothesis and the Role of
Rational Expectations
Regarding the natural rate hypothesis and
also the rational expectations hypothesis, we
saw that they will no longer hold if norms of
price and wage setting have nominal compo-
nents. Regarding prices and wages, the most  powerful evidence in favor of norms comes
from employees' resistance to money wage
cuts and customers' resistance to nominal
price increases. As long as inflation is low, it
is doubtful that small changes in inflation will
affect such norms. People seem to find it
easier to think in nominal, rather than in real,
terms. Indeed the facilitation of such thinking
is one of the benefits of money according to
the textbook mantra on its three uses: for
transactions, as a store of value, and as a unit
of account. Money is useful as a unit of
account especially if people think in nominal,
rather than in real, terms. As a result, as long
as inflation is low, people are unlikely to
forsake making calculations in nominal terms,
especially regarding the norms of what wages
or prices should be. Of course, if inflation
increases to high levels, the norms for wages
and prices and the method of calculating
those norms will change. Exactly how they
change-with the possibility that they under-
adjust to increases in inflation when it is low
and overadjust when it is high-should be
empirically investigated.
E. Where Do the Norms Come From?
We do not know the general answer to the
question where norms come from. This lecture
has tried to make the case that norms, such as
they are, could potentially play an important
role in macroeconomics. Hopefully, then, it has
added to the motivation for research on their
microfoundations.88
XI. Conclusion
This lecture has shown that the early Keyne-
sians got a great deal of the working of the
economic system right, in ways that are denied
by the five neutralities. As quoted from Keynes
earlier, they based their models on "our knowl-
edge of human nature and from the detailed
facts of experience." They used their intuitions
regarding the norms of how consumers, inves-
tors, and wage and price setters thought they
88 This lecture has been very much influenced by the
insights of the Ph.D. thesis of Robert Akerlof (2006) on  preferences for beliefs. His thinking on this subject has  influenced many of the sections of this paper, especially on  consumption and the endogeneity of norms.


### ---Economics-2007-0-29.txt---
should behave. There is systematic reason why
such knowledge and experience are likely to be
accurate: by their nature, norms are generated
and known by a whole community. They are
known to those who abide by them, and those
who observe them as well.
We have shown ways in which macroeconomic
variables will be affected by norms. The neutral-
ities say that consumption should have no special
dependence on current income; investment should
be independent of current cash flow; wages and
prices should not depend on nominal consider-
ations. The very construction of those neutralities
denies the possibility that peoples' decisions
might be influenced by their views regarding how
they, and how others, should behave. In practice,
however, the neutralities are systematically vio-
lated. Insofar as economists have felt it necessary
to explain these violations, they have appealed to
a variety of different frictions, such as myopia and
credit constraint. In so doing, they have failed to  consider that those violations would occur even in
the absence of those frictions: they will occur
because of decision makers' norms.
The incorporation of norms based on careful
observation imparts an appropriate balance to
macroeconomics. The New Classical research
program was correct in viewing models of the
early Keynesians as too primitive. They had not
been sufficiently attentive to the role of human
intent in choices regarding consumption, invest-
ment, wages, and prices. But that research pro-
gram itself has failed to appreciate the extent to
which the Keynesians' views of macroeconom-
ics were also reflective of reality, since they
were based on experience and observation.
A macroeconomics with norms in decision
makers' objective functions combines the best
features of the two approaches. It allows for
observations regarding how people think they
should behave. It also takes due account of the
purposefulness of human decisions.