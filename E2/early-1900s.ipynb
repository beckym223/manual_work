{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4141397846.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    words =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = \n",
    "\n",
    "counter=Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(counter.items())\n",
    "d = {}\n",
    "for word in df.loc[df[1]>1,0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m d2 \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 20\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mword\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m         d2[word] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "all_words2 = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    page = int(pagetxt[:-4])\n",
    "    year = int(year)\n",
    "    if year<1904 and year>1900 or (year==1900 and page>13):\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        words = re.findall(\"([A-Za-z]*ll[A-Za-z]*)\",text)\n",
    "        all_words2.extend([w.lower() for w in words])\n",
    "counter2=Counter(all_words2)\n",
    "df2 = pd.DataFrame(counter2.items())\n",
    "d2 = {}\n",
    "for word in df2[0]:\n",
    "    i = input(f\"{word}: \")\n",
    "    if len(i)>0:\n",
    "        d2[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         words \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m,text)\n\u001b[1;32m     17\u001b[0m         all_words\u001b[38;5;241m.\u001b[39mextend([w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words])\n\u001b[0;32m---> 19\u001b[0m all_counter\u001b[38;5;241m=\u001b[39m\u001b[43mCounter\u001b[49m(all_words)\n\u001b[1;32m     20\u001b[0m some_counter \u001b[38;5;241m=\u001b[39m Counter(words_1900s)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(\"[A-Za-z]*ll[A-Za-z]*|[A-Za-z]*cl[A-Za-z]*\",text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>clergylnen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>otlle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>lllln</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>preparillg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>sllrely</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>college</td>\n",
       "      <td>37</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>38</td>\n",
       "      <td>0.011370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>alld</td>\n",
       "      <td>47</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>129</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2\n",
       "1206  clergylnen    1  0.000299\n",
       "1598       otlle    1  0.000299\n",
       "1599       lllln    1  0.000299\n",
       "1600  preparillg    1  0.000299\n",
       "1601     sllrely    1  0.000299\n",
       "...          ...  ...       ...\n",
       "1074     college   37  0.011071\n",
       "7           well   38  0.011370\n",
       "151         alld   47  0.014063\n",
       "6           will   57  0.017056\n",
       "0            all  129  0.038600\n",
       "\n",
       "[2413 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = pd.DataFrame(all_counter.items())\n",
    "ac[2] = ac[1].apply(lambda x: x/sum(ac[1]))\n",
    "\n",
    "sc = pd.DataFrame(some_counter.items())\n",
    "\n",
    "sc[2] = sc[1].apply(lambda x: x/sum(sc[1]))\n",
    "# sc.sort_values(1)\n",
    "sc.sort_values(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [('n', 'll'),\n",
    "         ('u', 'll'),\n",
    "         ('h', 'll'),\n",
    "         ('n', 'il'),\n",
    "         ('u','il'),\n",
    "         ('h', 'il'),\n",
    "         ('m', 'nl'),\n",
    "         ('m', 'ln'),\n",
    "         ('d', 'cl'),\n",
    "         ('w', 'vv'),\n",
    "         ('m','lll'),\n",
    "         ('n','rl'),\n",
    "         ('u','tl'),\n",
    "         ('n','tl'),\n",
    "         ]\n",
    "         \n",
    "\n",
    "pattern = \"|\".join([f\"[A-Za-z]*{char[1]}[A-Za-z]*\" for char in set(chars) ])\n",
    "\n",
    "import re\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = []\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = re.findall(pattern,text)\n",
    "        words_1900s.extend([w.lower() for w in words])\n",
    "    else:\n",
    "        words = re.findall(r\"\\w+\",text)\n",
    "        all_words.extend([w.lower() for w in words])\n",
    "\n",
    "all_counter=Counter(all_words)\n",
    "some_counter = Counter(words_1900s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n",
    "\n",
    "#df = new_melt.merge(ac,left_on='new_word',right_on = 'corpus_word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>old_count</th>\n",
       "      <th>full_transformation</th>\n",
       "      <th>end_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>differellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sellse</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dyllamic</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dissellt</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>dissent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>collsistently</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n</td>\n",
       "      <td>consistently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75233</th>\n",
       "      <td>acllievelllellts</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>achievements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76742</th>\n",
       "      <td>colilnlissioll</td>\n",
       "      <td>1</td>\n",
       "      <td>_il-&gt;n_ln-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100186</th>\n",
       "      <td>ullclerstalldillg</td>\n",
       "      <td>1</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n_ll-&gt;n_cl-&gt;d</td>\n",
       "      <td>understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77036</th>\n",
       "      <td>lltllllall</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_ll-&gt;h_ll-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168328</th>\n",
       "      <td>ftltlclalnelltal</td>\n",
       "      <td>1</td>\n",
       "      <td>_tl-&gt;u_cl-&gt;d_ln-&gt;m_ll-&gt;n_tl-&gt;n</td>\n",
       "      <td>fundamental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  og_word old_count             full_transformation  \\\n",
       "3              differellt         1                          _ll->n   \n",
       "4                  sellse         1                          _ll->n   \n",
       "9                dyllamic         1                          _ll->n   \n",
       "15               dissellt         1                          _ll->n   \n",
       "16          collsistently         1                          _ll->n   \n",
       "...                   ...       ...                             ...   \n",
       "75233    acllievelllellts         1        _ll->h_ll->n_ll->n_nl->m   \n",
       "76742      colilnlissioll         1        _il->n_ln->m_ll->n_nl->m   \n",
       "100186  ullclerstalldillg         1        _ll->n_ll->n_ll->n_cl->d   \n",
       "77036          lltllllall         1  _tl->u_ll->h_ll->n_ll->n_nl->m   \n",
       "168328   ftltlclalnelltal         1  _tl->u_cl->d_ln->m_ll->n_tl->n   \n",
       "\n",
       "             end_word  \n",
       "3           different  \n",
       "4               sense  \n",
       "9             dynamic  \n",
       "15            dissent  \n",
       "16       consistently  \n",
       "...               ...  \n",
       "75233    achievements  \n",
       "76742      commission  \n",
       "100186  understanding  \n",
       "77036           human  \n",
       "168328    fundamental  \n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_word</th>\n",
       "      <th>transformations</th>\n",
       "      <th>duplicate_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>lllally</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>nlany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>goverlllnellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>governlnent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ecollolllics</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>econonlics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>developlllellt</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>developnlent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>departlllellts</td>\n",
       "      <td>_ll-&gt;n_ll-&gt;n</td>\n",
       "      <td>departnlents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78140</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;h_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>hmmderless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78180</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_rl-&gt;n_ll-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78386</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_rl-&gt;n_nl-&gt;m_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78797</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_rl-&gt;n_ll-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88577</th>\n",
       "      <td>llllllllderless</td>\n",
       "      <td>_ll-&gt;n_nl-&gt;m_ll-&gt;n_rl-&gt;n_nl-&gt;m</td>\n",
       "      <td>mmlldeness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               og_word                 transformations  duplicate_of\n",
       "460            lllally                    _ll->n_ll->n         nlany\n",
       "466      goverlllnellt                    _ll->n_ll->n   governlnent\n",
       "570       ecollolllics                    _ll->n_ll->n    econonlics\n",
       "575     developlllellt                    _ll->n_ll->n  developnlent\n",
       "729     departlllellts                    _ll->n_ll->n  departnlents\n",
       "...                ...                             ...           ...\n",
       "78140  llllllllderless  _ll->h_ll->n_nl->m_ll->n_nl->m    hmmderless\n",
       "78180  llllllllderless  _rl->n_ll->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78386  llllllllderless  _ll->n_rl->n_nl->m_ll->n_nl->m    mmlldeness\n",
       "78797  llllllllderless  _ll->n_nl->m_rl->n_ll->n_nl->m    mmlldeness\n",
       "88577  llllllllderless  _ll->n_nl->m_ll->n_rl->n_nl->m    mmlldeness\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_reached_elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found: 3028\n",
      "Total found: 0\n",
      "Iteration: 0\n",
      "Total not found: 2163\n",
      "Total found: 875\n",
      "Iteration: 1\n",
      "Total not found: 1067\n",
      "Total found: 1150\n",
      "Iteration: 2\n",
      "Total not found: 379\n",
      "Total found: 1193\n",
      "Iteration: 3\n",
      "Total not found: 107\n",
      "Total found: 1198\n",
      "Iteration: 4\n",
      "Total not found: 20\n",
      "Total found: 1200\n",
      "Iteration: 5\n",
      "Total not found: 3\n",
      "Total found: 1200\n",
      "Iteration: 6\n",
      "Total not found: 2\n",
      "Total found: 1200\n",
      "Iteration: 7\n",
      "Total not found: 1\n",
      "Total found: 1200\n",
      "Iteration: 8\n",
      "None left\n",
      "hi-(0)->man|hi-(0)->man\n",
      "hi-(0)->man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Transformation('hi','man','0'), Transformation('hi','man','0')]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Type\n",
    "from collections.abc import MutableSequence\n",
    "import numpy as np\n",
    "sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development\"\n",
    "known_words = exists.split(\"_\")+list(ac['corpus_word'])\n",
    "\n",
    "not_found_cols = ['og_word','old_count','prev_steps','current_word']\n",
    "found_cols = ['og_word','old_count','full_transformation','end_word']\n",
    "\n",
    "not_found = sc.loc[sc['og_word'].isin(known_words)==False].copy()\n",
    "not_found['current_word'] = not_found['og_word']\n",
    "not_found['prev_steps'] = ''\n",
    "\n",
    "step_reached_elsewhere = pd.DataFrame(columns = ['og_word','transformations','duplicate_of'])\n",
    "\n",
    "iterations = 0\n",
    "intermediate_steps = []\n",
    "\n",
    "found = pd.DataFrame(columns = found_cols)\n",
    "\n",
    "either_or = []\n",
    "\n",
    "print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "print(f\"Total found: {len(found)}\")\n",
    "already_made = set()\n",
    "\n",
    "while len(not_found)>0 and iterations<10:\n",
    "    print(f\"Iteration: {iterations}\")\n",
    "    for i,(b,a) in enumerate(chars):\n",
    "        col = f\"{a}->{b}\"\n",
    "        not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "    intermediate_steps.append(not_found)\n",
    "\n",
    "    new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "    if len(new_melt)==0:\n",
    "        print(\"None left\")\n",
    "        break\n",
    "    new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "    new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "    new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "    new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "    already_made.update(new_melt['current_word'])\n",
    "    newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "    found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "    \n",
    "    reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "    step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "    new_melt['current_word'] = new_melt['new_word']\n",
    "    not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Total not found: {not_found['og_word'].nunique()}\")\n",
    "    print(f\"Total found: {len(found)}\")\n",
    "    iterations+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.loc[ac['corp_count']==1,'corpus_word'].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FinishedState():\n",
    "#     all_intermediate: dict[str,str] = {}\n",
    "#     def __init__(self, start,end, transformations,intermediates):\n",
    "#         self.og:str = start\n",
    "#         self.end:str = end\n",
    "#         self.transformations: TransList = transformations\n",
    "\n",
    "#     def update_intermediate(self):\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable,Set,Dict\n",
    "class Transformation(object):\n",
    "    NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def is_null(self)->bool:\n",
    "        return self.old==self.new\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "    \n",
    "    def check_transform(self,s:str)->str|None:\n",
    "        i = self.start_idx\n",
    "        if not self.old in s[i:]:\n",
    "            return None\n",
    "        return self.transform(s)\n",
    "\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return Transformation(self.old,self.new,self.start_idx)\n",
    "    \n",
    "    def __repr__(self)->str:\n",
    "        return f\"Transformation('{self.old}','{self.new}','{self.start_idx}')\"\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return f\"{self.old}-({self.start_idx})->{self.new}\"\n",
    "\n",
    "class TransList(list[Transformation]):\n",
    "    \n",
    "    def __str__(self)->str:\n",
    "        return \"|\".join([str(s) for s in self])\n",
    "NULL_TRANS:Transformation = Transformation(\"\",\"\") #type:ignore\n",
    "\n",
    "class Transformation(object):\n",
    "    @classmethod\n",
    "    def from_str(cls,str):\n",
    "        try:\n",
    "            old,_,num,new = re.search(r\"\\[(\\w+)\\]-(\\((\\d+)\\))?->\\[(\\w+)\\]\",\"[hi]-(0)->[there]\").groups() #type:ignore\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Make sure string is in the pattern '[old]-(index[optional])->[new]'\")\n",
    "        return Transformation(old,new,str(num))\n",
    "class Transformation(object):\n",
    "    def __init__(self,old:str,new:str,start_idx=0):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def transform(self,s:str)->str:\n",
    "        i = self.start_idx\n",
    "        return s[:i] +s[i:].replace(self.old,self.new,1)\n",
    "\n",
    "    def change_start_idx(self,idx,inplace=False):\n",
    "        if inplace:\n",
    "            self.start_idx = i \n",
    "            return self\n",
    "        else:\n",
    "            return Transformation(self.old,self.new,idx)\n",
    "\n",
    "    \n",
    "\n",
    "class StrNode(object):\n",
    "    known_words:Set[str] = set()\n",
    "    known_transformations: dict[str,str] = {} #will be the og words that got transformed\n",
    "    @classmethod\n",
    "    def update_known_words(cls,words: Iterable[str]):\n",
    "        cls.known_words.update(words)\n",
    "\n",
    "    @classmethod\n",
    "    def from_parent(cls,parent,transformation:Transformation,check_if_finished=True): #type:ignore\n",
    "        parent_s = parent.current\n",
    "        new_str = transformation.transform(parent_s)\n",
    "        finished=False\n",
    "        if check_if_finished:\n",
    "            finished = new_str in StrNode.known_words\n",
    "        return StrNode(parent.og,new_str,parent,transformation,finished)\n",
    "\n",
    "\n",
    "    def __init__(self,start_str:str,current:str|None=None, parent= None,parent_trans:Transformation|None = None,finished=False):\n",
    "        self.og = start_str\n",
    "        self.children:list[StrNode]=[]\n",
    "        self.parent:Optional[StrNode] = parent\n",
    "        self.parent_trans:Transformation=parent_trans or Transformation(\"\",\"\")\n",
    "        self.current:str = current if current is not None else start_str\n",
    "        self.leaf:bool = finished\n",
    "        self.next:Optional[StrNode] = None\n",
    "\n",
    "    def is_root(self)->bool:\n",
    "        return self.parent is None\n",
    "\n",
    "\n",
    "    def make_children(self,t:Transformation)->list[StrNode]|StrNode #type:ignore\n",
    "        current = self.current\n",
    "        child_list:list[StrNode] = []\n",
    "\n",
    "        for i in range(len(current)):\n",
    "            new_t = t.change_start_idx(i)\n",
    "            n = StrNode.from_parent(self,new_t)\n",
    "            if n.current==current: #means no change\n",
    "                continue\n",
    "\n",
    "            if n.is_leaf():\n",
    "                print(f\"Found ending state from {self.og} to {n.current}\")\n",
    "                return n\n",
    "            if n.current in StrNode.known_transformations:\n",
    "                end_str = StrNode.known_transformations[n.current]\n",
    "                print(f\"Made known transformation from {self.og} to {n.current} to {end_str}\")\n",
    "                return StrNode(self.og,n.current,n,Transformation(n.current,end_str))\n",
    "            \n",
    "\n",
    "            child_list.append(n)\n",
    "        self.children.extend(child_list)\n",
    "\n",
    "        print(f\"Adding {len(child_list)} to children and returning new ones\")\n",
    "        return child_list\n",
    "    \n",
    "    def reset_orig_string(self):\n",
    "        self.og = self.current\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def is_leaf(self)->bool:\n",
    "        return self.leaf\n",
    "\n",
    "def get_previous_strings(finished_node:StrNode)->list[str]:\n",
    "    if not finished_node.is_leaf():\n",
    "        raise ValueError(\"we need to make sure the node is a final one\")\n",
    "    node = finished_node\n",
    "    strings = [node.current]\n",
    "    while node.parent is not None:\n",
    "        strings.append(node.current)\n",
    "        node = node.parent\n",
    "    return strings\n",
    "\n",
    "def iterate_through_changes(known_words:list[str],\n",
    "                            unknown_words:list[str],\n",
    "                            char_changes:list[tuple[str,str]],max_iterations=5):\n",
    "    \n",
    "\n",
    "    unfinished_nodes: dict[str,set[StrNode]] = {uk:set([StrNode(uk,uk,None,None,False)]) for uk in unknown_words}\n",
    "    known_mapping:dict[str,str] = {}\n",
    "    StrNode.known_words = set(known_words)\n",
    "    StrNode.known_transformations = known_mapping\n",
    "    iteration=0\n",
    "    any_change= True\n",
    "    while iteration<max_iterations and len(unknown_words)>0 and any_change:\n",
    "        iteration+=1\n",
    "        any_change = False\n",
    "        for new,old in char_changes:\n",
    "            t = Transformation(old,new)\n",
    "            for og_word,node_set in unfinished_nodes.items():\n",
    "                if og_word in known_mapping:\n",
    "                    unfinished_nodes.pop(og_word)\n",
    "                    continue\n",
    "                for node in node_set:\n",
    "                    node_str = node.current\n",
    "                    found_result = known_mapping.get(node_str)\n",
    "                    if found_result is not None:\n",
    "                        known_mapping[og_word] = found_result\n",
    "                        unfinished_nodes.pop(og_word)\n",
    "                        break\n",
    "                    children = node.make_children(t)\n",
    "                    if len(children)>0:\n",
    "                        any_change = True\n",
    "                    if isinstance(children,StrNode): #means they got finished state\n",
    "                        final:StrNode = children\n",
    "                        final_str:str = children.current\n",
    "                        known_mapping[og_word] = final_str\n",
    "                        known_mapping.update({intermediate:final_str for intermediate in get_previous_strings(final)})\n",
    "                        break\n",
    "                    else:\n",
    "                        unfinished_nodes[og_word].update(node.children)\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "            col = f\"{a}->{b}\"\n",
    "            not_found[col] = not_found['current_word'].apply(lambda x: x.replace(a,b,1) if a in x else pd.NA)\n",
    "        intermediate_steps.append(not_found)\n",
    "\n",
    "        new_melt = not_found.melt(id_vars=['og_word','old_count','prev_steps','current_word'],var_name='transformation',value_name='new_word').dropna(subset='new_word')\n",
    "        if len(new_melt)==0:\n",
    "            print(\"None left\")\n",
    "            break\n",
    "        new_melt['prev_steps'] = new_melt[['prev_steps','transformation']].apply(\"_\".join,axis=1)\n",
    "        new_melt['in_other'] = new_melt['new_word'].isin(known_words)\n",
    "        new_melt['any_found'] = new_melt.groupby('current_word')['in_other'].transform('any')\n",
    "        new_melt['step_reached'] = new_melt['new_word'].isin(already_made)\n",
    "        already_made.update(new_melt['current_word'])\n",
    "        newly_found = new_melt.rename(columns={'prev_steps':'full_transformation','new_word':'end_word'}).loc[new_melt['in_other'],found_cols]\n",
    "        found = pd.concat([found,newly_found]).drop_duplicates(['og_word','end_word'])\n",
    "        \n",
    "        reached_step  =new_melt.loc[new_melt['step_reached'],['og_word','prev_steps','new_word']].rename(columns = {'prev_steps':'transformations','new_word':'duplicate_of'})\n",
    "        step_reached_elsewhere = pd.concat([step_reached_elsewhere,reached_step])\n",
    "\n",
    "\n",
    "        new_melt['current_word'] = new_melt['new_word']\n",
    "        not_found = new_melt.loc[(new_melt[['any_found','step_reached']].any(axis=1)==False),not_found_cols].reset_index(drop=True).copy()\n",
    "\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/BeckyMarcusMacbook/Thesis/manual_work/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Set, Optional\n",
    "from collections import deque,defaultdict\n",
    "\n",
    "\n",
    "class Transformation:\n",
    "    def __init__(self, old: str, new: str):\n",
    "        self.old = old\n",
    "        self.new = new\n",
    "\n",
    "    def apply(self, s: str, start_idx: int) -> Optional[str]:\n",
    "        \"\"\"Applies the transformation at the given index.\"\"\"\n",
    "        if s[start_idx:].startswith(self.old):\n",
    "            return s[:start_idx] + self.new + s[start_idx + len(self.old):]\n",
    "        return None\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, known_words: Set[str]):\n",
    "        self.known_words = known_words\n",
    "        self.visited: Dict[str, str] = {}  # Tracks visited states and their closest known word.\n",
    "        self.paths: Dict[str, List[str]] = {}  # Stores paths from any word to its known word.\n",
    "\n",
    "\n",
    "    def is_known(self, word: str) -> bool:\n",
    "        \"\"\"Checks if the word is known.\"\"\"\n",
    "        return word in self.known_words\n",
    "\n",
    "    def any_previous_path_to_known(self,node:'Node')->bool:\n",
    "        path = node.get_path()\n",
    "        any_path = self.paths.keys()\n",
    "        try:\n",
    "            for p in path[1:]:\n",
    "                if p in any_path:\n",
    "                    return True\n",
    "            return False\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "    def mark_visited(self, word: str, path: List[str],real_word:bool) -> bool:\n",
    "        \"\"\"\n",
    "        Marks a word as visited.\n",
    "        If the word is already visited, returns False.\n",
    "        Otherwise, updates the path to the known word and returns True.\n",
    "        \"\"\"\n",
    "        if word in self.visited and not real_word:\n",
    "            return False\n",
    "        \n",
    "        self.visited[word] = path[-1]  # Store the last word in the path as the connection.\n",
    "        if real_word:\n",
    "            self.paths[word] = path\n",
    "        return True\n",
    "\n",
    "    def get_path_to_known(self, word: str) -> Optional[List[str]]:\n",
    "        \"\"\"Retrieves the path from the word to the known word, if available.\"\"\"\n",
    "        return self.paths.get(word)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, word: str, parent: Optional[\"Node\"], root_word:str, transformation: Optional[Transformation]):\n",
    "        self.word = word\n",
    "        self.parent = parent\n",
    "        self.root_word=root_word\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def get_path(self) -> List[str]:\n",
    "        \"\"\"Retrieves the transformation path from the root to this node.\"\"\"\n",
    "        path = []\n",
    "        node = self\n",
    "        while node:\n",
    "            path.append(node.word)\n",
    "            node = node.parent\n",
    "        return path[::-1]  # Reverse to get root-to-leaf order\n",
    "\n",
    "\n",
    "def iterate_through_changes(\n",
    "    known_words: set[str],\n",
    "    unknown_words: List[str],\n",
    "    char_changes: List[Tuple[str, str]],\n",
    "    max_iterations: int = 5): #-> Dict[str, List[str]]:\n",
    "    known_set = set(known_words)\n",
    "    graph = Graph(known_set)\n",
    "    results: Dict[str, List[str]] = {}\n",
    "    #connected_to_known:defaultdict[str,bool] =defaultdict(bool)\n",
    "\n",
    "    # Initialize the queue with all unknown words\n",
    "    queue = deque([Node(word, None, word,None) for word in unknown_words])\n",
    "    for word in unknown_words:\n",
    "        graph.mark_visited(word, [word],False)\n",
    "\n",
    "    for word in known_words:\n",
    "        graph.mark_visited(word,[word],True)\n",
    "\n",
    "    iteration = 0\n",
    "    while queue and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        next_iter_queue = deque()\n",
    "        print(f\"Iteration{iteration}: Queue of {len(queue)}\")\n",
    "        for old, new in char_changes:\n",
    "            transformation = Transformation(old, new)\n",
    "            next_char_queue = deque()\n",
    "            \n",
    "            while queue:\n",
    "                node = queue.popleft()\n",
    "                current_word = node.word\n",
    "                root = node.root_word\n",
    "                if graph.get_path_to_known(current_word) is not None or graph.get_path_to_known(root) is not None:\n",
    "                    continue\n",
    "\n",
    "                # Try applying the transformation at every valid index\n",
    "                for i in range(len(current_word) - len(old) + 1):\n",
    "                    new_word = transformation.apply(current_word, i)\n",
    "                    if zipf_frequency(new_word)>\n",
    "                    #print(\"Found new word:\", new_word)\n",
    "\n",
    "                    # If the new word is already connected to a known word\n",
    "                    if new_word in graph.visited:\n",
    "                        path_to_known = graph.get_path_to_known(new_word)\n",
    "                        if path_to_known:\n",
    "                            #print(f\"wow found a path from {current_word} to {new_word}\")\n",
    "                            node_path = node.get_path()\n",
    "                            full_path = node_path + path_to_known\n",
    "                            results[node_path[0]] = node.get_path() + path_to_known\n",
    "                            for i,step in enumerate(full_path):\n",
    "                                graph.paths[step] = full_path[i:]\n",
    "                            continue\n",
    "                    else:\n",
    "                        graph.mark_visited(new_word, node.get_path() + [new_word],False)\n",
    "                    next_iter_queue.append(node)\n",
    "                    next_iter_queue.append(Node(new_word, node, root, transformation))\n",
    "                next_char_queue.append(node)\n",
    "\n",
    "                    # Otherwise, mark it visited and enqueue for further exploration\n",
    "            queue = next_char_queue\n",
    "                #if graph.mark_visited(new_word, node.get_path() + [new_word]):\n",
    "        queue.clear()\n",
    "        print(f\"Queued for next iteration: {len(next_iter_queue)}\")\n",
    "        while next_iter_queue:\n",
    "\n",
    "            node = next_iter_queue.popleft()\n",
    "            if graph.any_previous_path_to_known(node):\n",
    "                continue\n",
    "            queue.append(node)\n",
    "        print(f\"After culling: \",len(queue))\n",
    "\n",
    "\n",
    "    # For any unknown word that has no transformation path, set an empty path\n",
    "    for word in unknown_words:\n",
    "        if word not in results:\n",
    "            results[word] = []\n",
    "\n",
    "    return results,graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'doing']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"hello I hope you're doing well\"\n",
    "p = r\"\\b\\w{5,}\\b(?=.*ll)\"\n",
    "re.findall(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known: 235940\n",
      "Prelim unknown: 2720\n",
      "Filtered: 2664\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import wordfreq #type:ignore\n",
    "from collections import Counter\n",
    "corrections:dict[str,str] = json.load(open('corrections.json'))\n",
    "level_2_chars = [\n",
    "    ('i','l'),\n",
    "    ('c','e'),\n",
    "    ('e','c'),\n",
    "    ('l','t'),\n",
    "    ('t','l'),\n",
    "    ('ttl','m'),\n",
    "    ('v','y'),\n",
    "    ('lil','m')\n",
    "    \n",
    "]\n",
    "MASTER_CHARS = [\n",
    "    #no mess ups probably\n",
    "    (\"vv\", \"w\"),\n",
    "    (\"cl\", \"d\"),\n",
    "\n",
    "\n",
    "    (\"lll\", \"m\"),\n",
    "    ('lil','m'),\n",
    "    (\"nl\", \"m\"),\n",
    "    (\"ln\", \"m\"),\n",
    "\n",
    "    (\"il\", \"h\"),\n",
    "    (\"ll\", \"h\"),\n",
    "\n",
    "\n",
    "    (\"ll\", \"n\"),\n",
    "    (\"rl\", \"n\"),\n",
    "    (\"il\", \"n\"),\n",
    "    (\"tl\", \"n\"),\n",
    "    \n",
    "    # ('lz','h'),\n",
    "    # ('lz','n'),\n",
    "\n",
    "    # ('la', 'n'),\n",
    "    # ('la', 'h'),\n",
    "\n",
    "     (\"tl\", \"u\"),\n",
    "    (\"il\", \"u\"),\n",
    "     (\"ll\", \"u\"),\n",
    "    #(r\"s\\b\",\"\"), # ones like these will remove any case of a pattern\n",
    "]\n",
    "\n",
    "pattern = \"|\".join([fr\"\\b[A-Za-z]*{char[0]}[A-Za-z]*\\b\" for char in set(MASTER_CHARS)])\n",
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "\n",
    "\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "words_1900s = set()\n",
    "all_words:list[str] = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    path = os.path.join(folder, file)\n",
    "    text=  open(path).read()\n",
    "    if year<1904 and year>=1900:\n",
    "        words = [w for w in re.findall(pattern,text) if len(w)>4]\n",
    "        words_1900s.update([w.lower() for w in words])\n",
    "\n",
    "\n",
    "# all_counter=Counter(all_words)\n",
    "# some_counter = Counter(words_1900s)\n",
    "# sc = pd.DataFrame(some_counter.items(),columns=['og_word','old_count'])\n",
    "# ac = pd.DataFrame(all_counter.items(),columns= ['corpus_word','corp_count'])\n",
    "\n",
    "exists = \"outlined_rightly_dynamic_fullest_material_dissent_consistently_domination_development_hospital_sometimes_healing_should_universities_undertake_departments_evolution\"\n",
    "false_positives = [\"xvhich\"] \n",
    "prelim_known:set[str] = set([*exists.split(\"_\"), *corrections.values(),*word_list]).difference(false_positives)\n",
    "print(f\"Known: {len(prelim_known)}\")\n",
    "\n",
    "prelim_unknown = set(words_1900s).difference(prelim_known)\n",
    "print(f\"Prelim unknown: {len(prelim_unknown)}\")\n",
    "import math\n",
    "def unknown_enough(word)->bool:\n",
    "    return zipf_frequency(word,'en')<math.e and len(word)<20\n",
    "    return \n",
    "UNKNOWN_WORDS = set([word for word in prelim_unknown if unknown_enough(word)])\n",
    "print(\"Filtered:\",len(UNKNOWN_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package wordfreq:\n",
      "\n",
      "NAME\n",
      "    wordfreq\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    chinese\n",
      "    language_info\n",
      "    mecab\n",
      "    numbers\n",
      "    preprocess\n",
      "    tokens\n",
      "    transliterate\n",
      "    util\n",
      "\n",
      "FUNCTIONS\n",
      "    available_languages(wordlist: 'str' = 'best') -> 'dict[str, str]'\n",
      "        Given a wordlist name, return a dictionary of language codes to filenames,\n",
      "        representing all the languages in which that wordlist is available.\n",
      "\n",
      "    cB_to_freq(cB: 'int') -> 'float'\n",
      "        Convert a word frequency from the logarithmic centibel scale that we use\n",
      "        internally, to a proportion from 0 to 1.\n",
      "\n",
      "        On this scale, 0 cB represents the maximum possible frequency of\n",
      "        1.0. -100 cB represents a word that happens 1 in 10 times,\n",
      "        -200 cB represents something that happens 1 in 100 times, and so on.\n",
      "\n",
      "        In general, x cB represents a frequency of 10 ** (x/100).\n",
      "\n",
      "    cB_to_zipf(cB: 'int') -> 'float'\n",
      "        Convert a word frequency from centibels to the Zipf scale\n",
      "        (see `zipf_to_freq`).\n",
      "\n",
      "        The Zipf scale is related to centibels, the logarithmic unit that wordfreq\n",
      "        uses internally, because the Zipf unit is simply the bel, with a different\n",
      "        zero point. To convert centibels to Zipf, add 900 and divide by 100.\n",
      "\n",
      "    freq_to_zipf(freq: 'float') -> 'float'\n",
      "        Convert a word frequency from a proportion between 0 and 1 to the\n",
      "        Zipf scale (see `zipf_to_freq`).\n",
      "\n",
      "    get_frequency_dict(lang: 'str', wordlist: 'str' = 'best', match_cutoff: 'None' = None) -> 'dict[str, float]'\n",
      "        Get a word frequency list as a dictionary, mapping tokens to\n",
      "        frequencies as floating-point probabilities.\n",
      "\n",
      "    get_frequency_list(lang: 'str', wordlist: 'str' = 'best', match_cutoff: 'None' = None) -> 'list[list[str]]'\n",
      "        Read the raw data from a wordlist file, returning it as a list of\n",
      "        lists. (See `read_cBpack` for what this represents.)\n",
      "\n",
      "        Because we use the `langcodes` module, we can handle slight\n",
      "        variations in language codes. For example, looking for 'pt-BR',\n",
      "        'pt_br', or even 'PT_BR' will get you the 'pt' (Portuguese) list.\n",
      "        Looking up the alternate code 'por' will also get the same list.\n",
      "\n",
      "    iter_wordlist(lang: 'str', wordlist: 'str' = 'best') -> 'Iterator[str]'\n",
      "        Yield the words in a wordlist in approximate descending order of\n",
      "        frequency.\n",
      "\n",
      "        Because wordfreq rounds off its frequencies, the words will form 'bands'\n",
      "        with the same rounded frequency, appearing in alphabetical order within\n",
      "        each band.\n",
      "\n",
      "    random_ascii_words(lang: 'str' = 'en', wordlist: 'str' = 'best', nwords: 'int' = 5, bits_per_word: 'int' = 12) -> 'str'\n",
      "        Returns a string of random, space separated, ASCII words.\n",
      "\n",
      "        These words are of the given language and from the given wordlist.\n",
      "        There will be `nwords` words in the string.\n",
      "\n",
      "        `bits_per_word` determines the amount of entropy provided by each word;\n",
      "        when it's higher, this function will choose from a larger list of\n",
      "        words, some of which are more rare.\n",
      "\n",
      "    random_words(lang: 'str' = 'en', wordlist: 'str' = 'best', nwords: 'int' = 5, bits_per_word: 'int' = 12, ascii_only: 'bool' = False) -> 'str'\n",
      "        Returns a string of random, space separated words.\n",
      "\n",
      "        These words are of the given language and from the given wordlist.\n",
      "        There will be `nwords` words in the string.\n",
      "\n",
      "        `bits_per_word` determines the amount of entropy provided by each word;\n",
      "        when it's higher, this function will choose from a larger list of\n",
      "        words, some of which are more rare.\n",
      "\n",
      "        You can restrict the selection of words to those written in ASCII\n",
      "        characters by setting `ascii_only` to True.\n",
      "\n",
      "    read_cBpack(filename: 'str') -> 'list[list[str]]'\n",
      "        Read a file from an idiosyncratic format that we use for storing\n",
      "        approximate word frequencies, called \"cBpack\".\n",
      "\n",
      "        The cBpack format is as follows:\n",
      "\n",
      "        - The file on disk is a gzipped file in msgpack format, which decodes to a\n",
      "          list whose first element is a header, and whose remaining elements are\n",
      "          lists of words.\n",
      "\n",
      "        - The header is a dictionary with 'format' and 'version' keys that make\n",
      "          sure that we're reading the right thing.\n",
      "\n",
      "        - Each inner list of words corresponds to a particular word frequency,\n",
      "          rounded to the nearest centibel -- that is, one tenth of a decibel, or\n",
      "          a factor of 10 ** .01.\n",
      "\n",
      "          0 cB represents a word that occurs with probability 1, so it is the only\n",
      "          word in the data (this of course doesn't happen). -200 cB represents a\n",
      "          word that occurs once per 100 tokens, -300 cB represents a word that\n",
      "          occurs once per 1000 tokens, and so on.\n",
      "\n",
      "        - The index of each list within the overall list (without the header) is\n",
      "          the negative of its frequency in centibels.\n",
      "\n",
      "        - Each inner list is sorted in alphabetical order.\n",
      "\n",
      "        As an example, consider a corpus consisting only of the words \"red fish\n",
      "        blue fish\". The word \"fish\" occurs as 50% of tokens (-30 cB), while \"red\"\n",
      "        and \"blue\" occur as 25% of tokens (-60 cB). The cBpack file of their word\n",
      "        frequencies would decode to this:\n",
      "\n",
      "            [\n",
      "                {'format': 'cB', 'version': 1},\n",
      "                [], [], [], ...    # 30 empty lists\n",
      "                ['fish'],\n",
      "                [], [], [], ...    # 29 more empty lists\n",
      "                ['blue', 'red']\n",
      "            ]\n",
      "\n",
      "    top_n_list(lang: 'str', n: 'int', wordlist: 'str' = 'best', ascii_only: 'bool' = False) -> 'list[str]'\n",
      "        Return a frequency list of length `n` in descending order of frequency.\n",
      "        This list contains words from `wordlist`, of the given language.\n",
      "        If `ascii_only`, then only ascii words are considered.\n",
      "\n",
      "        The frequency list will not contain multi-digit sequences, because we\n",
      "        estimate the frequencies of those using the functions in `numbers.py`,\n",
      "        not using a wordlist that contains all of them.\n",
      "\n",
      "    word_frequency(word: 'str', lang: 'str', wordlist: 'str' = 'best', minimum: 'float' = 0.0) -> 'float'\n",
      "        Get the frequency of `word` in the language with code `lang`, from the\n",
      "        specified `wordlist`.\n",
      "\n",
      "        These wordlists can be specified:\n",
      "\n",
      "        - 'large': a wordlist built from at least 5 sources, containing word\n",
      "          frequencies of 10^-8 and higher\n",
      "        - 'small': a wordlist built from at least 3 sources, containing word\n",
      "          frquencies of 10^-6 and higher\n",
      "        - 'best': uses 'large' if available, and 'small' otherwise\n",
      "\n",
      "        The value returned will always be at least as large as `minimum`.\n",
      "        You could set this value to 10^-8, for example, to return 10^-8 for\n",
      "        unknown words in the 'large' list instead of 0, avoiding a discontinuity.\n",
      "\n",
      "    zipf_frequency(word: 'str', lang: 'str', wordlist: 'str' = 'best', minimum: 'float' = 0.0) -> 'float'\n",
      "        Get the frequency of `word`, in the language with code `lang`, on the Zipf\n",
      "        scale.\n",
      "\n",
      "        The Zipf scale is a logarithmic frequency scale proposed by Marc Brysbaert,\n",
      "        who compiled the SUBTLEX data. The goal of the Zipf scale is to map\n",
      "        reasonable word frequencies to understandable, small positive numbers.\n",
      "\n",
      "        A word rates as x on the Zipf scale when it occurs 10**x times per billion\n",
      "        words. For example, a word that occurs once per million words is at 3.0 on\n",
      "        the Zipf scale.\n",
      "\n",
      "        Zipf values for reasonable words are between 0 and 8. The value this\n",
      "        function returns will always be at last as large as `minimum`, even for a\n",
      "        word that never appears. The default minimum is 0, representing words\n",
      "        that appear once per billion words or less.\n",
      "\n",
      "        wordfreq internally quantizes its frequencies to centibels, which are\n",
      "        1/100 of a Zipf unit. The output of `zipf_frequency` will be rounded to\n",
      "        the nearest hundredth to match this quantization.\n",
      "\n",
      "    zipf_to_freq(zipf: 'float') -> 'float'\n",
      "        Convert a word frequency from the Zipf scale to a proportion between 0 and\n",
      "        1.\n",
      "\n",
      "        The Zipf scale is a logarithmic frequency scale proposed by Marc Brysbaert,\n",
      "        who compiled the SUBTLEX data. The goal of the Zipf scale is to map\n",
      "        reasonable word frequencies to understandable, small positive numbers.\n",
      "\n",
      "        A word rates as x on the Zipf scale when it occurs 10**x times per billion\n",
      "        words. For example, a word that occurs once per million words is at 3.0 on\n",
      "        the Zipf scale.\n",
      "\n",
      "DATA\n",
      "    CACHE_SIZE = 100000\n",
      "    DATA_PATH = PosixPath('/opt/miniconda3/envs/thesis_env/lib/python3.12/...\n",
      "    INFERRED_SPACE_FACTOR = 10.0\n",
      "    Iterator = typing.Iterator\n",
      "        A generic version of collections.abc.Iterator.\n",
      "\n",
      "    __annotations__ = {'_wf_cache': 'dict[tuple[str, str, str, float], flo...\n",
      "    logger = <Logger wordfreq (WARNING)>\n",
      "\n",
      "FILE\n",
      "    /opt/miniconda3/envs/thesis_env/lib/python3.12/site-packages/wordfreq/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wordfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "NOTICE_LEVEL = 25\n",
    "logging.addLevelName(NOTICE_LEVEL, \"NOTICE\")\n",
    "\n",
    "# Create a custom logger class\n",
    "class MyLogger(logging.Logger):\n",
    "    def notice(self, message, *args, **kwargs):\n",
    "        if self.isEnabledFor(NOTICE_LEVEL):\n",
    "            self._log(NOTICE_LEVEL, message, args, **kwargs)\n",
    "\n",
    "# Set the custom logger as the default logger class\n",
    "logging.setLoggerClass(MyLogger)\n",
    "\n",
    "# Create the logger instance once\n",
    "logger:MyLogger = logging.getLogger(__name__) #type:ignore\n",
    "logger.setLevel(logging.INFO)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "# Stream handler for NOTICE and above (console)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(NOTICE_LEVEL)\n",
    "stream_format = logging.Formatter('%(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(stream_format)\n",
    "\n",
    "# File handler for INFO and above (temp file)\n",
    "temp_log_file = \"E2/last_run.log\"\n",
    "if not os.path.exists(temp_log_file):\n",
    "    with open(temp_log_file,'w') as f:\n",
    "        f.write('')\n",
    "file_handler = logging.FileHandler(temp_log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_log_file = \"E2/graph_runs.log\"\n",
    "temp_log_file = \"E2/last_run.log\"\n",
    "if not os.path.exists(main_log_file):\n",
    "    with open(main_log_file,'w') as f:\n",
    "        f.write(\"\")\n",
    "if not os.path.exists(temp_log_file):\n",
    "    with open(temp_log_file,'w') as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "def prepend_logs_to_file(main_log_file:str,temp_log_file:str):\n",
    "    with open(temp_log_file, 'r') as temp_file:\n",
    "        temp_logs = temp_file.readlines()\n",
    "    \n",
    "    with open(main_log_file, 'r') as main_file:\n",
    "        main_logs = main_file.readlines()\n",
    "\n",
    "    with open(main_log_file, 'w') as main_file:\n",
    "        main_file.writelines(temp_logs + main_logs)  # Prepend temp logs to existing logs\n",
    "\n",
    "def log_reset(temp_log_file:str=temp_log_file,notes:str =\"\",overwrite:bool=True):\n",
    "    if overwrite:\n",
    "        print(\"Overwriting\")\n",
    "    with open(temp_log_file,'w' if overwrite else 'a') as f:\n",
    "        f.write(\"\")\n",
    "    logger.notice(\"LOGGER RESET - %s\",notes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: No change on the chars\n",
      "10\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "For next iteration: 12\n",
      "10\n",
      "10\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "For next iteration: 17\n",
      "15\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "For next iteration: 48\n",
      "46\n",
      "41\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "For next iteration: 92\n"
     ]
    }
   ],
   "source": [
    "unknown_words = [*zip(range(10),[0]*10)]\n",
    "values=list(it.pairwise(range(10)))\n",
    "next_iter_queue = deque(unknown_words)\n",
    "next_char_queue = deque()\n",
    "start_unknown_ct = len(unknown_words)\n",
    "current_iter =0\n",
    "max_iteration=4\n",
    "while current_iter<max_iteration:\n",
    "    current_iter+=1\n",
    "    current_iter_queue = next_iter_queue+next_char_queue\n",
    "    if current_iter_queue==next_iter_queue:\n",
    "        print(\"Iteration %d: No change on the chars\" % current_iter)\n",
    "    next_iter_queue=deque()\n",
    "    next_char_queue = current_iter_queue\n",
    "    any_change = False\n",
    "    for add,mult in values:\n",
    "        current_char_queue=next_char_queue\n",
    "        next_char_queue = deque()\n",
    "        while current_char_queue:\n",
    "            \n",
    "            popped = current_char_queue.pop()\n",
    "            try:\n",
    "                node_word,iter = popped\n",
    "            except TypeError:\n",
    "                print(popped)\n",
    "                raise\n",
    "            if node_word ==add or iter==add: #means there's no opperation\n",
    "                #print(f\"Continuing: {popped} back in queue\")\n",
    "                next_char_queue.append(popped)\n",
    "                continue\n",
    "            new_word = (node_word+add)*mult\n",
    "            if (new_word % 3) == 0 and popped!=(7,0):\n",
    "                #success, means neither the old or new words are popped\n",
    "                #print(f\"Success, {popped} not put back in queue\")\n",
    "                any_change=True\n",
    "            else:\n",
    "                # print(f'{(new_word,current_iter)} in next iter')\n",
    "                # print(f'{popped} in next char')\n",
    "                next_iter_queue.append((new_word,current_iter))\n",
    "                next_char_queue.append(popped)\n",
    "        print(len(next_char_queue))\n",
    "    if not any_change:\n",
    "        print(\"No change in iteration: \",current_iter)\n",
    "    if not next_iter_queue:\n",
    "        print(\"Wow did we win\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"For next iteration: {len(next_iter_queue)}\")\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll\n"
     ]
    }
   ],
   "source": [
    "node_word = 'vvill'\n",
    "old='ll'\n",
    "def thing():\n",
    "    print(*x)\n",
    "\n",
    "for i in mit.locate(node_word,pred = lambda *x: mit.iequals(x,old),window_size=len(old)):\n",
    "    print(node_word[i:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals:set[str]=set()\n",
    "e=math.e\n",
    "results:dict[str,str] ={}\n",
    "from typing import Any,Hashable\n",
    "import networkx as nx\n",
    "from networkx import DiGraph\n",
    "import time\n",
    "import copy\n",
    "from datetime import timedelta\n",
    "import itertools as it\n",
    "import more_itertools as mit #type:ignore\n",
    "from typing import Any\n",
    "\n",
    "from collections import deque\n",
    "def apply_t(s,old,new,i)->str:\n",
    "    if i==-1:\n",
    "        return re.sub(old,new,s)\n",
    "    return s[:i] + new + s[i + len(old):] \n",
    "def iterate_word(G:DiGraph,\n",
    "                 current_iter:int,\n",
    "                 node_word:str,\n",
    "                 old:str,\n",
    "                 new:str,\n",
    "                 og:str,\n",
    "                 root_words:set,\n",
    "                 node_data:dict[str,Any],\n",
    "                 next_iter_queue:deque[Hashable],\n",
    "                 )->tuple[bool,bool]:\n",
    "    i=None\n",
    "    node_solved=False\n",
    "    for i in mit.locate(node_word,pred = lambda *x: mit.iequals(x,old),window_size=len(old)) if new!=\"\" else [-1]:\n",
    "        new_word:str|None = apply_t(node_word,old,new,i)\n",
    "        if not new_word in G:\n",
    "            zfreq:float = zipf_frequency(new_word,'en')\n",
    "            if zfreq>e:\n",
    "                logger.info(\"SUCCESS - Likely found a new word: %s with frequency %.2f\",new_word,zfreq)\n",
    "                G.add_node(new_word,root_unknown_words=root_words,final=new_word,root=og,originally_known=False,freq=zfreq,last_change=current_iter)\n",
    "                node_solved=True\n",
    "                logger.debug(\"Updating results for %d roots\")\n",
    "                results.update({root:new_word for root in root_words})\n",
    "\n",
    "            else:\n",
    "                logger.debug(\"Adding new word %s to graph and next next queue\",new_word)\n",
    "                G.add_node(new_word,root_unknown_words=root_words,final=None,root=og,originally_known=False,freq=zfreq,last_change=current_iter)\n",
    "                next_iter_queue.append(new_word)\n",
    "        else:\n",
    "            new_word_node = G.nodes[new_word]\n",
    "            new_word_roots:set = new_word_node['root_unknown_words'] #update so they share roots\n",
    "            root_words.update(new_word_roots)\n",
    "            final = new_word_node['final']\n",
    "           \n",
    "            if final is not None:\n",
    "                logger.info(\"SUCCESS - Created word %s from %s which connects to real word %s\",new_word, node_word,final )\n",
    "                node_data.update({'final':final})\n",
    "                results.update({root:final for root in root_words})\n",
    "                node_solved=True\n",
    "                new_word_roots.clear()\n",
    "                root_words.clear()\n",
    "            else:\n",
    "                assert new_word in next_iter_queue\n",
    "                logger.debug(\"%s in graph but not a final word, updating root words for next iteration\")\n",
    "                new_word_roots.update(root_words)\n",
    "        if not G.has_edge(node_word,new_word):\n",
    "            G.add_edge(node_word,new_word,old=old,new=new,idx=i)\n",
    "        if node_solved:\n",
    "            return True,True\n",
    "    return i is not None,False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "@dataclass(order=True)\n",
    "class Item:\n",
    "    priority: int\n",
    "    item: Any=field(compare=False)\n",
    "from queue import PriorityQueue\n",
    "pq = PriorityQueue()\n",
    "for i in range(10):\n",
    "    pq.put(Item(i%4,i))\n",
    "while not pq.empty():\n",
    "    print(pq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_success(G:nx.DiGraph,node_word:str):\n",
    "    data:dict = G.nodes[node_word]\n",
    "    og = data['root']\n",
    "    root_words:set[str] = data['root_unknown_words']\n",
    "    right_word = results.get(mit.first_true([og,*root_words],None,lambda x: results.get(x,False)))\n",
    "    if right_word is not None:\n",
    "        logger.info(\"One of %d root words has path to real world '%s', updating all\",len(root_words)+1,right_word)\n",
    "        results.update({**{word:right_word for word in root_words},og:right_word})\n",
    "        root_words.clear() \n",
    "        data.update({'final':right_word})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'how'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'how'"
     ]
    }
   ],
   "source": [
    "int(\"how\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTICE - LOGGER RESET - load results from json\n",
      "NOTICE - Starting Iteration 1\n",
      "NOTICE - Starting with 2664 in queue - 2664 nodes and 0 edges\n",
      "NOTICE - Iteration 1 END - Time: 0:00:00.375575 - Edges Added: 4902 - Nodes Added: 4845\n",
      "NOTICE - Leaves dead: 0\n",
      "NOTICE - 0 Result(s) Found in iteration\n",
      "NOTICE - 778 Result(s) Remaining\n",
      "NOTICE - Starting Iteration 2\n",
      "NOTICE - Starting with 8620 in queue - 7509 nodes and 4902 edges\n",
      "NOTICE - Iteration 2 END - Time: 0:00:02.043760 - Edges Added: 9678 - Nodes Added: 4714\n",
      "NOTICE - Leaves dead: 0\n",
      "NOTICE - 0 Result(s) Found in iteration\n",
      "NOTICE - 778 Result(s) Remaining\n",
      "NOTICE - Starting Iteration 3\n",
      "NOTICE - Starting with 19290 in queue - 12223 nodes and 14580 edges\n",
      "NOTICE - Iteration 3 END - Time: 0:00:05.705713 - Edges Added: 9967 - Nodes Added: 3184\n",
      "NOTICE - Leaves dead: 73980\n",
      "NOTICE - 0 Result(s) Found in iteration\n",
      "NOTICE - 778 Result(s) Remaining\n",
      "NOTICE - Ran 3 iterations over 0:00:08.179812 to get 1886 results out of 2664\n"
     ]
    }
   ],
   "source": [
    "unknown_words =UNKNOWN_WORDS\n",
    "chars:list[tuple[str,str]] = MASTER_CHARS\n",
    "default_max_iter=3\n",
    "note = input(\"Note for the run: \")\n",
    "try:\n",
    "    max_iteration = int(input(\"Max Iteration: \"))\n",
    "except ValueError:\n",
    "    logger.warning(\"Input unrecognized, defaulting to %d\",default_max_iter)\n",
    "    max_iteration = default_max_iter\n",
    "overwrite = re.search(r\"yY\", input(\"Do you want to overwrite the log file rather than appending to it? [y/n] \")) is not None\n",
    "\n",
    "log_reset(notes=note,overwrite=overwrite)\n",
    "logging.info(\"Initiating known words in graph\")\n",
    "\n",
    "G=DiGraph()\n",
    "results = dict(json.load(open('E2/results.json')))\n",
    "G.add_nodes_from(((word,\n",
    "                  dict(root=word,\n",
    "                       root_unknown_words=set([word]),\n",
    "                       final=None,\n",
    "                       last_change = 0,\n",
    "                       level=0,\n",
    "                       )\n",
    "                    )\n",
    "                    for word in unknown_words)\n",
    "                )\n",
    "# next_iter_pq:PriorityQueue[Item] = PriorityQueue()\n",
    "# for word in unknown_words:\n",
    "#     next_iter_pq.put(Item(0,word))\n",
    "run_start = time.monotonic()\n",
    "\n",
    "plurals.clear()\n",
    "made_change=True\n",
    "#results.clear()\n",
    "current_iter=0\n",
    "false_pos=['hong']\n",
    "logger.info(\"Max iteration: %d\",max_iteration)\n",
    "start_unknown_ct = len(unknown_words)\n",
    "next_iter_queue = deque(unknown_words)\n",
    "next_char_queue = deque()\n",
    "dead_leaves = set()\n",
    "    #next_char_pq:PriorityQueue[Item]= PriorityQueue()\n",
    "try:\n",
    "    while current_iter<max_iteration:\n",
    "        dead_leaves=0\n",
    "\n",
    "\n",
    "                \n",
    "        # Start iteration\n",
    "        current_iter_queue = next_iter_queue+next_char_queue\n",
    "        next_iter_pq=deque()\n",
    "        it_start_time = time.monotonic()\n",
    "        current_iter+=1\n",
    "        logger.notice(\"Starting Iteration %s\",current_iter)\n",
    "        n_nodes_start = G.number_of_nodes()\n",
    "        n_edges_start = G.number_of_edges()\n",
    "        results_start = len(results)\n",
    "        logger.notice(\"Starting with %d in queue - %d nodes and %d edges\",len(current_iter_queue),n_nodes_start,n_edges_start)\n",
    "        next_char_queue = current_iter_queue\n",
    "        for old,new in MASTER_CHARS:\n",
    "            ## Start Char\n",
    "            char_start = time.monotonic()\n",
    "            current_char_queue=next_char_queue\n",
    "            next_char_queue = deque()\n",
    "            old_tup = tuple(old)\n",
    "            logger.info(\"Replacing '%s' with '%s'\",old,new)\n",
    "            start_result = len(results)\n",
    "            start_nodes = G.number_of_nodes()\n",
    "            start_edges = G.number_of_edges()\n",
    "            #print(f\"In results: {len(results)} out of {len(unknown_words)}\")\n",
    "            time_start = time.time()\n",
    "            while current_char_queue:\n",
    "                ### Start Word\n",
    "                node_word = current_char_queue.pop()\n",
    "                node_solved=False\n",
    "                data:dict = G.nodes[node_word]\n",
    "                og = data['root']\n",
    "                logger.debug(\"Popping '%s' with root node %s\", node_word,og)\n",
    "                \n",
    "                root_words:set[str] = data['root_unknown_words']\n",
    "                right_word = results.get(mit.first_true([og,*root_words],None,lambda x: results.get(x,False)))\n",
    "                if right_word is not None:\n",
    "                    logger.info(\"On node '%s' - One of %d root words has path to real world '%s', updating all\",node_word,len(root_words),right_word)\n",
    "                    results.update({**{word:right_word for word in root_words}})\n",
    "                    root_words.clear() \n",
    "                    data.update({'final':right_word})\n",
    "                    continue\n",
    "                if data['last_change']<current_iter-1:\n",
    "                    #means it can't be chagned anymore\n",
    "                    logging.info(\"%s can't be changed further\")\n",
    "                    dead_leaves += 1\n",
    "                any_change, node_solved = iterate_word(G,current_iter,node_word,old,new,og,root_words,data,next_iter_queue)\n",
    "                \n",
    "                if node_solved:\n",
    "                    logger.debug(\"Continuing to next node word\")\n",
    "                    continue\n",
    "                if not any_change:\n",
    "                    logger.debug(\"'%s' not found in '%s', putting back in queue\",old,node_word)\n",
    "                else:\n",
    "                    logger.debug(\"No known word found for %s, putting back in queue\",node_word)\n",
    "                    data.update({'last_change':current_iter})\n",
    "\n",
    "                next_char_queue.append(node_word)\n",
    "                ### End word\n",
    "\n",
    "\n",
    "            char_elapsed = timedelta(seconds = time.monotonic()-char_start)\n",
    "            char_edge_diff= G.number_of_edges() - start_edges\n",
    "            char_node_diff = G.number_of_nodes() - start_nodes\n",
    "            logger.info(\"Iteration %d - '%s' to '%s' - Time: %s - Results Added: %d - Edges Added: %d - Nodes Added: %d\",\n",
    "                        current_iter,old,new,char_elapsed,len(results)-start_result,char_edge_diff,char_node_diff)\n",
    "            ## End char\n",
    "        it_elapsed= timedelta(seconds=time.monotonic() - it_start_time)\n",
    "        it_nodes =G.number_of_nodes() - n_nodes_start\n",
    "        it_edges = G.number_of_edges() -n_edges_start\n",
    "        logger.notice(\"Iteration %d END - Time: %s - Edges Added: %d - Nodes Added: %d\",\n",
    "                    current_iter,it_elapsed,it_edges,it_nodes)\n",
    "        logger.notice(\"Leaves dead: %d\",dead_leaves)\n",
    "        n_results = len(results)\n",
    "        logger.notice(\"%d Result(s) Found in iteration\", n_results-results_start)\n",
    "        logger.notice(\"%d Result(s) Remaining\",start_unknown_ct-n_results)\n",
    "\n",
    "        # End Iteration\n",
    "    if not made_change:\n",
    "        print(f\"No more changes made after iteration {current_iter}\")\n",
    "    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    reason = input(\"Reason for interrupting\")\n",
    "    logger.notice(\"Ending run: %s\",reason)\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.error(\"Error: %s\",e)\n",
    "    raise\n",
    "finally:\n",
    "    elapsed = timedelta(seconds=time.monotonic() - run_start)\n",
    "    still_out_there = [w for w in unknown_words if w not in results]\n",
    "\n",
    "    logger.notice(\"Ran %d iterations over %s to get %d results out of %d\",max_iteration,elapsed,len(results),start_unknown_ct )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vvith': 'with',\n",
       " 'vvill': 'will',\n",
       " 'follovving': 'following',\n",
       " 'hundrecls': 'hundreds',\n",
       " 'icleals': 'ideals',\n",
       " 'chilclren': 'children',\n",
       " 'icleas': 'ideas',\n",
       " 'clesired': 'desired',\n",
       " 'meclical': 'medical',\n",
       " 'eclucation': 'education',\n",
       " 'cecled': 'ceded',\n",
       " 'orcler': 'order',\n",
       " 'cleluded': 'deluded',\n",
       " 'unclertake': 'undertake',\n",
       " 'servitucle': 'servitude',\n",
       " 'indiviclually': 'individually',\n",
       " 'clegree': 'degree',\n",
       " 'stuclies': 'studies',\n",
       " 'cluring': 'during',\n",
       " 'clifficult': 'difficult',\n",
       " 'clishes': 'dishes',\n",
       " 'inclucles': 'includes',\n",
       " 'indiviclualism': 'individualism',\n",
       " 'stucly': 'study',\n",
       " 'boarcls': 'boards',\n",
       " 'cliscourages': 'discourages',\n",
       " 'cletain': 'detain',\n",
       " 'clivision': 'division',\n",
       " 'clivert': 'divert',\n",
       " 'everybocly': 'everybody',\n",
       " 'sicles': 'sides',\n",
       " 'clemand': 'demand',\n",
       " 'inclividualized': 'individualized',\n",
       " 'eclucated': 'educated',\n",
       " 'provicled': 'provided',\n",
       " 'climinished': 'diminished',\n",
       " 'aclded': 'added',\n",
       " 'bicls': 'bids',\n",
       " 'iclea': 'idea',\n",
       " 'renclered': 'rendered',\n",
       " 'clepartments': 'departments',\n",
       " 'clirected': 'directed',\n",
       " 'eviclence': 'evidence',\n",
       " 'aclvantage': 'advantage',\n",
       " 'neecled': 'needed',\n",
       " 'wicle': 'wide',\n",
       " 'clistress': 'distress',\n",
       " 'clesire': 'desire',\n",
       " 'moclern': 'modern',\n",
       " 'eviclent': 'evident',\n",
       " 'conclition': 'condition',\n",
       " 'clebate': 'debate',\n",
       " 'inclirectly': 'indirectly',\n",
       " 'icleal': 'ideal',\n",
       " 'eviclently': 'evidently',\n",
       " 'leacling': 'leading',\n",
       " 'clirectly': 'directly',\n",
       " 'procluction': 'production',\n",
       " 'clirection': 'direction',\n",
       " 'clesirable': 'desirable',\n",
       " 'aclams': 'adams',\n",
       " 'meclicine': 'medicine',\n",
       " 'outsicle': 'outside',\n",
       " 'moclels': 'models',\n",
       " 'clifference': 'difference',\n",
       " 'clevise': 'devise',\n",
       " 'clanger': 'danger',\n",
       " 'clisregard': 'disregard',\n",
       " 'clistrict': 'district',\n",
       " 'clevelopment': 'development',\n",
       " 'aclapt': 'adapt',\n",
       " 'consiclers': 'considers',\n",
       " 'cleveloped': 'developed',\n",
       " 'provicle': 'provide',\n",
       " 'aclam': 'adam',\n",
       " 'tracle': 'trade',\n",
       " 'aclapted': 'adapted',\n",
       " 'gracle': 'grade',\n",
       " 'knowleclge': 'knowledge',\n",
       " 'attenclance': 'attendance',\n",
       " 'aclvocacy': 'advocacy',\n",
       " 'aclequate': 'adequate',\n",
       " 'lonclon': 'london',\n",
       " 'cloing': 'doing',\n",
       " 'clozen': 'dozen',\n",
       " 'clestinies': 'destinies',\n",
       " 'clrafted': 'drafted',\n",
       " 'cliscover': 'discover',\n",
       " 'provicling': 'providing',\n",
       " 'canclid': 'candid',\n",
       " 'aucliting': 'auditing',\n",
       " 'conclitions': 'conditions',\n",
       " 'presiclent': 'president',\n",
       " 'stuclent': 'student',\n",
       " 'towarcls': 'towards',\n",
       " 'aclvantages': 'advantages',\n",
       " 'worcls': 'words',\n",
       " 'inclustrial': 'industrial',\n",
       " 'bocly': 'body',\n",
       " 'cloes': 'does',\n",
       " 'cleeper': 'deeper',\n",
       " 'sicle': 'side',\n",
       " 'clirect': 'direct',\n",
       " 'aclvance': 'advance',\n",
       " 'juclge': 'judge',\n",
       " 'philaclelphia': 'philadelphia',\n",
       " 'methocls': 'methods',\n",
       " 'uncler': 'under',\n",
       " 'clelicate': 'delicate',\n",
       " 'cleclare': 'declare',\n",
       " 'remincled': 'reminded',\n",
       " 'alreacly': 'already',\n",
       " 'cluty': 'duty',\n",
       " 'sturcly': 'sturdy',\n",
       " 'clifferent': 'different',\n",
       " 'clate': 'date',\n",
       " 'toclay': 'today',\n",
       " 'neecls': 'needs',\n",
       " 'aicls': 'aids',\n",
       " 'tracles': 'trades',\n",
       " 'attitucle': 'attitude',\n",
       " 'corresponclence': 'correspondence',\n",
       " 'clemocracy': 'democracy',\n",
       " 'inclelllent': 'inclement',\n",
       " 'illlmediately': 'immediately',\n",
       " 'tillle': 'time',\n",
       " 'jallles': 'james',\n",
       " 'elllploy': 'employ',\n",
       " 'colllplex': 'complex',\n",
       " 'perforlll': 'perform',\n",
       " 'illlportant': 'important',\n",
       " 'edlllund': 'edmund',\n",
       " 'colllfortable': 'comfortable',\n",
       " 'attelllpt': 'attempt',\n",
       " 'lllan': 'man',\n",
       " 'dellland': 'demand',\n",
       " 'lilllits': 'limits',\n",
       " 'collles': 'comes',\n",
       " 'seellls': 'seems',\n",
       " 'ralll': 'ram',\n",
       " 'lllysteries': 'mysteries',\n",
       " 'lllel': 'mel',\n",
       " 'outcollle': 'outcome',\n",
       " 'meantillle': 'meantime',\n",
       " 'lllode': 'mode',\n",
       " 'lllunicipal': 'municipal',\n",
       " 'sometillles': 'sometimes',\n",
       " 'criticislll': 'criticism',\n",
       " 'collle': 'come',\n",
       " 'governlllent': 'government',\n",
       " 'arllled': 'armed',\n",
       " 'forllled': 'formed',\n",
       " 'lllatter': 'matter',\n",
       " 'melllbers': 'members',\n",
       " 'reforlller': 'reformer',\n",
       " 'perlllit': 'permit',\n",
       " 'intilllately': 'intimately',\n",
       " 'favoritislll': 'favoritism',\n",
       " 'enorlllous': 'enormous',\n",
       " 'lelll': 'lem',\n",
       " 'colllpromise': 'compromise',\n",
       " 'lllean': 'mean',\n",
       " 'silllply': 'simply',\n",
       " 'lllotto': 'motto',\n",
       " 'colllpleted': 'completed',\n",
       " 'lilllited': 'limited',\n",
       " 'aillls': 'aims',\n",
       " 'colll': 'com',\n",
       " 'llleaning': 'meaning',\n",
       " 'farlller': 'farmer',\n",
       " 'colllplexity': 'complexity',\n",
       " 'lllethods': 'methods',\n",
       " 'silllilarly': 'similarly',\n",
       " 'dynalllic': 'dynamic',\n",
       " 'clailll': 'claim',\n",
       " 'lllerely': 'merely',\n",
       " 'lllakes': 'makes',\n",
       " 'assulllption': 'assumption',\n",
       " 'firlll': 'firm',\n",
       " 'lilllit': 'limit',\n",
       " 'llliss': 'miss',\n",
       " 'lllass': 'mass',\n",
       " 'llloreover': 'moreover',\n",
       " 'adlllinistration': 'administration',\n",
       " 'fallliliar': 'familiar',\n",
       " 'lllaking': 'making',\n",
       " 'agreelllents': 'agreements',\n",
       " 'illlperative': 'imperative',\n",
       " 'econollly': 'economy',\n",
       " 'lllodern': 'modern',\n",
       " 'llloclern': 'modern',\n",
       " 'silllple': 'simple',\n",
       " 'elelllents': 'elements',\n",
       " 'lllall': 'mall',\n",
       " 'colllmands': 'commands',\n",
       " 'cclll': 'ccm',\n",
       " 'rollle': 'rome',\n",
       " 'farlll': 'farm',\n",
       " 'suprellle': 'supreme',\n",
       " 'verlllont': 'vermont',\n",
       " 'lllember': 'member',\n",
       " 'forlllation': 'formation',\n",
       " 'lllal': 'mal',\n",
       " 'hilll': 'him',\n",
       " 'lllind': 'mind',\n",
       " 'solllething': 'something',\n",
       " 'movelllent': 'movement',\n",
       " 'accolllpanied': 'accompanied',\n",
       " 'stateslllan': 'statesman',\n",
       " 'overwhelllling': 'overwhelming',\n",
       " 'becollles': 'becomes',\n",
       " 'septelilber': 'september',\n",
       " 'adlilires': 'admires',\n",
       " 'nlove': 'move',\n",
       " 'firnl': 'firm',\n",
       " 'inlpossible': 'impossible',\n",
       " 'tinle': 'time',\n",
       " 'comnlercial': 'commercial',\n",
       " 'sometinles': 'sometimes',\n",
       " 'wonlen': 'women',\n",
       " 'colunlbia': 'columbia',\n",
       " 'nlany': 'many',\n",
       " 'fronl': 'from',\n",
       " 'nlake': 'make',\n",
       " 'willianl': 'william',\n",
       " 'deenl': 'deem',\n",
       " 'thenl': 'them',\n",
       " 'comnlerce': 'commerce',\n",
       " 'nlost': 'most',\n",
       " 'inlplies': 'implies',\n",
       " 'conle': 'come',\n",
       " 'nlore': 'more',\n",
       " 'nlull': 'mull',\n",
       " 'conlmerce': 'commerce',\n",
       " 'nlust': 'must',\n",
       " 'seenled': 'seemed',\n",
       " 'sinlilar': 'similar',\n",
       " 'econonlics': 'economics',\n",
       " 'developnlent': 'development',\n",
       " 'menlbers': 'members',\n",
       " 'anlong': 'among',\n",
       " 'sanle': 'same',\n",
       " 'beconle': 'become',\n",
       " 'departnlents': 'departments',\n",
       " 'clepartnlents': 'departments',\n",
       " 'conlpetition': 'competition',\n",
       " 'conlparisons': 'comparisons',\n",
       " 'systenl': 'system',\n",
       " 'problenls': 'problems',\n",
       " 'lnental': 'mental',\n",
       " 'nolninally': 'nominally',\n",
       " 'seelns': 'seems',\n",
       " 'curricululn': 'curriculum',\n",
       " 'econolnic': 'economic',\n",
       " 'gerlnany': 'germany',\n",
       " 'materialisln': 'materialism',\n",
       " 'lnind': 'mind',\n",
       " 'tilnid': 'timid',\n",
       " 'seelned': 'seemed',\n",
       " 'gerlnan': 'german',\n",
       " 'argulnent': 'argument',\n",
       " 'hilnself': 'himself',\n",
       " 'departlnents': 'departments',\n",
       " 'silnple': 'simple',\n",
       " 'lnunicipality': 'municipality',\n",
       " 'schelne': 'scheme',\n",
       " 'systeln': 'system',\n",
       " 'solne': 'some',\n",
       " 'estilnate': 'estimate',\n",
       " 'lnarket': 'market',\n",
       " 'lnastery': 'mastery',\n",
       " 'solnething': 'something',\n",
       " 'elnploying': 'employing',\n",
       " 'lnaster': 'master',\n",
       " 'imperialisln': 'imperialism',\n",
       " 'lilnitations': 'limitations',\n",
       " 'inforlnation': 'information',\n",
       " 'salne': 'same',\n",
       " 'lnoral': 'moral',\n",
       " 'colnpetition': 'competition',\n",
       " 'relnain': 'remain',\n",
       " 'hulnanity': 'humanity',\n",
       " 'warln': 'warm',\n",
       " 'falniliar': 'familiar',\n",
       " 'lnost': 'most',\n",
       " 'lneal': 'meal',\n",
       " 'lnany': 'many',\n",
       " 'adlnit': 'admit',\n",
       " 'becalne': 'became',\n",
       " 'tilne': 'time',\n",
       " 'lnutual': 'mutual',\n",
       " 'lnarked': 'marked',\n",
       " 'lnore': 'more',\n",
       " 'colnplexity': 'complexity',\n",
       " 'tilnes': 'times',\n",
       " 'outcolne': 'outcome',\n",
       " 'sometilnes': 'sometimes',\n",
       " 'perlnanent': 'permanent',\n",
       " 'colnmercial': 'commercial',\n",
       " 'lnake': 'make',\n",
       " 'treatlnent': 'treatment',\n",
       " 'clailned': 'claimed',\n",
       " 'colnplex': 'complex',\n",
       " 'fralne': 'frame',\n",
       " 'alnerican': 'american',\n",
       " 'lnust': 'must',\n",
       " 'environlnent': 'environment',\n",
       " 'adlnitting': 'admitting',\n",
       " 'exalnination': 'examination',\n",
       " 'legitilnate': 'legitimate',\n",
       " 'alnos': 'amos',\n",
       " 'colnpetitive': 'competitive',\n",
       " 'silnply': 'simply',\n",
       " 'lnove': 'move',\n",
       " 'comlnunities': 'communities',\n",
       " 'lnean': 'mean',\n",
       " 'nationalisln': 'nationalism',\n",
       " 'nalnely': 'namely',\n",
       " 'perlnanently': 'permanently',\n",
       " 'nulnber': 'number',\n",
       " 'lnakes': 'makes',\n",
       " 'forln': 'form',\n",
       " 'theln': 'them',\n",
       " 'elnployment': 'employment',\n",
       " 'silnilar': 'similar',\n",
       " 'parlialnents': 'parliaments',\n",
       " 'probleln': 'problem',\n",
       " 'lnacle': 'made',\n",
       " 'lnade': 'made',\n",
       " 'adlnitted': 'admitted',\n",
       " 'ilnmediate': 'immediate',\n",
       " 'governlnent': 'government',\n",
       " 'econolnics': 'economics',\n",
       " 'lnatter': 'matter',\n",
       " 'telnptation': 'temptation',\n",
       " 'telnporary': 'temporary',\n",
       " 'lnayor': 'mayor',\n",
       " 'lnention': 'mention',\n",
       " 'incolnpatible': 'incompatible',\n",
       " 'froln': 'from',\n",
       " 'nulnerous': 'numerous',\n",
       " 'alnong': 'among',\n",
       " 'thelnselves': 'themselves',\n",
       " 'lnodern': 'modern',\n",
       " 'lnonarchs': 'monarchs',\n",
       " 'extrelne': 'extreme',\n",
       " 'colnmon': 'common',\n",
       " 'lilnited': 'limited',\n",
       " 'colnlnercial': 'commercial',\n",
       " 'forlned': 'formed',\n",
       " 'lnall': 'mall',\n",
       " 'elelnent': 'element',\n",
       " 'comlnerce': 'commerce',\n",
       " 'colnlnunity': 'community',\n",
       " 'comlnunity': 'community',\n",
       " 'departlnent': 'department',\n",
       " 'otiler': 'other',\n",
       " 'wilich': 'which',\n",
       " 'tilis': 'this',\n",
       " 'silow': 'show',\n",
       " 'silall': 'shall',\n",
       " 'busil': 'bush',\n",
       " 'tilousands': 'thousands',\n",
       " 'englisil': 'english',\n",
       " 'tilat': 'that',\n",
       " 'witil': 'with',\n",
       " 'faitil': 'faith',\n",
       " 'higiler': 'higher',\n",
       " 'tilese': 'these',\n",
       " 'sylnpatlly': 'sympathy',\n",
       " 'sympatlly': 'sympathy',\n",
       " 'sclleme': 'scheme',\n",
       " 'lleed': 'heed',\n",
       " 'strengtll': 'strength',\n",
       " 'wortll': 'worth',\n",
       " 'nevertlleless': 'nevertheless',\n",
       " 'teaclling': 'teaching',\n",
       " 'perllaps': 'perhaps',\n",
       " 'llistorical': 'historical',\n",
       " 'llarmonious': 'harmonious',\n",
       " 'furnislling': 'furnishing',\n",
       " 'soutll': 'south',\n",
       " 'goetlle': 'goethe',\n",
       " 'reaclled': 'reached',\n",
       " 'worsllip': 'worship',\n",
       " 'fatller': 'father',\n",
       " 'tllreats': 'threats',\n",
       " 'sougllt': 'sought',\n",
       " 'annillilation': 'annihilation',\n",
       " 'sopllomore': 'sophomore',\n",
       " 'rapllael': 'raphael',\n",
       " 'bellind': 'behind',\n",
       " 'everytlling': 'everything',\n",
       " 'llowe': 'howe',\n",
       " 'insigllt': 'insight',\n",
       " 'bellalf': 'behalf',\n",
       " 'higllly': 'highly',\n",
       " 'stretclles': 'stretches',\n",
       " 'breadtll': 'breadth',\n",
       " 'llold': 'hold',\n",
       " 'frencll': 'french',\n",
       " 'tllrough': 'through',\n",
       " 'tllemselves': 'themselves',\n",
       " 'whetller': 'whether',\n",
       " 'sllould': 'should',\n",
       " 'thougllts': 'thoughts',\n",
       " 'frotll': 'froth',\n",
       " 'tllou': 'thou',\n",
       " 'lless': 'hess',\n",
       " 'llighly': 'highly',\n",
       " 'sllell': 'shell',\n",
       " 'llire': 'hire',\n",
       " 'healtlly': 'healthy',\n",
       " 'sllowed': 'showed',\n",
       " 'llaving': 'having',\n",
       " 'autlloritative': 'authoritative',\n",
       " 'lligh': 'high',\n",
       " 'allead': 'ahead',\n",
       " 'matllematics': 'mathematics',\n",
       " 'wllatever': 'whatever',\n",
       " 'inllabit': 'inhabit',\n",
       " 'slaugllter': 'slaughter',\n",
       " 'llong': 'hong',\n",
       " 'selfisllness': 'selfishness',\n",
       " 'riglltly': 'rightly',\n",
       " 'tlleln': 'them',\n",
       " 'ligllt': 'light',\n",
       " 'acllievement': 'achievement',\n",
       " 'acllievenlent': 'achievement',\n",
       " 'solnetlling': 'something',\n",
       " 'wllile': 'while',\n",
       " 'growtll': 'growth',\n",
       " 'ratller': 'rather',\n",
       " 'twentietll': 'twentieth',\n",
       " 'sllops': 'shops',\n",
       " 'wllereby': 'whereby',\n",
       " 'llospital': 'hospital',\n",
       " 'eigllteenth': 'eighteenth',\n",
       " 'establislles': 'establishes',\n",
       " 'etllics': 'ethics',\n",
       " 'tecllnically': 'technically',\n",
       " 'llasten': 'hasten',\n",
       " 'waslling': 'washing',\n",
       " 'englisll': 'english',\n",
       " 'sllort': 'short',\n",
       " 'lleld': 'held',\n",
       " 'sllut': 'shut',\n",
       " 'weigll': 'weigh',\n",
       " 'searcll': 'search',\n",
       " 'wllolly': 'wholly',\n",
       " 'llope': 'hope',\n",
       " 'llowever': 'however',\n",
       " 'metllocls': 'methods',\n",
       " 'metllods': 'methods',\n",
       " 'otllerwise': 'otherwise',\n",
       " 'lleavy': 'heavy',\n",
       " 'neigllbors': 'neighbors',\n",
       " 'establislled': 'established',\n",
       " 'splleres': 'spheres',\n",
       " 'pllysical': 'physical',\n",
       " 'lland': 'hand',\n",
       " 'tlleories': 'theories',\n",
       " 'trutlls': 'truths',\n",
       " 'prollibits': 'prohibits',\n",
       " 'sllape': 'shape',\n",
       " 'gllastly': 'ghastly',\n",
       " 'etller': 'ether',\n",
       " 'psycllology': 'psychology',\n",
       " 'llealing': 'healing',\n",
       " 'cllance': 'chance',\n",
       " 'notlling': 'nothing',\n",
       " 'wislled': 'wished',\n",
       " 'tlleoretical': 'theoretical',\n",
       " 'cllarmed': 'charmed',\n",
       " 'abolisll': 'abolish',\n",
       " 'sllip': 'ship',\n",
       " 'diminisll': 'diminish',\n",
       " 'llorse': 'horse',\n",
       " 'llard': 'hard',\n",
       " 'llelp': 'help',\n",
       " 'cllildren': 'children',\n",
       " 'pllysiology': 'physiology',\n",
       " 'cllaracters': 'characters',\n",
       " 'botll': 'both',\n",
       " 'tootll': 'tooth',\n",
       " 'prollibit': 'prohibit',\n",
       " 'epocll': 'epoch',\n",
       " 'exllaustive': 'exhaustive',\n",
       " 'clloose': 'choose',\n",
       " 'altllough': 'although',\n",
       " 'thorougllly': 'thoroughly',\n",
       " 'tllread': 'thread',\n",
       " 'patcllwork': 'patchwork',\n",
       " 'llere': 'here',\n",
       " 'livelillood': 'livelihood',\n",
       " 'utall': 'utah',\n",
       " 'rigllts': 'rights',\n",
       " 'tllousand': 'thousand',\n",
       " 'cllart': 'chart',\n",
       " 'eartll': 'earth',\n",
       " 'trutll': 'truth',\n",
       " 'tlleft': 'theft',\n",
       " 'llell': 'hell',\n",
       " 'sllop': 'shop',\n",
       " 'forefatllers': 'forefathers',\n",
       " 'dozell': 'dozen',\n",
       " 'lellt': 'lent',\n",
       " 'writtell': 'written',\n",
       " 'beyolld': 'beyond',\n",
       " 'trustillg': 'trusting',\n",
       " 'owller': 'owner',\n",
       " 'placillg': 'placing',\n",
       " 'expositioll': 'exposition',\n",
       " 'conditioll': 'condition',\n",
       " 'fillance': 'finance',\n",
       " 'lalld': 'land',\n",
       " 'translatioll': 'translation',\n",
       " 'elljoying': 'enjoying',\n",
       " 'plall': 'plan',\n",
       " 'salld': 'sand',\n",
       " 'illcrease': 'increase',\n",
       " 'sellse': 'sense',\n",
       " 'medicille': 'medicine',\n",
       " 'lnedicille': 'medicine',\n",
       " 'ellabled': 'enabled',\n",
       " 'utterallce': 'utterance',\n",
       " 'formatioll': 'formation',\n",
       " 'connectioll': 'connection',\n",
       " 'presentillg': 'presenting',\n",
       " 'admissioll': 'admission',\n",
       " 'adlnissioll': 'admission',\n",
       " 'overtakell': 'overtaken',\n",
       " 'detrimellt': 'detriment',\n",
       " 'apprehelld': 'apprehend',\n",
       " 'apprellelld': 'apprehend',\n",
       " 'expressillg': 'expressing',\n",
       " 'teell': 'teen',\n",
       " 'attelltion': 'attention',\n",
       " 'hallds': 'hands',\n",
       " 'ellable': 'enable',\n",
       " 'ullcertain': 'uncertain',\n",
       " 'sooll': 'soon',\n",
       " 'seell': 'seen',\n",
       " 'illtellectual': 'intellectual',\n",
       " 'callillg': 'calling',\n",
       " 'sioll': 'sion',\n",
       " 'cilildrell': 'children',\n",
       " 'cllildrell': 'children',\n",
       " 'adoptioll': 'adoption',\n",
       " 'recellt': 'recent',\n",
       " 'weaklless': 'weakness',\n",
       " 'irritatioll': 'irritation',\n",
       " 'colltrary': 'contrary',\n",
       " 'groullds': 'grounds',\n",
       " 'differellt': 'different',\n",
       " 'clifferellt': 'different',\n",
       " 'collcrete': 'concrete',\n",
       " 'sarill': 'sarin',\n",
       " 'llilnself': 'himself',\n",
       " 'lastillg': 'lasting',\n",
       " 'sanitatioll': 'sanitation',\n",
       " 'milld': 'mind',\n",
       " 'lllilld': 'mind',\n",
       " 'judgmellt': 'judgment',\n",
       " 'reasoll': 'reason',\n",
       " 'lillers': 'liners',\n",
       " 'poillt': 'point',\n",
       " 'illsurance': 'insurance',\n",
       " 'dissellt': 'dissent',\n",
       " 'admillistration': 'administration',\n",
       " 'includillg': 'including',\n",
       " 'illterpreter': 'interpreter',\n",
       " 'ullfavorable': 'unfavorable',\n",
       " 'spelld': 'spend',\n",
       " 'trailling': 'training',\n",
       " 'prillciples': 'principles',\n",
       " 'illstitute': 'institute',\n",
       " 'directioll': 'direction',\n",
       " 'potellt': 'potent',\n",
       " 'experimentatioll': 'experimentation',\n",
       " 'collcede': 'concede',\n",
       " 'illstances': 'instances',\n",
       " 'llational': 'national',\n",
       " 'collsiderations': 'considerations',\n",
       " 'anciellt': 'ancient',\n",
       " 'expellses': 'expenses',\n",
       " 'emergellce': 'emergence',\n",
       " 'pursuillg': 'pursuing',\n",
       " 'ollward': 'onward',\n",
       " 'decisioll': 'decision',\n",
       " 'advallced': 'advanced',\n",
       " 'enjoyillg': 'enjoying',\n",
       " 'killgs': 'kings',\n",
       " 'incidellt': 'incident',\n",
       " 'religioll': 'religion',\n",
       " 'appearallce': 'appearance',\n",
       " 'collsistently': 'consistently',\n",
       " 'ulllimited': 'unlimited',\n",
       " 'parellt': 'parent',\n",
       " 'eminellt': 'eminent',\n",
       " 'collflicting': 'conflicting',\n",
       " 'citizells': 'citizens',\n",
       " 'destilled': 'destined',\n",
       " 'lliln': 'him',\n",
       " 'llilll': 'him',\n",
       " 'lllln': 'him',\n",
       " 'llearly': 'nearly',\n",
       " 'reasolls': 'reasons',\n",
       " 'kllowledge': 'knowledge',\n",
       " 'colltest': 'contest',\n",
       " 'patiellts': 'patients',\n",
       " 'ullited': 'united',\n",
       " 'illtellect': 'intellect',\n",
       " 'fractiollal': 'fractional',\n",
       " 'understallds': 'understands',\n",
       " 'bargaill': 'bargain',\n",
       " 'collgressional': 'congressional',\n",
       " 'prevellt': 'prevent',\n",
       " 'commissioll': 'commission',\n",
       " 'fullction': 'function',\n",
       " 'stalldard': 'standard',\n",
       " 'llation': 'nation',\n",
       " 'weapolls': 'weapons',\n",
       " 'mallifests': 'manifests',\n",
       " 'crimillal': 'criminal',\n",
       " 'crilllillal': 'criminal',\n",
       " 'movemellt': 'movement',\n",
       " 'jullior': 'junior',\n",
       " 'orgallization': 'organization',\n",
       " 'orgailization': 'organization',\n",
       " 'trallsaction': 'transaction',\n",
       " 'rallge': 'range',\n",
       " 'ellgage': 'engage',\n",
       " 'distillctions': 'distinctions',\n",
       " 'ralld': 'rand',\n",
       " 'deville': 'devine',\n",
       " 'wisconsill': 'wisconsin',\n",
       " 'elljoy': 'enjoy',\n",
       " 'thillk': 'think',\n",
       " 'plalles': 'planes',\n",
       " 'ullravel': 'unravel',\n",
       " 'growll': 'grown',\n",
       " 'corporatiolls': 'corporations',\n",
       " 'generatioll': 'generation',\n",
       " 'llotice': 'notice',\n",
       " 'suillg': 'suing',\n",
       " 'partisall': 'partisan',\n",
       " 'cincinllati': 'cincinnati',\n",
       " 'ascendillg': 'ascending',\n",
       " 'willdy': 'windy',\n",
       " 'appropriatioll': 'appropriation',\n",
       " 'examille': 'examine',\n",
       " 'workillg': 'working',\n",
       " 'conflictillg': 'conflicting',\n",
       " 'restrictillg': 'restricting',\n",
       " 'wastillg': 'wasting',\n",
       " 'consequelltly': 'consequently',\n",
       " 'illdividual': 'individual',\n",
       " 'illclividual': 'individual',\n",
       " 'witllessed': 'witnessed',\n",
       " 'managemellt': 'management',\n",
       " 'anlollg': 'among',\n",
       " 'alnollg': 'among',\n",
       " 'strellgthenillg': 'strengthening',\n",
       " 'strengthenillg': 'strengthening',\n",
       " 'hollored': 'honored',\n",
       " 'ignorallce': 'ignorance',\n",
       " 'discrimillation': 'discrimination',\n",
       " 'illtense': 'intense',\n",
       " 'bargaills': 'bargains',\n",
       " 'ulliversities': 'universities',\n",
       " 'propositioll': 'proposition',\n",
       " 'governillg': 'governing',\n",
       " 'puritall': 'puritan',\n",
       " 'filld': 'find',\n",
       " 'centenllial': 'centennial',\n",
       " 'hellry': 'henry',\n",
       " 'restillg': 'resting',\n",
       " 'nothillg': 'nothing',\n",
       " 'llotlling': 'nothing',\n",
       " 'notllillg': 'nothing',\n",
       " 'llothing': 'nothing',\n",
       " 'stalld': 'stand',\n",
       " 'telln': 'tenn',\n",
       " 'conclusiolls': 'conclusions',\n",
       " 'londoll': 'london',\n",
       " 'belollgs': 'belongs',\n",
       " 'alltiquity': 'antiquity',\n",
       " 'combilled': 'combined',\n",
       " 'mailltained': 'maintained',\n",
       " 'jacobsell': 'jacobsen',\n",
       " 'persolls': 'persons',\n",
       " 'collception': 'conception',\n",
       " 'harmolly': 'harmony',\n",
       " 'sentimellt': 'sentiment',\n",
       " 'sentilnellt': 'sentiment',\n",
       " 'talkillg': 'talking',\n",
       " 'developillg': 'developing',\n",
       " 'lookillg': 'looking',\n",
       " 'origill': 'origin',\n",
       " 'collsciously': 'consciously',\n",
       " 'commollwealth': 'commonwealth',\n",
       " 'dependellce': 'dependence',\n",
       " 'livillg': 'living',\n",
       " 'represellt': 'represent',\n",
       " 'solls': 'sons',\n",
       " 'llloderll': 'modern',\n",
       " 'moclerll': 'modern',\n",
       " 'evokillg': 'evoking',\n",
       " 'editioll': 'edition',\n",
       " 'borll': 'born',\n",
       " 'elltrusted': 'entrusted',\n",
       " 'finallce': 'finance',\n",
       " 'persollal': 'personal',\n",
       " 'departlllellts': 'departments',\n",
       " 'departmellts': 'departments',\n",
       " 'selectioll': 'selection',\n",
       " 'ordillary': 'ordinary',\n",
       " 'trall': 'tran',\n",
       " 'elllarge': 'enlarge',\n",
       " 'embracillg': 'embracing',\n",
       " 'illevitably': 'inevitably',\n",
       " 'lllally': 'many',\n",
       " 'nlally': 'many',\n",
       " 'lnally': 'many',\n",
       " 'collllected': 'connected',\n",
       " 'collnected': 'connected',\n",
       " 'extensioll': 'extension',\n",
       " 'grall': 'gran',\n",
       " 'revealillg': 'revealing',\n",
       " 'alolle': 'alone',\n",
       " 'llationality': 'nationality',\n",
       " 'boullded': 'bounded',\n",
       " 'foulld': 'found',\n",
       " 'lilles': 'lines',\n",
       " 'colltrolled': 'controlled',\n",
       " 'illdependent': 'independent',\n",
       " 'humall': 'human',\n",
       " 'ollce': 'once',\n",
       " 'ullto': 'unto',\n",
       " 'inlling': 'inning',\n",
       " 'contellt': 'content',\n",
       " 'nallce': 'nance',\n",
       " 'productioll': 'production',\n",
       " 'visiollary': 'visionary',\n",
       " 'seeillg': 'seeing',\n",
       " 'illcludes': 'includes',\n",
       " 'restrictiolls': 'restrictions',\n",
       " 'ellter': 'enter',\n",
       " 'passillg': 'passing',\n",
       " 'greell': 'green',\n",
       " 'wiscollsin': 'wisconsin',\n",
       " 'absorbillg': 'absorbing',\n",
       " 'professioll': 'profession',\n",
       " 'efficielltly': 'efficiently',\n",
       " 'mailltain': 'maintain',\n",
       " 'cellters': 'centers',\n",
       " 'colltinually': 'continually',\n",
       " 'borlle': 'borne',\n",
       " 'llominally': 'nominally',\n",
       " 'installces': 'instances',\n",
       " 'fullctions': 'functions',\n",
       " 'lloble': 'noble',\n",
       " 'valls': 'vans',\n",
       " 'billd': 'bind',\n",
       " 'pregllant': 'pregnant',\n",
       " 'ballkers': 'bankers',\n",
       " 'defillite': 'definite',\n",
       " 'parlialnellt': 'parliament',\n",
       " 'parliamellt': 'parliament',\n",
       " 'pennsylvallia': 'pennsylvania',\n",
       " 'preparatioll': 'preparation',\n",
       " 'makillg': 'making',\n",
       " 'frellch': 'french',\n",
       " 'llight': 'night',\n",
       " 'apparelltly': 'apparently',\n",
       " 'departmellt': 'department',\n",
       " 'rallks': 'ranks',\n",
       " 'collsists': 'consists',\n",
       " 'exceptiollal': 'exceptional',\n",
       " 'benllett': 'bennett',\n",
       " 'trelld': 'trend',\n",
       " 'turll': 'turn',\n",
       " 'treatmellt': 'treatment',\n",
       " 'ullderlyillg': 'underlying',\n",
       " 'underlyillg': 'underlying',\n",
       " 'observatioll': 'observation',\n",
       " 'educatiollal': 'educational',\n",
       " 'regulatioll': 'regulation',\n",
       " 'differelltiate': 'differentiate',\n",
       " 'utopiall': 'utopian',\n",
       " 'depelld': 'depend',\n",
       " 'esselltial': 'essential',\n",
       " 'recognitioll': 'recognition',\n",
       " 'recogllitioll': 'recognition',\n",
       " 'llatural': 'natural',\n",
       " 'paillless': 'painless',\n",
       " 'permissioll': 'permission',\n",
       " 'achievemellts': 'achievements',\n",
       " 'dallger': 'danger',\n",
       " 'positiolls': 'positions',\n",
       " 'intellsively': 'intensively',\n",
       " 'ullknown': 'unknown',\n",
       " 'expellse': 'expense',\n",
       " 'bitterlless': 'bitterness',\n",
       " 'paills': 'pains',\n",
       " 'fulldamental': 'fundamental',\n",
       " 'fulldalnental': 'fundamental',\n",
       " 'explaills': 'explains',\n",
       " 'agellts': 'agents',\n",
       " 'sessioll': 'session',\n",
       " 'fitlless': 'fitness',\n",
       " 'accompallied': 'accompanied',\n",
       " 'avoidillg': 'avoiding',\n",
       " 'convictioll': 'conviction',\n",
       " 'collvictioll': 'conviction',\n",
       " 'agaillst': 'against',\n",
       " 'retailled': 'retained',\n",
       " 'combillations': 'combinations',\n",
       " 'ruilled': 'ruined',\n",
       " 'selld': 'send',\n",
       " 'referellce': 'reference',\n",
       " 'lollg': 'long',\n",
       " 'ellds': 'ends',\n",
       " 'beillgs': 'beings',\n",
       " 'showll': 'shown',\n",
       " 'recogllition': 'recognition',\n",
       " 'orgallizing': 'organizing',\n",
       " 'outlilled': 'outlined',\n",
       " 'operatioll': 'operation',\n",
       " 'argumellt': 'argument',\n",
       " 'confrollted': 'confronted',\n",
       " 'ecollomists': 'economists',\n",
       " 'additioll': 'addition',\n",
       " 'collduct': 'conduct',\n",
       " 'behilld': 'behind',\n",
       " 'pellalty': 'penalty',\n",
       " 'illstitutioll': 'institution',\n",
       " 'illstitution': 'institution',\n",
       " 'combinatiolls': 'combinations',\n",
       " 'prevellted': 'prevented',\n",
       " 'tearillg': 'tearing',\n",
       " 'illequality': 'inequality',\n",
       " 'illsists': 'insists',\n",
       " 'leadillg': 'leading',\n",
       " 'absellce': 'absence',\n",
       " 'illstruction': 'instruction',\n",
       " 'liell': 'lien',\n",
       " 'instructioll': 'instruction',\n",
       " 'coverillg': 'covering',\n",
       " 'gralld': 'grand',\n",
       " 'meallwhile': 'meanwhile',\n",
       " 'settillg': 'setting',\n",
       " 'trallsportation': 'transportation',\n",
       " 'prevellts': 'prevents',\n",
       " 'illitiative': 'initiative',\n",
       " 'plallned': 'planned',\n",
       " 'savillgs': 'savings',\n",
       " 'subsistellce': 'subsistence',\n",
       " 'engilleer': 'engineer',\n",
       " 'departllleilts': 'departments',\n",
       " 'techllical': 'technical',\n",
       " 'stallces': 'stances',\n",
       " 'constitutiollal': 'constitutional',\n",
       " 'directiolls': 'directions',\n",
       " 'defilles': 'defines',\n",
       " 'preparillg': 'preparing',\n",
       " 'illdi': 'indi',\n",
       " 'alollg': 'along',\n",
       " 'intervelltion': 'intervention',\n",
       " 'politicialls': 'politicians',\n",
       " 'holdillg': 'holding',\n",
       " 'persoll': 'person',\n",
       " 'johll': 'john',\n",
       " 'provisioll': 'provision',\n",
       " 'alltwerp': 'antwerp',\n",
       " 'extellt': 'extent',\n",
       " 'parliamelltary': 'parliamentary',\n",
       " 'learlled': 'learned',\n",
       " 'origillate': 'originate',\n",
       " 'illcreasingly': 'increasingly',\n",
       " 'illcreasillgly': 'increasingly',\n",
       " 'elevatiolls': 'elevations',\n",
       " 'uncollsciously': 'unconsciously',\n",
       " 'lyillg': 'lying',\n",
       " 'followillg': 'following',\n",
       " 'illustratioll': 'illustration',\n",
       " 'federatioll': 'federation',\n",
       " 'stolle': 'stone',\n",
       " 'inclillation': 'inclination',\n",
       " 'elltering': 'entering',\n",
       " 'esselltially': 'essentially',\n",
       " 'currellt': 'current',\n",
       " 'contractillg': 'contracting',\n",
       " 'fillding': 'finding',\n",
       " 'accumulatillg': 'accumulating',\n",
       " 'enlightelled': 'enlightened',\n",
       " 'ulldertake': 'undertake',\n",
       " 'foulldation': 'foundation',\n",
       " 'collceived': 'conceived',\n",
       " 'ratiollal': 'rational',\n",
       " 'indepelldent': 'independent',\n",
       " 'demallds': 'demands',\n",
       " 'denlallds': 'demands',\n",
       " 'remaill': 'remain',\n",
       " 'givillg': 'giving',\n",
       " 'orgallic': 'organic',\n",
       " 'illterchange': 'interchange',\n",
       " 'ellgaged': 'engaged',\n",
       " 'reasollable': 'reasonable',\n",
       " 'proviclillg': 'providing',\n",
       " 'providillg': 'providing',\n",
       " 'evellts': 'events',\n",
       " 'questioll': 'question',\n",
       " 'illstructioll': 'instruction',\n",
       " 'colltrol': 'control',\n",
       " 'plalle': 'plane',\n",
       " 'strellgth': 'strength',\n",
       " 'illstitutional': 'institutional',\n",
       " 'elltered': 'entered',\n",
       " 'selectillg': 'selecting',\n",
       " 'fallell': 'fallen',\n",
       " 'illterlude': 'interlude',\n",
       " 'tolle': 'tone',\n",
       " 'appellded': 'appended',\n",
       " 'appellcled': 'appended',\n",
       " 'deprivillg': 'depriving',\n",
       " 'attailled': 'attained',\n",
       " 'poillts': 'points',\n",
       " 'illfected': 'infected',\n",
       " 'nineteellth': 'nineteenth',\n",
       " 'balallce': 'balance',\n",
       " 'illdebtedness': 'indebtedness',\n",
       " 'depellds': 'depends',\n",
       " 'regulatillg': 'regulating',\n",
       " 'sillce': 'since',\n",
       " 'increasillg': 'increasing',\n",
       " 'illcreasillg': 'increasing',\n",
       " 'pretellds': 'pretends',\n",
       " 'residellt': 'resident',\n",
       " 'restrictioll': 'restriction',\n",
       " 'dyllamic': 'dynamic',\n",
       " 'warpillg': 'warping',\n",
       " 'attelldance': 'attendance',\n",
       " 'strellgthened': 'strengthened',\n",
       " 'limitatiorls': 'limitations',\n",
       " 'selectiorl': 'selection',\n",
       " 'fullctioll': 'function',\n",
       " 'illforlnation': 'information',\n",
       " 'eclucatioll': 'education',\n",
       " 'pellnsylvallia': 'pennsylvania',\n",
       " 'penllsylvallia': 'pennsylvania',\n",
       " 'takirlg': 'taking',\n",
       " 'relatiorl': 'relation',\n",
       " 'derlying': 'denying',\n",
       " 'rlatural': 'natural',\n",
       " 'ullcler': 'under',\n",
       " 'offerirlg': 'offering',\n",
       " 'collditiolls': 'conditions',\n",
       " 'conclitiolls': 'conditions',\n",
       " 'lleecls': 'needs',\n",
       " 'collsequelltly': 'consequently',\n",
       " 'traiilillg': 'training',\n",
       " 'traillillg': 'training',\n",
       " 'exterlsive': 'extensive',\n",
       " 'llalld': 'hand',\n",
       " 'cloillg': 'doing',\n",
       " 'alnericall': 'american',\n",
       " 'llulnber': 'number',\n",
       " 'llunlber': 'number',\n",
       " 'orgallizatioll': 'organization',\n",
       " 'llatiollal': 'national',\n",
       " 'illlportallt': 'important',\n",
       " 'lrlore': 'more',\n",
       " 'everl': 'even',\n",
       " 'llollg': 'hong',\n",
       " 'uiliversity': 'university',\n",
       " 'coiltract': 'contract',\n",
       " 'ageilt': 'agent',\n",
       " 'declaratioil': 'declaration',\n",
       " 'colrlpetitive': 'competitive',\n",
       " 'iilterests': 'interests',\n",
       " 'theil': 'then',\n",
       " 'tlleil': 'then',\n",
       " 'professioilal': 'professional',\n",
       " 'eighteeilth': 'eighteenth',\n",
       " 'tllell': 'then',\n",
       " 'tnell': 'then',\n",
       " 'thatl': 'than',\n",
       " 'applyitlg': 'applying',\n",
       " 'cotltract': 'contract',\n",
       " 'treatmetlt': 'treatment',\n",
       " 'listetl': 'listen',\n",
       " 'cotls': 'cons',\n",
       " 'whetl': 'when',\n",
       " 'utlfortunately': 'unfortunately',\n",
       " 'mitlers': 'miners',\n",
       " 'letld': 'lend',\n",
       " 'betweetl': 'between',\n",
       " 'benevoletlce': 'benevolence',\n",
       " ...}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.53"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipf_frequency('hong','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E2/results.json\",'a') as f:\n",
    "    json.dump({**results,**corrections},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full = json.load(open(\"E2/results.json\"))\n",
    "\n",
    "def match_case(original, replacement):\n",
    "    \"\"\"\n",
    "    Adjust the replacement text to match the case of the original text.\n",
    "    \"\"\"\n",
    "    if original.isupper():\n",
    "        return replacement.upper()\n",
    "    elif original.istitle():\n",
    "        return replacement.title()\n",
    "    elif original.islower():\n",
    "        return replacement.lower()\n",
    "    else:\n",
    "        return replacement\n",
    "\n",
    "def replace_with_case_sensitivity(text, replacements):\n",
    "    \"\"\"\n",
    "    Replace occurrences of lowercase keys in the text with their respective values, maintaining case.\n",
    "    \"\"\"\n",
    "    # Build regex pattern with all lowercase keys\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(k) for k in replacements.keys()) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    def replacement_function(match):\n",
    "        matched_text = match.group(0)  # Get the actual matched text from input\n",
    "        lower_matched = matched_text.lower()  # Convert to lowercase to match dictionary keys\n",
    "        replacement_value = replacements.get(lower_matched, matched_text)  # Get replacement or keep original\n",
    "        return match_case(matched_text, replacement_value)\n",
    "    return pattern.sub(replacement_function, text)\n",
    "\n",
    "folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/clean_para_split/E2'\n",
    "pre_fix = '/Users/BeckyMarcusMacbook/Thesis/manual_work/E2/problematic_unfixed'\n",
    "if not os.path.exists(pre_fix):\n",
    "    os.makedirs(pre_fix)\n",
    "new_folder = '/Users/BeckyMarcusMacbook/Thesis/manual_work/E2/problematic_fixed'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)\n",
    "all_words = []\n",
    "for file in sorted(os.listdir(folder)):\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    disc,year,num,pagetxt = file.split(\"-\")\n",
    "    year = int(year)\n",
    "    if year<1904 and year>=1900:\n",
    "        path = os.path.join(folder, file)\n",
    "        text=  open(path).read()\n",
    "        os.symlink(path,os.path.join(pre_fix,file))\n",
    "        new_text = replace_with_case_sensitivity(text,results)\n",
    "        if text!=new_text:\n",
    "            with open(os.path.join(new_folder,file),'w') as f:\n",
    "                f.write(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditions on economic theory has been, let us hope,\n",
      "abundantly demonstrated; but the reciprocal influence\n",
      "of economic theory on actual conditions is in danger of\n",
      "being overlooked. For as the science itself becomes\n",
      "more and more complete, it alone will be in a better\n",
      "position to apprehend and to explain the real content of\n",
      "existing conditions and the true method of making the\n",
      "actual conform to the ideal. Natural science necessarily\n",
      "movesawithin the framework of natural forces, but he\n",
      "who runs may read the lesson of the control of these\n",
      "same natural forces through modern scientific achievements.\n",
      "So in the same way economic science, which\n",
      "is to-day only in its infancy, and which of all disciplines\n",
      "is the most difficult and the most complicated, is indeed\n",
      "interlaced with and founded upon the actual conditions\n",
      "of the time; but, like natural science, the econotnics of\n",
      "the future will enable us to comprehend the living\n",
      "forces at work, and by comprehending will put us in a\n",
      "position to control them and to ulould them to ever\n",
      "higher uses. Economics is therefore both the creature\n",
      "and the creator. It is the creature of the past; it is\n",
      "the creator of the future. Correctly conceived, adequately\n",
      "outlined, fearlessly developed, it is the prop of\n",
      "ethical upbuilding, it is the basis of social progress.\n"
     ]
    }
   ],
   "source": [
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hellod ancly meowd'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"hellocl ancly meowcl\"\n",
    "re.sub(r\"\\b(\\w+)(cl)\\b\",lambda match:match.group(1)+\"d\",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betweell': 'between',\n",
       " 'ecollomics': 'economics',\n",
       " 'influellce': 'influence',\n",
       " 'opillion': 'opinion',\n",
       " 'mealls': 'means',\n",
       " 'presellt': 'present',\n",
       " 'ill': 'in',\n",
       " 'amollg': 'among',\n",
       " 'tlle': 'the',\n",
       " 'comlllercial': 'commercial',\n",
       " 'conditiolls': 'conditions',\n",
       " 'oll': 'on',\n",
       " 'witll': 'with',\n",
       " 'olles': 'ones',\n",
       " 'econolllics': 'economics',\n",
       " 'wllich': 'which',\n",
       " 'lle': 'he',\n",
       " 'olle': 'one',\n",
       " 'llis': 'his',\n",
       " 'standpoillt': 'standpoint',\n",
       " 'lleither': 'neither',\n",
       " 'llor': 'nor',\n",
       " 'halld': 'hand',\n",
       " 'alld': 'and',\n",
       " 'stalldards': 'standards',\n",
       " 'tllat': 'that',\n",
       " 'interactioll': 'interaction',\n",
       " 'whicll': 'which',\n",
       " 'whell': 'when',\n",
       " 'natioll': 'nation',\n",
       " 'illfluence': 'influence',\n",
       " 'sallle': 'same',\n",
       " 'higllest': 'highest',\n",
       " 'scielltific': 'scientific',\n",
       " 'wllo': 'who',\n",
       " 'tllose': 'those',\n",
       " 'llim': 'him',\n",
       " 'higll': 'high',\n",
       " 'tllree': 'three',\n",
       " 'llo': 'no',\n",
       " 'lllake': 'wake',\n",
       " 'beillg': 'being',\n",
       " 'owll': 'own',\n",
       " 'llave': 'have',\n",
       " 'mell': 'men',\n",
       " 'educatioll': 'education',\n",
       " 'llot': 'not',\n",
       " 'ollly': 'only',\n",
       " 'lllatters': 'matters',\n",
       " 'recognizillg': 'recognizing',\n",
       " 'olltside': 'outside',\n",
       " 'oftell': 'often',\n",
       " 'sucll': 'such',\n",
       " 'llloral': 'moral',\n",
       " 'tllelll': 'them',\n",
       " 'lille': 'line',\n",
       " 'ecollomist': 'economist',\n",
       " 'illterest': 'interest',\n",
       " 'colllmunity': 'community',\n",
       " 'eitller': 'either',\n",
       " 'claillls': 'claims',\n",
       " 'gelleral': 'general',\n",
       " 'illterests': 'interests',\n",
       " 'gettillg': 'getting',\n",
       " 'represelltatives': 'representatives',\n",
       " 'eacll': 'each',\n",
       " 'allother': 'another',\n",
       " 'opinioll': 'opinion',\n",
       " 'llecessary': 'necessary',\n",
       " 'thall': 'than',\n",
       " 'tllan': 'than',\n",
       " 'differellces': 'differences',\n",
       " 'ougllt': 'ought',\n",
       " 'allotller': 'another',\n",
       " 'collditions': 'conditions',\n",
       " 'moderll': 'modern',\n",
       " 'sollle': 'some',\n",
       " 'importallt': 'important',\n",
       " 'represelltative': 'representative',\n",
       " 'competitioll': 'competition',\n",
       " 'llow': 'now',\n",
       " 'advallce': 'advance',\n",
       " 'governmellt': 'government',\n",
       " 'llas': 'has',\n",
       " 'expressioll': 'expression',\n",
       " 'commullity': 'community',\n",
       " 'frolll': 'from',\n",
       " 'collflict': 'conflict',\n",
       " 'withill': 'within',\n",
       " 'tllinks': 'thinks',\n",
       " 'lllore': 'more',\n",
       " 'tllis': 'this',\n",
       " 'tllere': 'there',\n",
       " 'wllole': 'whole',\n",
       " 'sllall': 'small',\n",
       " 'tlleir': 'their',\n",
       " 'beell': 'been',\n",
       " 'celltury': 'century',\n",
       " 'togetller': 'together',\n",
       " 'otllers': 'others',\n",
       " 'wallts': 'wants',\n",
       " 'ullited': 'united',\n",
       " 'selltimellt': 'sentiment',\n",
       " 'actioll': 'action',\n",
       " 'tlley': 'they',\n",
       " 'lllust': 'must',\n",
       " 'evell': 'even',\n",
       " 'spllere': 'sphere',\n",
       " 'somethillg': 'something',\n",
       " 'thelll': 'them',\n",
       " 'centllry': 'century',\n",
       " 'pllblic': 'public',\n",
       " 'sllould': 'should',\n",
       " 'prillciple': 'principle',\n",
       " 'molley': 'money',\n",
       " 'witllin': 'within',\n",
       " 'legislatioll': 'legislation',\n",
       " 'cllange': 'change',\n",
       " 'golle': 'gone',\n",
       " 'wllose': 'whose',\n",
       " 'wllell': 'when',\n",
       " 'otller': 'other',\n",
       " 'busilless': 'business',\n",
       " 'witllout': 'without',\n",
       " 'upoll': 'upon',\n",
       " 'tlling': 'thing',\n",
       " 'tllese': 'these',\n",
       " 'autllority': 'authority',\n",
       " 'lllay': 'may',\n",
       " 'illdustrial': 'industrial',\n",
       " 'natiolls': 'nations',\n",
       " 'wllat': 'what',\n",
       " 'anotller': 'another',\n",
       " 'strollg': 'strong',\n",
       " 'conceptioll': 'conception',\n",
       " 'lligher': 'higher',\n",
       " 'killd': 'kind',\n",
       " 'llistory': 'history',\n",
       " 'natiollal': 'national',\n",
       " 'wllere': 'where',\n",
       " 'sciellce': 'science',\n",
       " 'sometlling': 'something',\n",
       " 'econolllic': 'economic',\n",
       " 'tllougllt': 'thought',\n",
       " 'foundatioll': 'foundation',\n",
       " 'colllpetition': 'competition',\n",
       " 'nilleteell': 'nineteen',\n",
       " 'cllristian': 'christian',\n",
       " 'existellce': 'existence',\n",
       " 'agaill': 'again',\n",
       " 'groulld': 'ground',\n",
       " 'wlly': 'why',\n",
       " 'colllpetitioll': 'competition',\n",
       " 'qllestion': 'question',\n",
       " 'disciplille': 'discipline',\n",
       " 'solllewllat': 'somewhat',\n",
       " 'indiviclllal': 'individual',\n",
       " 'coulltry': 'country',\n",
       " 'wlletller': 'whether',\n",
       " 'clloice': 'choice',\n",
       " 'strllggle': 'struggle',\n",
       " 'tllillgs': 'things',\n",
       " 'wealtll': 'wealth',\n",
       " 'lllany': 'many',\n",
       " 'alllong': 'along',\n",
       " 'ecollomic': 'economic',\n",
       " 'llpon': 'upon',\n",
       " 'figllt': 'fight',\n",
       " 'colllparatively': 'comparitively',\n",
       " 'cllaracter': 'character',\n",
       " 'etllical': 'ethical',\n",
       " 'paill': 'pain',\n",
       " 'attelltioll': 'attention',\n",
       " 'reslllt': 'result',\n",
       " 'evollltion': 'evolution',\n",
       " 'colnpetitioll': 'competition',\n",
       " 'evoltltioll': 'evolution',\n",
       " 'lllost': 'most',\n",
       " 'higller': 'higher',\n",
       " 'associatioll': 'association',\n",
       " 'illto': 'into',\n",
       " 'wllen': 'when',\n",
       " 'ulltil': 'until',\n",
       " 'cotllpetition': 'competition',\n",
       " 'evolutioll': 'evolution',\n",
       " 'growillt': 'growth',\n",
       " 'mally': 'many',\n",
       " 'discussioll': 'discussion',\n",
       " 'filld': 'find',\n",
       " 'americall': 'american',\n",
       " 'tllelllselves': 'themselves',\n",
       " 'colllpetitive': 'competitive',\n",
       " 'developlllent': 'development',\n",
       " 'cotnpetitioll': 'competition',\n",
       " 'civilizatioll': 'civilization',\n",
       " 'wolllcl': 'would',\n",
       " 'llew': 'new',\n",
       " 'lllen': 'men',\n",
       " 'efficiellt': 'efficient',\n",
       " 'lllell': 'well',\n",
       " 'cllief': 'chief',\n",
       " 'ecollolnic': 'economic',\n",
       " 'sllch': 'such',\n",
       " 'llloclerll': 'modern',\n",
       " 'petitioll': 'petition',\n",
       " 'frequelltly': 'frequently',\n",
       " 'qllalities': 'qualitites',\n",
       " 'tllus': 'thus',\n",
       " 'tllink': 'think',\n",
       " 'colldition': 'condition',\n",
       " 'cllarity': 'charity',\n",
       " 'becallse': 'because',\n",
       " 'opportllllities': 'opportunities',\n",
       " 'extetlsioll': 'extension',\n",
       " 'certaill': 'certain',\n",
       " 'opillioll': 'opinion',\n",
       " 'secllre': 'secure',\n",
       " 'celltllry': 'century',\n",
       " 'illstitutions': 'institutions',\n",
       " 'illust': 'must',\n",
       " 'eqllality': 'equality',\n",
       " 'twelltietll': 'twentieth',\n",
       " 'alltagollistic': 'antagonistic',\n",
       " 'llniversity': 'university',\n",
       " 'bllsiness': 'business',\n",
       " 'lleed': 'need',\n",
       " 'institutioll': 'institution',\n",
       " 'institutiolls': 'institutions',\n",
       " 'pellnsylvania': 'pennsylvania',\n",
       " 'establishmellt': 'astablishment',\n",
       " 'comlllerce': 'commerce',\n",
       " 'scllool': 'school',\n",
       " 'professiollal': 'professional',\n",
       " 'sllowll': 'shown',\n",
       " 'existellee': 'existence',\n",
       " 'lllovement': 'movement',\n",
       " 'rallk': 'rank',\n",
       " 'ulliversity': 'university',\n",
       " 'appoillted': 'appointed',\n",
       " 'forlll': 'form',\n",
       " 'ullder': 'under',\n",
       " 'eolleges': 'colleges',\n",
       " 'eollege': 'college',\n",
       " 'positioll': 'position',\n",
       " 'llear': 'near',\n",
       " 'llleans': 'means',\n",
       " 'througll': 'through',\n",
       " 'systelll': 'system',\n",
       " 'illstitutiolls': 'institutions',\n",
       " 'scllools': 'schools',\n",
       " 'nulllber': 'number',\n",
       " 'callillgs': 'callings',\n",
       " 'existillg': 'existing',\n",
       " 'takillg': 'taking',\n",
       " 'tllem': 'them',\n",
       " 'yollng': 'young',\n",
       " 'youllg': 'young',\n",
       " 'tllen': 'then',\n",
       " 'collrse': 'course',\n",
       " 'wollld': 'would',\n",
       " 'fashiollecl': 'fashioned',\n",
       " 'yollllg': 'young',\n",
       " 'migllt': 'might',\n",
       " 'trainillg': 'training',\n",
       " 'eallings': 'earnings',\n",
       " 'departlllents': 'departments',\n",
       " 'movelllellt': 'movement',\n",
       " 'variolls': 'various',\n",
       " 'tllrougll': 'through',\n",
       " 'curricululll': 'curriculum',\n",
       " 'collsidered': 'considered',\n",
       " 'elelllent': 'element',\n",
       " 'opportullity': 'opportunity',\n",
       " 'trllth': 'truth',\n",
       " 'takell': 'taken',\n",
       " 'elemellt': 'element',\n",
       " 'tlleoretieally': 'theoretically',\n",
       " 'tillles': 'times',\n",
       " 'cllrricula': 'curricula',\n",
       " 'tlleory': 'theory',\n",
       " 'melltal': 'mental',\n",
       " 'organizatioll': 'organization',\n",
       " 'bankillg': 'banking',\n",
       " 'illdustry': 'industry',\n",
       " 'colltracts': 'contracts',\n",
       " 'corporatioll': 'corporation',\n",
       " 'curriculllm': 'curriculum',\n",
       " 'bellefit': 'benefit',\n",
       " 'comlnullity': 'community',\n",
       " 'lleeds': 'needs',\n",
       " 'califorllia': 'california',\n",
       " 'colllmbia': 'columbia',\n",
       " 'endowmellt': 'endowment',\n",
       " 'bolles': 'bones',\n",
       " 'studellts': 'students',\n",
       " 'alllollg': 'among',\n",
       " 'pllilosophy': 'philosophy',\n",
       " 'indllstrial': 'industrial',\n",
       " 'wllicil': 'which',\n",
       " 'frellcll': 'french',\n",
       " 'eigllteeiltll': 'eighteenth',\n",
       " 'collceivecl': 'conceived',\n",
       " 'restraillts': 'restraints',\n",
       " 'follllcl': 'found',\n",
       " 'understalld': 'understand',\n",
       " 'llegative': 'negative',\n",
       " 'thougllt': 'thought',\n",
       " 'treatlllent': 'treatment',\n",
       " 'pllilosopllical': 'philosphical',\n",
       " 'cleveloplllellt': 'development',\n",
       " 'tllought': 'thought',\n",
       " 'envirollment': 'environment',\n",
       " 'colltract': 'contract',\n",
       " 'relatiolls': 'relations',\n",
       " 'ellactment': 'enactment',\n",
       " 'qllite': 'quite',\n",
       " 'regulatiolls': 'regulations',\n",
       " 'rigllt': 'right',\n",
       " 'problelll': 'problem',\n",
       " 'llature': 'nature',\n",
       " 'lleeded': 'needed',\n",
       " 'llours': 'hours',\n",
       " 'llour': 'hour',\n",
       " 'elemellts': 'elements',\n",
       " 'hollrs': 'hours',\n",
       " 'lllade': 'made',\n",
       " 'canllot': 'cannot',\n",
       " 'pressllre': 'pressure',\n",
       " 'dollbt': 'doubt',\n",
       " 'englalld': 'england',\n",
       " 'illclustrial': 'industrial',\n",
       " 'thell': 'then',\n",
       " 'fresll': 'fresh',\n",
       " 'eollditions': 'conditions'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
